From db4fc4d575ff44ab271de0be5d4e9b11b6d1c916 Mon Sep 17 00:00:00 2001
From: Oleksandr Mazur <oleksandr.mazur@plvision.eu>
Date: Tue, 11 Jan 2022 18:09:55 +0200
Subject: [PATCH 26/40] net: etherner: marvell: prestera: Update intree drivers
 to be based on CPSS repo's master branch

Signed-off-by: Oleksandr Mazur <oleksandr.mazur@plvision.eu>
Change-Id: I6ffc676539b2420537551496d02964d555d15f6d
---
 .../net/ethernet/marvell/prestera/Makefile    |   19 +-
 .../net/ethernet/marvell/prestera/prestera.h  |  644 +++-
 .../ethernet/marvell/prestera/prestera_acl.c  | 1184 +++++-
 .../ethernet/marvell/prestera/prestera_acl.h  |  336 +-
 .../marvell/prestera/prestera_counter.c       |  475 +++
 .../marvell/prestera/prestera_counter.h       |   28 +
 .../ethernet/marvell/prestera/prestera_ct.c   |  776 ++++
 .../ethernet/marvell/prestera/prestera_ct.h   |   39 +
 .../ethernet/marvell/prestera/prestera_dcb.c  |  216 ++
 .../ethernet/marvell/prestera/prestera_dcb.h  |   14 +
 .../marvell/prestera/prestera_debugfs.c       |  287 ++
 .../marvell/prestera/prestera_debugfs.h       |   12 +
 .../marvell/prestera/prestera_devlink.c       |  359 +-
 .../marvell/prestera/prestera_devlink.h       |    4 +-
 .../marvell/prestera/prestera_drv_ver.h       |   21 +
 .../ethernet/marvell/prestera/prestera_dsa.c  |  339 +-
 .../ethernet/marvell/prestera/prestera_dsa.h  |   63 +-
 .../marvell/prestera/prestera_ethtool.c       |  789 ++--
 .../marvell/prestera/prestera_ethtool.h       |    7 +-
 .../ethernet/marvell/prestera/prestera_flow.c |  180 +-
 .../marvell/prestera/prestera_flower.c        |  584 ++-
 .../ethernet/marvell/prestera/prestera_fw.c   |  445 +++
 .../ethernet/marvell/prestera/prestera_fw.h   |  127 +
 .../marvell/prestera/prestera_fw_log.c        |  429 +++
 .../marvell/prestera/prestera_fw_log.h        |   12 +
 .../ethernet/marvell/prestera/prestera_hw.c   | 3174 +++++++++++------
 .../ethernet/marvell/prestera/prestera_hw.h   |  409 ++-
 .../ethernet/marvell/prestera/prestera_log.c  |  201 ++
 .../ethernet/marvell/prestera/prestera_log.h  |   55 +
 .../ethernet/marvell/prestera/prestera_main.c | 2539 ++++++++++---
 .../marvell/prestera/prestera_matchall.c      |  146 +
 .../ethernet/marvell/prestera/prestera_pci.c  |  968 ++---
 .../marvell/prestera/prestera_router.c        | 2809 +++++++++++++++
 .../marvell/prestera/prestera_router_hw.c     |  832 +++++
 .../marvell/prestera/prestera_router_hw.h     |  120 +
 .../ethernet/marvell/prestera/prestera_rxtx.c |  862 +++--
 .../ethernet/marvell/prestera/prestera_rxtx.h |   15 +-
 .../ethernet/marvell/prestera/prestera_shm.c  |  617 ++++
 .../ethernet/marvell/prestera/prestera_shm.h  |   15 +
 .../marvell/prestera/prestera_storm_control.c |  189 +
 .../marvell/prestera/prestera_storm_control.h |   12 +
 .../marvell/prestera/prestera_switchdev.c     | 2099 +++++++----
 .../marvell/prestera/prestera_switchdev.h     |   15 +-
 43 files changed, 18087 insertions(+), 4379 deletions(-)
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_counter.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_counter.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_ct.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_ct.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_dcb.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_dcb.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_fw.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_fw.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_log.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_log.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_matchall.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_router.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_router_hw.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_router_hw.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_shm.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_shm.h
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_storm_control.c
 create mode 100644 drivers/net/ethernet/marvell/prestera/prestera_storm_control.h

diff --git a/drivers/net/ethernet/marvell/prestera/Makefile b/drivers/net/ethernet/marvell/prestera/Makefile
index 0609df8b913d..1928d2056131 100644
--- a/drivers/net/ethernet/marvell/prestera/Makefile
+++ b/drivers/net/ethernet/marvell/prestera/Makefile
@@ -1,8 +1,15 @@
 # SPDX-License-Identifier: GPL-2.0
-obj-$(CONFIG_PRESTERA)	+= prestera.o
-prestera-objs		:= prestera_main.o prestera_hw.o prestera_dsa.o \
-			   prestera_rxtx.o prestera_devlink.o prestera_ethtool.o \
-			   prestera_switchdev.o prestera_acl.o prestera_flow.o \
-			   prestera_flower.o prestera_span.o
 
-obj-$(CONFIG_PRESTERA_PCI)	+= prestera_pci.o
+obj-$(CONFIG_PRESTERA) += prestera.o
+prestera-objs := prestera_main.o \
+	prestera_hw.o prestera_switchdev.o prestera_devlink.o prestera_fw_log.o \
+	prestera_rxtx.o prestera_dsa.o prestera_router.o \
+	prestera_acl.o prestera_flow.o prestera_flower.o prestera_matchall.o prestera_debugfs.o \
+	prestera_ct.o prestera_ethtool.o prestera_counter.o \
+	prestera_fw.o prestera_router_hw.o prestera_dcb.o
+
+prestera-$(CONFIG_MRVL_PRESTERA_DEBUG) += prestera_log.o
+ccflags-$(CONFIG_MRVL_PRESTERA_DEBUG) += -DCONFIG_MRVL_PRESTERA_DEBUG
+
+obj-$(CONFIG_PRESTERA_PCI) += prestera_pci.o
+obj-$(CONFIG_PRESTERA_SHM) += prestera_shm.o
diff --git a/drivers/net/ethernet/marvell/prestera/prestera.h b/drivers/net/ethernet/marvell/prestera/prestera.h
index f18fe664b373..8d74db5e3d34 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera.h
@@ -1,18 +1,35 @@
 /* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved. */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _PRESTERA_H_
 #define _PRESTERA_H_
 
-#include <linux/notifier.h>
 #include <linux/skbuff.h>
+#include <linux/notifier.h>
+#include <uapi/linux/if_ether.h>
+#include <linux/if_macvlan.h>
 #include <linux/workqueue.h>
+#include <linux/phylink.h>
+#include <net/pkt_cls.h>
 #include <net/devlink.h>
-#include <uapi/linux/if_ether.h>
 
-#define PRESTERA_DRV_NAME	"prestera"
+#define PRESTERA_DRV_NAME       "prestera"
+
+#define PRESTERA_MSG_MAX_SIZE 1500
+#define PRESTERA_MSG_CHUNK_SIZE 1024
 
-#define PRESTERA_DEFAULT_VID    1
+#define PRESTERA_DEFAULT_VID 1
+
+#define PRESTERA_MIN_AGEING_TIME 32000
+#define PRESTERA_MAX_AGEING_TIME 1000000000
+#define PRESTERA_DEFAULT_AGEING_TIME 300000
+
+#define PRESTERA_NHGR_SIZE_MAX 4
+#define PRESTERA_AP_PORT_MAX   (10)
+
+#define PRESTERA_PORT_SRCID_ZERO 0 /* source_id */
+
+#define PRESTERA_SPAN_INVALID_ID -1
 
 struct prestera_fw_rev {
 	u16 maj;
@@ -20,6 +37,63 @@ struct prestera_fw_rev {
 	u16 sub;
 };
 
+struct prestera_bridge_port;
+struct prestera_kern_neigh_cache;
+struct prestera_acl;
+struct prestera_acl_rule;
+struct prestera_acl_ruleset;
+struct prestera_acl_nat_port;
+struct prestera_span;
+struct prestera_span_entry;
+struct prestera_storm_control;
+
+struct prestera_flow_block_binding {
+	struct list_head list;
+	struct prestera_port *port;
+	int span_id;
+};
+
+struct prestera_flow_block {
+	struct list_head binding_list;
+	struct list_head template_list;
+	struct prestera_switch *sw;
+	unsigned int rule_count;
+	unsigned int disable_count;
+	struct net *net;
+	struct prestera_acl_ruleset *ruleset_zero;
+	struct flow_block_cb *block_cb;
+	u32 mall_prio;
+	u32 flower_min_prio;
+};
+
+struct prestera_port_vlan {
+	struct list_head list;
+	struct prestera_port *port;
+	u16 vid;
+	struct prestera_bridge_port *bridge_port;
+	struct list_head bridge_vlan_node;
+};
+
+struct prestera_flood_domain {
+	struct prestera_switch *sw;
+	struct list_head flood_domain_port_list;
+	u32 idx;
+};
+
+struct prestera_mdb_entry {
+	unsigned char addr[ETH_ALEN];
+	struct prestera_switch *sw;
+	struct prestera_flood_domain *flood_domain;
+	u16 vid;
+};
+
+struct prestera_flood_domain_port {
+	struct prestera_flood_domain *flood_domain;
+	struct net_device *dev;
+	struct list_head flood_domain_port_node;
+	u16 vid;
+};
+
 struct prestera_port_stats {
 	u64 good_octets_received;
 	u64 bad_octets_received;
@@ -60,22 +134,55 @@ struct prestera_port_caps {
 	u8 transceiver;
 };
 
-struct prestera_lag {
-	struct net_device *dev;
-	struct list_head members;
-	u16 member_count;
-	u16 lag_id;
+struct prestera_port_mac_state {
+	bool valid;
+	bool oper;
+	u32 mode;
+	u32 speed;
+	u8 duplex;
+	u8 fc;
+	u8 fec;
+};
+
+struct prestera_port_phy_state {
+	u64 lmode_bmap;
+	struct {
+		bool pause;
+		bool asym_pause;
+	} remote_fc;
+	u8 mdix;
+};
+
+struct prestera_rxtx_stats {
+	u64 rx_packets;
+	u64 rx_bytes;
+	u64 tx_packets;
+	u64 tx_bytes;
+	u32 tx_dropped;
+	struct u64_stats_sync syncp;
 };
 
-struct prestera_flow_block;
+/* used for hw call */
+struct prestera_port_mac_config {
+	bool admin;
+	u32 mode;
+	u8 inband;
+	u32 speed;
+	u8 duplex;
+	u8 fec;
+};
+
+/* TODO: add another paramters here: modes, etc... */
+struct prestera_port_phy_config {
+	bool admin;
+	u32 mode;
+	u8 mdix;
+};
 
 struct prestera_port {
-	struct net_device *dev;
-	struct prestera_switch *sw;
-	struct prestera_flow_block *flow_block;
 	struct devlink_port dl_port;
-	struct list_head lag_member;
-	struct prestera_lag *lag;
+	struct net_device *net_dev;
+	struct prestera_switch *sw;
 	u32 id;
 	u32 hw_id;
 	u32 dev_id;
@@ -84,59 +191,87 @@ struct prestera_port {
 	bool autoneg;
 	u64 adver_link_modes;
 	u8 adver_fec;
+	u16 lag_id;
+	u32 qos_trust_mode;
 	struct prestera_port_caps caps;
+	struct prestera_port_mac_config cfg_mac;
+	struct prestera_port_phy_config cfg_phy;
 	struct list_head list;
 	struct list_head vlans_list;
 	struct {
 		struct prestera_port_stats stats;
 		struct delayed_work caching_dw;
 	} cached_hw_stats;
+	struct prestera_flow_block *flow_block;
+
+	struct phylink_config phy_config;
+	struct phylink *phy_link;
+
+	rwlock_t state_mac_lock;
+	struct prestera_port_mac_state state_mac;
+	/* TODO: phy lock */
+	struct prestera_port_phy_state state_phy;
+
+	struct prestera_rxtx_stats __percpu *rxtx_stats;
 };
 
 struct prestera_device {
 	struct device *dev;
-	u8 __iomem *ctl_regs;
-	u8 __iomem *pp_regs;
 	struct prestera_fw_rev fw_rev;
+	struct workqueue_struct *dev_wq;
+	u8 __iomem *pp_regs;
 	void *priv;
+	gfp_t dma_flags;
+
+	struct delayed_work keepalive_wdog_work;
+	atomic_t keepalive_wdog_counter;
+	bool running;
 
 	/* called by device driver to handle received packets */
 	void (*recv_pkt)(struct prestera_device *dev);
 
 	/* called by device driver to pass event up to the higher layer */
-	int (*recv_msg)(struct prestera_device *dev, void *msg, size_t size);
+	int (*recv_msg)(struct prestera_device *dev, u8 *msg, size_t size);
 
 	/* called by higher layer to send request to the firmware */
-	int (*send_req)(struct prestera_device *dev, void *in_msg,
-			size_t in_size, void *out_msg, size_t out_size,
+	int (*send_req)(struct prestera_device *dev, int qid,
+			u8 *in_msg, size_t in_size,
+			u8 *out_msg, size_t out_size,
 			unsigned int wait);
 };
 
 enum prestera_event_type {
 	PRESTERA_EVENT_TYPE_UNSPEC,
-
 	PRESTERA_EVENT_TYPE_PORT,
 	PRESTERA_EVENT_TYPE_FDB,
 	PRESTERA_EVENT_TYPE_RXTX,
+	PRESTERA_EVENT_TYPE_FW_LOG,
+	PRESTERA_EVENT_TYPE_PULSE,
 
-	PRESTERA_EVENT_TYPE_MAX
+	PRESTERA_EVENT_TYPE_MAX,
 };
 
 enum prestera_rxtx_event_id {
 	PRESTERA_RXTX_EVENT_UNSPEC,
+
 	PRESTERA_RXTX_EVENT_RCV_PKT,
+
+	PRESTERA_RXTX_EVENT_MAX,
 };
 
 enum prestera_port_event_id {
 	PRESTERA_PORT_EVENT_UNSPEC,
-	PRESTERA_PORT_EVENT_STATE_CHANGED,
+	PRESTERA_PORT_EVENT_MAC_STATE_CHANGED,
+
+	PRESTERA_PORT_EVENT_MAX,
 };
 
-struct prestera_port_event {
-	u32 port_id;
-	union {
-		u32 oper_state;
-	} data;
+enum prestera_fdb_event_id {
+	PRESTERA_FDB_EVENT_UNSPEC,
+	PRESTERA_FDB_EVENT_LEARNED,
+	PRESTERA_FDB_EVENT_AGED,
+
+	PRESTERA_FDB_EVENT_MAX,
 };
 
 enum prestera_fdb_entry_type {
@@ -145,12 +280,6 @@ enum prestera_fdb_entry_type {
 	PRESTERA_FDB_ENTRY_TYPE_MAX
 };
 
-enum prestera_fdb_event_id {
-	PRESTERA_FDB_EVENT_UNSPEC,
-	PRESTERA_FDB_EVENT_LEARNED,
-	PRESTERA_FDB_EVENT_AGED,
-};
-
 struct prestera_fdb_event {
 	enum prestera_fdb_entry_type type;
 	union {
@@ -163,81 +292,450 @@ struct prestera_fdb_event {
 	} data;
 };
 
+struct prestera_port_event {
+	u32 port_id;
+	union {
+		struct {
+			u8 oper;
+			u32 mode;
+			u32 speed;
+			u8 duplex;
+			u8 fc;
+			u8 fec;
+		} mac;
+		struct {
+			u8 mdix;
+			u64 lmode_bmap;
+			struct {
+				bool pause;
+				bool asym_pause;
+			} remote_fc;
+		} phy;
+	} data;
+};
+
+struct prestera_fw_log_event {
+	u32 log_len;
+	u8 *data;
+};
+
 struct prestera_event {
 	u16 id;
 	union {
 		struct prestera_port_event port_evt;
 		struct prestera_fdb_event fdb_evt;
+		struct prestera_fw_log_event fw_log_evt;
 	};
 };
 
+struct prestera_lag_member {
+	struct list_head list;
+	struct prestera_port *port;
+};
+
+struct prestera_lag {
+	struct net_device *dev;
+	u16 member_count;
+	struct list_head members;
+};
+
+enum prestera_if_type {
+	/* the interface is of port type (dev,port) */
+	PRESTERA_IF_PORT_E = 0,
+
+	/* the interface is of lag type (lag-id) */
+	PRESTERA_IF_LAG_E = 1,
+
+	/* the interface is of Vid type (vlan-id) */
+	PRESTERA_IF_VID_E = 3,
+};
+
+struct prestera_iface {
+	enum prestera_if_type type;
+	struct {
+		u32 hw_dev_num;
+		u32 port_num;
+	} dev_port;
+	u16 vr_id;
+	u16 lag_id;
+	u16 vlan_id;
+	u32 hw_dev_num;
+};
+
 struct prestera_switchdev;
-struct prestera_span;
-struct prestera_rxtx;
+struct prestera_router;
+struct prestera_rif;
 struct prestera_trap_data;
-struct prestera_acl;
+struct prestera_rxtx;
 
 struct prestera_switch {
+	struct list_head list;
 	struct prestera_device *dev;
-	struct prestera_switchdev *swdev;
-	struct prestera_rxtx *rxtx;
-	struct prestera_acl *acl;
-	struct prestera_span *span;
 	struct list_head event_handlers;
-	struct notifier_block netdev_nb;
-	struct prestera_trap_data *trap_data;
 	char base_mac[ETH_ALEN];
 	struct list_head port_list;
-	rwlock_t port_list_lock;
 	u32 port_count;
 	u32 mtu_min;
 	u32 mtu_max;
 	u8 id;
-	struct prestera_lag *lags;
-	u8 lag_member_max;
 	u8 lag_max;
+	u8 lag_member_max;
+	u32 size_tbl_router_nexthop;
+	struct prestera_storm_control *storm_control;
+	struct prestera_acl *acl;
+	struct prestera_span *span;
+	struct prestera_switchdev *swdev;
+	struct prestera_router *router;
+	struct prestera_lag *lags;
+	struct notifier_block netdev_nb;
+	struct device_node *np;
+	struct prestera_trap_data *trap_data;
+	struct prestera_rxtx *rxtx;
+	struct prestera_counter *counter;
 };
 
-struct prestera_rxtx_params {
-	bool use_sdma;
-	u32 map_addr;
+struct prestera_router {
+	struct prestera_switch *sw;
+	struct list_head rif_list;	/* list of mvsw_pr_rif */
+	struct list_head vr_list;	/* list of mvsw_pr_vr */
+	struct list_head rif_entry_list;
+	struct rhashtable nh_neigh_ht;
+	struct rhashtable nexthop_group_ht;
+	struct rhashtable fib_ht;
+	struct rhashtable kern_fib_cache_ht;
+	struct rhashtable kern_neigh_cache_ht;
+	u8 *nhgrp_hw_state_cache; /* Bitmap cached hw state of nhs */
+	unsigned long nhgrp_hw_cache_kick; /* jiffies */
+	struct {
+		struct delayed_work dw;
+		unsigned int interval;	/* ms */
+	} neighs_update;
+	struct notifier_block netevent_nb;
+	struct notifier_block inetaddr_nb;
+	struct notifier_block fib_nb;
+	bool aborted;
 };
 
-#define prestera_dev(sw)		((sw)->dev->dev)
+enum prestera_fdb_flush_mode {
+	PRESTERA_FDB_FLUSH_MODE_DYNAMIC = BIT(0),
+	PRESTERA_FDB_FLUSH_MODE_STATIC = BIT(1),
+	PRESTERA_FDB_FLUSH_MODE_ALL = PRESTERA_FDB_FLUSH_MODE_DYNAMIC
+				    | PRESTERA_FDB_FLUSH_MODE_STATIC,
+};
 
-static inline void prestera_write(const struct prestera_switch *sw,
-				  unsigned int reg, u32 val)
-{
-	writel(val, sw->dev->pp_regs + reg);
-}
+struct prestera_ip_addr {
+	enum {
+		PRESTERA_IPV4 = 0,
+		PRESTERA_IPV6
+	} v;
+	union {
+		__be32 ipv4;
+		struct in6_addr ipv6;
+	} u;
+};
 
-static inline u32 prestera_read(const struct prestera_switch *sw,
-				unsigned int reg)
-{
-	return readl(sw->dev->pp_regs + reg);
-}
+/* Used for hw call */
+struct prestera_neigh_info {
+	struct prestera_iface iface;
+	unsigned char ha[ETH_ALEN];
+	bool connected; /* indicate, if mac/oif valid */
+};
 
-int prestera_device_register(struct prestera_device *dev);
-void prestera_device_unregister(struct prestera_device *dev);
+enum prestera_acl_match_type {
+	PRESTERA_ACL_RULE_MATCH_TYPE_PCL_ID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_TYPE,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_DMAC_0,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_DMAC_1,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_SMAC_0,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_SMAC_1,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_PROTO,
+	PRESTERA_ACL_RULE_MATCH_TYPE_SYS_PORT,
+	PRESTERA_ACL_RULE_MATCH_TYPE_SYS_DEV,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_RANGE_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_RANGE_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_VLAN_ID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_VLAN_TPID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ICMP_TYPE,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ICMP_CODE,
+
+	__PRESTERA_ACL_RULE_MATCH_TYPE_MAX
+};
 
-struct prestera_port *prestera_port_find_by_hwid(struct prestera_switch *sw,
-						 u32 dev_id, u32 hw_id);
+struct prestera_acl_match {
+	__be32 key[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	__be32 mask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+};
 
-int prestera_port_autoneg_set(struct prestera_port *port, bool enable,
-			      u64 adver_link_modes, u8 adver_fec);
+enum prestera_acl_rule_action {
+	PRESTERA_ACL_RULE_ACTION_ACCEPT,
+	PRESTERA_ACL_RULE_ACTION_DROP,
+	PRESTERA_ACL_RULE_ACTION_TRAP,
+	PRESTERA_ACL_RULE_ACTION_POLICE,
+	PRESTERA_ACL_RULE_ACTION_NAT,
+	PRESTERA_ACL_RULE_ACTION_JUMP,
+	PRESTERA_ACL_RULE_ACTION_NH,
+	PRESTERA_ACL_RULE_ACTION_COUNT
+};
 
-struct prestera_port *prestera_find_port(struct prestera_switch *sw, u32 id);
+struct prestera_acl_action_jump {
+	u32 index;
+};
 
-struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev);
+struct prestera_acl_action_trap {
+	u8 hw_tc;
+};
 
-int prestera_port_pvid_set(struct prestera_port *port, u16 vid);
+struct prestera_acl_action_police {
+	u64 rate;
+	u64 burst;
+};
 
-bool prestera_netdev_check(const struct net_device *dev);
+struct prestera_acl_action_nat {
+	__be32 old_addr;
+	__be32 new_addr;
+	u32 port;
+	u32 dev;
+	u32 flags;
+};
 
+struct prestera_acl_action_count {
+	u32 id;
+};
+
+/* Used for hw call */
+struct prestera_acl_hw_action_info {
+	enum prestera_acl_rule_action id;
+	union {
+		struct prestera_acl_action_trap trap;
+		struct prestera_acl_action_police police;
+		u32 nh;
+		struct prestera_acl_action_nat nat;
+		struct prestera_acl_action_jump jump;
+		struct prestera_acl_action_count count;
+	};
+};
+
+struct prestera_nh_neigh_key {
+	struct prestera_ip_addr addr;
+	/* Seems like rif is obsolete, because there is iface in info ?
+	 * Key can contain functional fields, or fields, which is used to
+	 * filter duplicate objects on logical level (before you pass it to
+	 * HW)... also key can be used to cover hardware restrictions.
+	 * In our case rif - is logical interface (even can be VLAN), which
+	 * is used in combination with IP address (which is also not related to
+	 * hardware nexthop) to provide logical compression of created nexthops.
+	 * You even can imagine, that rif+IPaddr is just cookie.
+	 */
+	/* struct prestera_rif *rif; */
+	/* Use just as cookie, to divide ARP domains (in order with addr) */
+	void *rif;
+};
+
+/* Used to notify nh about neigh change */
+struct prestera_nh_neigh {
+	struct prestera_nh_neigh_key key;
+	struct prestera_neigh_info info;
+	struct rhash_head ht_node; /* node of mvsw_pr_vr */
+	struct list_head nexthop_group_list;
+	struct list_head nh_mangle_entry_list;
+};
+
+struct prestera_nexthop_group_key {
+	struct prestera_nh_neigh_key neigh[PRESTERA_NHGR_SIZE_MAX];
+};
+
+struct prestera_port *dev_to_prestera_port(struct device *dev);
+
+struct prestera_port *prestera_port_find_by_fp_id(u32 fp_id);
+
+int prestera_port_learning_set(struct prestera_port *port, bool learn_enable);
+int prestera_port_uc_flood_set(struct prestera_port *port, bool flood);
+int prestera_port_mc_flood_set(struct prestera_port *port, bool flood);
+int prestera_port_isolation_grp_set(struct prestera_port *port,
+				    u32 sourceid);
+int prestera_port_pvid_set(struct prestera_port *port, u16 vid);
+int prestera_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state);
+struct prestera_port_vlan *
+prestera_port_vlan_create(struct prestera_port *port, u16 vid, bool untagged);
+void prestera_port_vlan_destroy(struct prestera_port_vlan *mvsw_pr_port_vlan);
+int prestera_port_vlan_set(struct prestera_port *port, u16 vid,
+			   bool is_member, bool untagged);
+
+struct prestera_bridge *
+prestera_bridge_device_find(const struct prestera_switch *sw,
+			    const struct net_device *br_dev);
+u16 prestera_vlan_dev_vlan_id(struct prestera_switch *sw,
+			      struct net_device *dev);
+
+int prestera_lag_member_add(struct prestera_port *port,
+			    struct net_device *lag_dev, u16 lag_id);
+int prestera_lag_member_del(struct prestera_port *port);
+int prestera_lag_member_enable(struct prestera_port *port, bool enable);
 bool prestera_port_is_lag_member(const struct prestera_port *port);
+struct prestera_lag *prestera_lag_get(struct prestera_switch *sw, u8 id);
+int prestera_lag_id_find(struct prestera_switch *sw, struct net_device *lag_dev,
+			 u16 *lag_id);
+void prestera_lag_member_rif_leave(const struct prestera_port *port,
+				   u16 lag_id, u16 vr_id);
+
+/* SPAN */
+int prestera_span_get(struct prestera_port *port, u8 *span_id);
+int prestera_span_put(const struct prestera_switch *sw, u8 span_id);
+
+int prestera_dev_if_type(const struct net_device *dev);
+
+/* prestera_flower.c */
+int prestera_flower_replace(struct prestera_switch *sw,
+			    struct prestera_flow_block *block,
+			    struct flow_cls_offload *f);
+void prestera_flower_destroy(struct prestera_switch *sw,
+			     struct prestera_flow_block *block,
+			     struct flow_cls_offload *f);
+int prestera_flower_stats(struct prestera_switch *sw,
+			  struct prestera_flow_block *block,
+			  struct flow_cls_offload *f);
+int prestera_flower_prio_get(struct prestera_flow_block *block,
+			     u32 *prio);
+int prestera_flower_tmplt_create(struct prestera_switch *sw,
+				 struct prestera_flow_block *block,
+				 struct flow_cls_offload *f);
+void prestera_flower_tmplt_destroy(struct prestera_switch *sw,
+				   struct prestera_flow_block *block,
+				   struct flow_cls_offload *f);
+void prestera_flower_template_cleanup(struct prestera_flow_block *block);
+
+/* prestera_matchall.c */
+int prestera_mall_replace(struct prestera_flow_block *block,
+			  struct tc_cls_matchall_offload *f);
+void prestera_mall_destroy(struct prestera_flow_block *block);
+int prestera_mall_prio_get(struct prestera_flow_block *block,
+			   u32 *prio);
+
+/* prestera_flow.c */
+int prestera_setup_tc_block(struct prestera_port *port,
+			    struct flow_block_offload *f);
+
+/* prestera_acl.c */
+int prestera_acl_init(struct prestera_switch *sw);
+void prestera_acl_fini(struct prestera_switch *sw);
+struct net *prestera_acl_block_net(struct prestera_flow_block *block);
+struct prestera_switch *
+prestera_acl_block_sw(struct prestera_flow_block *block);
+unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block);
+void prestera_acl_block_disable_inc(struct prestera_flow_block *block);
+void prestera_acl_block_disable_dec(struct prestera_flow_block *block);
+bool prestera_acl_block_disabled(const struct prestera_flow_block *block);
+void prestera_acl_block_prio_update(struct prestera_switch *sw,
+				    struct prestera_flow_block *block);
+
+/* ACL-NAT */
+struct prestera_acl_nat_port *
+prestera_acl_nat_port_get(struct prestera_acl *acl, u32 port_hw_id,
+			  u32 port_dev_id);
+void prestera_acl_nat_port_put(struct prestera_acl_nat_port *nat_port);
+struct prestera_port *
+prestera_acl_nat_port_to_port(struct prestera_acl_nat_port *nat_port);
+
+/* VLAN API */
+struct prestera_port_vlan *
+prestera_port_vlan_find_by_vid(const struct prestera_port *port, u16 vid);
+void
+prestera_port_vlan_bridge_leave(struct prestera_port_vlan *mvsw_pr_port_vlan);
+
+/* MDB / flood domain API*/
+struct prestera_mdb_entry *
+prestera_mdb_entry_create(struct prestera_switch *sw,
+			  const unsigned char *addr, u16 vid);
+void prestera_mdb_entry_destroy(struct prestera_mdb_entry *mdb_entry);
+
+struct prestera_flood_domain *
+prestera_flood_domain_create(struct prestera_switch *sw);
+void prestera_flood_domain_destroy(struct prestera_flood_domain *flood_domain);
+
+int
+prestera_flood_domain_port_create(struct prestera_flood_domain *flood_domain,
+				  struct net_device *dev,
+				  u16 vid);
+struct prestera_flood_domain_port *
+prestera_flood_domain_port_find(struct prestera_flood_domain *flood_domain,
+				struct net_device *dev, u16 vid);
+void
+prestera_flood_domain_port_destroy(struct prestera_flood_domain_port *port);
+
+int prestera_switchdev_register(struct prestera_switch *sw);
+void prestera_switchdev_unregister(struct prestera_switch *sw);
 
-struct prestera_lag *prestera_lag_by_id(struct prestera_switch *sw, u16 id);
+int prestera_device_register(struct prestera_device *dev);
+void prestera_device_unregister(struct prestera_device *dev);
+
+bool prestera_netdev_check(const struct net_device *dev);
+struct prestera_switch *prestera_switch_get(struct net_device *dev);
+int prestera_port_cfg_mac_read(struct prestera_port *port,
+			       struct prestera_port_mac_config *cfg);
+int prestera_port_cfg_mac_write(struct prestera_port *port,
+				struct prestera_port_mac_config *cfg);
+void prestera_port_mac_state_cache_read(struct prestera_port *port,
+					struct prestera_port_mac_state *state);
+void prestera_port_mac_state_cache_write(struct prestera_port *port,
+					 struct prestera_port_mac_state *state);
+struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev);
 
-u16 prestera_port_lag_id(const struct prestera_port *port);
+struct prestera_port *prestera_port_find(u32 dev_hw_id, u32 port_hw_id);
+
+int prestera_port_autoneg_set(struct prestera_port *port, u64 link_modes);
+
+/* prestera_router.c */
+int prestera_router_init(struct prestera_switch *sw);
+void prestera_router_fini(struct prestera_switch *sw);
+int prestera_netdevice_router_port_event(struct net_device *dev,
+					 unsigned long event, void *ptr);
+int prestera_netdevice_vrf_event(struct net_device *dev, unsigned long event,
+				 struct netdev_notifier_changeupper_info *info);
+void prestera_port_router_leave(struct prestera_port *port);
+int prestera_lpm_add(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct prestera_ip_addr *addr, u32 prefix_len, u32 grp_id);
+int prestera_lpm_del(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct prestera_ip_addr *addr, u32 prefix_len);
+int prestera_nh_entries_set(const struct prestera_switch *sw, int count,
+			    struct prestera_neigh_info *nhs, u32 grp_id);
+int prestera_nh_entries_get(const struct prestera_switch *sw, int count,
+			    struct prestera_neigh_info *nhs, u32 grp_id);
+int prestera_nhgrp_blk_get(const struct prestera_switch *sw, u8 *hw_state,
+			   u32 buf_size);
+int prestera_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
+			     u32 *grp_id);
+int prestera_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
+			     u32 grp_id);
+int prestera_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy);
+
+struct prestera_nh_neigh *
+prestera_nh_neigh_find(struct prestera_switch *sw,
+		       struct prestera_nh_neigh_key *key);
+struct prestera_nh_neigh *
+prestera_nh_neigh_get(struct prestera_switch *sw,
+		      struct prestera_nh_neigh_key *key);
+void prestera_nh_neigh_put(struct prestera_switch *sw,
+			   struct prestera_nh_neigh *neigh);
+int prestera_util_kern_dip2nh_grp_key(struct prestera_switch *sw,
+				      u32 tb_id, struct prestera_ip_addr *addr,
+				      struct prestera_nexthop_group_key *res);
+void prestera_rif_enable(struct prestera_switch *sw, struct net_device *dev,
+			 bool enable);
+bool prestera_rif_exists(const struct prestera_switch *sw,
+			 const struct net_device *dev);
+void prestera_router_lag_member_leave(const struct prestera_port *port,
+				      const struct net_device *dev);
+void prestera_lag_router_leave(struct prestera_switch *sw,
+			       struct net_device *lag_dev);
+
+void prestera_bridge_rifs_destroy(struct prestera_switch *sw,
+				  struct net_device *bridge_dev);
+void prestera_k_arb_fdb_evt(struct prestera_switch *sw, struct net_device *dev);
+struct prestera_neigh_info *
+prestera_kern_neigh_cache_to_neigh_info(struct prestera_kern_neigh_cache *nc);
 
 #endif /* _PRESTERA_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_acl.c b/drivers/net/ethernet/marvell/prestera/prestera_acl.c
index 83c75ffb1a1c..a0f4a03ecbf3 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_acl.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_acl.c
@@ -1,37 +1,61 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <linux/rhashtable.h>
 
 #include "prestera.h"
 #include "prestera_hw.h"
+#include "prestera_log.h"
+#include "prestera_ct.h"
 #include "prestera_acl.h"
-#include "prestera_span.h"
 
-struct prestera_acl {
-	struct prestera_switch *sw;
-	struct list_head rules;
+#define PRESTERA_ACL_RULE_DEF_HW_TC	3
+#define ACL_KEYMASK_SIZE	\
+	(sizeof(__be32) * __PRESTERA_ACL_RULE_MATCH_TYPE_MAX)
+/* Need to merge it with router_manager */
+#define MVSW_PR_NH_ACTIVE_JIFFER_FILTER 3000 /* ms */
+
+struct prestera_acl_ruleset_ht_key {
+	struct prestera_flow_block *block;
+	u32 chain_index;
 };
 
 struct prestera_acl_ruleset {
+	struct rhash_head ht_node; /* Member of acl HT */
+	struct prestera_acl_ruleset_ht_key ht_key;
 	struct rhashtable rule_ht;
-	struct prestera_switch *sw;
-	u16 id;
+	struct prestera_acl *acl;
+	unsigned long rule_count;
+	refcount_t refcount;
+	void *keymask;
+	bool offload;
+	u32 vtcam_id;
+	u16 pcl_id;
+	u32 index;
 };
 
-struct prestera_acl_rule {
-	struct rhash_head ht_node;
+struct prestera_acl_uid_entry {
 	struct list_head list;
-	struct list_head match_list;
-	struct list_head action_list;
-	struct prestera_flow_block *block;
-	unsigned long cookie;
-	u32 priority;
-	u8 n_actions;
-	u8 n_matches;
+	u8 id;
+};
+
+struct prestera_acl_vtcam {
+	struct list_head list;
+	__be32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	bool is_keymask_set;
+	refcount_t refcount;
+	u8 direction;
+	u8 lookup;
 	u32 id;
 };
 
+static const struct rhashtable_params prestera_acl_ruleset_ht_params = {
+	.key_len = sizeof(struct prestera_acl_ruleset_ht_key),
+	.key_offset = offsetof(struct prestera_acl_ruleset, ht_key),
+	.head_offset = offsetof(struct prestera_acl_ruleset, ht_node),
+	.automatic_shrinking = true,
+};
+
 static const struct rhashtable_params prestera_acl_rule_ht_params = {
 	.key_len = sizeof(unsigned long),
 	.key_offset = offsetof(struct prestera_acl_rule, cookie),
@@ -39,28 +63,133 @@ static const struct rhashtable_params prestera_acl_rule_ht_params = {
 	.automatic_shrinking = true,
 };
 
+static const struct rhashtable_params __prestera_nh_mangle_entry_ht_params = {
+	.key_offset  = offsetof(struct prestera_nh_mangle_entry, key),
+	.head_offset = offsetof(struct prestera_nh_mangle_entry, ht_node),
+	.key_len     = sizeof(struct prestera_nh_mangle_entry_key),
+	.automatic_shrinking = true,
+};
+
+static const struct rhashtable_params __prestera_acl_rule_entry_ht_params = {
+	.key_offset  = offsetof(struct prestera_acl_rule_entry, key),
+	.head_offset = offsetof(struct prestera_acl_rule_entry, ht_node),
+	.key_len     = sizeof(struct prestera_acl_rule_entry_key),
+	.automatic_shrinking = true,
+};
+
+int prestera_acl_chain_to_client(u32 chain_index, u32 *client)
+{
+	u32 client_map[] = {
+		PRESTERA_HW_COUNTER_CLIENT_LOOKUP_0,
+		PRESTERA_HW_COUNTER_CLIENT_LOOKUP_1,
+		PRESTERA_HW_COUNTER_CLIENT_LOOKUP_2
+	};
+
+	if (chain_index > ARRAY_SIZE(client_map))
+		return -EINVAL;
+
+	*client = client_map[chain_index];
+	return 0;
+}
+
+struct prestera_acl_nat_port *
+prestera_acl_nat_port_get(struct prestera_acl *acl, u32 port_hw_id,
+			  u32 port_dev_id)
+{
+	struct prestera_acl_nat_port *nat_port;
+	struct list_head *pos, *n;
+
+	list_for_each_safe(pos, n, &acl->nat_port_list) {
+		nat_port = list_entry(pos, typeof(*nat_port), list);
+		if (nat_port->port->hw_id == port_hw_id &&
+		    nat_port->port->dev_id == port_dev_id) {
+			refcount_inc(&nat_port->refcount);
+			return nat_port;
+		}
+	}
+
+	return NULL;
+}
+
+void prestera_acl_nat_port_put(struct prestera_acl_nat_port *nat_port)
+{
+	if (!refcount_dec_and_test(&nat_port->refcount))
+		return;
+
+	list_del(&nat_port->list);
+	kfree(nat_port);
+}
+
+struct prestera_port *
+prestera_acl_nat_port_to_port(struct prestera_acl_nat_port *nat_port)
+{
+	return nat_port->port;
+}
+
+static struct prestera_acl_nat_port *
+prestera_acl_nat_port_create(struct prestera_acl *acl,
+			     struct prestera_port *port)
+{
+	struct prestera_acl_nat_port *nat_port;
+
+	nat_port = kzalloc(sizeof(*nat_port), GFP_KERNEL);
+	if (!nat_port)
+		return ERR_PTR(-ENOMEM);
+
+	nat_port->port = port;
+	refcount_set(&nat_port->refcount, 1);
+	list_add(&nat_port->list, &acl->nat_port_list);
+
+	return nat_port;
+}
+
+static inline bool prestera_acl_chain_is_supported(u32 chain_index)
+{
+	return (chain_index & ~PRESTERA_ACL_CHAIN_MASK) == 0;
+}
+
 static struct prestera_acl_ruleset *
-prestera_acl_ruleset_create(struct prestera_switch *sw)
+prestera_acl_ruleset_create(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index)
 {
 	struct prestera_acl_ruleset *ruleset;
 	int err;
+	u32 uid = 0;
+
+	if (!prestera_acl_chain_is_supported(chain_index))
+		return ERR_PTR(-EINVAL);
 
 	ruleset = kzalloc(sizeof(*ruleset), GFP_KERNEL);
 	if (!ruleset)
 		return ERR_PTR(-ENOMEM);
 
+	ruleset->acl = acl;
+	ruleset->ht_key.block = block;
+	ruleset->ht_key.chain_index = chain_index;
+	refcount_set(&ruleset->refcount, 1);
+
 	err = rhashtable_init(&ruleset->rule_ht, &prestera_acl_rule_ht_params);
 	if (err)
 		goto err_rhashtable_init;
 
-	err = prestera_hw_acl_ruleset_create(sw, &ruleset->id);
+	err = idr_alloc_u32(&acl->uid, NULL, &uid, U8_MAX, GFP_KERNEL);
 	if (err)
 		goto err_ruleset_create;
 
-	ruleset->sw = sw;
+	/* make pcl-id based on uid and chain */
+	ruleset->pcl_id = PRESTERA_ACL_PCL_ID_MAKE((u8)uid, chain_index);
+	ruleset->index = uid;
+
+	err = rhashtable_insert_fast(&acl->ruleset_ht, &ruleset->ht_node,
+				     prestera_acl_ruleset_ht_params);
+	if (err)
+		goto err_ruleset_ht_insert;
 
 	return ruleset;
 
+err_ruleset_ht_insert:
+	idr_remove(&acl->uid, uid);
 err_ruleset_create:
 	rhashtable_destroy(&ruleset->rule_ht);
 err_rhashtable_init:
@@ -68,107 +197,247 @@ prestera_acl_ruleset_create(struct prestera_switch *sw)
 	return ERR_PTR(err);
 }
 
+int prestera_acl_ruleset_keymask_set(struct prestera_acl_ruleset *ruleset,
+				     void *keymask)
+{
+	void *__keymask;
+
+	if (!keymask || !ruleset)
+		return -EINVAL;
+
+	__keymask = kmalloc(ACL_KEYMASK_SIZE, GFP_KERNEL);
+	if (!__keymask)
+		return -ENOMEM;
+
+	memcpy(__keymask, keymask, ACL_KEYMASK_SIZE);
+	ruleset->keymask = __keymask;
+
+	return 0;
+}
+
+int prestera_acl_ruleset_offload(struct prestera_acl_ruleset *ruleset)
+{
+	struct prestera_acl_iface iface;
+	u32 vtcam_id;
+	int err;
+
+	if (ruleset->offload)
+		return -EEXIST;
+
+	err = prestera_acl_vtcam_id_get(ruleset->acl,
+					ruleset->ht_key.chain_index,
+					PRESTERA_HW_VTCAM_DIR_INGRESS,
+					ruleset->keymask, &vtcam_id);
+	if (err)
+		goto err_vtcam_create;
+
+	if (ruleset->ht_key.chain_index) {
+		/* for chain > 0, bind iface index to pcl-id to be able
+		 * to jump from any other ruleset to this one using the index.
+		 */
+		iface.index = ruleset->index;
+		iface.type = PRESTERA_ACL_IFACE_TYPE_INDEX;
+		err = prestera_hw_vtcam_iface_bind(ruleset->acl->sw, &iface,
+						   vtcam_id, ruleset->pcl_id);
+		if (err)
+			goto err_ruleset_bind;
+	}
+
+	ruleset->vtcam_id = vtcam_id;
+	ruleset->offload = true;
+	return 0;
+
+err_ruleset_bind:
+	prestera_acl_vtcam_id_put(ruleset->acl, ruleset->vtcam_id);
+err_vtcam_create:
+	return err;
+}
+
 static void prestera_acl_ruleset_destroy(struct prestera_acl_ruleset *ruleset)
 {
-	prestera_hw_acl_ruleset_del(ruleset->sw, ruleset->id);
+	struct prestera_acl *acl = ruleset->acl;
+	u8 uid = ruleset->pcl_id & PRESTERA_ACL_KEYMASK_PCL_ID_USER;
+	int err;
+
+	rhashtable_remove_fast(&acl->ruleset_ht, &ruleset->ht_node,
+			       prestera_acl_ruleset_ht_params);
+
+	if (ruleset->offload) {
+		if (ruleset->ht_key.chain_index) {
+			struct prestera_acl_iface iface = {
+				.type = PRESTERA_ACL_IFACE_TYPE_INDEX,
+				.index = ruleset->index
+			};
+			err = prestera_hw_vtcam_iface_unbind(acl->sw, &iface,
+							     ruleset->vtcam_id);
+			WARN_ON(err);
+		}
+		WARN_ON(prestera_acl_vtcam_id_put(acl, ruleset->vtcam_id));
+	}
+
+	idr_remove(&acl->uid, uid);
 	rhashtable_destroy(&ruleset->rule_ht);
+	kfree(ruleset->keymask);
 	kfree(ruleset);
 }
 
-struct prestera_flow_block *
-prestera_acl_block_create(struct prestera_switch *sw, struct net *net)
+static struct prestera_acl_ruleset *
+__prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			      struct prestera_flow_block *block,
+			      u32 chain_index)
 {
-	struct prestera_flow_block *block;
+	struct prestera_acl_ruleset_ht_key ht_key;
+
+	memset(&ht_key, 0, sizeof(ht_key));
+	ht_key.block = block;
+	ht_key.chain_index = chain_index;
+	return rhashtable_lookup_fast(&acl->ruleset_ht, &ht_key,
+				      prestera_acl_ruleset_ht_params);
+}
+
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index)
+{
+	struct prestera_acl_ruleset *ruleset;
 
-	block = kzalloc(sizeof(*block), GFP_KERNEL);
-	if (!block)
-		return NULL;
-	INIT_LIST_HEAD(&block->binding_list);
-	block->net = net;
-	block->sw = sw;
-
-	block->ruleset = prestera_acl_ruleset_create(sw);
-	if (IS_ERR(block->ruleset)) {
-		kfree(block);
-		return NULL;
+	ruleset = __prestera_acl_ruleset_lookup(acl, block, chain_index);
+	if (!ruleset)
+		return ERR_PTR(-ENOENT);
+
+	refcount_inc(&ruleset->refcount);
+	return ruleset;
+}
+
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_get(struct prestera_acl *acl,
+			 struct prestera_flow_block *block,
+			 u32 chain_index)
+{
+	struct prestera_acl_ruleset *ruleset;
+
+	ruleset = __prestera_acl_ruleset_lookup(acl, block, chain_index);
+	if (ruleset) {
+		refcount_inc(&ruleset->refcount);
+		return ruleset;
 	}
 
-	return block;
+	return prestera_acl_ruleset_create(acl, block, chain_index);
 }
 
-void prestera_acl_block_destroy(struct prestera_flow_block *block)
+void prestera_acl_ruleset_put(struct prestera_acl_ruleset *ruleset)
 {
-	prestera_acl_ruleset_destroy(block->ruleset);
-	WARN_ON(!list_empty(&block->binding_list));
-	kfree(block);
+	if (!refcount_dec_and_test(&ruleset->refcount))
+		return;
+
+	prestera_acl_ruleset_destroy(ruleset);
 }
 
-static struct prestera_flow_block_binding *
-prestera_acl_block_lookup(struct prestera_flow_block *block,
-			  struct prestera_port *port)
+int prestera_acl_ruleset_bind(struct prestera_acl_ruleset *ruleset,
+			      struct prestera_port *port)
 {
-	struct prestera_flow_block_binding *binding;
+	struct prestera_acl_iface iface = {
+		.type = PRESTERA_ACL_IFACE_TYPE_PORT,
+		.port = port
+	};
 
-	list_for_each_entry(binding, &block->binding_list, list)
-		if (binding->port == port)
-			return binding;
+	return prestera_hw_vtcam_iface_bind(port->sw, &iface, ruleset->vtcam_id,
+					    ruleset->pcl_id);
+}
 
-	return NULL;
+int prestera_acl_ruleset_unbind(struct prestera_acl_ruleset *ruleset,
+				struct prestera_port *port)
+{
+	struct prestera_acl_iface iface = {
+		.type = PRESTERA_ACL_IFACE_TYPE_PORT,
+		.port = port
+	};
+
+	return prestera_hw_vtcam_iface_unbind(port->sw, &iface,
+					      ruleset->vtcam_id);
 }
 
-int prestera_acl_block_bind(struct prestera_flow_block *block,
-			    struct prestera_port *port)
+static int prestera_acl_ruleset_block_bind(struct prestera_acl_ruleset *ruleset,
+					   struct prestera_flow_block *block)
 {
 	struct prestera_flow_block_binding *binding;
 	int err;
 
-	if (WARN_ON(prestera_acl_block_lookup(block, port)))
-		return -EEXIST;
-
-	binding = kzalloc(sizeof(*binding), GFP_KERNEL);
-	if (!binding)
-		return -ENOMEM;
-	binding->span_id = PRESTERA_SPAN_INVALID_ID;
-	binding->port = port;
-
-	err = prestera_hw_acl_port_bind(port, block->ruleset->id);
-	if (err)
-		goto err_rules_bind;
-
-	list_add(&binding->list, &block->binding_list);
+	block->ruleset_zero = ruleset;
+	list_for_each_entry(binding, &block->binding_list, list) {
+		err = prestera_acl_ruleset_bind(ruleset, binding->port);
+		if (err)
+			goto rollback;
+	}
 	return 0;
 
-err_rules_bind:
-	kfree(binding);
+rollback:
+	list_for_each_entry_continue_reverse(binding, &block->binding_list,
+					     list)
+		err = prestera_acl_ruleset_unbind(ruleset, binding->port);
+	block->ruleset_zero = NULL;
+
 	return err;
 }
 
-int prestera_acl_block_unbind(struct prestera_flow_block *block,
-			      struct prestera_port *port)
+static void
+prestera_acl_ruleset_block_unbind(struct prestera_acl_ruleset *ruleset,
+				  struct prestera_flow_block *block)
 {
 	struct prestera_flow_block_binding *binding;
 
-	binding = prestera_acl_block_lookup(block, port);
-	if (!binding)
-		return -ENOENT;
+	list_for_each_entry(binding, &block->binding_list, list)
+		prestera_acl_ruleset_unbind(ruleset, binding->port);
+	block->ruleset_zero = NULL;
+}
 
-	list_del(&binding->list);
+void prestera_acl_block_prio_update(struct prestera_switch *sw,
+				    struct prestera_flow_block *block)
+{
+	struct prestera_acl *acl = sw->acl;
+	struct prestera_acl_rule *rule;
+	u32 new_prio = UINT_MAX;
 
-	prestera_hw_acl_port_unbind(port, block->ruleset->id);
+	list_for_each_entry(rule, &acl->rules, list) {
+		if (rule->priority < new_prio)
+			new_prio = rule->priority;
+	}
 
-	kfree(binding);
-	return 0;
+	block->flower_min_prio = new_prio;
 }
 
-struct prestera_acl_ruleset *
-prestera_acl_block_ruleset_get(struct prestera_flow_block *block)
+unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block)
+{
+	return block ? block->rule_count : 0;
+}
+
+void prestera_acl_block_disable_inc(struct prestera_flow_block *block)
+{
+	if (block)
+		block->disable_count++;
+}
+
+void prestera_acl_block_disable_dec(struct prestera_flow_block *block)
+{
+	if (block)
+		block->disable_count--;
+}
+
+bool prestera_acl_block_disabled(const struct prestera_flow_block *block)
 {
-	return block->ruleset;
+	return block->disable_count;
 }
 
-u16 prestera_acl_rule_ruleset_id_get(const struct prestera_acl_rule *rule)
+void
+prestera_acl_rule_keymask_pcl_id_set(struct prestera_acl_rule *rule, u16 pcl_id)
 {
-	return rule->block->ruleset->id;
+	struct prestera_acl_match *r_match = &rule->re_key.match;
+	__be16 pcl_id_mask = htons(PRESTERA_ACL_KEYMASK_PCL_ID);
+	__be16 pcl_id_key = htons(pcl_id);
+
+	rule_match_set(r_match->key, PCL_ID, pcl_id_key);
+	rule_match_set(r_match->mask, PCL_ID, pcl_id_mask);
 }
 
 struct net *prestera_acl_block_net(struct prestera_flow_block *block)
@@ -189,60 +458,47 @@ prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
 				      prestera_acl_rule_ht_params);
 }
 
-struct prestera_acl_rule *
-prestera_acl_rule_create(struct prestera_flow_block *block,
-			 unsigned long cookie)
+u32 prestera_acl_ruleset_index_get(const struct prestera_acl_ruleset *ruleset)
 {
-	struct prestera_acl_rule *rule;
-
-	rule = kzalloc(sizeof(*rule), GFP_KERNEL);
-	if (!rule)
-		return ERR_PTR(-ENOMEM);
-
-	INIT_LIST_HEAD(&rule->match_list);
-	INIT_LIST_HEAD(&rule->action_list);
-	rule->cookie = cookie;
-	rule->block = block;
-
-	return rule;
+	return ruleset->index;
 }
 
-struct list_head *
-prestera_acl_rule_match_list_get(struct prestera_acl_rule *rule)
+bool prestera_acl_ruleset_is_offload(struct prestera_acl_ruleset *ruleset)
 {
-	return &rule->match_list;
+	return ruleset->offload;
 }
 
-struct list_head *
-prestera_acl_rule_action_list_get(struct prestera_acl_rule *rule)
+struct prestera_acl_rule *
+prestera_acl_rule_create(struct prestera_acl_ruleset *ruleset,
+			 unsigned long cookie, u32 chain_index)
 {
-	return &rule->action_list;
-}
+	struct prestera_acl_rule *rule;
 
-int prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
-				 struct prestera_acl_rule_action_entry *entry)
-{
-	struct prestera_acl_rule_action_entry *a_entry;
+	rule = kzalloc(sizeof(*rule), GFP_KERNEL);
+	if (!rule)
+		return ERR_PTR(-ENOMEM);
 
-	a_entry = kmalloc(sizeof(*a_entry), GFP_KERNEL);
-	if (!a_entry)
-		return -ENOMEM;
+	rule->ruleset = ruleset;
+	rule->cookie = cookie;
+	rule->chain_index = chain_index;
+	rule->hw_tc = PRESTERA_ACL_RULE_DEF_HW_TC;
 
-	memcpy(a_entry, entry, sizeof(*entry));
-	list_add(&a_entry->list, &rule->action_list);
+	refcount_inc(&ruleset->refcount);
 
-	rule->n_actions++;
-	return 0;
+	return rule;
 }
 
-u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule)
+void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
+				unsigned long flag)
 {
-	return rule->n_actions;
+	set_bit(flag, &rule->attr.flags);
 }
 
-u32 prestera_acl_rule_priority_get(struct prestera_acl_rule *rule)
+bool
+prestera_acl_rule_flag_test(const struct prestera_acl_rule *rule,
+			    unsigned long flag)
 {
-	return rule->priority;
+	return test_bit(flag, &rule->attr.flags);
 }
 
 void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
@@ -251,88 +507,196 @@ void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
 	rule->priority = priority;
 }
 
-int prestera_acl_rule_match_add(struct prestera_acl_rule *rule,
-				struct prestera_acl_rule_match_entry *entry)
+u8 prestera_acl_rule_hw_tc_get(struct prestera_acl_rule *rule)
 {
-	struct prestera_acl_rule_match_entry *m_entry;
-
-	m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-	if (!m_entry)
-		return -ENOMEM;
-
-	memcpy(m_entry, entry, sizeof(*entry));
-	list_add(&m_entry->list, &rule->match_list);
+	return rule->hw_tc;
+}
 
-	rule->n_matches++;
-	return 0;
+void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc)
+{
+	rule->hw_tc = hw_tc;
 }
 
-u8 prestera_acl_rule_match_len(struct prestera_acl_rule *rule)
+static int prestera_acl_nat_port_neigh_lookup(struct prestera_port *port,
+					      struct prestera_neigh_info *ni)
 {
-	return rule->n_matches;
+	struct prestera_kern_neigh_cache *n_cache;
+	struct prestera_neigh_info *n_info;
+	struct rhashtable_iter iter;
+	int err = -ENOENT;
+
+	rhashtable_walk_enter(&port->sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while ((n_cache = rhashtable_walk_next(&iter)) != NULL) {
+		if (IS_ERR(n_cache))
+			continue;
+		n_info = prestera_kern_neigh_cache_to_neigh_info(n_cache);
+		if (n_info->iface.type == PRESTERA_IF_PORT_E &&
+		    n_info->iface.dev_port.port_num == port->hw_id &&
+		    n_info->iface.dev_port.hw_dev_num == port->dev_id) {
+			memcpy(ni, n_info, sizeof(*n_info));
+			err = 0;
+			break;
+		}
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+	return err;
 }
 
 void prestera_acl_rule_destroy(struct prestera_acl_rule *rule)
 {
-	struct prestera_acl_rule_action_entry *a_entry;
-	struct prestera_acl_rule_match_entry *m_entry;
-	struct list_head *pos, *n;
+	if (rule->nat_port)
+		prestera_acl_nat_port_put(rule->nat_port);
 
-	list_for_each_safe(pos, n, &rule->match_list) {
-		m_entry = list_entry(pos, typeof(*m_entry), list);
-		list_del(pos);
-		kfree(m_entry);
-	}
-
-	list_for_each_safe(pos, n, &rule->action_list) {
-		a_entry = list_entry(pos, typeof(*a_entry), list);
-		list_del(pos);
-		kfree(a_entry);
-	}
+	if (rule->jump_ruleset)
+		/* release ruleset kept by jump action */
+		prestera_acl_ruleset_put(rule->jump_ruleset);
 
+	prestera_acl_ruleset_put(rule->ruleset);
 	kfree(rule);
 }
 
 int prestera_acl_rule_add(struct prestera_switch *sw,
 			  struct prestera_acl_rule *rule)
 {
-	u32 rule_id;
 	int err;
+	struct prestera_acl_ruleset *ruleset = rule->ruleset;
+	struct prestera_flow_block *block = ruleset->ht_key.block;
+	struct prestera_flow_block_binding *binding;
+	struct prestera_acl_nat_port *nat_port;
+	struct prestera_neigh_info n_info;
+
+	err = rule_flag_test(rule, CT) && rule_flag_test(rule, GOTO) ?
+	      -ENOTSUPP : 0;
+	if (err)
+		goto err_sanity;
 
 	/* try to add rule to hash table first */
-	err = rhashtable_insert_fast(&rule->block->ruleset->rule_ht,
-				     &rule->ht_node,
+	err = rhashtable_insert_fast(&ruleset->rule_ht, &rule->ht_node,
 				     prestera_acl_rule_ht_params);
 	if (err)
-		return err;
+		goto err_ht_insert;
 
-	/* add rule to hw */
-	err = prestera_hw_acl_rule_add(sw, rule, &rule_id);
+	prestera_acl_rule_keymask_pcl_id_set(rule, ruleset->pcl_id);
+	rule->re_arg.vtcam_id = ruleset->vtcam_id;
+	rule->re_key.prio = rule->priority;
+
+	/* setup counter */
+	rule->re_arg.count.valid = true;
+	err = prestera_acl_chain_to_client(ruleset->ht_key.chain_index,
+					   &rule->re_arg.count.client);
 	if (err)
 		goto err_rule_add;
 
-	rule->id = rule_id;
+	if (rule_flag_test(rule, CT)) {
+		err = prestera_ct_ft_offload_add_cb(sw, rule);
+		if (err)
+			goto err_rule_add;
 
-	list_add_tail(&rule->list, &sw->acl->rules);
+		goto hw_handled;
+	}
+
+	rule->re = prestera_acl_rule_entry_find(sw->acl, &rule->re_key);
+	err = WARN_ON(rule->re) ? -EEXIST : 0;
+	if (err)
+		goto err_rule_add;
+
+	rule->re = prestera_acl_rule_entry_create(sw->acl, &rule->re_key,
+						  &rule->re_arg);
+	err = !rule->re ? -EINVAL : 0;
+	if (err)
+		goto err_rule_add;
+
+	if (!rule_flag_test(rule, NAT))
+		goto nat_port_neigh_not_found;
+
+	/* TODO: assign port to NAT here instead of doing this in
+	 * flower action.
+	 *
+	 * Get first interface bound to the block same as
+	 * in NAT action for now
+	 */
+	binding = list_first_entry(&block->binding_list,
+				   struct prestera_flow_block_binding, list);
+	nat_port = prestera_acl_nat_port_get(sw->acl, binding->port->hw_id,
+					     binding->port->dev_id);
+	if (!nat_port) {
+		nat_port = prestera_acl_nat_port_create(sw->acl, binding->port);
+		MVSW_LOG_INFO("NAT port created");
+		err = !nat_port ? -EINVAL : 0;
+		if (err)
+			goto err_rule_add_nat;
+	}
+	rule->nat_port = nat_port;
+
+	/* try to lookup neigh for this port and update HW */
+	err = prestera_acl_nat_port_neigh_lookup(nat_port->port, &n_info);
+	if (err == -ENOENT) {
+		MVSW_LOG_INFO("Neighbour for NAT port not found");
+		goto nat_port_neigh_not_found;
+	}
+	if (err)
+		goto err_rule_add_nat;
+
+	MVSW_LOG_INFO("Found a neighbour for NAT port");
+	err = prestera_hw_nat_port_neigh_update(nat_port->port, n_info.ha);
+	if (err)
+		goto err_rule_add_nat;
+
+hw_handled:
+nat_port_neigh_not_found:
+	/* bind the block (all ports) to chain index 0, rest of
+	 * the chains are bound to goto action
+	 */
+	if (!ruleset->ht_key.chain_index && !ruleset->rule_count) {
+		err = prestera_acl_ruleset_block_bind(ruleset, block);
+		if (err)
+			goto err_acl_block_bind;
+	}
 
+	list_add_tail(&rule->list, &sw->acl->rules);
+	ruleset->ht_key.block->rule_count++;
+	ruleset->rule_count++;
 	return 0;
 
+err_acl_block_bind:
+err_rule_add_nat:
+	prestera_acl_rule_entry_destroy(sw->acl, rule->re);
 err_rule_add:
-	rhashtable_remove_fast(&rule->block->ruleset->rule_ht, &rule->ht_node,
+	rule->re = NULL;
+	rhashtable_remove_fast(&ruleset->rule_ht, &rule->ht_node,
 			       prestera_acl_rule_ht_params);
+err_ht_insert:
+err_sanity:
 	return err;
 }
 
 void prestera_acl_rule_del(struct prestera_switch *sw,
 			   struct prestera_acl_rule *rule)
 {
-	rhashtable_remove_fast(&rule->block->ruleset->rule_ht, &rule->ht_node,
+	struct prestera_acl_ruleset *ruleset = rule->ruleset;
+	struct prestera_flow_block *block = ruleset->ht_key.block;
+
+	rhashtable_remove_fast(&ruleset->rule_ht, &rule->ht_node,
 			       prestera_acl_rule_ht_params);
+	block->rule_count--;
+	ruleset->rule_count--;
 	list_del(&rule->list);
-	prestera_hw_acl_rule_del(sw, rule->id);
+
+	if (rule_flag_test(rule, CT)) {
+		prestera_ct_ft_offload_del_cb(sw, rule);
+	} else {
+		prestera_acl_rule_entry_destroy(sw->acl, rule->re);
+		prestera_acl_block_prio_update(sw, block);
+	}
+
+	/* unbind block (all ports) */
+	if (!ruleset->ht_key.chain_index && !ruleset->rule_count)
+		prestera_acl_ruleset_block_unbind(ruleset, block);
 }
 
-int prestera_acl_rule_get_stats(struct prestera_switch *sw,
+int prestera_acl_rule_get_stats(struct prestera_acl *acl,
 				struct prestera_acl_rule *rule,
 				u64 *packets, u64 *bytes, u64 *last_use)
 {
@@ -340,8 +704,10 @@ int prestera_acl_rule_get_stats(struct prestera_switch *sw,
 	u64 current_bytes;
 	int err;
 
-	err = prestera_hw_acl_rule_stats_get(sw, rule->id, &current_packets,
-					     &current_bytes);
+	err = prestera_counter_stats_get(acl->sw->counter,
+					 rule->re->counter.block,
+					 rule->re->counter.id,
+					 &current_packets, &current_bytes);
 	if (err)
 		return err;
 
@@ -352,25 +718,525 @@ int prestera_acl_rule_get_stats(struct prestera_switch *sw,
 	return 0;
 }
 
+/* HW objects infrastructure */
+static struct prestera_nh_mangle_entry *
+__prestera_nh_mangle_entry_find(struct prestera_switch *sw,
+				struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+
+	e = rhashtable_lookup_fast(&sw->acl->nh_mangle_entry_ht, key,
+				   __prestera_nh_mangle_entry_ht_params);
+	return IS_ERR(e) ? NULL : e;
+}
+
+static void
+__prestera_nh_mangle_entry_destroy(struct prestera_switch *sw,
+				   struct prestera_nh_mangle_entry *e)
+{
+	rhashtable_remove_fast(&sw->acl->nh_mangle_entry_ht, &e->ht_node,
+			       __prestera_nh_mangle_entry_ht_params);
+	list_del(&e->nh_neigh_head);
+	prestera_nh_neigh_put(sw, e->n);
+	WARN_ON(prestera_hw_nh_mangle_del(sw, e->hw_id));
+	kfree(e);
+}
+
+int prestera_nh_mangle_entry_set(struct prestera_switch *sw,
+				 struct prestera_nh_mangle_entry *e)
+{
+	return prestera_hw_nh_mangle_set(sw, e->hw_id,
+					 e->key.mangle.l4_src_valid,
+					 e->key.mangle.l4_src,
+					 e->key.mangle.l4_dst_valid,
+					 e->key.mangle.l4_dst,
+					 e->key.mangle.sip_valid,
+					 e->key.mangle.sip,
+					 e->key.mangle.dip_valid,
+					 e->key.mangle.dip,
+					 e->n->info);
+}
+
+static struct prestera_nh_mangle_entry *
+__prestera_nh_mangle_entry_create(struct prestera_switch *sw,
+				  struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+	int err;
+
+	e = kzalloc(sizeof(*e), GFP_KERNEL);
+	if (!e)
+		goto err_kzalloc;
+
+	memcpy(&e->key, key, sizeof(*key));
+	e->n = prestera_nh_neigh_get(sw, &e->key.n);
+	if (!e->n)
+		goto err_nh_get;
+
+	list_add(&e->nh_neigh_head, &e->n->nh_mangle_entry_list);
+
+	err = prestera_hw_nh_mangle_add(sw, &e->hw_id);
+	if (err)
+		goto err_hw_add;
+
+	err = prestera_nh_mangle_entry_set(sw, e);
+	if (err)
+		goto err_set;
+
+	err = rhashtable_insert_fast(&sw->acl->nh_mangle_entry_ht, &e->ht_node,
+				     __prestera_nh_mangle_entry_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	return e;
+
+err_ht_insert:
+err_set:
+	WARN_ON(prestera_hw_nh_mangle_del(sw, e->hw_id));
+err_hw_add:
+	list_del(&e->nh_neigh_head);
+	prestera_nh_neigh_put(sw, e->n);
+err_nh_get:
+	kfree(e);
+err_kzalloc:
+	return NULL;
+}
+
+static void prestera_nh_mangle_entry_put(struct prestera_switch *sw,
+					 struct prestera_nh_mangle_entry *e)
+{
+	if (!e->ref_cnt)
+		__prestera_nh_mangle_entry_destroy(sw, e);
+}
+
+static struct prestera_nh_mangle_entry *
+prestera_nh_mangle_entry_get(struct prestera_switch *sw,
+			     struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+
+	e = __prestera_nh_mangle_entry_find(sw, key);
+	if (!e)
+		e = __prestera_nh_mangle_entry_create(sw, key);
+
+	return e;
+}
+
+bool prestera_nh_mangle_entry_util_hw_state(struct prestera_switch *sw,
+					    struct prestera_nh_mangle_entry *e)
+{
+	int err;
+
+	/* Antijitter
+	 * Prevent situation, when we read state of nh_grp twice in short time,
+	 * and state bit is still cleared on second call. So just stuck active
+	 * state for MVSW_PR_NH_ACTIVE_JIFFER_FILTER, after last occurred.
+	 */
+	if (!time_before(jiffies, e->is_active_hw_cache_kick +
+			msecs_to_jiffies(MVSW_PR_NH_ACTIVE_JIFFER_FILTER))) {
+		err = prestera_hw_nh_mangle_get(sw, e->hw_id,
+						&e->is_active_hw_cache);
+		if (err) {
+			MVSW_LOG_ERROR("Failed to get nh_mangle %pI4n hw_state",
+				       &e->key.n.addr.u.ipv4);
+			return false;
+		}
+
+		e->is_active_hw_cache_kick = jiffies;
+	}
+
+	return e->is_active_hw_cache;
+}
+
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_find(struct prestera_acl *acl,
+			     struct prestera_acl_rule_entry_key *key)
+{
+	return rhashtable_lookup_fast(&acl->acl_rule_entry_ht, key,
+				      __prestera_acl_rule_entry_ht_params);
+}
+
+static int __prestera_acl_rule_entry2hw_del(struct prestera_switch *sw,
+					    struct prestera_acl_rule_entry *e)
+{
+	return prestera_hw_vtcam_rule_del(sw, e->vtcam_id, e->hw_id);
+}
+
+static int __prestera_acl_rule_entry2hw_add(struct prestera_switch *sw,
+					    struct prestera_acl_rule_entry *e)
+{
+	struct prestera_acl_hw_action_info act_hw[PRESTERA_ACL_ACTION_MAX];
+	int act_num;
+
+	memset(&act_hw, 0, sizeof(act_hw));
+	act_num = 0;
+
+	/* accept */
+	if (e->accept.valid) {
+		act_hw[act_num].id = PRESTERA_ACL_RULE_ACTION_ACCEPT;
+		act_num++;
+	}
+	/* drop */
+	if (e->drop.valid) {
+		act_hw[act_num].id = PRESTERA_ACL_RULE_ACTION_DROP;
+		act_num++;
+	}
+	/* trap */
+	if (e->trap.valid) {
+		act_hw[act_num].id = PRESTERA_ACL_RULE_ACTION_TRAP;
+		act_hw[act_num].trap = e->trap.i;
+		act_num++;
+	}
+	/* police */
+	if (e->police.valid) {
+		act_hw[act_num].id = PRESTERA_ACL_RULE_ACTION_POLICE;
+		act_hw[act_num].police = e->police.i;
+		act_num++;
+	}
+	/* nat */
+	if (e->nat.valid) {
+		act_hw[act_num].id = PRESTERA_ACL_RULE_ACTION_NAT;
+		act_hw[act_num].nat = e->nat.i;
+		act_num++;
+	}
+	/* jump */
+	if (e->jump.valid) {
+		act_hw[act_num].id = PRESTERA_ACL_RULE_ACTION_JUMP;
+		act_hw[act_num].jump = e->jump.i;
+		act_num++;
+	}
+	/* nh */
+	if (e->nh.valid) {
+		act_hw[act_num].id = PRESTERA_ACL_RULE_ACTION_NH;
+		act_hw[act_num].nh = e->nh.e->hw_id;
+		act_num++;
+	}
+	/* counter */
+	if (e->counter.block) {
+		act_hw[act_num].id = PRESTERA_ACL_RULE_ACTION_COUNT;
+		act_hw[act_num].count.id = e->counter.id;
+		act_num++;
+	}
+
+	return prestera_hw_vtcam_rule_add(sw, e->vtcam_id, e->key.prio,
+					  e->key.match.key, e->key.match.mask,
+					  act_hw, act_num, &e->hw_id);
+}
+
+static void
+__prestera_acl_rule_entry_act_destruct(struct prestera_switch *sw,
+				       struct prestera_acl_rule_entry *e)
+{
+	/* nh */
+	if (e->nh.valid) {
+		e->nh.e->ref_cnt--;
+		prestera_nh_mangle_entry_put(sw, e->nh.e);
+	}
+	/* counter */
+	prestera_counter_put(sw->counter, e->counter.block, e->counter.id);
+}
+
+void prestera_acl_rule_entry_destroy(struct prestera_acl *acl,
+				     struct prestera_acl_rule_entry *e)
+{
+	int ret;
+
+	rhashtable_remove_fast(&acl->acl_rule_entry_ht, &e->ht_node,
+			       __prestera_acl_rule_entry_ht_params);
+
+	ret = __prestera_acl_rule_entry2hw_del(acl->sw, e);
+	WARN_ON(ret && ret != -ENODEV);
+
+	__prestera_acl_rule_entry_act_destruct(acl->sw, e);
+	kfree(e);
+}
+
+static int
+__prestera_acl_rule_entry_act_construct(struct prestera_switch *sw,
+					struct prestera_acl_rule_entry *e,
+					struct prestera_acl_rule_entry_arg *arg)
+{
+	/* accept */
+	e->accept.valid = arg->accept.valid;
+	/* drop */
+	e->drop.valid = arg->drop.valid;
+	/* trap */
+	e->trap.valid = arg->trap.valid;
+	e->trap.i = arg->trap.i;
+	/* police */
+	e->police.valid = arg->police.valid;
+	e->police.i = arg->police.i;
+	/* nat */
+	e->nat.valid = arg->nat.valid;
+	e->nat.i = arg->nat.i;
+	/* jump */
+	e->jump.valid = arg->jump.valid;
+	e->jump.i = arg->jump.i;
+	/* nh */
+	if (arg->nh.valid) {
+		e->nh.e = prestera_nh_mangle_entry_get(sw, &arg->nh.k);
+		if (!e->nh.e)
+			goto err_out;
+
+		e->nh.e->ref_cnt++;
+		e->nh.valid = 1;
+	}
+	/* counter */
+	if (arg->count.valid) {
+		int err;
+
+		err = prestera_counter_get(sw->counter, arg->count.client,
+					   &e->counter.block,
+					   &e->counter.id);
+		if (err && arg->count.fail_on_err)
+			goto err_out;
+	}
+
+	return 0;
+
+err_out:
+	__prestera_acl_rule_entry_act_destruct(sw, e);
+	return -EINVAL;
+}
+
+/* TODO: move acl_rule entry and lowest objects to
+ * appropriate files (hw_nh.c, hw_match.c)
+ */
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_create(struct prestera_acl *acl,
+			       struct prestera_acl_rule_entry_key *key,
+			       struct prestera_acl_rule_entry_arg *arg)
+{
+	struct prestera_acl_rule_entry *e;
+	int err;
+
+	e = kzalloc(sizeof(*e), GFP_KERNEL);
+	if (!e)
+		goto err_kzalloc;
+
+	memcpy(&e->key, key, sizeof(*key));
+	e->vtcam_id = arg->vtcam_id;
+	err = __prestera_acl_rule_entry_act_construct(acl->sw, e, arg);
+	if (err)
+		goto err_act_construct;
+
+	err = __prestera_acl_rule_entry2hw_add(acl->sw, e);
+	if (err)
+		goto err_hw_add;
+
+	err = rhashtable_insert_fast(&acl->acl_rule_entry_ht, &e->ht_node,
+				     __prestera_acl_rule_entry_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	return e;
+
+err_ht_insert:
+	WARN_ON(__prestera_acl_rule_entry2hw_del(acl->sw, e));
+err_hw_add:
+	__prestera_acl_rule_entry_act_destruct(acl->sw, e);
+err_act_construct:
+	kfree(e);
+err_kzalloc:
+	return NULL;
+}
+
+static int __prestera_acl_vtcam_id_try_fit(struct prestera_acl *acl, u8 lookup,
+					   void *keymask, u32 *vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	int i;
+
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (lookup != vtcam->lookup)
+			continue;
+
+		if (!keymask && !vtcam->is_keymask_set)
+			goto vtcam_found;
+
+		if (!(keymask && vtcam->is_keymask_set))
+			continue;
+
+		/* try to fit with vtcam keymask */
+		for (i = 0; i < __PRESTERA_ACL_RULE_MATCH_TYPE_MAX; i++) {
+			__be32 __keymask = ((__be32 *)keymask)[i];
+
+			if (!__keymask)
+				/* vtcam keymask in not interested */
+				continue;
+
+			if (__keymask & ~vtcam->keymask[i])
+				/* keymask does not fit the vtcam keymask */
+				break;
+		}
+
+		if (i == __PRESTERA_ACL_RULE_MATCH_TYPE_MAX)
+			/* keymask fits vtcam keymask, return it */
+			goto vtcam_found;
+	}
+
+	/* nothing is found */
+	return -ENOENT;
+
+vtcam_found:
+	refcount_inc(&vtcam->refcount);
+	*vtcam_id = vtcam->id;
+	return 0;
+}
+
+int prestera_acl_vtcam_id_get(struct prestera_acl *acl, u8 lookup, u8 dir,
+			      void *keymask, u32 *vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	u32 new_vtcam_id;
+	int err;
+
+	/* find the vtcam that suits keymask. We do not expect to have
+	 * a big number of vtcams, so, the list type for vtcam list is
+	 * fine for now
+	 */
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (lookup != vtcam->lookup ||
+		    dir != vtcam->direction)
+			continue;
+
+		if (!keymask && !vtcam->is_keymask_set) {
+			refcount_inc(&vtcam->refcount);
+			goto vtcam_found;
+		}
+
+		if (keymask && vtcam->is_keymask_set &&
+		    !memcmp(keymask, vtcam->keymask, sizeof(vtcam->keymask))) {
+			refcount_inc(&vtcam->refcount);
+			goto vtcam_found;
+		}
+	}
+
+	/* vtcam not found, try to create new one */
+	vtcam = kzalloc(sizeof(*vtcam), GFP_KERNEL);
+	if (!vtcam)
+		return -ENOMEM;
+
+	err = prestera_hw_vtcam_create(acl->sw, lookup, keymask, &new_vtcam_id,
+				       dir);
+	if (err) {
+		kfree(vtcam);
+
+		/* cannot create new, try to fit into existing vtcam */
+		if (__prestera_acl_vtcam_id_try_fit(acl, lookup,
+						    keymask, &new_vtcam_id))
+			return err;
+
+		*vtcam_id = new_vtcam_id;
+		return 0;
+	}
+
+	vtcam->direction = dir;
+	vtcam->id = new_vtcam_id;
+	vtcam->lookup = lookup;
+	if (keymask) {
+		memcpy(vtcam->keymask, keymask, sizeof(vtcam->keymask));
+		vtcam->is_keymask_set = true;
+	}
+	refcount_set(&vtcam->refcount, 1);
+	list_add_rcu(&vtcam->list, &acl->vtcam_list);
+
+vtcam_found:
+	*vtcam_id = vtcam->id;
+	return 0;
+}
+
+int prestera_acl_vtcam_id_put(struct prestera_acl *acl, u32 vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	int err;
+
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (vtcam_id != vtcam->id)
+			continue;
+
+		if (!refcount_dec_and_test(&vtcam->refcount))
+			return 0;
+
+		err = prestera_hw_vtcam_destroy(acl->sw, vtcam->id);
+		if (err && err != -ENODEV) {
+			refcount_set(&vtcam->refcount, 1);
+			return err;
+		}
+
+		list_del(&vtcam->list);
+		kfree(vtcam);
+		return 0;
+	}
+
+	return -ENOENT;
+}
+
 int prestera_acl_init(struct prestera_switch *sw)
 {
 	struct prestera_acl *acl;
+	int err;
 
 	acl = kzalloc(sizeof(*acl), GFP_KERNEL);
 	if (!acl)
 		return -ENOMEM;
 
+	acl->sw = sw;
 	INIT_LIST_HEAD(&acl->rules);
+	INIT_LIST_HEAD(&acl->nat_port_list);
+	INIT_LIST_HEAD(&acl->vtcam_list);
+	idr_init(&acl->uid);
+
+	err = rhashtable_init(&acl->acl_rule_entry_ht,
+			      &__prestera_acl_rule_entry_ht_params);
+	if (err)
+		goto err_acl_rule_entry_ht_init;
+
+	err = rhashtable_init(&acl->nh_mangle_entry_ht,
+			      &__prestera_nh_mangle_entry_ht_params);
+	if (err)
+		goto err_nh_mangle_entry_ht_init;
+
+	err = rhashtable_init(&acl->ruleset_ht,
+			      &prestera_acl_ruleset_ht_params);
+	if (err)
+		goto err_ruleset_ht_init;
+
+	acl->ct_priv = prestera_ct_init(acl);
+	if (IS_ERR(acl->ct_priv)) {
+		err = PTR_ERR(acl->ct_priv);
+		goto err_ct_init;
+	}
+
 	sw->acl = acl;
-	acl->sw = sw;
 
 	return 0;
+
+err_ct_init:
+	rhashtable_destroy(&acl->ruleset_ht);
+err_ruleset_ht_init:
+	rhashtable_destroy(&acl->nh_mangle_entry_ht);
+err_nh_mangle_entry_ht_init:
+	rhashtable_destroy(&acl->acl_rule_entry_ht);
+err_acl_rule_entry_ht_init:
+	kfree(acl);
+	return err;
 }
 
 void prestera_acl_fini(struct prestera_switch *sw)
 {
 	struct prestera_acl *acl = sw->acl;
 
+	prestera_ct_clean(acl->ct_priv);
+	idr_destroy(&acl->uid);
+
+	WARN_ON(!list_empty(&acl->vtcam_list));
+	WARN_ON(!list_empty(&acl->nat_port_list));
 	WARN_ON(!list_empty(&acl->rules));
+
+	rhashtable_destroy(&acl->ruleset_ht);
+	rhashtable_destroy(&acl->nh_mangle_entry_ht);
+	rhashtable_destroy(&acl->acl_rule_entry_ht);
+
 	kfree(acl);
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_acl.h b/drivers/net/ethernet/marvell/prestera/prestera_acl.h
index 39b7869be659..40cbf8756291 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_acl.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_acl.h
@@ -1,114 +1,237 @@
 /* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
-/* Copyright (c) 2020 Marvell International Ltd. All rights reserved. */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _PRESTERA_ACL_H_
 #define _PRESTERA_ACL_H_
 
-enum prestera_acl_rule_match_entry_type {
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE = 1,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_PORT,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE,
-	PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE
+#include <linux/types.h>
+#include "prestera_ct.h"
+#include "prestera_counter.h"
+
+#define PRESTERA_ACL_RULE_DEF_HW_CHAIN_ID	0
+
+#define PRESTERA_ACL_KEYMASK_PCL_ID		0x3FF
+#define PRESTERA_ACL_KEYMASK_PCL_ID_USER			\
+	(PRESTERA_ACL_KEYMASK_PCL_ID & 0x00FF)
+#define PRESTERA_ACL_KEYMASK_PCL_ID_CHAIN			\
+	(PRESTERA_ACL_KEYMASK_PCL_ID & 0xFF00)
+#define PRESTERA_ACL_CHAIN_MASK					\
+	(PRESTERA_ACL_KEYMASK_PCL_ID >> 8)
+
+#define PRESTERA_ACL_PCL_ID_MAKE(uid, chain_id)			\
+	(((uid) & PRESTERA_ACL_KEYMASK_PCL_ID_USER) |		\
+	(((chain_id) << 8) & PRESTERA_ACL_KEYMASK_PCL_ID_CHAIN))
+
+#define rule_flag_set(rule, flag) \
+	prestera_acl_rule_flag_set(rule, PRESTERA_ACL_RULE_FLAG_##flag)
+#define rule_flag_test(rule, flag) \
+	prestera_acl_rule_flag_test(rule, PRESTERA_ACL_RULE_FLAG_##flag)
+
+#define rule_match_set_n(match_p, type, val_p, size)		\
+	memcpy(&(match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type],	\
+	       val_p, size)
+#define rule_match_set(match_p, type, val)			\
+	memcpy(&(match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type],	\
+	       &(val), sizeof(val))
+#define rule_match_set_u32(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       htonl(val))
+#define rule_match_set_u16(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       (__force __be32)htons(val))
+#define rule_match_set_u8(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       (__force __be32)(val))
+#define rule_match_get_u32(match_p, type)			\
+	(match_p[PRESTERA_ACL_RULE_MATCH_TYPE_##type])
+
+#define MVSW_ACL_RULE_DEF_HW_CHAIN_ID	0
+#define MVSW_ACL_RULESET_ALL		0xff
+
+#define PRESTERA_ACL_ACTION_MAX 8
+
+/* HW objects infrastructure */
+struct prestera_mangle_cfg {
+	u8 l4_src_valid:1, l4_dst_valid:1,
+	   sip_valid:1, dip_valid:1;
+	__be16 l4_src;
+	__be16 l4_dst;
+	struct prestera_ip_addr sip;
+	struct prestera_ip_addr dip;
 };
 
-enum prestera_acl_rule_action {
-	PRESTERA_ACL_RULE_ACTION_ACCEPT,
-	PRESTERA_ACL_RULE_ACTION_DROP,
-	PRESTERA_ACL_RULE_ACTION_TRAP
+/* TODO: Move mangle_entry to router ? */
+struct prestera_nh_mangle_entry {
+	struct rhash_head ht_node; /* node of prestera_router */
+	struct prestera_nh_mangle_entry_key {
+		struct prestera_mangle_cfg mangle;
+		struct prestera_nh_neigh_key n;
+	} key;
+	struct prestera_nh_neigh *n;
+	u32 hw_id;
+	unsigned long is_active_hw_cache_kick; /* jiffies */
+	bool is_active_hw_cache;
+	u32 ref_cnt;
+	struct list_head nh_neigh_head;
 };
 
-struct prestera_switch;
-struct prestera_port;
-struct prestera_acl_rule;
-struct prestera_acl_ruleset;
+struct prestera_acl_rule_entry {
+	struct rhash_head ht_node; /* node of prestera_sw */
+	struct prestera_acl_rule_entry_key {
+		u32 prio;
+		struct prestera_acl_match match;
+	} key;
+	u32 hw_id;
+	u32 vtcam_id;
+	/* This struct seems to be dublicate of arg, but purpose is to pass
+	 * in cfg objet keys, resolve them and save object links here.
+	 * E.g. chain can be link to object, when chain_id just key in cfg.
+	 */
+	struct {
+		struct {
+			u8 valid:1;
+		} accept, drop;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_trap i;
+		} trap;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_police i;
+		} police;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_nat i;
+		} nat;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_jump i;
+		} jump;
+		struct {
+			u8 valid:1;
+			struct prestera_nh_mangle_entry *e; /* entry */
+		} nh;
+		struct {
+			u32 id;
+			struct prestera_counter_block *block;
+		} counter;
+	};
+};
 
-struct prestera_flow_block_binding {
-	struct list_head list;
-	struct prestera_port *port;
-	int span_id;
+/* This struct (arg) used only to be passed as parameter for
+ * acl_rule_entry_create. Must be flat. Can contain object keys, which will be
+ * resolved to object links, before saving to acl_rule_entry struct
+ */
+struct prestera_acl_rule_entry_arg {
+	u32 vtcam_id;
+	struct {
+		struct {
+			u8 valid:1;
+		} accept, drop;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_trap i;
+		} trap;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_police i;
+		} police;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_nat i;
+		} nat;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_jump i;
+		} jump;
+		struct {
+			u8 valid:1;
+			struct prestera_nh_mangle_entry_key k; /* key */
+		} nh;
+		struct {
+			u8 valid:1, fail_on_err:1;
+			u32 client;
+		} count;
+	};
 };
 
-struct prestera_flow_block {
-	struct list_head binding_list;
+enum {
+	PRESTERA_ACL_RULE_FLAG_CT,
+	PRESTERA_ACL_RULE_FLAG_GOTO,
+	PRESTERA_ACL_RULE_FLAG_NAT
+};
+
+struct prestera_acl_stats {
+	u64 packets;
+	u64 bytes;
+};
+
+struct prestera_acl {
 	struct prestera_switch *sw;
-	struct net *net;
-	struct prestera_acl_ruleset *ruleset;
-	struct flow_block_cb *block_cb;
+	struct list_head nat_port_list;
+	struct list_head vtcam_list;
+	struct list_head rules;
+	struct rhashtable ruleset_ht;
+	struct rhashtable acl_rule_entry_ht;
+	/* TODO: move nh_mangle_entry_ht to router ? */
+	struct rhashtable nh_mangle_entry_ht;
+	struct prestera_ct_priv *ct_priv;
+	struct idr uid;
 };
 
-struct prestera_acl_rule_action_entry {
+struct prestera_acl_nat_port {
 	struct list_head list;
-	enum prestera_acl_rule_action id;
+	struct prestera_port *port;
+	refcount_t refcount;
 };
 
-struct prestera_acl_rule_match_entry {
+struct prestera_acl_rule_attr {
+	struct prestera_ct_attr ct_attr;
+	unsigned long flags;
+};
+
+struct prestera_acl_rule {
+	struct rhash_head ht_node; /* Member of acl HT */
 	struct list_head list;
-	enum prestera_acl_rule_match_entry_type type;
+	struct prestera_acl_nat_port *nat_port;
+	struct prestera_acl_rule_attr attr;
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl_ruleset *jump_ruleset;
+	unsigned long cookie;
+	u32 chain_index;
+	u32 priority;
+	u8 hw_tc;
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_rule_entry *re;
+};
+
+enum {
+	PRESTERA_ACL_IFACE_TYPE_PORT,
+	PRESTERA_ACL_IFACE_TYPE_INDEX
+};
+
+struct prestera_acl_iface {
+	u8 type;
 	union {
-		struct {
-			u8 key;
-			u8 mask;
-		} u8;
-		struct {
-			u16 key;
-			u16 mask;
-		} u16;
-		struct {
-			u32 key;
-			u32 mask;
-		} u32;
-		struct {
-			u64 key;
-			u64 mask;
-		} u64;
-		struct {
-			u8 key[ETH_ALEN];
-			u8 mask[ETH_ALEN];
-		} mac;
-	} keymask;
+		struct prestera_port *port;
+		u32 index;
+	};
 };
 
-int prestera_acl_init(struct prestera_switch *sw);
-void prestera_acl_fini(struct prestera_switch *sw);
-struct prestera_flow_block *
-prestera_acl_block_create(struct prestera_switch *sw, struct net *net);
-void prestera_acl_block_destroy(struct prestera_flow_block *block);
-struct net *prestera_acl_block_net(struct prestera_flow_block *block);
-struct prestera_switch *prestera_acl_block_sw(struct prestera_flow_block *block);
-int prestera_acl_block_bind(struct prestera_flow_block *block,
-			    struct prestera_port *port);
-int prestera_acl_block_unbind(struct prestera_flow_block *block,
-			      struct prestera_port *port);
-struct prestera_acl_ruleset *
-prestera_acl_block_ruleset_get(struct prestera_flow_block *block);
+void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
+				unsigned long flag);
+bool
+prestera_acl_rule_flag_test(const struct prestera_acl_rule *rule,
+			    unsigned long flag);
 struct prestera_acl_rule *
-prestera_acl_rule_create(struct prestera_flow_block *block,
-			 unsigned long cookie);
-u32 prestera_acl_rule_priority_get(struct prestera_acl_rule *rule);
+prestera_acl_rule_create(struct prestera_acl_ruleset *ruleset,
+			 unsigned long cookie, u32 chain_index);
 void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
 				    u32 priority);
-u16 prestera_acl_rule_ruleset_id_get(const struct prestera_acl_rule *rule);
-struct list_head *
-prestera_acl_rule_action_list_get(struct prestera_acl_rule *rule);
-u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule);
-u8 prestera_acl_rule_match_len(struct prestera_acl_rule *rule);
-int prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
-				 struct prestera_acl_rule_action_entry *entry);
-struct list_head *
-prestera_acl_rule_match_list_get(struct prestera_acl_rule *rule);
-int prestera_acl_rule_match_add(struct prestera_acl_rule *rule,
-				struct prestera_acl_rule_match_entry *entry);
+u8 prestera_acl_rule_hw_tc_get(struct prestera_acl_rule *rule);
+void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc);
+u8 prestera_acl_rule_hw_chain_id_get(const struct prestera_acl_rule *rule);
 void prestera_acl_rule_destroy(struct prestera_acl_rule *rule);
 struct prestera_acl_rule *
 prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
@@ -117,8 +240,47 @@ int prestera_acl_rule_add(struct prestera_switch *sw,
 			  struct prestera_acl_rule *rule);
 void prestera_acl_rule_del(struct prestera_switch *sw,
 			   struct prestera_acl_rule *rule);
-int prestera_acl_rule_get_stats(struct prestera_switch *sw,
+int prestera_acl_rule_get_stats(struct prestera_acl *acl,
 				struct prestera_acl_rule *rule,
 				u64 *packets, u64 *bytes, u64 *last_use);
 
+int prestera_nh_mangle_entry_set(struct prestera_switch *sw,
+				 struct prestera_nh_mangle_entry *e);
+bool prestera_nh_mangle_entry_util_hw_state(struct prestera_switch *sw,
+					    struct prestera_nh_mangle_entry *e);
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_find(struct prestera_acl *acl,
+			     struct prestera_acl_rule_entry_key *key);
+void prestera_acl_rule_entry_destroy(struct prestera_acl *acl,
+				     struct prestera_acl_rule_entry *e);
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_create(struct prestera_acl *acl,
+			       struct prestera_acl_rule_entry_key *key,
+			       struct prestera_acl_rule_entry_arg *arg);
+int prestera_acl_chain_to_client(u32 chain_index, u32 *client);
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_get(struct prestera_acl *acl,
+			 struct prestera_flow_block *block,
+			 u32 chain_index);
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index);
+int prestera_acl_ruleset_keymask_set(struct prestera_acl_ruleset *ruleset,
+				     void *keymask);
+int prestera_acl_ruleset_offload(struct prestera_acl_ruleset *ruleset);
+u32 prestera_acl_ruleset_index_get(const struct prestera_acl_ruleset *ruleset);
+bool prestera_acl_ruleset_is_offload(struct prestera_acl_ruleset *ruleset);
+void prestera_acl_ruleset_put(struct prestera_acl_ruleset *ruleset);
+int prestera_acl_ruleset_bind(struct prestera_acl_ruleset *ruleset,
+			      struct prestera_port *port);
+int prestera_acl_ruleset_unbind(struct prestera_acl_ruleset *ruleset,
+				struct prestera_port *port);
+void
+prestera_acl_rule_keymask_pcl_id_set(struct prestera_acl_rule *rule,
+				     u16 pcl_id);
+int prestera_acl_vtcam_id_get(struct prestera_acl *acl, u8 lookup, u8 dir,
+			      void *keymask, u32 *vtcam_id);
+int prestera_acl_vtcam_id_put(struct prestera_acl *acl, u32 vtcam_id);
+
 #endif /* _PRESTERA_ACL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_counter.c b/drivers/net/ethernet/marvell/prestera/prestera_counter.c
new file mode 100644
index 000000000000..7020c03ef330
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_counter.c
@@ -0,0 +1,475 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2021 Marvell International Ltd. All rights reserved */
+
+#include "prestera.h"
+#include "prestera_hw.h"
+#include "prestera_acl.h"
+#include "prestera_counter.h"
+
+#define COUNTER_POLL_TIME	(msecs_to_jiffies(1000))
+#define COUNTER_RESCHED_TIME	(msecs_to_jiffies(50))
+#define COUNTER_BULK_SIZE	(256)
+
+struct prestera_counter {
+	struct prestera_switch *sw;
+	struct delayed_work stats_dw;
+	bool is_fetching;
+	u32 total_read;
+	struct mutex mtx;  /* protect block_list */
+	struct prestera_counter_block **block_list;
+	u32 block_list_len;
+	u32 curr_idx;
+};
+
+struct prestera_counter_block {
+	struct list_head list;
+	u32 id;
+	u32 offset;
+	u32 num_counters;
+	u32 client;
+	struct idr counter_idr;
+	bool full;
+	bool is_updating;
+	refcount_t refcnt;
+	struct mutex mtx;  /* protect stats and counter_idr */
+	struct prestera_counter_stats *stats;
+	u8 *counter_flag;
+};
+
+enum {
+	COUNTER_FLAG_READY = 0,
+	COUNTER_FLAG_INVALID = 1
+};
+
+static inline bool
+prestera_counter_is_ready(struct prestera_counter_block *block, u32 id)
+{
+	return block->counter_flag[id - block->offset] == COUNTER_FLAG_READY;
+}
+
+static void prestera_counter_lock(struct prestera_counter *counter)
+{
+	mutex_lock(&counter->mtx);
+}
+
+static void prestera_counter_unlock(struct prestera_counter *counter)
+{
+	mutex_unlock(&counter->mtx);
+}
+
+static void prestera_counter_block_lock(struct prestera_counter_block *block)
+{
+	mutex_lock(&block->mtx);
+}
+
+static void prestera_counter_block_unlock(struct prestera_counter_block *block)
+{
+	mutex_unlock(&block->mtx);
+}
+
+static bool prestera_counter_block_incref(struct prestera_counter_block *block)
+{
+	return refcount_inc_not_zero(&block->refcnt);
+}
+
+static bool prestera_counter_block_decref(struct prestera_counter_block *block)
+{
+	return refcount_dec_and_test(&block->refcnt);
+}
+
+/* must be called with prestera_counter_block_lock() */
+static void prestera_counter_stats_clear(struct prestera_counter_block *block,
+					 u32 counter_id)
+{
+	memset(&block->stats[counter_id - block->offset], 0,
+	       sizeof(*block->stats));
+}
+
+static struct prestera_counter_block *
+prestera_counter_block_lookup_not_full(struct prestera_counter *counter,
+				       u32 client)
+{
+	u32 i;
+
+	prestera_counter_lock(counter);
+	for (i = 0; i < counter->block_list_len; i++) {
+		if (counter->block_list[i] &&
+		    counter->block_list[i]->client == client &&
+		    !counter->block_list[i]->full &&
+		    prestera_counter_block_incref(counter->block_list[i])) {
+			prestera_counter_unlock(counter);
+			return counter->block_list[i];
+		}
+	}
+	prestera_counter_unlock(counter);
+
+	return NULL;
+}
+
+static int prestera_counter_block_list_add(struct prestera_counter *counter,
+					   struct prestera_counter_block *block)
+{
+	struct prestera_counter_block **arr;
+	u32 i;
+
+	prestera_counter_lock(counter);
+
+	for (i = 0; i < counter->block_list_len; i++) {
+		if (counter->block_list[i])
+			continue;
+
+		counter->block_list[i] = block;
+		prestera_counter_unlock(counter);
+		return 0;
+	}
+
+	arr = krealloc(counter->block_list, (counter->block_list_len + 1) *
+		       sizeof(*counter->block_list), GFP_KERNEL);
+	if (!arr) {
+		prestera_counter_unlock(counter);
+		return -ENOMEM;
+	}
+
+	counter->block_list = arr;
+	counter->block_list[counter->block_list_len] = block;
+	counter->block_list_len++;
+	prestera_counter_unlock(counter);
+	return 0;
+}
+
+static struct prestera_counter_block *
+prestera_counter_block_get(struct prestera_counter *counter,
+			   u32 client)
+{
+	struct prestera_counter_block *block;
+	int err;
+
+	block = prestera_counter_block_lookup_not_full(counter, client);
+	if (!block) {
+		block = kzalloc(sizeof(*block), GFP_KERNEL);
+		if (!block)
+			return ERR_PTR(-ENOMEM);
+
+		err = prestera_hw_counter_block_get(counter->sw, client,
+						    &block->id, &block->offset,
+						    &block->num_counters);
+		if (err)
+			goto err_block;
+
+		block->stats = kcalloc(block->num_counters,
+				       sizeof(*block->stats), GFP_KERNEL);
+		if (!block->stats) {
+			err = -ENOMEM;
+			goto err_stats;
+		}
+
+		block->counter_flag = kcalloc(block->num_counters,
+					      sizeof(*block->counter_flag),
+					      GFP_KERNEL);
+		if (!block->counter_flag) {
+			err = -ENOMEM;
+			goto err_flag;
+		}
+
+		block->client = client;
+		mutex_init(&block->mtx);
+		refcount_set(&block->refcnt, 1);
+		idr_init_base(&block->counter_idr, block->offset);
+
+		err = prestera_counter_block_list_add(counter, block);
+		if (err)
+			goto err_list_add;
+	}
+
+	return block;
+
+err_list_add:
+	idr_destroy(&block->counter_idr);
+	mutex_destroy(&block->mtx);
+	kfree(block->counter_flag);
+err_flag:
+	kfree(block->stats);
+err_stats:
+	prestera_hw_counter_block_release(counter->sw, block->id);
+err_block:
+	kfree(block);
+	return ERR_PTR(err);
+}
+
+static void prestera_counter_block_put(struct prestera_counter *counter,
+				       struct prestera_counter_block *block)
+{
+	u32 i;
+
+	if (!prestera_counter_block_decref(block))
+		return;
+
+	prestera_counter_lock(counter);
+	for (i = 0; i < counter->block_list_len; i++) {
+		if (counter->block_list[i] &&
+		    counter->block_list[i]->id == block->id) {
+			counter->block_list[i] = NULL;
+			break;
+		}
+	}
+	prestera_counter_unlock(counter);
+
+	WARN_ON(!idr_is_empty(&block->counter_idr));
+
+	prestera_hw_counter_block_release(counter->sw, block->id);
+	idr_destroy(&block->counter_idr);
+	mutex_destroy(&block->mtx);
+	kfree(block->stats);
+	kfree(block);
+}
+
+static int prestera_counter_get_vacant(struct prestera_counter_block *block,
+				       u32 *id)
+{
+	int free_id;
+
+	if (block->full)
+		return -ENOSPC;
+
+	prestera_counter_block_lock(block);
+	free_id = idr_alloc_cyclic(&block->counter_idr, NULL, block->offset,
+				   block->offset + block->num_counters,
+				   GFP_KERNEL);
+	if (free_id < 0) {
+		if (free_id == -ENOSPC)
+			block->full = true;
+
+		prestera_counter_block_unlock(block);
+		return free_id;
+	}
+	*id = free_id;
+	prestera_counter_block_unlock(block);
+
+	return 0;
+}
+
+int prestera_counter_get(struct prestera_counter *counter, u32 client,
+			 struct prestera_counter_block **bl, u32 *counter_id)
+{
+	struct prestera_counter_block *block;
+	int err;
+	u32 id;
+
+get_next_block:
+	block = prestera_counter_block_get(counter, client);
+	if (IS_ERR(block))
+		return PTR_ERR(block);
+
+	err = prestera_counter_get_vacant(block, &id);
+	if (err) {
+		prestera_counter_block_put(counter, block);
+
+		if (err == -ENOSPC)
+			goto get_next_block;
+
+		return err;
+	}
+
+	prestera_counter_block_lock(block);
+	if (block->is_updating)
+		block->counter_flag[id - block->offset] = COUNTER_FLAG_INVALID;
+	prestera_counter_block_unlock(block);
+
+	*counter_id = id;
+	*bl = block;
+
+	return 0;
+}
+
+void prestera_counter_put(struct prestera_counter *counter,
+			  struct prestera_counter_block *block, u32 counter_id)
+{
+	if (!block)
+		return;
+
+	prestera_counter_block_lock(block);
+	idr_remove(&block->counter_idr, counter_id);
+	block->full = false;
+	prestera_counter_stats_clear(block, counter_id);
+	prestera_counter_block_unlock(block);
+
+	prestera_hw_counter_clear(counter->sw, block->id, counter_id);
+	prestera_counter_block_put(counter, block);
+}
+
+static u32 prestera_counter_block_idx_next(struct prestera_counter *counter,
+					   u32 curr_idx)
+{
+	u32 idx, i, start = curr_idx + 1;
+
+	prestera_counter_lock(counter);
+	for (i = 0; i < counter->block_list_len; i++) {
+		idx = (start + i) % counter->block_list_len;
+		if (!counter->block_list[idx])
+			continue;
+
+		prestera_counter_unlock(counter);
+		return idx;
+	}
+	prestera_counter_unlock(counter);
+
+	return 0;
+}
+
+static struct prestera_counter_block *
+prestera_counter_block_get_by_idx(struct prestera_counter *counter, u32 idx)
+{
+	if (idx >= counter->block_list_len)
+		return NULL;
+
+	prestera_counter_lock(counter);
+
+	if (!counter->block_list[idx] ||
+	    !prestera_counter_block_incref(counter->block_list[idx])) {
+		prestera_counter_unlock(counter);
+		return NULL;
+	}
+
+	prestera_counter_unlock(counter);
+	return counter->block_list[idx];
+}
+
+static void prestera_counter_stats_work(struct work_struct *work)
+{
+	struct delayed_work *dl_work =
+		container_of(work, struct delayed_work, work);
+	struct prestera_counter *counter =
+		container_of(dl_work, struct prestera_counter, stats_dw);
+	struct prestera_counter_block *block;
+	u32 resched_time = COUNTER_POLL_TIME;
+	u32 count = COUNTER_BULK_SIZE;
+	bool done = false;
+	int err;
+	u32 i;
+
+	block = prestera_counter_block_get_by_idx(counter, counter->curr_idx);
+	if (!block) {
+		if (counter->is_fetching)
+			goto abort;
+
+		goto next;
+	}
+
+	if (!counter->is_fetching) {
+		err = prestera_hw_counter_trigger(counter->sw, block->id);
+		if (err)
+			goto abort;
+
+		prestera_counter_block_lock(block);
+		block->is_updating = true;
+		prestera_counter_block_unlock(block);
+
+		counter->is_fetching = true;
+		counter->total_read = 0;
+		resched_time = COUNTER_RESCHED_TIME;
+		goto resched;
+	}
+
+	prestera_counter_block_lock(block);
+	err = prestera_hw_counters_get(counter->sw, counter->total_read,
+				       &count, &done,
+				       &block->stats[counter->total_read]);
+	prestera_counter_block_unlock(block);
+	if (err)
+		goto abort;
+
+	counter->total_read += count;
+	if (!done || counter->total_read < block->num_counters) {
+		resched_time = COUNTER_RESCHED_TIME;
+		goto resched;
+	}
+
+	for (i = 0; i < block->num_counters; i++) {
+		if (block->counter_flag[i] == COUNTER_FLAG_INVALID) {
+			prestera_counter_block_lock(block);
+			block->counter_flag[i] = COUNTER_FLAG_READY;
+			memset(&block->stats[i], 0, sizeof(*block->stats));
+			prestera_counter_block_unlock(block);
+		}
+	}
+
+	prestera_counter_block_lock(block);
+	block->is_updating = false;
+	prestera_counter_block_unlock(block);
+
+	goto next;
+abort:
+	prestera_hw_counter_abort(counter->sw);
+next:
+	counter->is_fetching = false;
+	counter->curr_idx =
+		prestera_counter_block_idx_next(counter, counter->curr_idx);
+resched:
+	if (block)
+		prestera_counter_block_put(counter, block);
+
+	schedule_delayed_work(&counter->stats_dw, resched_time);
+}
+
+/* Can be executed without rtnl_lock().
+ * So pay attention when something changing.
+ */
+int prestera_counter_stats_get(struct prestera_counter *counter,
+			       struct prestera_counter_block *block,
+			       u32 counter_id, u64 *packets, u64 *bytes)
+{
+	if (!block || !prestera_counter_is_ready(block, counter_id)) {
+		*packets = 0;
+		*bytes = 0;
+		return 0;
+	}
+
+	prestera_counter_block_lock(block);
+	*packets = block->stats[counter_id - block->offset].packets;
+	*bytes = block->stats[counter_id - block->offset].bytes;
+
+	prestera_counter_stats_clear(block, counter_id);
+	prestera_counter_block_unlock(block);
+
+	return 0;
+}
+
+int prestera_counter_init(struct prestera_switch *sw)
+{
+	struct prestera_counter *counter;
+
+	counter = kzalloc(sizeof(*counter), GFP_KERNEL);
+	if (!counter)
+		return -ENOMEM;
+
+	counter->block_list = kzalloc(sizeof(*counter->block_list), GFP_KERNEL);
+	if (!counter->block_list) {
+		kfree(counter);
+		return -ENOMEM;
+	}
+
+	mutex_init(&counter->mtx);
+	counter->block_list_len = 1;
+	counter->sw = sw;
+	sw->counter = counter;
+
+	INIT_DELAYED_WORK(&counter->stats_dw, prestera_counter_stats_work);
+	schedule_delayed_work(&counter->stats_dw, COUNTER_POLL_TIME);
+
+	return 0;
+}
+
+void prestera_counter_fini(struct prestera_switch *sw)
+{
+	struct prestera_counter *counter = sw->counter;
+	u32 i;
+
+	cancel_delayed_work_sync(&counter->stats_dw);
+
+	for (i = 0; i < counter->block_list_len; i++)
+		WARN_ON(counter->block_list[i]);
+
+	mutex_destroy(&counter->mtx);
+	kfree(counter->block_list);
+	kfree(counter);
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_counter.h b/drivers/net/ethernet/marvell/prestera/prestera_counter.h
new file mode 100644
index 000000000000..2d99a967ee97
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_counter.h
@@ -0,0 +1,28 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _PRESTERA_COUNTER_H_
+#define _PRESTERA_COUNTER_H_
+
+#include <linux/types.h>
+
+struct prestera_counter_stats {
+	u64 packets;
+	u64 bytes;
+};
+
+struct prestera_counter_block;
+
+int prestera_counter_init(struct prestera_switch *sw);
+void prestera_counter_fini(struct prestera_switch *sw);
+
+int prestera_counter_get(struct prestera_counter *counter, u32 client,
+			 struct prestera_counter_block **block,
+			 u32 *counter_id);
+void prestera_counter_put(struct prestera_counter *counter,
+			  struct prestera_counter_block *block, u32 counter_id);
+int prestera_counter_stats_get(struct prestera_counter *counter,
+			       struct prestera_counter_block *block,
+			       u32 counter_id, u64 *packets, u64 *bytes);
+
+#endif /* _PRESTERA_COUNTER_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ct.c b/drivers/net/ethernet/marvell/prestera/prestera_ct.c
new file mode 100644
index 000000000000..8cbb3870ccee
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ct.c
@@ -0,0 +1,776 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/rhashtable.h>
+#include <net/netfilter/nf_flow_table.h>
+#include <net/tc_act/tc_ct.h>
+#include <linux/bitops.h>
+
+#include "prestera.h"
+#include "prestera_log.h"
+#include "prestera_hw.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
+#include "prestera_counter.h"
+
+#define PRESTERA_ACL_CT_CHAIN 1
+#define PRESTERA_ACL_CT_TRAP_PRIO 0xfffffffe
+#define PRESTERA_ACL_CT_MATCHES 4
+#define PRESTERA_ACL_CT_HW_TC	18
+
+enum mangle_act_mask {
+	MANGLE_ACT_IP4_SRC_BIT = BIT(0),
+	MANGLE_ACT_IP4_DST_BIT = BIT(1),
+	MANGLE_ACT_PORT_SRC_BIT = BIT(2),
+	MANGLE_ACT_PORT_DST_BIT = BIT(3)
+};
+
+struct prestera_ct_tuple {
+	u16 zone;
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_rule_entry *re;
+};
+
+struct prestera_ct_priv {
+	struct prestera_acl *acl;
+	struct rhashtable zone_ht;
+	struct prestera_acl_rule_entry *re;
+	u32 vtcam_id;
+	u16 pcl_id;
+	u32 index;
+};
+
+struct prestera_ct_entry {
+	struct rhash_head node;
+	unsigned long cookie;
+	struct prestera_ct_tuple tuple;
+	volatile struct {
+		u64 lastuse, packets, bytes;
+	} stats; /* cache */
+};
+
+struct prestera_ct_ft {
+	struct rhash_head node;
+	u16 zone;
+	refcount_t refcount;
+	struct prestera_ct_priv *ct_priv;
+	struct nf_flowtable *nf_ft;
+	struct rhashtable ct_entries_ht;
+};
+
+static const struct rhashtable_params ct_entry_ht_params = {
+	.head_offset = offsetof(struct prestera_ct_entry, node),
+	.key_offset = offsetof(struct prestera_ct_entry, cookie),
+	.key_len = sizeof(((struct prestera_ct_entry *)0)->cookie),
+	.automatic_shrinking = true,
+};
+
+static const struct rhashtable_params ct_zone_ht_params = {
+	.head_offset = offsetof(struct prestera_ct_ft, node),
+	.key_offset = offsetof(struct prestera_ct_ft, zone),
+	.key_len = sizeof(((struct prestera_ct_ft *)0)->zone),
+	.automatic_shrinking = true,
+};
+
+static struct workqueue_struct *prestera_ct_owq;
+
+static int prestera_ct_chain_init(struct prestera_ct_priv *priv)
+{
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_iface iface;
+	u16 pcl_id;
+	u32 uid = 0;
+	int err;
+
+	err = idr_alloc_u32(&priv->acl->uid, NULL, &uid, U8_MAX, GFP_KERNEL);
+	if (err)
+		return err;
+
+	/* create vtcam with specific keymask/template */
+	memset(&re_key, 0, sizeof(re_key));
+	rule_match_set_u16(re_key.match.mask, PCL_ID,
+			   PRESTERA_ACL_KEYMASK_PCL_ID);
+	rule_match_set_u16(re_key.match.mask, ETH_TYPE, 0xFFFF);
+	rule_match_set_u8(re_key.match.mask, IP_PROTO, 0xFF);
+	rule_match_set_u32(re_key.match.mask, IP_SRC, 0xFFFFFFFF);
+	rule_match_set_u32(re_key.match.mask, IP_DST, 0xFFFFFFFF);
+	rule_match_set_u16(re_key.match.mask, L4_PORT_SRC, 0xFFFF);
+	rule_match_set_u16(re_key.match.mask, L4_PORT_DST, 0xFFFF);
+
+	err = prestera_acl_vtcam_id_get(priv->acl, PRESTERA_ACL_CT_CHAIN,
+					PRESTERA_HW_VTCAM_DIR_INGRESS,
+					re_key.match.mask, &priv->vtcam_id);
+	if (err)
+		goto err_vtcam_create;
+
+	/* make pcl-id based on uid and chain */
+	pcl_id = PRESTERA_ACL_PCL_ID_MAKE(uid, PRESTERA_ACL_CT_CHAIN);
+
+	/* bind iface index to pcl-id to be able to jump to this from
+	 * any other rules.
+	 */
+	iface.index = uid;
+	iface.type = PRESTERA_ACL_IFACE_TYPE_INDEX;
+	err = prestera_hw_vtcam_iface_bind(priv->acl->sw, &iface,
+					   priv->vtcam_id, pcl_id);
+	if (err)
+		goto err_rule_entry_bind;
+
+	memset(&re_key, 0, sizeof(re_key));
+	re_key.prio = PRESTERA_ACL_CT_TRAP_PRIO;
+	rule_match_set_u16(re_key.match.key, PCL_ID, pcl_id);
+	rule_match_set_u16(re_key.match.mask, PCL_ID,
+			   PRESTERA_ACL_KEYMASK_PCL_ID);
+
+	memset(&re_arg, 0, sizeof(re_arg));
+	re_arg.trap.valid = 1;
+	re_arg.trap.i.hw_tc = PRESTERA_ACL_CT_HW_TC;
+	re_arg.vtcam_id = priv->vtcam_id;
+
+	priv->re = prestera_acl_rule_entry_create(priv->acl, &re_key, &re_arg);
+	if (!priv->re) {
+		err = -EINVAL;
+		goto err_rule_entry_create;
+	}
+
+	priv->pcl_id = pcl_id;
+	priv->index = uid;
+	return 0;
+
+err_rule_entry_create:
+	prestera_hw_vtcam_iface_unbind(priv->acl->sw, &iface, priv->vtcam_id);
+err_rule_entry_bind:
+	prestera_acl_vtcam_id_put(priv->acl, priv->vtcam_id);
+err_vtcam_create:
+	idr_remove(&priv->acl->uid, uid);
+	return err;
+}
+
+struct prestera_ct_priv *prestera_ct_init(struct prestera_acl *acl)
+{
+	struct prestera_ct_priv *ct_priv;
+
+	ct_priv = kzalloc(sizeof(*ct_priv), GFP_KERNEL);
+	if (!ct_priv)
+		return ERR_PTR(-ENOMEM);
+
+	rhashtable_init(&ct_priv->zone_ht, &ct_zone_ht_params);
+	ct_priv->acl = acl;
+
+	if (prestera_ct_chain_init(ct_priv))
+		return ERR_PTR(-EINVAL);
+
+	prestera_ct_owq = alloc_ordered_workqueue("%s_ordered", 0,
+						  "prestera_ct");
+	if (!prestera_ct_owq)
+		return ERR_PTR(-ENOMEM);
+
+	return ct_priv;
+}
+
+void prestera_ct_clean(struct prestera_ct_priv *ct_priv)
+{
+	u8 uid = ct_priv->pcl_id & PRESTERA_ACL_KEYMASK_PCL_ID_USER;
+
+	if (!ct_priv)
+		return;
+
+	destroy_workqueue(prestera_ct_owq);
+
+	prestera_acl_rule_entry_destroy(ct_priv->acl, ct_priv->re);
+	prestera_acl_vtcam_id_put(ct_priv->acl, ct_priv->vtcam_id);
+	idr_remove(&ct_priv->acl->uid, uid);
+	rhashtable_destroy(&ct_priv->zone_ht);
+	kfree(ct_priv);
+}
+
+int prestera_ct_match_parse(struct flow_cls_offload *f,
+			    struct netlink_ext_ack *extack)
+{
+	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
+	struct flow_dissector_key_ct *mask, *key;
+	bool trk, est, untrk, unest, new;
+	u16 ct_state_on, ct_state_off;
+	u16 ct_state, ct_state_mask;
+	struct flow_match_ct match;
+
+	if (!flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_CT))
+		return 0;
+
+	flow_rule_match_ct(f_rule, &match);
+
+	key = match.key;
+	mask = match.mask;
+
+	ct_state = key->ct_state;
+	ct_state_mask = mask->ct_state;
+
+	if (ct_state_mask & ~(TCA_FLOWER_KEY_CT_FLAGS_TRACKED |
+			      TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED |
+			      TCA_FLOWER_KEY_CT_FLAGS_NEW)) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "only ct_state trk, est and new are supported for offload");
+		return -EOPNOTSUPP;
+	}
+
+	ct_state_on = ct_state & ct_state_mask;
+	ct_state_off = (ct_state & ct_state_mask) ^ ct_state_mask;
+
+	trk = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_TRACKED;
+	new = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_NEW;
+	est = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED;
+
+	untrk = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_TRACKED;
+	unest = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED;
+
+	MVSW_LOG_INFO("trk=%d new=%d est=%d untrk=%d unest=%d",
+		      trk, new, est, untrk, unest);
+
+	if (new) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "matching on ct_state +new isn't supported");
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+int prestera_ct_parse_action(const struct flow_action_entry *act,
+			     struct prestera_acl_rule *rule,
+			     struct netlink_ext_ack *extack)
+
+{
+	struct prestera_ct_attr *ct_attr;
+
+	ct_attr = &rule->attr.ct_attr;
+
+	ct_attr->zone = act->ct.zone;
+	ct_attr->ct_action = act->ct.action;
+	ct_attr->nf_ft = act->ct.flow_table;
+
+	return 0;
+}
+
+static struct flow_action_entry *
+prestera_ct_get_ct_metadata_action(struct flow_rule *flow_rule)
+{
+	struct flow_action *flow_action = &flow_rule->action;
+	struct flow_action_entry *act;
+	int i;
+
+	flow_action_for_each(i, act, flow_action) {
+		if (act->id == FLOW_ACTION_CT_METADATA)
+			return act;
+	}
+
+	return NULL;
+}
+
+static int
+prestera_ct_flow_rule_to_tuple(struct flow_rule *rule,
+			       struct prestera_ct_tuple *tuple)
+{
+	struct prestera_acl_match *r_match = &tuple->re_key.match;
+	struct flow_match_ipv4_addrs ipv4_match;
+	struct flow_match_ports ports_match;
+	struct flow_match_control control;
+	struct flow_match_basic basic;
+	u16 addr_type;
+	u8 ip_proto;
+
+	flow_rule_match_basic(rule, &basic);
+	flow_rule_match_control(rule, &control);
+
+	ip_proto = basic.key->ip_proto;
+	addr_type = control.key->addr_type;
+
+	if (addr_type != FLOW_DISSECTOR_KEY_IPV4_ADDRS)
+		return -EOPNOTSUPP;
+
+	flow_rule_match_ipv4_addrs(rule, &ipv4_match);
+
+	rule_match_set(r_match->key, IP_SRC, ipv4_match.key->src);
+	rule_match_set(r_match->mask, IP_SRC, ipv4_match.mask->src);
+
+	rule_match_set(r_match->key, IP_DST, ipv4_match.key->dst);
+	rule_match_set(r_match->mask, IP_DST, ipv4_match.mask->dst);
+
+	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS))
+		return -EOPNOTSUPP;
+
+	flow_rule_match_ports(rule, &ports_match);
+	switch (ip_proto) {
+	case IPPROTO_TCP:
+	case IPPROTO_UDP:
+		rule_match_set(r_match->key,
+			       L4_PORT_SRC, ports_match.key->src);
+		rule_match_set(r_match->mask,
+			       L4_PORT_SRC, ports_match.mask->src);
+
+		rule_match_set(r_match->key,
+			       L4_PORT_DST, ports_match.key->dst);
+		rule_match_set(r_match->mask,
+			       L4_PORT_DST, ports_match.mask->dst);
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_META))
+		return -EOPNOTSUPP;
+
+	/* metadata match is set but not information is present.
+	 * Issue? Need to investigate on kernel side.
+	 */
+	return 0;
+}
+
+static int
+__prestera_ct_tuple_get_mangle(struct flow_rule *rule,
+			       struct prestera_ct_tuple *tuple)
+{
+	struct flow_action *flow_action = &rule->action;
+	struct flow_action_entry *act;
+	u32 offset, val;
+	int i;
+	struct prestera_mangle_cfg *mc;
+
+	mc = &tuple->re_arg.nh.k.mangle;
+	flow_action_for_each(i, act, flow_action) {
+		if (act->id != FLOW_ACTION_MANGLE)
+			continue;
+
+		offset = act->mangle.offset;
+		val = act->mangle.val;
+		switch (act->mangle.htype) {
+		case FLOW_ACT_MANGLE_HDR_TYPE_IP4:
+			if (offset == offsetof(struct iphdr, saddr)) {
+				mc->sip.u.ipv4 =
+					cpu_to_be32(val);
+				mc->sip_valid = true;
+			} else if (offset == offsetof(struct iphdr, daddr)) {
+				mc->dip.u.ipv4 =
+					cpu_to_be32(val);
+				mc->dip_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		case FLOW_ACT_MANGLE_HDR_TYPE_TCP:
+			if (offset == offsetof(struct tcphdr, source)) {
+				mc->l4_src = cpu_to_be16(val);
+				mc->l4_src_valid = true;
+			} else if (offset == offsetof(struct tcphdr, dest)) {
+				mc->l4_dst = cpu_to_be16(val);
+				mc->l4_dst_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		case FLOW_ACT_MANGLE_HDR_TYPE_UDP:
+			if (offset == offsetof(struct udphdr, source)) {
+				mc->l4_src = cpu_to_be16(val);
+				mc->l4_src_valid = true;
+			} else if (offset == offsetof(struct udphdr, dest)) {
+				mc->l4_dst = cpu_to_be16(val);
+				mc->l4_dst_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		default:
+			return -EOPNOTSUPP;
+		}
+	}
+
+	return 0;
+}
+
+static int __prestera_ct_tuple_get_nh(struct prestera_switch *sw,
+				      struct prestera_ct_tuple *tuple)
+{
+	struct prestera_ip_addr ip;
+	struct prestera_nexthop_group_key nh_grp_key;
+	struct prestera_mangle_cfg *mc;
+
+	mc = &tuple->re_arg.nh.k.mangle;
+	memset(&ip, 0, sizeof(ip));
+	memcpy(&ip.u.ipv4,
+	       mc->sip_valid ?
+	       (void *)&rule_match_get_u32(tuple->re_key.match.key, IP_DST) :
+	       (void *)&mc->dip.u.ipv4,
+	       sizeof(ip.u.ipv4));
+
+	/* TODO: VRF */
+	/* TODO: ECMP */
+	if (prestera_util_kern_dip2nh_grp_key(sw, RT_TABLE_MAIN, &ip,
+					      &nh_grp_key) != 1)
+		return -ENOTSUPP;
+
+	tuple->re_arg.nh.k.n = nh_grp_key.neigh[0];
+
+	return 0;
+}
+
+static int __prestera_ct_tuple2acl_add(struct prestera_acl *acl,
+				       struct prestera_ct_tuple *tuple)
+{
+	tuple->re = prestera_acl_rule_entry_find(acl, &tuple->re_key);
+	if (tuple->re) {
+		tuple->re = NULL;
+		return -EEXIST;
+	}
+
+	tuple->re = prestera_acl_rule_entry_create(acl, &tuple->re_key,
+						   &tuple->re_arg);
+	if (!tuple->re)
+		return -EINVAL;
+
+	return 0;
+}
+
+static int
+prestera_ct_block_flow_offload_add(struct prestera_ct_ft *ft,
+				   struct flow_cls_offload *flow)
+{
+	struct flow_rule *flow_rule = flow_cls_offload_flow_rule(flow);
+	struct flow_action_entry *meta_action;
+	unsigned long cookie = flow->cookie;
+	struct prestera_ct_entry *entry;
+	int err;
+
+	meta_action = prestera_ct_get_ct_metadata_action(flow_rule);
+	if (!meta_action)
+		return -EOPNOTSUPP;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (entry)
+		return 0;
+
+	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
+	if (!entry)
+		return -ENOMEM;
+
+	entry->tuple.zone = ft->zone;
+	entry->cookie = flow->cookie;
+	entry->tuple.re_key.prio = flow->common.prio;
+	entry->tuple.re_arg.vtcam_id = ft->ct_priv->vtcam_id;
+
+	/* set pcl-id for this rule */
+	rule_match_set_u16(entry->tuple.re_key.match.key,
+			   PCL_ID, ft->ct_priv->pcl_id);
+	rule_match_set_u16(entry->tuple.re_key.match.mask,
+			   PCL_ID, PRESTERA_ACL_KEYMASK_PCL_ID);
+
+	err = prestera_ct_flow_rule_to_tuple(flow_rule, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	/* Do we need sanity check before "valid = 1" ? */
+	entry->tuple.re_arg.nh.valid = 1;
+
+	err = __prestera_ct_tuple_get_mangle(flow_rule, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	/* setup counter */
+	entry->tuple.re_arg.count.valid = true;
+	entry->tuple.re_arg.count.fail_on_err = true;
+	err = prestera_acl_chain_to_client(PRESTERA_ACL_CT_CHAIN,
+					   &entry->tuple.re_arg.count.client);
+	if (err)
+		goto err_set;
+
+	err = __prestera_ct_tuple_get_nh(ft->ct_priv->acl->sw, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	/* HW offload */
+	err = __prestera_ct_tuple2acl_add(ft->ct_priv->acl, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	err = rhashtable_insert_fast(&ft->ct_entries_ht, &entry->node,
+				     ct_entry_ht_params);
+	if (err)
+		goto err_insert;
+
+	return 0;
+
+err_insert:
+	prestera_acl_rule_entry_destroy(ft->ct_priv->acl, entry->tuple.re);
+
+err_set:
+	kfree(entry);
+	return err;
+}
+
+static int
+prestera_ct_block_flow_offload_del(struct prestera_ct_ft *ft,
+				   struct flow_cls_offload *flow)
+{
+	unsigned long cookie = flow->cookie;
+	struct prestera_ct_entry *entry;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (!entry)
+		return -ENOENT;
+
+	prestera_acl_rule_entry_destroy(ft->ct_priv->acl, entry->tuple.re);
+	rhashtable_remove_fast(&ft->ct_entries_ht,
+			       &entry->node, ct_entry_ht_params);
+	kfree(entry);
+	return 0;
+}
+
+static int
+prestera_ct_block_flow_offload_stats(struct prestera_ct_ft *ft,
+				     struct flow_cls_offload *f)
+{
+	unsigned long cookie = f->cookie;
+	struct prestera_ct_entry *entry;
+	u64 packets, bytes;
+	int err;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (!entry)
+		return -ENOENT;
+
+	err = prestera_counter_stats_get(ft->ct_priv->acl->sw->counter,
+					 entry->tuple.re->counter.block,
+					 entry->tuple.re->counter.id,
+					 &packets, &bytes);
+	if (err)
+		return err;
+
+	if (packets != entry->stats.packets || bytes != entry->stats.bytes) {
+		entry->stats.packets = packets;
+		entry->stats.bytes = bytes;
+		entry->stats.lastuse = jiffies;
+	}
+
+	flow_stats_update(&f->stats,
+			  entry->stats.bytes,
+			  entry->stats.packets,
+			  0,
+			  entry->stats.lastuse,
+			  FLOW_ACTION_HW_STATS_DELAYED);
+
+	return 0;
+}
+
+static int
+prestera_ct_block_flow_offload(enum tc_setup_type type, void *type_data,
+			       void *cb_priv)
+{
+	struct flow_cls_offload *f = type_data;
+	struct prestera_ct_ft *ft = cb_priv;
+	int err;
+
+	if (type != TC_SETUP_CLSFLOWER)
+		return -EOPNOTSUPP;
+
+	switch (f->command) {
+	case FLOW_CLS_REPLACE:
+		rtnl_lock();
+		err = prestera_ct_block_flow_offload_add(ft, f);
+		rtnl_unlock();
+		break;
+	case FLOW_CLS_DESTROY:
+		rtnl_lock();
+		err = prestera_ct_block_flow_offload_del(ft, f);
+		rtnl_unlock();
+		break;
+	case FLOW_CLS_STATS:
+		err = prestera_ct_block_flow_offload_stats(ft, f);
+		break;
+	default:
+		err =  -EOPNOTSUPP;
+		break;
+	}
+
+	return err;
+}
+
+static struct prestera_ct_ft *
+__prestera_ct_ft_offload_add_cb(struct prestera_ct_priv *ct_priv,
+				u16 zone, struct nf_flowtable *nf_ft)
+{
+	struct prestera_ct_ft *ft;
+	int err;
+
+	ft = rhashtable_lookup_fast(&ct_priv->zone_ht, &zone,
+				    ct_zone_ht_params);
+	if (ft) {
+		refcount_inc(&ft->refcount);
+		return ft;
+	}
+
+	ft = kzalloc(sizeof(*ft), GFP_KERNEL);
+	if (!ft)
+		return ERR_PTR(-ENOMEM);
+
+	/* ft->net = read_pnet(&nf_ft->net); */
+	ft->zone = zone;
+	ft->nf_ft = nf_ft;
+	ft->ct_priv = ct_priv;
+	refcount_set(&ft->refcount, 1);
+
+	err = rhashtable_init(&ft->ct_entries_ht, &ct_entry_ht_params);
+	if (err)
+		goto err_init;
+
+	err = rhashtable_insert_fast(&ct_priv->zone_ht, &ft->node,
+				     ct_zone_ht_params);
+	if (err)
+		goto err_insert;
+
+	err = nf_flow_table_offload_add_cb(ft->nf_ft,
+					   prestera_ct_block_flow_offload, ft);
+	if (err)
+		goto err_add_cb;
+
+	return ft;
+
+err_add_cb:
+	rhashtable_remove_fast(&ct_priv->zone_ht, &ft->node, ct_zone_ht_params);
+err_insert:
+	rhashtable_destroy(&ft->ct_entries_ht);
+err_init:
+	kfree(ft);
+	return ERR_PTR(err);
+}
+
+/* Add gateway rule in def chain and add TRAP rule in CT chain */
+static int __prestera_ct_rule2gateway(struct prestera_switch *sw,
+				      struct prestera_acl_rule *rule)
+{
+	struct prestera_ct_priv *ct_priv = sw->acl->ct_priv;
+
+	/* TODO: fill this in flower parse */
+
+	/* just update the action for this rule */
+	rule->re_arg.jump.valid = 1;
+	rule->re_arg.jump.i.index = ct_priv->index;
+
+	rule->re = prestera_acl_rule_entry_find(sw->acl, &rule->re_key);
+	if (WARN_ON(rule->re)) {
+		rule->re = NULL;
+		return -EEXIST;
+	}
+
+	rule->re = prestera_acl_rule_entry_create(sw->acl, &rule->re_key,
+						  &rule->re_arg);
+	if (!rule->re)
+		return -EINVAL;
+
+	return 0;
+}
+
+int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
+				  struct prestera_acl_rule *rule)
+{
+	struct prestera_ct_attr *ct_attr;
+	int err;
+
+	ct_attr = &rule->attr.ct_attr;
+
+	if (ct_attr->ct_action & TCA_CT_ACT_CLEAR)
+		return -EOPNOTSUPP;
+
+	ct_attr->ft = __prestera_ct_ft_offload_add_cb(sw->acl->ct_priv,
+						      ct_attr->zone,
+						      ct_attr->nf_ft);
+	if (IS_ERR(ct_attr->ft))
+		return PTR_ERR(ct_attr->ft);
+
+	err = __prestera_ct_rule2gateway(sw, rule);
+	if (err) {
+		prestera_ct_ft_offload_del_cb(sw, rule);
+		return err;
+	}
+
+	return 0;
+}
+
+static void prestera_ct_flush_ft_entry(void *ptr, void *arg)
+{
+	struct prestera_ct_priv *ct_priv = arg;
+	struct prestera_ct_entry *entry = ptr;
+
+	prestera_acl_rule_entry_destroy(ct_priv->acl, entry->tuple.re);
+	kfree(entry);
+}
+
+struct prestera_ct_ft_cb_work {
+	struct work_struct work;
+	struct prestera_switch *sw;
+	struct prestera_ct_ft *ft;
+};
+
+static void __prestera_ct_ft_cb_work(struct work_struct *work)
+{
+	struct prestera_ct_ft_cb_work *ct_work;
+	struct prestera_switch *sw;
+	struct prestera_ct_ft *ft;
+
+	ct_work = container_of(work, struct prestera_ct_ft_cb_work, work);
+	sw = ct_work->sw;
+	ft = ct_work->ft;
+
+	/* Will take ct_lock inside.
+	 * Also ensures, that there is no more events.
+	 */
+	nf_flow_table_offload_del_cb(ft->nf_ft,
+				     prestera_ct_block_flow_offload, ft);
+
+	/* This code can be executed without rtnl_lock,
+	 * because nf_flow_table_offload_del_cb already delete all entries ?
+	 */
+	rtnl_lock();
+	rhashtable_free_and_destroy(&ft->ct_entries_ht,
+				    prestera_ct_flush_ft_entry,
+				    sw->acl->ct_priv);
+	rtnl_unlock();
+	kfree(ft);
+
+	kfree(ct_work);
+}
+
+void prestera_ct_ft_offload_del_cb(struct prestera_switch *sw,
+				   struct prestera_acl_rule *rule)
+{
+	struct prestera_ct_attr *ct_attr;
+	struct prestera_ct_ft *ft;
+	struct prestera_ct_ft_cb_work *ct_work;
+
+	ct_attr = &rule->attr.ct_attr;
+	ft = ct_attr->ft;
+
+	if (rule->re)
+		prestera_acl_rule_entry_destroy(sw->acl, rule->re);
+
+	if (!refcount_dec_and_test(&ft->refcount))
+		return;
+
+	/* Delete this ft from HT to prevent occurring in search results of
+	 * __prestera_ct_ft_offload_add_cb. Prevents reusing after refcnt
+	 * became zero.
+	 */
+	rhashtable_remove_fast(&sw->acl->ct_priv->zone_ht,
+			       &ft->node, ct_zone_ht_params);
+
+	ct_work = kzalloc(sizeof(*ct_work), GFP_ATOMIC);
+	if (WARN_ON(!ct_work))
+		return;
+
+	ct_work->sw = sw;
+	ct_work->ft = ft;
+	INIT_WORK(&ct_work->work, __prestera_ct_ft_cb_work);
+	queue_work(prestera_ct_owq, &ct_work->work);
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ct.h b/drivers/net/ethernet/marvell/prestera/prestera_ct.h
new file mode 100644
index 000000000000..3901af6c9d93
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ct.h
@@ -0,0 +1,39 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _PRESTERA_CT_H_
+#define _PRESTERA_CT_H_
+
+#include <linux/types.h>
+#include <linux/netlink.h>
+#include <net/flow_offload.h>
+
+struct prestera_switch;
+struct prestera_ct_ft;
+struct prestera_ct_priv;
+
+struct prestera_ct_attr {
+	u16 zone;
+	u16 ct_action;
+	struct net *net;
+	struct prestera_ct_ft *ft;
+	struct nf_flowtable *nf_ft;
+};
+
+struct prestera_ct_priv *prestera_ct_init(struct prestera_acl *acl);
+void prestera_ct_clean(struct prestera_ct_priv *ct_priv);
+
+/* match & action */
+int prestera_ct_match_parse(struct flow_cls_offload *f,
+			    struct netlink_ext_ack *extack);
+int prestera_ct_parse_action(const struct flow_action_entry *act,
+			     struct prestera_acl_rule *rule,
+			     struct netlink_ext_ack *extack);
+
+/* flowtable */
+int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
+				  struct prestera_acl_rule *rule);
+void prestera_ct_ft_offload_del_cb(struct prestera_switch *sw,
+				   struct prestera_acl_rule *rule);
+
+#endif /* _PRESTERA_CT_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_dcb.c b/drivers/net/ethernet/marvell/prestera/prestera_dcb.c
new file mode 100644
index 000000000000..e456ea8b8e62
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_dcb.c
@@ -0,0 +1,216 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/netdevice.h>
+#include <net/dcbnl.h>
+
+#include "prestera.h"
+#include "prestera_hw.h"
+#include "prestera_dcb.h"
+
+static int prestera_dcb_app_validate(struct net_device *dev,
+				     struct dcb_app *app)
+{
+	int prio;
+
+	if (app->priority >= IEEE_8021QAZ_MAX_TCS) {
+		netdev_err(dev, "APP entry with priority value %u is invalid\n",
+			   app->priority);
+		return -EINVAL;
+	}
+
+	switch (app->selector) {
+	case IEEE_8021QAZ_APP_SEL_DSCP:
+		if (app->protocol >= 64) {
+			netdev_err(dev, "DSCP APP entry with protocol value %u is invalid\n",
+				   app->protocol);
+			return -EINVAL;
+		}
+
+		/* Warn about any DSCP APP entries with the same PID. */
+		prio = fls(dcb_ieee_getapp_mask(dev, app));
+		if (prio--) {
+			if (prio < app->priority)
+				netdev_warn(dev, "Choosing priority %d for DSCP %d in favor of previously-active value of %d\n",
+					    app->priority, app->protocol, prio);
+			else if (prio > app->priority)
+				netdev_warn(dev, "Ignoring new priority %d for DSCP %d in favor of current value of %d\n",
+					    app->priority, app->protocol, prio);
+		}
+		break;
+
+	case IEEE_8021QAZ_APP_SEL_ETHERTYPE:
+		if (app->protocol) {
+			netdev_err(dev, "EtherType APP entries with protocol value != 0 not supported\n");
+			return -EINVAL;
+		}
+		break;
+
+	default:
+		netdev_err(dev, "APP entries with selector %u not supported\n",
+			   app->selector);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static u8 prestera_dcb_port_default_prio(struct prestera_port *port)
+{
+	u8 prio_mask;
+
+	prio_mask = dcb_ieee_getapp_default_prio_mask(port->net_dev);
+	if (prio_mask)
+		/* Take the highest configured priority. */
+		return fls(prio_mask) - 1;
+
+	return 0;
+}
+
+static void prestera_dcb_port_dscp_prio_map(struct prestera_port *port,
+					    u8 default_prio,
+					    struct dcb_ieee_app_dscp_map *map)
+{
+	int i;
+
+	dcb_ieee_getapp_dscp_prio_mask_map(port->net_dev, map);
+	for (i = 0; i < ARRAY_SIZE(map->map); ++i) {
+		if (map->map[i])
+			map->map[i] = fls(map->map[i]) - 1;
+		else
+			map->map[i] = default_prio;
+	}
+}
+
+static bool prestera_dcb_port_have_dscp(struct prestera_port *port)
+{
+	struct dcb_ieee_app_prio_map map;
+	int i;
+
+	dcb_ieee_getapp_prio_dscp_mask_map(port->net_dev, &map);
+	for (i = 0; i < ARRAY_SIZE(map.map); ++i)
+		if (map.map[i])
+			return true;
+
+	return false;
+}
+
+static int prestera_dcb_port_app_update(struct prestera_port *port,
+					struct dcb_app *app)
+{
+	struct dcb_ieee_app_dscp_map map;
+	u8 default_prio;
+	int err = 0;
+	u8 mode;
+
+	mode = prestera_dcb_port_have_dscp(port) ?
+		PRESTERA_HW_QOS_TRUST_MODE_L3 :
+		PRESTERA_HW_QOS_TRUST_MODE_L2;
+
+	if (port->qos_trust_mode != mode) {
+		err = prestera_hw_port_qos_trust_mode_set(port, mode);
+		if (err) {
+			netdev_err(port->net_dev,
+				   "Failed to configure trust mode\n");
+			return err;
+		}
+
+		port->qos_trust_mode = mode;
+	}
+
+	default_prio = prestera_dcb_port_default_prio(port);
+	prestera_dcb_port_dscp_prio_map(port, default_prio, &map);
+
+	err = prestera_hw_port_qos_default_prio_set(port, default_prio);
+	if (err) {
+		netdev_err(port->net_dev,
+			   "Failed to configure default priority\n");
+		return err;
+	}
+
+	if (mode != PRESTERA_HW_QOS_TRUST_MODE_L3)
+		return 0;
+
+	err = prestera_hw_port_qos_mapping_update(port, &map);
+	if (err)
+		netdev_err(port->net_dev, "Failed to configure priority\n");
+
+	return err;
+}
+
+static int prestera_dcb_port_app_flush(struct prestera_port *port,
+				       struct dcb_app *app)
+{
+	int err;
+
+	err = prestera_hw_port_qos_default_prio_set(port, 0);
+	if (err) {
+		netdev_err(port->net_dev,
+			   "Failed to reset default priority\n");
+		return err;
+	}
+
+	err = prestera_hw_port_qos_trust_mode_set(port,
+						  PRESTERA_HW_QOS_TRUST_MODE_L2);
+	if (err) {
+		netdev_err(port->net_dev,
+			   "Failed to reset trust mode\n");
+		return err;
+	}
+
+	return 0;
+}
+
+static int prestera_dcb_ieee_setapp(struct net_device *dev,
+				    struct dcb_app *app)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	int err;
+
+	err = prestera_dcb_app_validate(dev, app);
+	if (err)
+		return err;
+
+	err = dcb_ieee_setapp(dev, app);
+	if (err)
+		return err;
+
+	err = prestera_dcb_port_app_update(port, app);
+	if (err)
+		dcb_ieee_delapp(dev, app);
+
+	return err;
+}
+
+static int prestera_dcb_ieee_delapp(struct net_device *dev,
+				    struct dcb_app *app)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	int err;
+
+	err = dcb_ieee_delapp(dev, app);
+	if (err)
+		return err;
+
+	err = prestera_dcb_port_app_flush(port, app);
+	if (err)
+		return err;
+
+	return 0;
+}
+
+static const struct dcbnl_rtnl_ops prestera_dcbnl_ops = {
+	.ieee_setapp		= prestera_dcb_ieee_setapp,
+	.ieee_delapp		= prestera_dcb_ieee_delapp,
+};
+
+int prestera_port_dcb_init(struct prestera_port *port)
+{
+	port->net_dev->dcbnl_ops = &prestera_dcbnl_ops;
+	port->qos_trust_mode = PRESTERA_HW_QOS_TRUST_MODE_L2;
+
+	return 0;
+}
+
+void prestera_port_dcb_fini(struct prestera_port *port)
+{}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_dcb.h b/drivers/net/ethernet/marvell/prestera/prestera_dcb.h
new file mode 100644
index 000000000000..634853484f51
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_dcb.h
@@ -0,0 +1,14 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2022 Marvell International Ltd. All rights reserved. */
+
+#ifndef _PRESTERA_DCB_H_
+#define _PRESTERA_DCB_H_
+
+#include <linux/types.h>
+
+struct prestera_port;
+
+int prestera_port_dcb_init(struct prestera_port *port);
+void prestera_port_dcb_fini(struct prestera_port *port);
+
+#endif /* _PRESTERA_DCB_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
new file mode 100644
index 000000000000..d8242021b44a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
@@ -0,0 +1,287 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/device.h>
+#include <linux/debugfs.h>
+
+#include "prestera_debugfs.h"
+#include "prestera.h"
+#include "prestera_log.h"
+#include "prestera_fw_log.h"
+#include "prestera_rxtx.h"
+#include "prestera_hw.h"
+
+#define PRESTERA_DEBUGFS_ROOTDIR	"prestera"
+
+#define CPU_CODE_HW_CNT_SUBDIR_NAME	"hw_counters"
+#define CPU_CODE_SW_CNT_SUBDIR_NAME	"sw_counters"
+
+#define CPU_CODE_CNT_SUBDIR_TRAP_NAME	"traps"
+#define CPU_CODE_CNT_SUBDIR_DROP_NAME	"drops"
+
+#define CPU_CODE_CNT_BUF_MAX_SIZE	(MVSW_PR_RXTX_CPU_CODE_MAX_NUM * 32)
+
+static ssize_t prestera_cnt_read(struct file *file, char __user *ubuf,
+				 size_t count, loff_t *ppos);
+
+struct prestera_debugfs {
+	struct dentry *root_dir;
+	const struct file_operations cpu_code_cnt_fops;
+	char *cpu_code_cnt_buf;
+	/* serialize access to cpu_code_cnt_buf */
+	struct mutex cpu_code_cnt_buf_mtx;
+	struct prestera_switch *sw;
+};
+
+struct prestera_cpu_code_data {
+	union {
+		long data;
+		struct {
+			u16 cpu_code;
+			u8 cpu_code_cnt_type;
+		} __packed __aligned(4);
+	};
+} __packed __aligned(4);
+
+static struct prestera_debugfs prestera_debugfs = {
+	.cpu_code_cnt_fops = {
+		.read = prestera_cnt_read,
+		.open = simple_open,
+		.llseek = default_llseek,
+	},
+};
+
+enum {
+	CPU_CODE_CNT_TYPE_HW_DROP = PRESTERA_HW_CPU_CODE_CNT_TYPE_DROP,
+	CPU_CODE_CNT_TYPE_HW_TRAP = PRESTERA_HW_CPU_CODE_CNT_TYPE_TRAP,
+	CPU_CODE_CNT_TYPE_SW_TRAP = CPU_CODE_CNT_TYPE_HW_TRAP + 1,
+};
+
+int prestera_debugfs_init(struct prestera_switch *sw)
+{
+	struct prestera_debugfs *debugfs = &prestera_debugfs;
+	struct dentry *cpu_code_hw_cnt_trap_subdir;
+	struct dentry *cpu_code_hw_cnt_drop_subdir;
+	struct dentry *cpu_code_sw_cnt_trap_subdir;
+	struct dentry *cpu_code_sw_cnt_subdir;
+	struct dentry *cpu_code_hw_counters_subdir;
+	char file_name[] = "cpu_code_XXX_stats";
+	const struct file_operations *fops =
+		&prestera_debugfs.cpu_code_cnt_fops;
+	struct prestera_cpu_code_data f_data;
+	struct dentry *debugfs_file;
+	int err;
+	int i;
+
+	mutex_init(&debugfs->cpu_code_cnt_buf_mtx);
+
+	debugfs->sw = sw;
+
+	debugfs->cpu_code_cnt_buf = kzalloc(CPU_CODE_CNT_BUF_MAX_SIZE,
+					    GFP_KERNEL);
+	if (!debugfs->cpu_code_cnt_buf)
+		return -ENOMEM;
+
+	err = mvsw_pr_fw_log_init(sw);
+	if (err)
+		goto err_fw_log_init;
+
+	debugfs->root_dir = debugfs_create_dir(PRESTERA_DEBUGFS_ROOTDIR, NULL);
+	if (PTR_ERR_OR_ZERO(debugfs->root_dir)) {
+		err = (int)PTR_ERR(debugfs->root_dir);
+		goto err_root_dir_alloc;
+	}
+
+	cpu_code_sw_cnt_subdir = debugfs_create_dir(CPU_CODE_SW_CNT_SUBDIR_NAME,
+						    debugfs->root_dir);
+	if (PTR_ERR_OR_ZERO(cpu_code_sw_cnt_subdir)) {
+		err = (int)PTR_ERR(debugfs->root_dir);
+		goto err_subdir_alloc;
+	}
+
+	cpu_code_sw_cnt_trap_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_TRAP_NAME,
+				   cpu_code_sw_cnt_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_sw_cnt_trap_subdir)) {
+		err = (int)PTR_ERR(cpu_code_sw_cnt_trap_subdir);
+		goto err_subdir_alloc;
+	}
+
+	cpu_code_hw_counters_subdir =
+		debugfs_create_dir(CPU_CODE_HW_CNT_SUBDIR_NAME,
+				   debugfs->root_dir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_counters_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_counters_subdir);
+		goto err_subdir_alloc;
+	}
+
+	cpu_code_hw_cnt_trap_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_TRAP_NAME,
+				   cpu_code_hw_counters_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_cnt_trap_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_cnt_trap_subdir);
+		goto err_subdir_alloc;
+	}
+
+	cpu_code_hw_cnt_drop_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_DROP_NAME,
+				   cpu_code_hw_counters_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_cnt_drop_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_cnt_trap_subdir);
+		goto err_subdir_alloc;
+	}
+
+	for (i = 0; i < MVSW_PR_RXTX_CPU_CODE_MAX_NUM; ++i) {
+		f_data.cpu_code = i;
+
+		snprintf(file_name, sizeof(file_name), "cpu_code_%d_stats", i);
+
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_SW_TRAP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_sw_cnt_trap_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
+
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_TRAP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_hw_cnt_trap_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
+
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_DROP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_hw_cnt_drop_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
+	}
+
+	f_data.cpu_code = MVSW_PR_RXTX_CPU_CODE_MAX_NUM;
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_SW_TRAP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_sw_cnt_trap_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_TRAP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_hw_cnt_trap_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_DROP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_hw_cnt_drop_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
+	return 0;
+
+err_single_file_creation:
+	err = (int)PTR_ERR(debugfs_file);
+err_subdir_alloc:
+	/*
+	 * Removing root directory would result in recursive
+	 * subdirectories / files cleanup of all child nodes;
+	 */
+	debugfs_remove(debugfs->root_dir);
+err_root_dir_alloc:
+	mvsw_pr_fw_log_fini(sw);
+err_fw_log_init:
+	kfree(debugfs->cpu_code_cnt_buf);
+	return err;
+}
+
+void prestera_debugfs_fini(struct prestera_switch *sw)
+{
+	mvsw_pr_fw_log_fini(sw);
+	debugfs_remove(prestera_debugfs.root_dir);
+	mutex_destroy(&prestera_debugfs.cpu_code_cnt_buf_mtx);
+	kfree(prestera_debugfs.cpu_code_cnt_buf);
+}
+
+/*
+ * Software: only TRAP counters are present
+ * Hardware: counters can be either TRAP or drops
+ */
+static int prestera_cpu_code_cnt_get(u64 *stats, u8 cpu_code, u8 cnt_type)
+{
+	switch (cnt_type) {
+	case CPU_CODE_CNT_TYPE_HW_DROP:
+	case CPU_CODE_CNT_TYPE_HW_TRAP:
+		/* fall through */
+		return prestera_hw_cpu_code_counters_get(prestera_debugfs.sw,
+							 cpu_code, cnt_type,
+							 stats);
+	case CPU_CODE_CNT_TYPE_SW_TRAP:
+		*stats = mvsw_pr_rxtx_get_cpu_code_stats(cpu_code);
+		return 0;
+	default:
+		return -EINVAL;
+	}
+}
+
+static ssize_t prestera_cnt_read(struct file *file, char __user *ubuf,
+				 size_t count, loff_t *ppos)
+{
+	char *buf = prestera_debugfs.cpu_code_cnt_buf;
+	struct prestera_cpu_code_data f_data = {
+		.data = (long)file->private_data,
+	};
+	u64 cpu_code_stats;
+	/* as the snprintf doesn't count for \0, start with 1 */
+	int buf_len = 1;
+	int ret;
+
+	mutex_lock(&prestera_debugfs.cpu_code_cnt_buf_mtx);
+
+	if (f_data.cpu_code == MVSW_PR_RXTX_CPU_CODE_MAX_NUM) {
+		int i;
+
+		memset(buf, 0, CPU_CODE_CNT_BUF_MAX_SIZE);
+
+		for (i = 0; i < MVSW_PR_RXTX_CPU_CODE_MAX_NUM; ++i) {
+			ret = prestera_cpu_code_cnt_get
+				(&cpu_code_stats, (u8)i,
+				 f_data.cpu_code_cnt_type);
+			if (ret)
+				goto err_get_stats;
+
+			if (!cpu_code_stats)
+				continue;
+
+			buf_len += snprintf(buf + buf_len,
+					    CPU_CODE_CNT_BUF_MAX_SIZE - buf_len,
+					    "%u:%llu\n", i, cpu_code_stats);
+		}
+
+	} else {
+		ret = prestera_cpu_code_cnt_get(&cpu_code_stats,
+						(u8)f_data.cpu_code,
+						f_data.cpu_code_cnt_type);
+		if (ret)
+			goto err_get_stats;
+
+		buf_len += sprintf(buf, "%llu\n", cpu_code_stats);
+	}
+
+	ret = simple_read_from_buffer(ubuf, count, ppos, buf, buf_len);
+
+err_get_stats:
+	mutex_unlock(&prestera_debugfs.cpu_code_cnt_buf_mtx);
+
+	return ret;
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
new file mode 100644
index 000000000000..10c60e6ea428
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
@@ -0,0 +1,12 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _MVSW_PRESTERA_DEBUGFS_H_
+#define _MVSW_PRESTERA_DEBUGFS_H_
+
+struct prestera_switch;
+
+int prestera_debugfs_init(struct prestera_switch *sw);
+void prestera_debugfs_fini(struct prestera_switch *sw);
+
+#endif /* _MVSW_PRESTERA_DEBUGFS_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_devlink.c b/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
index 68b442eb6d69..0e1748018a88 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
@@ -1,11 +1,15 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <net/devlink.h>
+#include <linux/version.h>
+#include <linux/bitops.h>
+#include <linux/bitfield.h>
 
 #include "prestera_devlink.h"
 #include "prestera_hw.h"
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
 /* All driver-specific traps must be documented in
  * Documentation/networking/devlink/prestera.rst
  */
@@ -42,7 +46,6 @@ enum {
 	DEVLINK_PRESTERA_TRAP_ID_ILLEGAL_IP_ADDR,
 	DEVLINK_PRESTERA_TRAP_ID_INVALID_SA,
 	DEVLINK_PRESTERA_TRAP_ID_LOCAL_PORT,
-	DEVLINK_PRESTERA_TRAP_ID_PORT_NO_VLAN,
 	DEVLINK_PRESTERA_TRAP_ID_RXDMA_DROP,
 };
 
@@ -96,8 +99,6 @@ enum {
 	"icmp"
 #define DEVLINK_PRESTERA_TRAP_NAME_RXDMA_DROP \
 	"rxdma_drop"
-#define DEVLINK_PRESTERA_TRAP_NAME_PORT_NO_VLAN \
-	"port_no_vlan"
 #define DEVLINK_PRESTERA_TRAP_NAME_LOCAL_PORT \
 	"local_port"
 #define DEVLINK_PRESTERA_TRAP_NAME_INVALID_SA \
@@ -159,6 +160,36 @@ struct prestera_trap_data {
 			    DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
 			    PRESTERA_TRAP_METADATA)
 
+#define PRESTERA_DEVLINK_PORT_PARAM_NUM		(3)
+#define PRESTERA_DEVLINK_PORT_PARAM_FP_MASK	GENMASK(5, 0)
+#define PRESTERA_DEVLINK_PORT_PARAM_TYPE_MASK	GENMASK(7, 6)
+#define PRESTERA_DEVLINK_PORT_PARAM_PREP_ID(type_id, fp_id)		      \
+	((FIELD_PREP(PRESTERA_DEVLINK_PORT_PARAM_TYPE_MASK, type_id) |	      \
+	 FIELD_PREP(PRESTERA_DEVLINK_PORT_PARAM_FP_MASK, fp_id)) +	      \
+	 PRESTERA_DEVLINK_PORT_PARAM_ID_BASE)
+
+enum {
+	PORT_PARAM_ID_BC_RATE = 0,
+	PORT_PARAM_ID_UC_UNK_RATE = 1,
+	PORT_PARAM_ID_MC_RATE = 2
+};
+
+struct prestera_strom_control_cfg {
+	u32 bc_kbyte_per_sec_rate;
+	u32 unk_uc_kbyte_per_sec_rate;
+	u32 unreg_mc_kbyte_per_sec_rate;
+};
+
+struct prestera_storm_control {
+	struct prestera_switch *sw;
+	struct prestera_strom_control_cfg *cfg;
+	struct devlink_param *port_params[PRESTERA_DEVLINK_PORT_PARAM_NUM];
+};
+
+enum prestera_devlink_port_param_id {
+	PRESTERA_DEVLINK_PORT_PARAM_ID_BASE = DEVLINK_PARAM_GENERIC_ID_MAX + 1,
+};
+
 static const struct devlink_trap_group prestera_trap_groups_arr[] = {
 	/* No policer is associated with following groups (policerid == 0)*/
 	DEVLINK_TRAP_GROUP_GENERIC(L2_DROPS, 0),
@@ -310,10 +341,6 @@ static struct prestera_trap prestera_trap_items_arr[] = {
 		.trap = PRESTERA_TRAP_DRIVER_DROP(RXDMA_DROP, BUFFER_DROPS),
 		.cpu_code = 37,
 	},
-	{
-		.trap = PRESTERA_TRAP_DRIVER_DROP(PORT_NO_VLAN, L2_DROPS),
-		.cpu_code = 39,
-	},
 	{
 		.trap = PRESTERA_TRAP_DRIVER_DROP(LOCAL_PORT, L2_DROPS),
 		.cpu_code = 56,
@@ -341,16 +368,121 @@ static struct prestera_trap prestera_trap_items_arr[] = {
 	},
 	{
 		.trap = PRESTERA_TRAP_DRIVER_DROP(MET_RED, BUFFER_DROPS),
-		.cpu_code = 185,
+		.cpu_code = 186,
 	},
 };
+#endif
+
+static int prestera_storm_control_rate_set(struct devlink *dl, u32 id,
+					   struct devlink_param_gset_ctx *ctx);
+
+static int prestera_storm_control_rate_get(struct devlink *dl, u32 id,
+					   struct devlink_param_gset_ctx *ct);
 
 static void prestera_devlink_traps_fini(struct prestera_switch *sw);
 
+static int prestera_trap_init(struct devlink *devlink,
+			      const struct devlink_trap *trap, void *trap_ctx);
+
+static int prestera_trap_action_set(struct devlink *devlink,
+				    const struct devlink_trap *trap,
+				    enum devlink_trap_action action,
+				    struct netlink_ext_ack *extack);
+
+static int prestera_devlink_traps_register(struct prestera_switch *sw);
+
 static int prestera_drop_counter_get(struct devlink *devlink,
 				     const struct devlink_trap *trap,
 				     u64 *p_drops);
 
+static int prestera_storm_control_init(struct prestera_switch *sw);
+static void prestera_storm_control_fini(struct prestera_switch *sw);
+
+static int prestera_storm_control_rate_set(struct devlink *dl, u32 id,
+					   struct devlink_param_gset_ctx *ctx)
+{
+	struct prestera_switch *sw = devlink_priv(dl);
+	struct prestera_strom_control_cfg *cfg;
+	u32 kbyte_per_sec_rate = ctx->val.vu32;
+	struct prestera_port *port = NULL;
+	struct prestera_storm_control *sc;
+	u32 *param_to_set = NULL;
+	u32 storm_type;
+	int type_id;
+	int fp_id;
+	int ret;
+
+	id -= PRESTERA_DEVLINK_PORT_PARAM_ID_BASE;
+	fp_id = FIELD_GET(PRESTERA_DEVLINK_PORT_PARAM_FP_MASK, id);
+	type_id = FIELD_GET(PRESTERA_DEVLINK_PORT_PARAM_TYPE_MASK, id);
+
+	port = prestera_port_find_by_fp_id(fp_id);
+	if (!port)
+		return -EINVAL;
+
+	sc = sw->storm_control;
+	cfg = &sc->cfg[fp_id - 1];
+
+	switch (type_id) {
+	case PORT_PARAM_ID_BC_RATE:
+		param_to_set = &cfg->bc_kbyte_per_sec_rate;
+		storm_type = PRESTERA_PORT_STORM_CTL_TYPE_BC;
+		break;
+	case PORT_PARAM_ID_UC_UNK_RATE:
+		param_to_set = &cfg->unk_uc_kbyte_per_sec_rate;
+		storm_type = PRESTERA_PORT_STORM_CTL_TYPE_UC_UNK;
+		break;
+	case PORT_PARAM_ID_MC_RATE:
+		param_to_set = &cfg->unreg_mc_kbyte_per_sec_rate;
+		storm_type = PRESTERA_PORT_STORM_CTL_TYPE_MC;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (kbyte_per_sec_rate != *param_to_set) {
+		ret = prestera_hw_port_storm_control_cfg_set(port, storm_type,
+							     kbyte_per_sec_rate);
+		if (ret)
+			return ret;
+
+		*param_to_set = kbyte_per_sec_rate;
+	}
+
+	return 0;
+}
+
+static int prestera_storm_control_rate_get(struct devlink *dl, u32 id,
+					   struct devlink_param_gset_ctx *ctx)
+{
+	struct prestera_switch *sw = devlink_priv(dl);
+	struct prestera_strom_control_cfg *cfg;
+	struct prestera_storm_control *sc;
+	int type_id;
+	int fp_id;
+
+	id -= PRESTERA_DEVLINK_PORT_PARAM_ID_BASE;
+	fp_id = FIELD_GET(PRESTERA_DEVLINK_PORT_PARAM_FP_MASK, id);
+	type_id = FIELD_GET(PRESTERA_DEVLINK_PORT_PARAM_TYPE_MASK, id);
+
+	sc = sw->storm_control;
+	cfg = &sc->cfg[fp_id - 1];
+
+	switch (type_id) {
+	case PORT_PARAM_ID_BC_RATE:
+		ctx->val.vu32 = cfg->bc_kbyte_per_sec_rate;
+		return 0;
+	case PORT_PARAM_ID_UC_UNK_RATE:
+		ctx->val.vu32 = cfg->unk_uc_kbyte_per_sec_rate;
+		return 0;
+	case PORT_PARAM_ID_MC_RATE:
+		ctx->val.vu32 = cfg->unreg_mc_kbyte_per_sec_rate;
+		return 0;
+	default:
+		return -EINVAL;
+	}
+}
+
 static int prestera_dl_info_get(struct devlink *dl,
 				struct devlink_info_req *req,
 				struct netlink_ext_ack *extack)
@@ -373,16 +505,6 @@ static int prestera_dl_info_get(struct devlink *dl,
 					       buf);
 }
 
-static int prestera_trap_init(struct devlink *devlink,
-			      const struct devlink_trap *trap, void *trap_ctx);
-
-static int prestera_trap_action_set(struct devlink *devlink,
-				    const struct devlink_trap *trap,
-				    enum devlink_trap_action action,
-				    struct netlink_ext_ack *extack);
-
-static int prestera_devlink_traps_register(struct prestera_switch *sw);
-
 static const struct devlink_ops prestera_dl_ops = {
 	.info_get = prestera_dl_info_get,
 	.trap_init = prestera_trap_init,
@@ -390,12 +512,11 @@ static const struct devlink_ops prestera_dl_ops = {
 	.trap_drop_counter_get = prestera_drop_counter_get,
 };
 
-struct prestera_switch *prestera_devlink_alloc(struct prestera_device *dev)
+struct prestera_switch *prestera_devlink_alloc(void)
 {
 	struct devlink *dl;
 
-	dl = devlink_alloc(&prestera_dl_ops, sizeof(struct prestera_switch),
-			   dev->dev);
+	dl = devlink_alloc(&prestera_dl_ops, sizeof(struct prestera_switch));
 
 	return devlink_priv(dl);
 }
@@ -412,9 +533,9 @@ int prestera_devlink_register(struct prestera_switch *sw)
 	struct devlink *dl = priv_to_devlink(sw);
 	int err;
 
-	err = devlink_register(dl);
+	err = devlink_register(dl, sw->dev->dev);
 	if (err) {
-		dev_err(prestera_dev(sw), "devlink_register failed: %d\n", err);
+		dev_err(sw->dev->dev, "devlink_register failed: %d\n", err);
 		return err;
 	}
 
@@ -426,27 +547,40 @@ int prestera_devlink_register(struct prestera_switch *sw)
 		return err;
 	}
 
+	err = prestera_storm_control_init(sw);
+	if (err) {
+		prestera_devlink_traps_fini(sw);
+		devlink_unregister(dl);
+		dev_err(sw->dev->dev,
+			"prestera_storm_control_init failed: %d\n",
+			err);
+		return err;
+	}
+
 	return 0;
 }
 
 void prestera_devlink_unregister(struct prestera_switch *sw)
 {
-	struct prestera_trap_data *trap_data = sw->trap_data;
 	struct devlink *dl = priv_to_devlink(sw);
 
 	prestera_devlink_traps_fini(sw);
+	prestera_storm_control_fini(sw);
 	devlink_unregister(dl);
-
-	kfree(trap_data->trap_items_arr);
-	kfree(trap_data);
 }
 
 int prestera_devlink_port_register(struct prestera_port *port)
 {
 	struct prestera_switch *sw = port->sw;
-	struct devlink *dl = priv_to_devlink(sw);
 	struct devlink_port_attrs attrs = {};
+	struct prestera_storm_control *sc;
+	struct devlink *dl;
 	int err;
+	int i;
+
+	sc = sw->storm_control;
+
+	dl = priv_to_devlink(sw);
 
 	attrs.flavour = DEVLINK_PORT_FLAVOUR_PHYSICAL;
 	attrs.phys.port_number = port->fp_id;
@@ -457,21 +591,54 @@ int prestera_devlink_port_register(struct prestera_port *port)
 
 	err = devlink_port_register(dl, &port->dl_port, port->fp_id);
 	if (err) {
-		dev_err(prestera_dev(sw), "devlink_port_register failed: %d\n", err);
+		dev_err(sw->dev->dev, "devlink_port_register failed\n");
 		return err;
 	}
 
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i) {
+		struct devlink_param *port_params =
+			&sc->port_params[i][port->fp_id - 1];
+
+		err = devlink_port_params_register(&port->dl_port,
+						   port_params,
+						   1);
+		if (err) {
+			devlink_port_unregister(&port->dl_port);
+			dev_err(sw->dev->dev,
+				"devlink_port_params_register failed\n");
+			return err;
+		}
+	}
+
+	devlink_port_params_publish(&port->dl_port);
+
 	return 0;
 }
 
 void prestera_devlink_port_unregister(struct prestera_port *port)
 {
+	struct prestera_switch *sw = port->sw;
+	struct prestera_storm_control *sc;
+	int i;
+
+	sc = sw->storm_control;
+
+	devlink_port_params_unpublish(&port->dl_port);
+
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i) {
+		struct devlink_param *port_params = sc->port_params[i];
+
+		devlink_port_params_unregister(&port->dl_port,
+					       &port_params[port->fp_id - 1],
+					       1);
+	}
+
 	devlink_port_unregister(&port->dl_port);
 }
 
 void prestera_devlink_port_set(struct prestera_port *port)
 {
-	devlink_port_type_eth_set(&port->dl_port, port->dev);
+	devlink_port_type_eth_set(&port->dl_port, port->net_dev);
 }
 
 void prestera_devlink_port_clear(struct prestera_port *port)
@@ -486,20 +653,98 @@ struct devlink_port *prestera_devlink_get_port(struct net_device *dev)
 	return &port->dl_port;
 }
 
+static int prestera_storm_control_init(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc;
+	int i, j;
+	int err;
+
+	sc = kzalloc(sizeof(*sc), GFP_KERNEL);
+	if (!sc)
+		return -ENOMEM;
+
+	sc->cfg = kcalloc(sw->port_count,
+			  sizeof(*sc->cfg),
+			  GFP_KERNEL);
+	if (!sc->cfg) {
+		err = -ENOMEM;
+		goto err_values_alloca;
+	}
+
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i) {
+		sc->port_params[i] =
+			kcalloc(sw->port_count, sizeof(struct devlink_param),
+				GFP_KERNEL);
+		if (!sc->port_params[i]) {
+			err = -ENOMEM;
+			goto err_params_alloca;
+		}
+	}
+
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i) {
+		const char *param_names[PRESTERA_DEVLINK_PORT_PARAM_NUM] = {
+			[PORT_PARAM_ID_BC_RATE] =
+				"bc_kbyte_per_sec_rate",
+			[PORT_PARAM_ID_UC_UNK_RATE] =
+				"unk_uc_kbyte_per_sec_rate",
+			[PORT_PARAM_ID_MC_RATE] =
+				"unreg_mc_kbyte_per_sec_rate",
+		};
+		struct devlink_param *port_params = sc->port_params[i];
+
+		for (j = 0; j < sw->port_count; ++j) {
+			port_params[j].id =
+				PRESTERA_DEVLINK_PORT_PARAM_PREP_ID(i, j + 1);
+			port_params[j].name = param_names[i];
+			port_params[j].type = DEVLINK_PARAM_TYPE_U32;
+			port_params[j].supported_cmodes =
+				BIT(DEVLINK_PARAM_CMODE_RUNTIME);
+			port_params[j].get = prestera_storm_control_rate_get;
+			port_params[j].set = prestera_storm_control_rate_set;
+		}
+	}
+
+	sc->sw = sw;
+	sw->storm_control = sc;
+
+	return 0;
+
+err_params_alloca:
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i)
+		kfree(sc->port_params[i]);
+	kfree(sc->cfg);
+err_values_alloca:
+	kfree(sc);
+	return err;
+}
+
+static void prestera_storm_control_fini(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc = sw->storm_control;
+	int i;
+
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i)
+		kfree(sc->port_params[i]);
+
+	kfree(sc->cfg);
+	kfree(sc);
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
 static int prestera_devlink_traps_register(struct prestera_switch *sw)
 {
 	const u32 groups_count = ARRAY_SIZE(prestera_trap_groups_arr);
 	const u32 traps_count = ARRAY_SIZE(prestera_trap_items_arr);
 	struct devlink *devlink = priv_to_devlink(sw);
-	struct prestera_trap_data *trap_data;
 	struct prestera_trap *prestera_trap;
+	struct prestera_trap_data *trap_data;
 	int err, i;
 
 	trap_data = kzalloc(sizeof(*trap_data), GFP_KERNEL);
 	if (!trap_data)
 		return -ENOMEM;
 
-	trap_data->trap_items_arr = kcalloc(traps_count,
+	trap_data->trap_items_arr = kcalloc(ARRAY_SIZE(prestera_trap_items_arr),
 					    sizeof(struct prestera_trap_item),
 					    GFP_KERNEL);
 	if (!trap_data->trap_items_arr) {
@@ -508,7 +753,7 @@ static int prestera_devlink_traps_register(struct prestera_switch *sw)
 	}
 
 	trap_data->sw = sw;
-	trap_data->traps_count = traps_count;
+	trap_data->traps_count = ARRAY_SIZE(prestera_trap_items_arr);
 	sw->trap_data = trap_data;
 
 	err = devlink_trap_groups_register(devlink, prestera_trap_groups_arr,
@@ -531,8 +776,6 @@ static int prestera_devlink_traps_register(struct prestera_switch *sw)
 		prestera_trap = &prestera_trap_items_arr[i];
 		devlink_traps_unregister(devlink, &prestera_trap->trap, 1);
 	}
-	devlink_trap_groups_unregister(devlink, prestera_trap_groups_arr,
-				       groups_count);
 err_groups_register:
 	kfree(trap_data->trap_items_arr);
 err_trap_items_alloc:
@@ -608,7 +851,7 @@ static int prestera_trap_action_set(struct devlink *devlink,
 				    struct netlink_ext_ack *extack)
 {
 	/* Currently, driver does not support trap action altering */
-	return -EOPNOTSUPP;
+	return -ENOTSUPP;
 }
 
 static int prestera_drop_counter_get(struct devlink *devlink,
@@ -620,13 +863,19 @@ static int prestera_drop_counter_get(struct devlink *devlink,
 		PRESTERA_HW_CPU_CODE_CNT_TYPE_DROP;
 	struct prestera_trap *prestera_trap =
 		container_of(trap, struct prestera_trap, trap);
+	int ret;
+
+	ret = prestera_hw_cpu_code_counters_get(sw, prestera_trap->cpu_code,
+						cpu_code_type, p_drops);
+	if (ret)
+		return ret;
 
-	return prestera_hw_cpu_code_counters_get(sw, prestera_trap->cpu_code,
-						 cpu_code_type, p_drops);
+	return 0;
 }
 
 static void prestera_devlink_traps_fini(struct prestera_switch *sw)
 {
+	struct prestera_trap_data *trap_data = sw->trap_data;
 	struct devlink *dl = priv_to_devlink(sw);
 	const struct devlink_trap *trap;
 	int i;
@@ -638,4 +887,36 @@ static void prestera_devlink_traps_fini(struct prestera_switch *sw)
 
 	devlink_trap_groups_unregister(dl, prestera_trap_groups_arr,
 				       ARRAY_SIZE(prestera_trap_groups_arr));
+
+	kfree(trap_data->trap_items_arr);
+	kfree(trap_data);
+}
+#else
+static int prestera_devlink_traps_register(struct prestera_switch *sw)
+{
+	return 0;
+}
+
+static int prestera_trap_init(struct devlink *devlink,
+			      const struct devlink_trap *trap, void *trap_ctx)
+{
+	return 0;
+}
+
+static int prestera_trap_action_set(struct devlink *devlink,
+				    const struct devlink_trap *trap,
+				    enum devlink_trap_action action,
+				    struct netlink_ext_ack *extack)
+{
+	return 0;
+}
+
+static void prestera_devlink_traps_fini(struct prestera_switch *sw)
+{
+}
+
+void prestera_devlink_trap_report(struct prestera_port *port,
+				  struct sk_buff *skb, u8 cpu_code)
+{
 }
+#endif
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_devlink.h b/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
index cc34c3db13a2..27bc1c812a33 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
@@ -1,12 +1,12 @@
 /* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved. */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _PRESTERA_DEVLINK_H_
 #define _PRESTERA_DEVLINK_H_
 
 #include "prestera.h"
 
-struct prestera_switch *prestera_devlink_alloc(struct prestera_device *dev);
+struct prestera_switch *prestera_devlink_alloc(void);
 void prestera_devlink_free(struct prestera_switch *sw);
 
 int prestera_devlink_register(struct prestera_switch *sw);
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h b/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
new file mode 100644
index 000000000000..b2ffa442d223
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _PRESTERA_DRV_VER_H_
+#define _PRESTERA_DRV_VER_H_
+
+#include <linux/stringify.h>
+
+/* Prestera driver version */
+#define PRESTERA_DRV_VER_MAJOR	2
+#define PRESTERA_DRV_VER_MINOR	0
+#define PRESTERA_DRV_VER_PATCH	0
+#define PRESTERA_DRV_VER_EXTRA
+
+#define PRESTERA_DRV_VER \
+		__stringify(PRESTERA_DRV_VER_MAJOR)  "." \
+		__stringify(PRESTERA_DRV_VER_MINOR)  "." \
+		__stringify(PRESTERA_DRV_VER_PATCH)  \
+		__stringify(PRESTERA_DRV_VER_EXTRA)
+
+#endif  /* _PRESTERA_DRV_VER_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_dsa.c b/drivers/net/ethernet/marvell/prestera/prestera_dsa.c
index b7e89c0ca5c0..96103af7dec8 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_dsa.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_dsa.c
@@ -1,107 +1,314 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
-#include <linux/bitfield.h>
+#include "prestera.h"
+#include "prestera_dsa.h"
+
+#include <linux/string.h>
 #include <linux/bitops.h>
+#include <linux/bitfield.h>
 #include <linux/errno.h>
-#include <linux/string.h>
 
-#include "prestera_dsa.h"
+#define W0_MASK_IS_TAGGED	BIT(29)
+
+/* TrgDev[4:0] = {Word0[28:24]} */
+#define W0_MASK_HW_DEV_NUM	GENMASK(28, 24)
+
+/* SrcPort/TrgPort extended to 8b
+ * SrcPort/TrgPort[7:0] = {Word2[20], Word1[11:10], Word0[23:19]}
+ */
+#define W0_MASK_IFACE_PORT_NUM	GENMASK(23, 19)
+
+/* bits 30:31 - TagCommand 1 = FROM_CPU */
+#define W0_MASK_DSA_CMD		GENMASK(31, 30)
+
+/* bits 13:15 -- UP */
+#define W0_MASK_VPT		GENMASK(15, 13)
+
+#define W0_MASK_EXT_BIT		BIT(12)
+#define W0_MASK_OPCODE		GENMASK(18, 16)
+
+/* bit 16 - CFI */
+#define W0_MASK_CFI_BIT		BIT(16)
+
+/* bits 0:11 -- VID */
+#define W0_MASK_VID		GENMASK(11, 0)
+
+#define W1_MASK_SRC_IS_TARNK	BIT(27)
+
+/* SrcPort/TrgPort extended to 8b
+ * SrcPort/TrgPort[7:0] = {Word2[20], Word1[11:10], Word0[23:19]}
+ */
+#define W1_MASK_IFACE_PORT_NUM	GENMASK(11, 10)
+
+#define W1_MASK_EXT_BIT		BIT(31)
+#define W1_MASK_CFI_BIT		BIT(30)
+
+/* bit 30 -- EgressFilterEn */
+#define W1_MASK_EGR_FILTER_EN	BIT(30)
 
-#define PRESTERA_DSA_W0_CMD		GENMASK(31, 30)
-#define PRESTERA_DSA_W0_IS_TAGGED	BIT(29)
-#define PRESTERA_DSA_W0_DEV_NUM		GENMASK(28, 24)
-#define PRESTERA_DSA_W0_PORT_NUM	GENMASK(23, 19)
-#define PRESTERA_DSA_W0_VPT		GENMASK(15, 13)
-#define PRESTERA_DSA_W0_EXT_BIT		BIT(12)
-#define PRESTERA_DSA_W0_VID		GENMASK(11, 0)
+/* bit 28 -- egrFilterRegistered */
+#define W1_MASK_EGR_FILTER_REG	BIT(28)
 
-#define PRESTERA_DSA_W1_EXT_BIT		BIT(31)
-#define PRESTERA_DSA_W1_CFI_BIT		BIT(30)
-#define PRESTERA_DSA_W1_PORT_NUM	GENMASK(11, 10)
-#define PRESTERA_DSA_W1_MASK_CPU_CODE	GENMASK(7, 0)
+/* bits 20-24 -- Src-ID */
+#define W1_MASK_SRC_ID		GENMASK(24, 20)
 
-#define PRESTERA_DSA_W2_EXT_BIT		BIT(31)
-#define PRESTERA_DSA_W2_PORT_NUM	BIT(20)
+/* bits 15-19 -- SrcDev */
+#define W1_MASK_SRC_DEV		GENMASK(19, 15)
 
-#define PRESTERA_DSA_W3_VID		GENMASK(30, 27)
-#define PRESTERA_DSA_W3_DST_EPORT	GENMASK(23, 7)
-#define PRESTERA_DSA_W3_DEV_NUM		GENMASK(6, 0)
+/* SrcTrunk is extended to 12b
+ * SrcTrunk[11:0] = {Word2[14:3]
+ */
+#define W2_MASK_SRC_TRANK_ID	GENMASK(14, 3)
 
-#define PRESTERA_DSA_VID		GENMASK(15, 12)
-#define PRESTERA_DSA_DEV_NUM		GENMASK(11, 5)
+/* SRCePort[16:0]/TRGePort[16:0]/ = {Word2[19:3]} */
+#define W2_MASK_IFACE_EPORT	GENMASK(19, 3)
 
-int prestera_dsa_parse(struct prestera_dsa *dsa, const u8 *dsa_buf)
+/* SrcPort/TrgPort extended to 8b
+ * SrcPort/TrgPort[7:0] = {Word2[20], Word1[11:10], Word0[23:19]}
+ */
+#define W2_MASK_IFACE_PORT_NUM	BIT(20)
+
+#define W2_MASK_EXT_BIT		BIT(31)
+
+/* 5b SrcID is extended to 12 bits
+ * SrcID[11:0] = {Word2[27:21], Word1[24:20]}
+ */
+#define W2_MASK_SRC_ID		GENMASK(27, 21)
+
+/* 5b SrcDev is extended to 12b
+ * SrcDev[11:0] = {Word2[20:14], Word1[19:15]}
+ */
+#define W2_MASK_SRC_DEV		GENMASK(20, 14)
+
+/* trgHwDev and trgPort
+ * TrgDev[11:5] = {Word3[6:0]}
+ */
+#define W3_MASK_HW_DEV_NUM	GENMASK(6, 0)
+
+/* bits 0-7 -- CpuCode */
+#define W1_MASK_CPU_CODE	GENMASK(7, 0)
+
+/* VID becomes 16b eVLAN. eVLAN[15:0] = {Word3[30:27], Word0[11:0]} */
+#define W3_MASK_VID		GENMASK(30, 27)
+
+/* TRGePort[16:0] = {Word3[23:7]} */
+#define W3_MASK_DST_EPORT	GENMASK(23, 7)
+
+#define DEV_NUM_MASK		GENMASK(11, 5)
+#define VID_MASK		GENMASK(15, 12)
+
+static int net_if_dsa_to_cpu_parse(const u32 *words_ptr,
+				   struct mvsw_pr_dsa *dsa_info_ptr)
 {
-	__be32 *dsa_words = (__be32 *)dsa_buf;
-	enum prestera_dsa_cmd cmd;
-	u32 words[4];
-	u32 field;
+	u32 get_value;	/* used to get needed bits from the DSA */
+	struct mvsw_pr_dsa_to_cpu *to_cpu_ptr;
 
-	words[0] = ntohl(dsa_words[0]);
-	words[1] = ntohl(dsa_words[1]);
-	words[2] = ntohl(dsa_words[2]);
-	words[3] = ntohl(dsa_words[3]);
+	to_cpu_ptr = &dsa_info_ptr->dsa_info.to_cpu;
+	to_cpu_ptr->is_tagged =
+	    (bool)FIELD_GET(W0_MASK_IS_TAGGED, words_ptr[0]);
+	to_cpu_ptr->hw_dev_num = FIELD_GET(W0_MASK_HW_DEV_NUM, words_ptr[0]);
+	to_cpu_ptr->src_is_trunk =
+	    (bool)FIELD_GET(W1_MASK_SRC_IS_TARNK, words_ptr[1]);
+
+	/* set hw dev num */
+	get_value = FIELD_GET(W3_MASK_HW_DEV_NUM, words_ptr[3]);
+	to_cpu_ptr->hw_dev_num &= W3_MASK_HW_DEV_NUM;
+	to_cpu_ptr->hw_dev_num |= FIELD_PREP(DEV_NUM_MASK, get_value);
+
+	get_value = FIELD_GET(W1_MASK_CPU_CODE, words_ptr[1]);
+	to_cpu_ptr->cpu_code = (u8)get_value;
+
+	if (to_cpu_ptr->src_is_trunk) {
+		to_cpu_ptr->iface.src_trunk_id =
+		    (u16)FIELD_GET(W2_MASK_SRC_TRANK_ID, words_ptr[2]);
+	} else {
+		/* When to_cpu_ptr->is_egress_pipe = false:
+		 *   this field indicates the source ePort number assigned by
+		 *   the ingress device.
+		 * When to_cpu_ptr->is_egress_pipe = true:
+		 *   this field indicates the target ePort number assigned by
+		 *   the ingress device.
+		 */
+		to_cpu_ptr->iface.eport =
+		    FIELD_GET(W2_MASK_IFACE_EPORT, words_ptr[2]);
+	}
+	to_cpu_ptr->iface.port_num =
+	    (FIELD_GET(W0_MASK_IFACE_PORT_NUM, words_ptr[0]) << 0) |
+	    (FIELD_GET(W1_MASK_IFACE_PORT_NUM, words_ptr[1]) << 5) |
+	    (FIELD_GET(W2_MASK_IFACE_PORT_NUM, words_ptr[2]) << 7);
+
+	return 0;
+}
+
+int mvsw_pr_dsa_parse(const u8 *dsa_bytes_ptr, struct mvsw_pr_dsa *dsa_info_ptr)
+{
+	u32 get_value;		/* used to get needed bits from the DSA */
+	u32 words_ptr[4] = { 0 };	/* DSA tag can be up to 4 words */
+	u32 *dsa_words_ptr = (u32 *)dsa_bytes_ptr;
+
+	/* sanity */
+	if (unlikely(!dsa_info_ptr || !dsa_bytes_ptr))
+		return -EINVAL;
+
+	/* zero results */
+	memset(dsa_info_ptr, 0, sizeof(struct mvsw_pr_dsa));
+
+	/* copy the data of the first word */
+	words_ptr[0] = ntohl((__force __be32)dsa_words_ptr[0]);
 
 	/* set the common parameters */
-	cmd = (enum prestera_dsa_cmd)FIELD_GET(PRESTERA_DSA_W0_CMD, words[0]);
+	dsa_info_ptr->dsa_cmd =
+	    (enum mvsw_pr_dsa_cmd)FIELD_GET(W0_MASK_DSA_CMD, words_ptr[0]);
+
+	/* vid & vlan prio */
+	dsa_info_ptr->common_params.vid =
+	    (u16)FIELD_GET(W0_MASK_VID, words_ptr[0]);
+	dsa_info_ptr->common_params.vpt =
+	    (u8)FIELD_GET(W0_MASK_VPT, words_ptr[0]);
 
 	/* only to CPU is supported */
-	if (unlikely(cmd != PRESTERA_DSA_CMD_TO_CPU))
+	if (unlikely(dsa_info_ptr->dsa_cmd != MVSW_NET_DSA_CMD_TO_CPU_E))
 		return -EINVAL;
 
-	if (FIELD_GET(PRESTERA_DSA_W0_EXT_BIT, words[0]) == 0)
+	/* check extended bit */
+	if (FIELD_GET(W0_MASK_EXT_BIT, words_ptr[0]) == 0)
+		/* 1 words DSA tag is not supported */
 		return -EINVAL;
-	if (FIELD_GET(PRESTERA_DSA_W1_EXT_BIT, words[1]) == 0)
+
+	/* check that the "old" cpu opcode is set the 0xF
+	 * (with the extended bit)
+	 */
+	if (FIELD_GET(W0_MASK_OPCODE, words_ptr[0]) != 0x07)
 		return -EINVAL;
-	if (FIELD_GET(PRESTERA_DSA_W2_EXT_BIT, words[2]) == 0)
+
+	/* copy the data of the second word */
+	words_ptr[1] = ntohl((__force __be32)dsa_words_ptr[1]);
+
+	/* check the extended bit */
+	if (FIELD_GET(W1_MASK_EXT_BIT, words_ptr[1]) == 0)
+		/* 2 words DSA tag is not supported */
+		return -EINVAL;
+
+	/* copy the data of the third word */
+	words_ptr[2] = ntohl((__force __be32)dsa_words_ptr[2]);
+
+	/* check the extended bit */
+	if (FIELD_GET(W2_MASK_EXT_BIT, words_ptr[1]) == 0)
+		/* 3 words DSA tag is not supported */
 		return -EINVAL;
 
-	field = FIELD_GET(PRESTERA_DSA_W3_VID, words[3]);
+	/* copy the data of the forth word */
+	words_ptr[3] = ntohl((__force __be32)dsa_words_ptr[3]);
 
-	dsa->vlan.is_tagged = FIELD_GET(PRESTERA_DSA_W0_IS_TAGGED, words[0]);
-	dsa->vlan.cfi_bit = FIELD_GET(PRESTERA_DSA_W1_CFI_BIT, words[1]);
-	dsa->vlan.vpt = FIELD_GET(PRESTERA_DSA_W0_VPT, words[0]);
-	dsa->vlan.vid = FIELD_GET(PRESTERA_DSA_W0_VID, words[0]);
-	dsa->vlan.vid &= ~PRESTERA_DSA_VID;
-	dsa->vlan.vid |= FIELD_PREP(PRESTERA_DSA_VID, field);
+	/* VID */
+	get_value = FIELD_GET(W3_MASK_VID, words_ptr[3]);
+	dsa_info_ptr->common_params.vid &= ~VID_MASK;
+	dsa_info_ptr->common_params.vid |= FIELD_PREP(VID_MASK, get_value);
 
-	field = FIELD_GET(PRESTERA_DSA_W3_DEV_NUM, words[3]);
+	dsa_info_ptr->common_params.cfi_bit =
+	    (u8)FIELD_GET(W1_MASK_CFI_BIT, words_ptr[1]);
 
-	dsa->hw_dev_num = FIELD_GET(PRESTERA_DSA_W0_DEV_NUM, words[0]);
-	dsa->hw_dev_num |= FIELD_PREP(PRESTERA_DSA_DEV_NUM, field);
+	return net_if_dsa_to_cpu_parse(words_ptr, dsa_info_ptr);
+}
 
-	dsa->port_num = (FIELD_GET(PRESTERA_DSA_W0_PORT_NUM, words[0]) << 0) |
-			(FIELD_GET(PRESTERA_DSA_W1_PORT_NUM, words[1]) << 5) |
-			(FIELD_GET(PRESTERA_DSA_W2_PORT_NUM, words[2]) << 7);
+static int net_if_dsa_tag_from_cpu_build(const struct mvsw_pr_dsa *dsa_info_ptr,
+					 u32 *words_ptr)
+{
+	u32 trg_hw_dev = 0;
+	u32 trg_port = 0;
+	const struct mvsw_pr_dsa_from_cpu *from_cpu_ptr =
+	    &dsa_info_ptr->dsa_info.from_cpu;
+
+	if (unlikely(from_cpu_ptr->dst_iface.type != PRESTERA_IF_PORT_E))
+		/* only sending to port interface is supported */
+		return -EINVAL;
 
-	dsa->cpu_code = FIELD_GET(PRESTERA_DSA_W1_MASK_CPU_CODE, words[1]);
+	words_ptr[0] |=
+	    FIELD_PREP(W0_MASK_DSA_CMD, MVSW_NET_DSA_CMD_FROM_CPU_E);
+
+	trg_hw_dev = from_cpu_ptr->dst_iface.dev_port.hw_dev_num;
+	trg_port = from_cpu_ptr->dst_iface.dev_port.port_num;
+
+	if (trg_hw_dev >= BIT(12))
+		return -EINVAL;
+
+	if (trg_port >= BIT(8) || trg_port >= BIT(10))
+		return -EINVAL;
+
+	words_ptr[0] |= FIELD_PREP(W0_MASK_HW_DEV_NUM, trg_hw_dev);
+	words_ptr[3] |= FIELD_PREP(W3_MASK_HW_DEV_NUM, (trg_hw_dev >> 5));
+
+	if (dsa_info_ptr->common_params.cfi_bit == 1)
+		words_ptr[0] |= FIELD_PREP(W0_MASK_CFI_BIT, 1);
+
+	words_ptr[0] |= FIELD_PREP(W0_MASK_VPT,
+				   dsa_info_ptr->common_params.vpt);
+	words_ptr[0] |= FIELD_PREP(W0_MASK_VID,
+				   dsa_info_ptr->common_params.vid);
+
+	/* set extended bits */
+	words_ptr[0] |= FIELD_PREP(W0_MASK_EXT_BIT, 1);
+	words_ptr[1] |= FIELD_PREP(W1_MASK_EXT_BIT, 1);
+	words_ptr[2] |= FIELD_PREP(W2_MASK_EXT_BIT, 1);
+
+	if (from_cpu_ptr->egr_filter_en)
+		words_ptr[1] |= FIELD_PREP(W1_MASK_EGR_FILTER_EN, 1);
+
+	if (from_cpu_ptr->egr_filter_registered)
+		words_ptr[1] |= FIELD_PREP(W1_MASK_EGR_FILTER_REG, 1);
+
+	/* check src_id & src_hw_dev */
+	if (from_cpu_ptr->src_id >= BIT(12) ||
+	    from_cpu_ptr->src_hw_dev >= BIT(12)) {
+		return -EINVAL;
+	}
+
+	words_ptr[1] |= FIELD_PREP(W1_MASK_SRC_ID, from_cpu_ptr->src_id);
+	words_ptr[1] |= FIELD_PREP(W1_MASK_SRC_DEV, from_cpu_ptr->src_hw_dev);
+
+	words_ptr[2] |= FIELD_PREP(W2_MASK_SRC_ID, from_cpu_ptr->src_id >> 5);
+	words_ptr[2] |= FIELD_PREP(W2_MASK_SRC_DEV,
+				   from_cpu_ptr->src_hw_dev >> 5);
+
+	/* bits 0:9 -- reserved with value 0 */
+	if (from_cpu_ptr->dst_eport >= BIT(17))
+		return -EINVAL;
+
+	words_ptr[3] |= FIELD_PREP(W3_MASK_DST_EPORT, from_cpu_ptr->dst_eport);
+	words_ptr[3] |= FIELD_PREP(W3_MASK_VID,
+				   (dsa_info_ptr->common_params.vid >> 12));
 
 	return 0;
 }
 
-int prestera_dsa_build(const struct prestera_dsa *dsa, u8 *dsa_buf)
+int mvsw_pr_dsa_build(const struct mvsw_pr_dsa *dsa_info_ptr,
+		      u8 *dsa_bytes_ptr)
 {
-	__be32 *dsa_words = (__be32 *)dsa_buf;
-	u32 dev_num = dsa->hw_dev_num;
-	u32 words[4] = { 0 };
+	int rc;
+	u32 words_ptr[4] = { 0 };	/* 4 words of DSA tag */
+	__be32 *dsa_words_ptr = (__be32 *)dsa_bytes_ptr;
 
-	words[0] |= FIELD_PREP(PRESTERA_DSA_W0_CMD, PRESTERA_DSA_CMD_FROM_CPU);
+	if (unlikely(!dsa_info_ptr || !dsa_bytes_ptr))
+		return -EINVAL;
 
-	words[0] |= FIELD_PREP(PRESTERA_DSA_W0_DEV_NUM, dev_num);
-	dev_num = FIELD_GET(PRESTERA_DSA_DEV_NUM, dev_num);
-	words[3] |= FIELD_PREP(PRESTERA_DSA_W3_DEV_NUM, dev_num);
+	if (dsa_info_ptr->common_params.cfi_bit >= BIT(1) ||
+	    dsa_info_ptr->common_params.vpt >= BIT(3)) {
+		return -EINVAL;
+	}
 
-	words[3] |= FIELD_PREP(PRESTERA_DSA_W3_DST_EPORT, dsa->port_num);
+	if (unlikely(dsa_info_ptr->dsa_cmd != MVSW_NET_DSA_CMD_FROM_CPU_E))
+		return -EINVAL;
 
-	words[0] |= FIELD_PREP(PRESTERA_DSA_W0_EXT_BIT, 1);
-	words[1] |= FIELD_PREP(PRESTERA_DSA_W1_EXT_BIT, 1);
-	words[2] |= FIELD_PREP(PRESTERA_DSA_W2_EXT_BIT, 1);
+	/* build form CPU DSA tag */
+	rc = net_if_dsa_tag_from_cpu_build(dsa_info_ptr, words_ptr);
+	if (rc != 0)
+		return rc;
 
-	dsa_words[0] = htonl(words[0]);
-	dsa_words[1] = htonl(words[1]);
-	dsa_words[2] = htonl(words[2]);
-	dsa_words[3] = htonl(words[3]);
+	dsa_words_ptr[0] = htonl(words_ptr[0]);
+	dsa_words_ptr[1] = htonl(words_ptr[1]);
+	dsa_words_ptr[2] = htonl(words_ptr[2]);
+	dsa_words_ptr[3] = htonl(words_ptr[3]);
 
 	return 0;
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_dsa.h b/drivers/net/ethernet/marvell/prestera/prestera_dsa.h
index c99342f475cf..d2e9c0de6606 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_dsa.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_dsa.h
@@ -1,36 +1,65 @@
 /* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
-/* Copyright (c) 2020 Marvell International Ltd. All rights reserved. */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
-#ifndef __PRESTERA_DSA_H_
-#define __PRESTERA_DSA_H_
+#ifndef _MVSW_PRESTERA_DSA_H_
+#define _MVSW_PRESTERA_DSA_H_
 
 #include <linux/types.h>
 
-#define PRESTERA_DSA_HLEN	16
+#define MVSW_PR_DSA_HLEN	16
 
-enum prestera_dsa_cmd {
+enum mvsw_pr_dsa_cmd {
 	/* DSA command is "To CPU" */
-	PRESTERA_DSA_CMD_TO_CPU = 0,
+	MVSW_NET_DSA_CMD_TO_CPU_E = 0,
 
-	/* DSA command is "From CPU" */
-	PRESTERA_DSA_CMD_FROM_CPU,
+	/* DSA command is "FROM CPU" */
+	MVSW_NET_DSA_CMD_FROM_CPU_E,
 };
 
-struct prestera_dsa_vlan {
-	u16 vid;
+struct mvsw_pr_dsa_common {
+	/* the value vlan priority tag (APPLICABLE RANGES: 0..7) */
 	u8 vpt;
+
+	/* CFI bit of the vlan tag (APPLICABLE RANGES: 0..1) */
 	u8 cfi_bit;
-	bool is_tagged;
+
+	/* Vlan id */
+	u16 vid;
 };
 
-struct prestera_dsa {
-	struct prestera_dsa_vlan vlan;
+struct mvsw_pr_dsa_to_cpu {
+	bool is_tagged;
 	u32 hw_dev_num;
-	u32 port_num;
+	bool src_is_trunk;
 	u8 cpu_code;
+	struct {
+		u16 src_trunk_id;
+		u32 port_num;
+		u32 eport;
+	} iface;
+};
+
+struct mvsw_pr_dsa_from_cpu {
+	struct prestera_iface dst_iface;	/* vid/port */
+	bool egr_filter_en;
+	bool egr_filter_registered;
+	u32 src_id;
+	u32 src_hw_dev;
+	u32 dst_eport;	/* for port but not for vid */
+};
+
+struct mvsw_pr_dsa {
+	struct mvsw_pr_dsa_common common_params;
+	enum mvsw_pr_dsa_cmd dsa_cmd;
+	union {
+		struct mvsw_pr_dsa_to_cpu to_cpu;
+		struct mvsw_pr_dsa_from_cpu from_cpu;
+	} dsa_info;
 };
 
-int prestera_dsa_parse(struct prestera_dsa *dsa, const u8 *dsa_buf);
-int prestera_dsa_build(const struct prestera_dsa *dsa, u8 *dsa_buf);
+int mvsw_pr_dsa_parse(const u8 *dsa_bytes_ptr,
+		      struct mvsw_pr_dsa *dsa_info_ptr);
+int mvsw_pr_dsa_build(const struct mvsw_pr_dsa *dsa_info_ptr,
+		      u8 *dsa_bytes_ptr);
 
-#endif /* _PRESTERA_DSA_H_ */
+#endif /* _MVSW_PRESTERA_DSA_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c
index 93a5e2baf808..2ddf22c23402 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <linux/ethtool.h>
 #include <linux/kernel.h>
@@ -9,22 +9,24 @@
 #include "prestera.h"
 #include "prestera_hw.h"
 
-#define PRESTERA_STATS_CNT \
-	(sizeof(struct prestera_port_stats) / sizeof(u64))
-#define PRESTERA_STATS_IDX(name) \
-	(offsetof(struct prestera_port_stats, name) / sizeof(u64))
-#define PRESTERA_STATS_FIELD(name)	\
-	[PRESTERA_STATS_IDX(name)] = __stringify(name)
+static const char prestera_driver_kind[] = "prestera";
 
-static const char driver_kind[] = "prestera";
+#define PORT_STATS_CNT	(sizeof(struct prestera_port_stats) / sizeof(u64))
+#define PORT_STATS_IDX(name) \
+	(offsetof(struct prestera_port_stats, name) / sizeof(u64))
+#define PORT_STATS_FIELD(name)	\
+	[PORT_STATS_IDX(name)] = __stringify(name)
 
-static const struct prestera_link_mode {
+struct prestera_link_mode {
 	enum ethtool_link_mode_bit_indices eth_mode;
 	u32 speed;
 	u64 pr_mask;
 	u8 duplex;
 	u8 port_type;
-} port_link_modes[PRESTERA_LINK_MODE_MAX] = {
+};
+
+static const struct prestera_link_mode
+prestera_link_modes[PRESTERA_LINK_MODE_MAX] = {
 	[PRESTERA_LINK_MODE_10baseT_Half] = {
 		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Half_BIT,
 		.speed = 10,
@@ -201,11 +203,13 @@ static const struct prestera_link_mode {
 	}
 };
 
-static const struct prestera_fec {
+struct prestera_fec {
 	u32 eth_fec;
 	enum ethtool_link_mode_bit_indices eth_mode;
 	u8 pr_fec;
-} port_fec_caps[PRESTERA_PORT_FEC_MAX] = {
+};
+
+static const struct prestera_fec prestera_fec_caps[PRESTERA_PORT_FEC_MAX] = {
 	[PRESTERA_PORT_FEC_OFF] = {
 		.eth_fec = ETHTOOL_FEC_OFF,
 		.eth_mode = ETHTOOL_LINK_MODE_FEC_NONE_BIT,
@@ -223,10 +227,13 @@ static const struct prestera_fec {
 	}
 };
 
-static const struct prestera_port_type {
+struct prestera_port_type {
 	enum ethtool_link_mode_bit_indices eth_mode;
 	u8 eth_type;
-} port_types[PRESTERA_PORT_TYPE_MAX] = {
+};
+
+static const struct prestera_port_type
+prestera_port_types[PRESTERA_PORT_TYPE_MAX] = {
 	[PRESTERA_PORT_TYPE_NONE] = {
 		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
 		.eth_type = PORT_NONE,
@@ -261,157 +268,253 @@ static const struct prestera_port_type {
 	}
 };
 
-static const char prestera_cnt_name[PRESTERA_STATS_CNT][ETH_GSTRING_LEN] = {
-	PRESTERA_STATS_FIELD(good_octets_received),
-	PRESTERA_STATS_FIELD(bad_octets_received),
-	PRESTERA_STATS_FIELD(mac_trans_error),
-	PRESTERA_STATS_FIELD(broadcast_frames_received),
-	PRESTERA_STATS_FIELD(multicast_frames_received),
-	PRESTERA_STATS_FIELD(frames_64_octets),
-	PRESTERA_STATS_FIELD(frames_65_to_127_octets),
-	PRESTERA_STATS_FIELD(frames_128_to_255_octets),
-	PRESTERA_STATS_FIELD(frames_256_to_511_octets),
-	PRESTERA_STATS_FIELD(frames_512_to_1023_octets),
-	PRESTERA_STATS_FIELD(frames_1024_to_max_octets),
-	PRESTERA_STATS_FIELD(excessive_collision),
-	PRESTERA_STATS_FIELD(multicast_frames_sent),
-	PRESTERA_STATS_FIELD(broadcast_frames_sent),
-	PRESTERA_STATS_FIELD(fc_sent),
-	PRESTERA_STATS_FIELD(fc_received),
-	PRESTERA_STATS_FIELD(buffer_overrun),
-	PRESTERA_STATS_FIELD(undersize),
-	PRESTERA_STATS_FIELD(fragments),
-	PRESTERA_STATS_FIELD(oversize),
-	PRESTERA_STATS_FIELD(jabber),
-	PRESTERA_STATS_FIELD(rx_error_frame_received),
-	PRESTERA_STATS_FIELD(bad_crc),
-	PRESTERA_STATS_FIELD(collisions),
-	PRESTERA_STATS_FIELD(late_collision),
-	PRESTERA_STATS_FIELD(unicast_frames_received),
-	PRESTERA_STATS_FIELD(unicast_frames_sent),
-	PRESTERA_STATS_FIELD(sent_multiple),
-	PRESTERA_STATS_FIELD(sent_deferred),
-	PRESTERA_STATS_FIELD(good_octets_sent),
+static const char prestera_port_cnt_name[PORT_STATS_CNT][ETH_GSTRING_LEN] = {
+	PORT_STATS_FIELD(good_octets_received),
+	PORT_STATS_FIELD(bad_octets_received),
+	PORT_STATS_FIELD(mac_trans_error),
+	PORT_STATS_FIELD(broadcast_frames_received),
+	PORT_STATS_FIELD(multicast_frames_received),
+	PORT_STATS_FIELD(frames_64_octets),
+	PORT_STATS_FIELD(frames_65_to_127_octets),
+	PORT_STATS_FIELD(frames_128_to_255_octets),
+	PORT_STATS_FIELD(frames_256_to_511_octets),
+	PORT_STATS_FIELD(frames_512_to_1023_octets),
+	PORT_STATS_FIELD(frames_1024_to_max_octets),
+	PORT_STATS_FIELD(excessive_collision),
+	PORT_STATS_FIELD(multicast_frames_sent),
+	PORT_STATS_FIELD(broadcast_frames_sent),
+	PORT_STATS_FIELD(fc_sent),
+	PORT_STATS_FIELD(fc_received),
+	PORT_STATS_FIELD(buffer_overrun),
+	PORT_STATS_FIELD(undersize),
+	PORT_STATS_FIELD(fragments),
+	PORT_STATS_FIELD(oversize),
+	PORT_STATS_FIELD(jabber),
+	PORT_STATS_FIELD(rx_error_frame_received),
+	PORT_STATS_FIELD(bad_crc),
+	PORT_STATS_FIELD(collisions),
+	PORT_STATS_FIELD(late_collision),
+	PORT_STATS_FIELD(unicast_frames_received),
+	PORT_STATS_FIELD(unicast_frames_sent),
+	PORT_STATS_FIELD(sent_multiple),
+	PORT_STATS_FIELD(sent_deferred),
+	PORT_STATS_FIELD(good_octets_sent),
 };
 
-static void prestera_ethtool_get_drvinfo(struct net_device *dev,
-					 struct ethtool_drvinfo *drvinfo)
+static void prestera_modes_to_eth(unsigned long *eth_modes, u64 link_modes,
+				  u8 fec, u8 type)
 {
-	struct prestera_port *port = netdev_priv(dev);
-	struct prestera_switch *sw = port->sw;
+	u32 mode;
 
-	strlcpy(drvinfo->driver, driver_kind, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->bus_info, dev_name(prestera_dev(sw)),
-		sizeof(drvinfo->bus_info));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),
-		 "%d.%d.%d",
-		 sw->dev->fw_rev.maj,
-		 sw->dev->fw_rev.min,
-		 sw->dev->fw_rev.sub);
+	for (mode = 0; mode < PRESTERA_LINK_MODE_MAX; mode++) {
+		if ((prestera_link_modes[mode].pr_mask & link_modes) == 0)
+			continue;
+		if (type != PRESTERA_PORT_TYPE_NONE &&
+		    prestera_link_modes[mode].port_type != type)
+			continue;
+		__set_bit(prestera_link_modes[mode].eth_mode, eth_modes);
+	}
+
+	for (mode = 0; mode < PRESTERA_PORT_FEC_MAX; mode++) {
+		if ((prestera_fec_caps[mode].pr_fec & fec) == 0)
+			continue;
+		__set_bit(prestera_fec_caps[mode].eth_mode, eth_modes);
+	}
 }
 
-static u8 prestera_port_type_get(struct prestera_port *port)
+static void prestera_port_remote_cap_cache(struct prestera_port *port)
 {
-	if (port->caps.type < PRESTERA_PORT_TYPE_MAX)
-		return port_types[port->caps.type].eth_type;
+	struct prestera_port_phy_state *state = &port->state_phy;
+
+	if (prestera_hw_port_phy_mode_get(port, NULL, &state->lmode_bmap,
+					  &state->remote_fc.pause,
+					  &state->remote_fc.asym_pause))
+		netdev_warn(port->net_dev,
+			    "Remote link caps get failed %d",
+			    port->caps.transceiver);
+}
+
+static void prestera_port_mdix_cache(struct prestera_port *port)
+{
+	struct prestera_port_phy_state *state = &port->state_phy;
 
-	return PORT_OTHER;
+	if (prestera_hw_port_phy_mode_get(port, &state->mdix,
+					  NULL, NULL, NULL)) {
+		netdev_warn(port->net_dev, "MDIX params get failed");
+		state->mdix = ETH_TP_MDI_INVALID;
+	}
 }
 
-static int prestera_port_type_set(const struct ethtool_link_ksettings *ecmd,
-				  struct prestera_port *port)
+static void prestera_port_mdix_get(struct ethtool_link_ksettings *ecmd,
+				   struct prestera_port *port)
 {
-	u32 new_mode = PRESTERA_LINK_MODE_MAX;
-	u32 type, mode;
-	int err;
+	prestera_port_mdix_cache(port);
 
-	for (type = 0; type < PRESTERA_PORT_TYPE_MAX; type++) {
-		if (port_types[type].eth_type == ecmd->base.port &&
-		    test_bit(port_types[type].eth_mode,
-			     ecmd->link_modes.supported)) {
-			break;
-		}
+	ecmd->base.eth_tp_mdix = port->state_phy.mdix;
+	ecmd->base.eth_tp_mdix_ctrl = port->cfg_phy.mdix;
+}
+
+static void prestera_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
+					 struct prestera_port *port)
+{
+	struct prestera_port_phy_state *state = &port->state_phy;
+	bool asym_pause;
+	bool pause;
+	u64 bitmap;
+
+	prestera_port_remote_cap_cache(port);
+
+	bitmap = state->lmode_bmap;
+
+	prestera_modes_to_eth(ecmd->link_modes.lp_advertising,
+			      bitmap, 0, PRESTERA_PORT_TYPE_NONE);
+
+	if (!bitmap_empty(ecmd->link_modes.lp_advertising,
+			  __ETHTOOL_LINK_MODE_MASK_NBITS)) {
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Autoneg);
 	}
 
-	if (type == port->caps.type)
-		return 0;
-	if (type != port->caps.type && ecmd->base.autoneg == AUTONEG_ENABLE)
-		return -EINVAL;
-	if (type == PRESTERA_PORT_TYPE_MAX)
-		return -EOPNOTSUPP;
+	pause = state->remote_fc.pause;
+	asym_pause = state->remote_fc.asym_pause;
+
+	if (pause)
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Pause);
+	if (asym_pause)
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Asym_Pause);
+}
+
+/* TODO:  Rename, that it only for integral */
+/* TODO: use speed/duplex direct in Agent ? */
+/* TODO: remove type, as it is always integral phy */
+int prestera_port_link_mode_set(struct prestera_port *port,
+				u32 speed, u8 duplex, u8 type)
+{
+	u32 new_mode = PRESTERA_LINK_MODE_MAX;
+	u32 mode;
 
 	for (mode = 0; mode < PRESTERA_LINK_MODE_MAX; mode++) {
-		if ((port_link_modes[mode].pr_mask &
-		    port->caps.supp_link_modes) &&
-		    type == port_link_modes[mode].port_type) {
-			new_mode = mode;
-		}
+		if (speed != SPEED_UNKNOWN &&
+		    speed != prestera_link_modes[mode].speed)
+			continue;
+		if (duplex != DUPLEX_UNKNOWN &&
+		    duplex != prestera_link_modes[mode].duplex)
+			continue;
+		if (!(prestera_link_modes[mode].pr_mask &
+		    port->caps.supp_link_modes))
+			continue;
+		if (type != prestera_link_modes[mode].port_type)
+			continue;
+
+		new_mode = mode;
+		/* Find highest compatible mode */
 	}
 
-	if (new_mode < PRESTERA_LINK_MODE_MAX)
-		err = prestera_hw_port_link_mode_set(port, new_mode);
-	else
-		err = -EINVAL;
+	if (new_mode == PRESTERA_LINK_MODE_MAX) {
+		netdev_err(port->net_dev, "Unsupported speed/duplex requested");
+		return -EINVAL;
+	}
 
-	if (err)
-		return err;
+	if (prestera_hw_port_phy_mode_set(port, port->cfg_phy.admin,
+					  false, new_mode, 0,
+					  port->cfg_phy.mdix))
+		return -EINVAL;
 
-	port->caps.type = type;
+	/* TODO: move all this parameters to cfg_phy */
 	port->autoneg = false;
+	port->cfg_phy.mode = new_mode;
+	port->adver_link_modes = 0;
+	port->adver_fec = BIT(PRESTERA_PORT_FEC_OFF);
 
 	return 0;
 }
 
-static void prestera_modes_to_eth(unsigned long *eth_modes, u64 link_modes,
-				  u8 fec, u8 type)
+static void prestera_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
+				      struct prestera_port *port)
 {
-	u32 mode;
+	ecmd->base.autoneg = port->autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
 
-	for (mode = 0; mode < PRESTERA_LINK_MODE_MAX; mode++) {
-		if ((port_link_modes[mode].pr_mask & link_modes) == 0)
-			continue;
+	prestera_modes_to_eth(ecmd->link_modes.supported,
+			      port->caps.supp_link_modes,
+			      port->caps.supp_fec,
+			      port->caps.type);
 
-		if (type != PRESTERA_PORT_TYPE_NONE &&
-		    port_link_modes[mode].port_type != type)
-			continue;
+	if (port->caps.type != PRESTERA_PORT_TYPE_TP)
+		return;
 
-		__set_bit(port_link_modes[mode].eth_mode, eth_modes);
-	}
+	ethtool_link_ksettings_add_link_mode(ecmd, supported, Autoneg);
 
-	for (mode = 0; mode < PRESTERA_PORT_FEC_MAX; mode++) {
-		if ((port_fec_caps[mode].pr_fec & fec) == 0)
-			continue;
+	if (!netif_running(port->net_dev))
+		return;
 
-		__set_bit(port_fec_caps[mode].eth_mode, eth_modes);
-	}
+	if (port->autoneg) {
+		prestera_modes_to_eth(ecmd->link_modes.advertising,
+				      port->adver_link_modes,
+				      port->adver_fec,
+				      port->caps.type);
+		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
+						     Autoneg);
+	} else if (port->caps.transceiver == PRESTERA_PORT_TCVR_COPPER)
+		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
+						     Autoneg);
 }
 
-static void prestera_modes_from_eth(const unsigned long *eth_modes,
-				    u64 *link_modes, u8 *fec, u8 type)
+static int prestera_modes_from_eth(struct prestera_port *port,
+				   const unsigned long *advertising,
+				   const unsigned long *supported,
+				   u64 *link_modes, u8 *fec)
 {
-	u64 adver_modes = 0;
-	u32 fec_modes = 0;
+	struct ethtool_link_ksettings curr = {};
 	u32 mode;
 
+	ethtool_link_ksettings_zero_link_mode(&curr, supported);
+	ethtool_link_ksettings_zero_link_mode(&curr, advertising);
+
+	prestera_port_autoneg_get(&curr, port);
+
+	if (linkmode_equal(advertising, curr.link_modes.advertising)) {
+		*link_modes = port->adver_link_modes;
+		*fec = port->adver_fec;
+		return 0;
+	}
+
+	if (!linkmode_subset(advertising, supported)) {
+		netdev_err(port->net_dev, "Unsupported link mode requested");
+		return -EINVAL;
+	}
+
+	*link_modes  = 0;
+	*fec = 0;
 	for (mode = 0; mode < PRESTERA_LINK_MODE_MAX; mode++) {
-		if (!test_bit(port_link_modes[mode].eth_mode, eth_modes))
+		if (!test_bit(prestera_link_modes[mode].eth_mode, advertising))
 			continue;
-
-		if (port_link_modes[mode].port_type != type)
+		if (prestera_link_modes[mode].port_type != port->caps.type)
 			continue;
-
-		adver_modes |= port_link_modes[mode].pr_mask;
+		*link_modes |= prestera_link_modes[mode].pr_mask;
 	}
 
 	for (mode = 0; mode < PRESTERA_PORT_FEC_MAX; mode++) {
-		if (!test_bit(port_fec_caps[mode].eth_mode, eth_modes))
+		if (!test_bit(prestera_fec_caps[mode].eth_mode, advertising))
 			continue;
+		*fec |= prestera_fec_caps[mode].pr_fec;
+	}
 
-		fec_modes |= port_fec_caps[mode].pr_fec;
+	if (*link_modes == 0 && *fec == 0) {
+		netdev_err(port->net_dev, "No link modes requested");
+		return -EINVAL;
 	}
+	if (*link_modes == 0)
+		*link_modes = port->adver_link_modes;
+	if (*fec == 0)
+		*fec = port->adver_fec ? port->adver_fec :
+					 BIT(PRESTERA_PORT_FEC_OFF);
 
-	*link_modes = adver_modes;
-	*fec = fec_modes;
+	return 0;
 }
 
 static void prestera_port_supp_types_get(struct ethtool_link_ksettings *ecmd,
@@ -421,134 +524,106 @@ static void prestera_port_supp_types_get(struct ethtool_link_ksettings *ecmd,
 	u8 ptype;
 
 	for (mode = 0; mode < PRESTERA_LINK_MODE_MAX; mode++) {
-		if ((port_link_modes[mode].pr_mask &
+		if ((prestera_link_modes[mode].pr_mask &
 		    port->caps.supp_link_modes) == 0)
 			continue;
-
-		ptype = port_link_modes[mode].port_type;
-		__set_bit(port_types[ptype].eth_mode,
+		ptype = prestera_link_modes[mode].port_type;
+		__set_bit(prestera_port_types[ptype].eth_mode,
 			  ecmd->link_modes.supported);
 	}
 }
 
-static void prestera_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
-					 struct prestera_port *port)
+static void prestera_port_link_mode_get(struct ethtool_link_ksettings *ecmd,
+					struct prestera_port *port)
 {
-	bool asym_pause;
-	bool pause;
-	u64 bitmap;
-	int err;
+	struct prestera_port_mac_state state;
 
-	err = prestera_hw_port_remote_cap_get(port, &bitmap);
-	if (!err) {
-		prestera_modes_to_eth(ecmd->link_modes.lp_advertising,
-				      bitmap, 0, PRESTERA_PORT_TYPE_NONE);
-
-		if (!bitmap_empty(ecmd->link_modes.lp_advertising,
-				  __ETHTOOL_LINK_MODE_MASK_NBITS)) {
-			ethtool_link_ksettings_add_link_mode(ecmd,
-							     lp_advertising,
-							     Autoneg);
-		}
-	}
+	/* We don't need explicity read state from FW,
+	 * because there are events
+	 */
+	prestera_port_mac_state_cache_read(port, &state);
 
-	err = prestera_hw_port_remote_fc_get(port, &pause, &asym_pause);
-	if (err)
-		return;
-
-	if (pause)
-		ethtool_link_ksettings_add_link_mode(ecmd,
-						     lp_advertising,
-						     Pause);
-	if (asym_pause)
-		ethtool_link_ksettings_add_link_mode(ecmd,
-						     lp_advertising,
-						     Asym_Pause);
+	if (state.valid) {
+		ecmd->base.speed = state.speed;
+		ecmd->base.duplex = state.duplex;
+	} else {
+		ecmd->base.speed = SPEED_UNKNOWN;
+		ecmd->base.duplex = DUPLEX_UNKNOWN;
+	}
 }
 
-static void prestera_port_speed_get(struct ethtool_link_ksettings *ecmd,
-				    struct prestera_port *port)
+static void prestera_port_get_drvinfo(struct net_device *dev,
+				      struct ethtool_drvinfo *drvinfo)
 {
-	u32 speed;
-	int err;
+	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_switch *sw = port->sw;
 
-	err = prestera_hw_port_speed_get(port, &speed);
-	ecmd->base.speed = err ? SPEED_UNKNOWN : speed;
+	strlcpy(drvinfo->driver, prestera_driver_kind, sizeof(drvinfo->driver));
+	strlcpy(drvinfo->bus_info, dev_name(sw->dev->dev),
+		sizeof(drvinfo->bus_info));
+	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),
+		 "%d.%d.%d",
+		 sw->dev->fw_rev.maj,
+		 sw->dev->fw_rev.min,
+		 sw->dev->fw_rev.sub);
 }
 
-static void prestera_port_duplex_get(struct ethtool_link_ksettings *ecmd,
-				     struct prestera_port *port)
+static void prestera_port_type_get(struct ethtool_link_ksettings *ecmd,
+				   struct prestera_port *port)
 {
-	u8 duplex;
-	int err;
-
-	err = prestera_hw_port_duplex_get(port, &duplex);
-	if (err) {
-		ecmd->base.duplex = DUPLEX_UNKNOWN;
-		return;
-	}
-
-	ecmd->base.duplex = duplex == PRESTERA_PORT_DUPLEX_FULL ?
-			    DUPLEX_FULL : DUPLEX_HALF;
+	if (port->caps.type < PRESTERA_PORT_TYPE_MAX)
+		ecmd->base.port = prestera_port_types[port->caps.type].eth_type;
+	else
+		ecmd->base.port = PORT_OTHER;
 }
 
-static int
-prestera_ethtool_get_link_ksettings(struct net_device *dev,
-				    struct ethtool_link_ksettings *ecmd)
+static int prestera_port_type_set(const struct ethtool_link_ksettings *ecmd,
+				  struct prestera_port *port)
 {
-	struct prestera_port *port = netdev_priv(dev);
-
-	ethtool_link_ksettings_zero_link_mode(ecmd, supported);
-	ethtool_link_ksettings_zero_link_mode(ecmd, advertising);
-	ethtool_link_ksettings_zero_link_mode(ecmd, lp_advertising);
-
-	ecmd->base.autoneg = port->autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
-
-	if (port->caps.type == PRESTERA_PORT_TYPE_TP) {
-		ethtool_link_ksettings_add_link_mode(ecmd, supported, Autoneg);
+	int err;
+	u32 type, mode;
+	u32 new_mode = PRESTERA_LINK_MODE_MAX;
 
-		if (netif_running(dev) &&
-		    (port->autoneg ||
-		     port->caps.transceiver == PRESTERA_PORT_TCVR_COPPER))
-			ethtool_link_ksettings_add_link_mode(ecmd, advertising,
-							     Autoneg);
+	for (type = 0; type < PRESTERA_PORT_TYPE_MAX; type++) {
+		if (prestera_port_types[type].eth_type == ecmd->base.port &&
+		    test_bit(prestera_port_types[type].eth_mode,
+			     ecmd->link_modes.supported)) {
+			break;
+		}
 	}
 
-	prestera_modes_to_eth(ecmd->link_modes.supported,
-			      port->caps.supp_link_modes,
-			      port->caps.supp_fec,
-			      port->caps.type);
+	if (type == port->caps.type)
+		return 0;
 
-	prestera_port_supp_types_get(ecmd, port);
+	if (type != port->caps.type && ecmd->base.autoneg == AUTONEG_ENABLE)
+		return -EINVAL;
 
-	if (netif_carrier_ok(dev)) {
-		prestera_port_speed_get(ecmd, port);
-		prestera_port_duplex_get(ecmd, port);
-	} else {
-		ecmd->base.speed = SPEED_UNKNOWN;
-		ecmd->base.duplex = DUPLEX_UNKNOWN;
+	if (type == PRESTERA_PORT_TYPE_MAX) {
+		pr_err("Unsupported port type requested\n");
+		return -EINVAL;
 	}
 
-	ecmd->base.port = prestera_port_type_get(port);
+	for (mode = 0; mode < PRESTERA_LINK_MODE_MAX; mode++) {
+		if ((prestera_link_modes[mode].pr_mask &
+		    port->caps.supp_link_modes) &&
+		    type == prestera_link_modes[mode].port_type) {
+			new_mode = mode;
+		}
+	}
 
-	if (port->autoneg) {
-		if (netif_running(dev))
-			prestera_modes_to_eth(ecmd->link_modes.advertising,
-					      port->adver_link_modes,
-					      port->adver_fec,
-					      port->caps.type);
-
-		if (netif_carrier_ok(dev) &&
-		    port->caps.transceiver == PRESTERA_PORT_TCVR_COPPER)
-			prestera_port_remote_cap_get(ecmd, port);
+	if (new_mode < PRESTERA_LINK_MODE_MAX)
+	{
+		/* err = mvsw_pr_hw_port_link_mode_set(port, new_mode); */
+		pr_err("Unexpected call of type set on integral phy");
+		err = -EINVAL;
 	}
 
-	if (port->caps.type == PRESTERA_PORT_TYPE_TP &&
-	    port->caps.transceiver == PRESTERA_PORT_TCVR_COPPER)
-		prestera_hw_port_mdix_get(port, &ecmd->base.eth_tp_mdix,
-					  &ecmd->base.eth_tp_mdix_ctrl);
+	if (!err) {
+		port->caps.type = type;
+		port->autoneg = false;
+	}
 
-	return 0;
+	return err;
 }
 
 static int prestera_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
@@ -556,225 +631,251 @@ static int prestera_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
 {
 	if (ecmd->base.eth_tp_mdix_ctrl != ETH_TP_MDI_INVALID &&
 	    port->caps.transceiver == PRESTERA_PORT_TCVR_COPPER &&
-	    port->caps.type == PRESTERA_PORT_TYPE_TP)
-		return prestera_hw_port_mdix_set(port,
-						 ecmd->base.eth_tp_mdix_ctrl);
-
+	    port->caps.type == PRESTERA_PORT_TYPE_TP) {
+		port->cfg_phy.mdix = ecmd->base.eth_tp_mdix_ctrl;
+		return prestera_hw_port_phy_mode_set(port, port->cfg_phy.admin,
+						     port->autoneg,
+						     port->cfg_phy.mode,
+						     port->adver_link_modes,
+						     port->cfg_phy.mdix);
+	}
 	return 0;
 }
 
-static int prestera_port_link_mode_set(struct prestera_port *port,
-				       u32 speed, u8 duplex, u8 type)
+static int prestera_port_get_link_ksettings(struct net_device *dev,
+					    struct ethtool_link_ksettings *ecmd)
 {
-	u32 new_mode = PRESTERA_LINK_MODE_MAX;
-	u32 mode;
+	struct prestera_port *port = netdev_priv(dev);
 
-	for (mode = 0; mode < PRESTERA_LINK_MODE_MAX; mode++) {
-		if (speed != port_link_modes[mode].speed)
-			continue;
+	/* Dirty hook: Deinit ecmd.
+	 * It caused by suspicious phylink_ethtool_ksettings_get()
+	 * implementation, which can left "kset" uninitialized, when there is no
+	 * SFP plugged
+	 */
+	ethtool_link_ksettings_zero_link_mode(ecmd, supported);
+	ethtool_link_ksettings_zero_link_mode(ecmd, advertising);
+	ethtool_link_ksettings_zero_link_mode(ecmd, lp_advertising);
+	ecmd->base.speed = SPEED_UNKNOWN;
+	ecmd->base.duplex = DUPLEX_UNKNOWN;
+#ifdef CONFIG_PHYLINK
+	if (port->phy_link)
+		return phylink_ethtool_ksettings_get(port->phy_link, ecmd);
+#endif /* CONFIG_PHYLINK */
 
-		if (duplex != port_link_modes[mode].duplex)
-			continue;
+	prestera_port_supp_types_get(ecmd, port);
+	prestera_port_autoneg_get(ecmd, port);
+	prestera_port_type_get(ecmd, port);
 
-		if (!(port_link_modes[mode].pr_mask &
-		    port->caps.supp_link_modes))
-			continue;
+	if (netif_carrier_ok(dev))
+		prestera_port_link_mode_get(ecmd, port);
 
-		if (type != port_link_modes[mode].port_type)
-			continue;
+	if (port->caps.transceiver == PRESTERA_PORT_TCVR_SFP)
+		return 0;
 
-		new_mode = mode;
-		break;
-	}
+	if (port->autoneg && netif_carrier_ok(dev))
+		prestera_port_remote_cap_get(ecmd, port);
 
-	if (new_mode == PRESTERA_LINK_MODE_MAX)
-		return -EOPNOTSUPP;
+	if (port->caps.type == PRESTERA_PORT_TYPE_TP)
+		prestera_port_mdix_get(ecmd, port);
 
-	return prestera_hw_port_link_mode_set(port, new_mode);
+	return 0;
 }
 
-static int
-prestera_port_speed_duplex_set(const struct ethtool_link_ksettings *ecmd,
-			       struct prestera_port *port)
+static int prestera_port_set_link_ksettings(struct net_device *dev,
+					    const struct ethtool_link_ksettings
+					    *ecmd)
 {
-	u32 curr_mode;
-	u8 duplex;
-	u32 speed;
+	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_port_mac_config cfg_mac;
+	u64 adver_modes = 0;
+	u8 adver_fec = 0;
 	int err;
 
-	err = prestera_hw_port_link_mode_get(port, &curr_mode);
+#ifdef CONFIG_PHYLINK
+	if (port->phy_link)
+		return phylink_ethtool_ksettings_set(port->phy_link, ecmd);
+#endif /* CONFIG_PHYLINK */
+
+	err = prestera_port_type_set(ecmd, port);
 	if (err)
 		return err;
-	if (curr_mode >= PRESTERA_LINK_MODE_MAX)
-		return -EINVAL;
-
-	if (ecmd->base.duplex != DUPLEX_UNKNOWN)
-		duplex = ecmd->base.duplex == DUPLEX_FULL ?
-			 PRESTERA_PORT_DUPLEX_FULL : PRESTERA_PORT_DUPLEX_HALF;
-	else
-		duplex = port_link_modes[curr_mode].duplex;
 
-	if (ecmd->base.speed != SPEED_UNKNOWN)
-		speed = ecmd->base.speed;
-	else
-		speed = port_link_modes[curr_mode].speed;
-
-	return prestera_port_link_mode_set(port, speed, duplex,
-					   port->caps.type);
-}
+	if (port->caps.transceiver == PRESTERA_PORT_TCVR_SFP) {
+		prestera_port_cfg_mac_read(port, &cfg_mac);
+		switch (ecmd->base.speed) {
+		case SPEED_1000:
+			cfg_mac.mode = PRESTERA_MAC_MODE_1000BASE_X;
+			cfg_mac.inband = false;
+			break;
+		case SPEED_10000:
+			cfg_mac.mode = PRESTERA_MAC_MODE_SR_LR;
+			cfg_mac.speed = SPEED_10000;
+			cfg_mac.inband = false;
+			break;
+		default:
+			cfg_mac.mode = PRESTERA_MAC_MODE_SGMII;
+			cfg_mac.speed = 0;
+			cfg_mac.duplex = DUPLEX_UNKNOWN;
+			cfg_mac.inband = true;
+		}
 
-static int
-prestera_ethtool_set_link_ksettings(struct net_device *dev,
-				    const struct ethtool_link_ksettings *ecmd)
-{
-	struct prestera_port *port = netdev_priv(dev);
-	u64 adver_modes;
-	u8 adver_fec;
-	int err;
+		return prestera_port_cfg_mac_write(port, &cfg_mac);
+	}
 
-	err = prestera_port_type_set(ecmd, port);
+	err = prestera_port_mdix_set(ecmd, port);
 	if (err)
 		return err;
 
-	if (port->caps.transceiver == PRESTERA_PORT_TCVR_COPPER) {
-		err = prestera_port_mdix_set(ecmd, port);
-		if (err)
-			return err;
+	if (ecmd->base.autoneg == AUTONEG_ENABLE) {
+		if (prestera_modes_from_eth(port, ecmd->link_modes.advertising,
+					    ecmd->link_modes.supported,
+					    &adver_modes, &adver_fec))
+			return -EINVAL;
+		if (!port->autoneg && !adver_modes)
+			adver_modes = port->caps.supp_link_modes;
+	} else {
+		adver_modes = port->adver_link_modes;
+		adver_fec = port->adver_fec;
 	}
 
-	prestera_modes_from_eth(ecmd->link_modes.advertising, &adver_modes,
-				&adver_fec, port->caps.type);
+	if (ecmd->base.autoneg == AUTONEG_DISABLE)
+		err = prestera_port_link_mode_set(port, ecmd->base.speed,
+						  ecmd->base.duplex ==
+						  DUPLEX_UNKNOWN ?
+						  DUPLEX_UNKNOWN :
+						  (ecmd->base.duplex ==
+						   DUPLEX_HALF ?
+						   PRESTERA_PORT_DUPLEX_HALF :
+						   PRESTERA_PORT_DUPLEX_FULL),
+						  port->caps.type);
+	else
+		err = prestera_port_autoneg_set(port, adver_modes);
 
-	err = prestera_port_autoneg_set(port,
-					ecmd->base.autoneg == AUTONEG_ENABLE,
-					adver_modes, adver_fec);
 	if (err)
 		return err;
 
-	if (ecmd->base.autoneg == AUTONEG_DISABLE) {
-		err = prestera_port_speed_duplex_set(ecmd, port);
-		if (err)
-			return err;
-	}
-
 	return 0;
 }
 
-static int prestera_ethtool_get_fecparam(struct net_device *dev,
-					 struct ethtool_fecparam *fecparam)
+static int prestera_port_nway_reset(struct net_device *dev)
+{
+	struct prestera_port *port = netdev_priv(dev);
+
+	if (netif_running(dev) &&
+	    port->caps.transceiver == PRESTERA_PORT_TCVR_COPPER &&
+	    port->caps.type == PRESTERA_PORT_TYPE_TP)
+		return prestera_hw_port_autoneg_restart(port);
+
+	return -EINVAL;
+}
+
+static int prestera_port_get_fecparam(struct net_device *dev,
+				      struct ethtool_fecparam *fecparam)
 {
 	struct prestera_port *port = netdev_priv(dev);
-	u8 active;
 	u32 mode;
+	u8 active;
 	int err;
 
-	err = prestera_hw_port_fec_get(port, &active);
+	err = prestera_hw_port_mac_mode_get(port, NULL, NULL, NULL, &active);
 	if (err)
 		return err;
 
 	fecparam->fec = 0;
-
 	for (mode = 0; mode < PRESTERA_PORT_FEC_MAX; mode++) {
-		if ((port_fec_caps[mode].pr_fec & port->caps.supp_fec) == 0)
+		if ((prestera_fec_caps[mode].pr_fec & port->caps.supp_fec) == 0)
 			continue;
-
-		fecparam->fec |= port_fec_caps[mode].eth_fec;
+		fecparam->fec |= prestera_fec_caps[mode].eth_fec;
 	}
 
 	if (active < PRESTERA_PORT_FEC_MAX)
-		fecparam->active_fec = port_fec_caps[active].eth_fec;
+		fecparam->active_fec = prestera_fec_caps[active].eth_fec;
 	else
 		fecparam->active_fec = ETHTOOL_FEC_AUTO;
 
 	return 0;
 }
 
-static int prestera_ethtool_set_fecparam(struct net_device *dev,
-					 struct ethtool_fecparam *fecparam)
+static int prestera_port_set_fecparam(struct net_device *dev,
+				      struct ethtool_fecparam *fecparam)
 {
 	struct prestera_port *port = netdev_priv(dev);
-	u8 fec, active;
+	u8 fec;
 	u32 mode;
-	int err;
+	struct prestera_port_mac_config cfg_mac;
 
 	if (port->autoneg) {
 		netdev_err(dev, "FEC set is not allowed while autoneg is on\n");
 		return -EINVAL;
 	}
 
-	err = prestera_hw_port_fec_get(port, &active);
-	if (err)
-		return err;
+	if (port->caps.transceiver == PRESTERA_PORT_TCVR_SFP) {
+		netdev_err(dev, "FEC set is not allowed on non-SFP ports\n");
+		return -EINVAL;
+	}
 
 	fec = PRESTERA_PORT_FEC_MAX;
 	for (mode = 0; mode < PRESTERA_PORT_FEC_MAX; mode++) {
-		if ((port_fec_caps[mode].eth_fec & fecparam->fec) &&
-		    (port_fec_caps[mode].pr_fec & port->caps.supp_fec)) {
+		if ((prestera_fec_caps[mode].eth_fec & fecparam->fec) &&
+		    (prestera_fec_caps[mode].pr_fec & port->caps.supp_fec)) {
 			fec = mode;
 			break;
 		}
 	}
 
-	if (fec == active)
+	prestera_port_cfg_mac_read(port, &cfg_mac);
+
+	if (fec == cfg_mac.fec)
 		return 0;
 
-	if (fec == PRESTERA_PORT_FEC_MAX)
-		return -EOPNOTSUPP;
+	if (fec == PRESTERA_PORT_FEC_MAX) {
+		netdev_err(dev, "Unsupported FEC requested");
+		return -EINVAL;
+	}
+
+	cfg_mac.fec = fec;
 
-	return prestera_hw_port_fec_set(port, fec);
+	return prestera_port_cfg_mac_write(port, &cfg_mac);
 }
 
-static int prestera_ethtool_get_sset_count(struct net_device *dev, int sset)
+static int prestera_port_get_sset_count(struct net_device *dev, int sset)
 {
 	switch (sset) {
 	case ETH_SS_STATS:
-		return PRESTERA_STATS_CNT;
+		return PORT_STATS_CNT;
 	default:
 		return -EOPNOTSUPP;
 	}
 }
 
-static void prestera_ethtool_get_strings(struct net_device *dev,
-					 u32 stringset, u8 *data)
-{
-	if (stringset != ETH_SS_STATS)
-		return;
-
-	memcpy(data, prestera_cnt_name, sizeof(prestera_cnt_name));
-}
-
-static void prestera_ethtool_get_stats(struct net_device *dev,
-				       struct ethtool_stats *stats, u64 *data)
+static void prestera_port_get_ethtool_stats(struct net_device *dev,
+					    struct ethtool_stats *stats,
+					    u64 *data)
 {
 	struct prestera_port *port = netdev_priv(dev);
-	struct prestera_port_stats *port_stats;
-
-	port_stats = &port->cached_hw_stats.stats;
+	struct prestera_port_stats *port_stats = &port->cached_hw_stats.stats;
 
-	memcpy(data, port_stats, sizeof(*port_stats));
+	memcpy((u8 *)data, port_stats, sizeof(*port_stats));
 }
 
-static int prestera_ethtool_nway_reset(struct net_device *dev)
+static void prestera_port_get_strings(struct net_device *dev,
+				      u32 stringset, u8 *data)
 {
-	struct prestera_port *port = netdev_priv(dev);
-
-	if (netif_running(dev) &&
-	    port->caps.transceiver == PRESTERA_PORT_TCVR_COPPER &&
-	    port->caps.type == PRESTERA_PORT_TYPE_TP)
-		return prestera_hw_port_autoneg_restart(port);
+	if (stringset != ETH_SS_STATS)
+		return;
 
-	return -EINVAL;
+	memcpy(data, *prestera_port_cnt_name, sizeof(prestera_port_cnt_name));
 }
 
 const struct ethtool_ops prestera_ethtool_ops = {
-	.get_drvinfo = prestera_ethtool_get_drvinfo,
-	.get_link_ksettings = prestera_ethtool_get_link_ksettings,
-	.set_link_ksettings = prestera_ethtool_set_link_ksettings,
-	.get_fecparam = prestera_ethtool_get_fecparam,
-	.set_fecparam = prestera_ethtool_set_fecparam,
-	.get_sset_count = prestera_ethtool_get_sset_count,
-	.get_strings = prestera_ethtool_get_strings,
-	.get_ethtool_stats = prestera_ethtool_get_stats,
+	.get_drvinfo = prestera_port_get_drvinfo,
+	.get_link_ksettings = prestera_port_get_link_ksettings,
+	.set_link_ksettings = prestera_port_set_link_ksettings,
+	.get_fecparam = prestera_port_get_fecparam,
+	.set_fecparam = prestera_port_set_fecparam,
+	.get_sset_count = prestera_port_get_sset_count,
+	.get_strings = prestera_port_get_strings,
+	.get_ethtool_stats = prestera_port_get_ethtool_stats,
 	.get_link = ethtool_op_get_link,
-	.nway_reset = prestera_ethtool_nway_reset
+	.nway_reset = prestera_port_nway_reset
 };
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h
index 523ef1f592ce..83b2b47a6042 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h
@@ -1,11 +1,16 @@
 /* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved. */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef __PRESTERA_ETHTOOL_H_
 #define __PRESTERA_ETHTOOL_H_
 
 #include <linux/ethtool.h>
 
+#include "prestera.h"
+
 extern const struct ethtool_ops prestera_ethtool_ops;
 
+int prestera_port_link_mode_set(struct prestera_port *port,
+				u32 speed, u8 duplex, u8 type);
+
 #endif /* _PRESTERA_ETHTOOL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_flow.c b/drivers/net/ethernet/marvell/prestera/prestera_flow.c
index c9891e968259..a1d9d0844e60 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_flow.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_flow.c
@@ -1,25 +1,28 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <linux/kernel.h>
 #include <linux/list.h>
+#include <linux/netdevice.h>
 
 #include "prestera.h"
 #include "prestera_acl.h"
-#include "prestera_flow.h"
-#include "prestera_span.h"
-#include "prestera_flower.h"
 
 static LIST_HEAD(prestera_block_cb_list);
 
 static int prestera_flow_block_mall_cb(struct prestera_flow_block *block,
 				       struct tc_cls_matchall_offload *f)
 {
+	if (f->common.chain_index != 0) {
+		NL_SET_ERR_MSG(f->common.extack, "Only chain 0 is supported");
+		return -EOPNOTSUPP;
+	}
+
 	switch (f->command) {
 	case TC_CLSMATCHALL_REPLACE:
-		return prestera_span_replace(block, f);
+		return prestera_mall_replace(block, f);
 	case TC_CLSMATCHALL_DESTROY:
-		prestera_span_destroy(block);
+		prestera_mall_destroy(block);
 		return 0;
 	default:
 		return -EOPNOTSUPP;
@@ -29,17 +32,21 @@ static int prestera_flow_block_mall_cb(struct prestera_flow_block *block,
 static int prestera_flow_block_flower_cb(struct prestera_flow_block *block,
 					 struct flow_cls_offload *f)
 {
-	if (f->common.chain_index != 0)
-		return -EOPNOTSUPP;
+	struct prestera_switch *sw = prestera_acl_block_sw(block);
 
 	switch (f->command) {
 	case FLOW_CLS_REPLACE:
-		return prestera_flower_replace(block, f);
+		return prestera_flower_replace(sw, block, f);
 	case FLOW_CLS_DESTROY:
-		prestera_flower_destroy(block, f);
+		prestera_flower_destroy(sw, block, f);
 		return 0;
 	case FLOW_CLS_STATS:
-		return prestera_flower_stats(block, f);
+		return prestera_flower_stats(sw, block, f);
+	case FLOW_CLS_TMPLT_CREATE:
+		return prestera_flower_tmplt_create(sw, block, f);
+	case FLOW_CLS_TMPLT_DESTROY:
+		prestera_flower_tmplt_destroy(sw, block, f);
+		return 0;
 	default:
 		return -EOPNOTSUPP;
 	}
@@ -50,6 +57,9 @@ static int prestera_flow_block_cb(enum tc_setup_type type,
 {
 	struct prestera_flow_block *block = cb_priv;
 
+	if (prestera_acl_block_disabled(block))
+		return -EOPNOTSUPP;
+
 	switch (type) {
 	case TC_SETUP_CLSFLOWER:
 		return prestera_flow_block_flower_cb(block, type_data);
@@ -60,11 +70,106 @@ static int prestera_flow_block_cb(enum tc_setup_type type,
 	}
 }
 
+static void prestera_flow_block_destroy(void *cb_priv)
+{
+	struct prestera_flow_block *block = cb_priv;
+
+	prestera_flower_template_cleanup(block);
+
+	WARN_ON(!list_empty(&block->template_list));
+	WARN_ON(!list_empty(&block->binding_list));
+
+	kfree(block);
+}
+
 static void prestera_flow_block_release(void *cb_priv)
 {
 	struct prestera_flow_block *block = cb_priv;
 
-	prestera_acl_block_destroy(block);
+	prestera_flow_block_destroy(block);
+}
+
+static inline bool
+prestera_flow_block_is_bound(const struct prestera_flow_block *block)
+{
+	return block->ruleset_zero;
+}
+
+static struct prestera_flow_block_binding *
+prestera_flow_block_lookup(struct prestera_flow_block *block,
+			   struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+
+	list_for_each_entry(binding, &block->binding_list, list)
+		if (binding->port == port)
+			return binding;
+
+	return NULL;
+}
+
+static int prestera_flow_block_bind(struct prestera_flow_block *block,
+				    struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+	int err;
+
+	binding = kzalloc(sizeof(*binding), GFP_KERNEL);
+	if (!binding)
+		return -ENOMEM;
+
+	binding->span_id = PRESTERA_SPAN_INVALID_ID;
+	binding->port = port;
+
+	if (prestera_flow_block_is_bound(block)) {
+		err = prestera_acl_ruleset_bind(block->ruleset_zero, port);
+		if (err)
+			goto err_ruleset_bind;
+	}
+
+	list_add(&binding->list, &block->binding_list);
+	return 0;
+
+err_ruleset_bind:
+	kfree(binding);
+	return err;
+}
+
+static int prestera_flow_block_unbind(struct prestera_flow_block *block,
+				      struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+
+	binding = prestera_flow_block_lookup(block, port);
+	if (!binding)
+		return -ENOENT;
+
+	list_del(&binding->list);
+
+	if (prestera_flow_block_is_bound(block))
+		prestera_acl_ruleset_unbind(block->ruleset_zero, port);
+
+	kfree(binding);
+	return 0;
+}
+
+static struct prestera_flow_block *
+prestera_flow_block_create(struct prestera_switch *sw, struct net *net)
+{
+	struct prestera_flow_block *block;
+
+	block = kzalloc(sizeof(*block), GFP_KERNEL);
+	if (!block)
+		return NULL;
+
+	INIT_LIST_HEAD(&block->binding_list);
+	INIT_LIST_HEAD(&block->template_list);
+	block->net = net;
+	block->sw = sw;
+	block->mall_prio = UINT_MAX;
+	block->flower_min_prio = UINT_MAX;
+
+	return block;
 }
 
 static struct prestera_flow_block *
@@ -78,7 +183,7 @@ prestera_flow_block_get(struct prestera_switch *sw,
 	block_cb = flow_block_cb_lookup(f->block,
 					prestera_flow_block_cb, sw);
 	if (!block_cb) {
-		block = prestera_acl_block_create(sw, f->net);
+		block = prestera_flow_block_create(sw, f->net);
 		if (!block)
 			return ERR_PTR(-ENOMEM);
 
@@ -86,7 +191,7 @@ prestera_flow_block_get(struct prestera_switch *sw,
 					       sw, block,
 					       prestera_flow_block_release);
 		if (IS_ERR(block_cb)) {
-			prestera_acl_block_destroy(block);
+			prestera_flow_block_destroy(block);
 			return ERR_CAST(block_cb);
 		}
 
@@ -110,15 +215,16 @@ static void prestera_flow_block_put(struct prestera_flow_block *block)
 		return;
 
 	flow_block_cb_free(block_cb);
-	prestera_acl_block_destroy(block);
+	prestera_flow_block_destroy(block);
 }
 
-static int prestera_setup_flow_block_bind(struct prestera_port *port,
-					  struct flow_block_offload *f)
+static int prestera_setup_tc_block_bind(struct prestera_port *port,
+					struct flow_block_offload *f)
 {
 	struct prestera_switch *sw = port->sw;
 	struct prestera_flow_block *block;
 	struct flow_block_cb *block_cb;
+	bool disable_block = false;
 	bool register_block;
 	int err;
 
@@ -128,7 +234,16 @@ static int prestera_setup_flow_block_bind(struct prestera_port *port,
 
 	block_cb = block->block_cb;
 
-	err = prestera_acl_block_bind(block, port);
+	if (!tc_can_offload(port->net_dev)) {
+		if (prestera_acl_block_rule_count(block)) {
+			err = -EOPNOTSUPP;
+			goto err_block_bind;
+		}
+
+		disable_block = true;
+	}
+
+	err = prestera_flow_block_bind(block, port);
 	if (err)
 		goto err_block_bind;
 
@@ -137,17 +252,19 @@ static int prestera_setup_flow_block_bind(struct prestera_port *port,
 		list_add_tail(&block_cb->driver_list, &prestera_block_cb_list);
 	}
 
+	if (disable_block)
+		prestera_acl_block_disable_inc(block);
+
 	port->flow_block = block;
 	return 0;
 
 err_block_bind:
 	prestera_flow_block_put(block);
-
 	return err;
 }
 
-static void prestera_setup_flow_block_unbind(struct prestera_port *port,
-					     struct flow_block_offload *f)
+static void prestera_setup_tc_block_unbind(struct prestera_port *port,
+					   struct flow_block_offload *f)
 {
 	struct prestera_switch *sw = port->sw;
 	struct prestera_flow_block *block;
@@ -160,22 +277,26 @@ static void prestera_setup_flow_block_unbind(struct prestera_port *port,
 
 	block = flow_block_cb_priv(block_cb);
 
-	prestera_span_destroy(block);
+	if (!tc_can_offload(port->net_dev))
+		prestera_acl_block_disable_dec(block);
 
-	err = prestera_acl_block_unbind(block, port);
+	prestera_mall_destroy(block);
+
+	err = prestera_flow_block_unbind(block, port);
 	if (err)
-		goto error;
+		goto err_flow_block_unbind;
 
 	if (!flow_block_cb_decref(block_cb)) {
 		flow_block_cb_remove(block_cb, f);
 		list_del(&block_cb->driver_list);
 	}
-error:
+
+err_flow_block_unbind:
 	port->flow_block = NULL;
 }
 
-int prestera_flow_block_setup(struct prestera_port *port,
-			      struct flow_block_offload *f)
+int prestera_setup_tc_block(struct prestera_port *port,
+			    struct flow_block_offload *f)
 {
 	if (f->binder_type != FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS)
 		return -EOPNOTSUPP;
@@ -184,11 +305,12 @@ int prestera_flow_block_setup(struct prestera_port *port,
 
 	switch (f->command) {
 	case FLOW_BLOCK_BIND:
-		return prestera_setup_flow_block_bind(port, f);
+		return prestera_setup_tc_block_bind(port, f);
 	case FLOW_BLOCK_UNBIND:
-		prestera_setup_flow_block_unbind(port, f);
+		prestera_setup_tc_block_unbind(port, f);
 		return 0;
 	default:
 		return -EOPNOTSUPP;
 	}
 }
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_flower.c b/drivers/net/ethernet/marvell/prestera/prestera_flower.c
index e571ba09ec08..ea0fd79a23ef 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_flower.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_flower.c
@@ -1,58 +1,176 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include "prestera.h"
+#include "prestera_ct.h"
 #include "prestera_acl.h"
-#include "prestera_flower.h"
+#include "prestera_log.h"
+#include "prestera_hw.h"
 
-static int prestera_flower_parse_actions(struct prestera_flow_block *block,
-					 struct prestera_acl_rule *rule,
-					 struct flow_action *flow_action,
-					 struct netlink_ext_ack *extack)
+#define PRESTERA_DEFAULT_TC_NUM	8
+
+struct prestera_flower_template {
+	struct prestera_acl_ruleset *ruleset;
+	struct list_head list;
+	u32 chain_index;
+};
+
+void prestera_flower_template_cleanup(struct prestera_flow_block *block)
+{
+	struct prestera_flower_template *template;
+	struct list_head *pos, *n;
+
+	/* put the reference to all rulesets kept in tmpl create */
+	list_for_each_safe(pos, n, &block->template_list) {
+		template = list_entry(pos, typeof(*template), list);
+		prestera_acl_ruleset_put(template->ruleset);
+		list_del(&template->list);
+		kfree(template);
+	}
+}
+
+static int
+prestera_flower_parse_goto_action(struct prestera_flow_block *block,
+				  struct prestera_acl_rule *rule,
+				  u32 chain_index,
+				  const struct flow_action_entry *act)
+{
+	struct prestera_acl_ruleset *ruleset;
+
+	if (act->chain_index <= chain_index)
+		/* we can jump only forward */
+		return -EINVAL;
+
+	if (rule->re_arg.jump.valid)
+		return -EEXIST;
+
+	ruleset = prestera_acl_ruleset_get(block->sw->acl, block,
+					   act->chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
+
+	rule->re_arg.jump.valid = 1;
+	rule->re_arg.jump.i.index = prestera_acl_ruleset_index_get(ruleset);
+
+	rule->jump_ruleset = ruleset;
+
+	return 0;
+}
+
+static int mvsw_pr_flower_parse_actions(struct prestera_flow_block *block,
+					struct prestera_acl_rule *rule,
+					struct flow_action *flow_action,
+					u32 chain_index,
+					struct netlink_ext_ack *extack)
 {
-	struct prestera_acl_rule_action_entry a_entry;
 	const struct flow_action_entry *act;
+	struct prestera_flow_block_binding *binding;
 	int err, i;
 
+	/* whole struct (rule->re_arg) must be initialized with 0 */
 	if (!flow_action_has_entries(flow_action))
 		return 0;
 
 	flow_action_for_each(i, act, flow_action) {
-		memset(&a_entry, 0, sizeof(a_entry));
-
 		switch (act->id) {
 		case FLOW_ACTION_ACCEPT:
-			a_entry.id = PRESTERA_ACL_RULE_ACTION_ACCEPT;
+			if (rule->re_arg.accept.valid)
+				return -EEXIST;
+
+			rule->re_arg.accept.valid = 1;
 			break;
 		case FLOW_ACTION_DROP:
-			a_entry.id = PRESTERA_ACL_RULE_ACTION_DROP;
+			if (rule->re_arg.drop.valid)
+				return -EEXIST;
+
+			rule->re_arg.drop.valid = 1;
 			break;
 		case FLOW_ACTION_TRAP:
-			a_entry.id = PRESTERA_ACL_RULE_ACTION_TRAP;
+			if (rule->re_arg.trap.valid)
+				return -EEXIST;
+
+			rule->re_arg.trap.valid = 1;
+			rule->re_arg.trap.i.hw_tc =
+				prestera_acl_rule_hw_tc_get(rule);
+			break;
+		case FLOW_ACTION_POLICE:
+			if (rule->re_arg.police.valid)
+				return -EEXIST;
+
+			rule->re_arg.police.valid = 1;
+			rule->re_arg.police.i.rate =
+				act->police.rate_bytes_ps;
+			rule->re_arg.police.i.burst = act->police.burst;
+			break;
+		case FLOW_ACTION_GOTO:
+			err = prestera_flower_parse_goto_action(block, rule,
+								chain_index,
+								act);
+			if (err)
+				return err;
+
+			rule_flag_set(rule, GOTO);
+			break;
+		case FLOW_ACTION_NAT:
+			if (rule->re_arg.nat.valid)
+				return -EEXIST;
+
+			if (~act->nat.mask) {
+				NL_SET_ERR_MSG_MOD(extack,
+						   "Netmask is not supported");
+				return -EOPNOTSUPP;
+			}
+			if (!act->nat.old_addr || !act->nat.new_addr) {
+				NL_SET_ERR_MSG_MOD
+				    (extack,
+				     "All-zero IP address isn't supported");
+				return -EOPNOTSUPP;
+			}
+
+			rule->re_arg.nat.valid = 1;
+			rule->re_arg.nat.i.old_addr = act->nat.old_addr;
+			rule->re_arg.nat.i.new_addr = act->nat.new_addr;
+			rule->re_arg.nat.i.flags = act->nat.flags;
+
+			/* TODO: move this to the rule_add() */
+			binding = list_first_entry
+			    (&block->binding_list,
+			     struct prestera_flow_block_binding, list);
+			rule->re_arg.nat.i.dev = binding->port->dev_id;
+			rule->re_arg.nat.i.port = binding->port->hw_id;
+			rule_flag_set(rule, NAT);
+			break;
+		case FLOW_ACTION_CT:
+			/* TODO: check ct nat commit */
+			if (rule_flag_test(rule, CT))
+				return -EEXIST;
+
+			err = prestera_ct_parse_action(act, rule, extack);
+			if (err)
+				return err;
+
+			rule_flag_set(rule, CT);
 			break;
 		default:
 			NL_SET_ERR_MSG_MOD(extack, "Unsupported action");
 			pr_err("Unsupported action\n");
 			return -EOPNOTSUPP;
 		}
-
-		err = prestera_acl_rule_action_add(rule, &a_entry);
-		if (err)
-			return err;
 	}
 
 	return 0;
 }
 
-static int prestera_flower_parse_meta(struct prestera_acl_rule *rule,
-				      struct flow_cls_offload *f,
-				      struct prestera_flow_block *block)
+static int mvsw_pr_flower_parse_meta(struct prestera_acl_rule *rule,
+				     struct flow_cls_offload *f,
+				     struct prestera_flow_block *block)
 {
 	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
-	struct prestera_acl_rule_match_entry m_entry = {0};
+	struct prestera_acl_match *r_match = &rule->re_key.match;
+	struct prestera_port *port;
 	struct net_device *ingress_dev;
 	struct flow_match_meta match;
-	struct prestera_port *port;
+	__be16 key, mask;
 
 	flow_rule_match_meta(f_rule, &match);
 	if (match.mask->ingress_ifindex != 0xFFFFFFFF) {
@@ -76,24 +194,31 @@ static int prestera_flower_parse_meta(struct prestera_acl_rule *rule,
 	}
 	port = netdev_priv(ingress_dev);
 
-	m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_PORT;
-	m_entry.keymask.u64.key = port->hw_id | ((u64)port->dev_id << 32);
-	m_entry.keymask.u64.mask = ~(u64)0;
+	mask = htons(0x1FFF);
+	key = htons(port->hw_id);
+	rule_match_set(r_match->key, SYS_PORT, key);
+	rule_match_set(r_match->mask, SYS_PORT, mask);
 
-	return prestera_acl_rule_match_add(rule, &m_entry);
+	mask = htons(0x1FF);
+	key = htons(port->dev_id);
+	rule_match_set(r_match->key, SYS_DEV, key);
+	rule_match_set(r_match->mask, SYS_DEV, mask);
+
+	return 0;
 }
 
-static int prestera_flower_parse(struct prestera_flow_block *block,
-				 struct prestera_acl_rule *rule,
-				 struct flow_cls_offload *f)
+static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
+				struct prestera_acl_rule *rule,
+				struct flow_cls_offload *f)
 {
 	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
 	struct flow_dissector *dissector = f_rule->match.dissector;
-	struct prestera_acl_rule_match_entry m_entry;
-	u16 n_proto_mask = 0;
-	u16 n_proto_key = 0;
+	struct prestera_acl_match *r_match = &rule->re_key.match;
+	__be16 n_proto_mask = 0;
+	__be16 n_proto_key = 0;
 	u16 addr_type = 0;
 	u8 ip_proto = 0;
+	u32 hwtc = 0;
 	int err;
 
 	if (dissector->used_keys &
@@ -105,19 +230,40 @@ static int prestera_flower_parse(struct prestera_flow_block *block,
 	      BIT(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |
 	      BIT(FLOW_DISSECTOR_KEY_ICMP) |
 	      BIT(FLOW_DISSECTOR_KEY_PORTS) |
+	      BIT(FLOW_DISSECTOR_KEY_PORTS_RANGE) |
+	      BIT(FLOW_DISSECTOR_KEY_CT) |
 	      BIT(FLOW_DISSECTOR_KEY_VLAN))) {
 		NL_SET_ERR_MSG_MOD(f->common.extack, "Unsupported key");
+		MVSW_LOG_INFO("Unsupported key");
 		return -EOPNOTSUPP;
 	}
 
+	if (f->classid) {
+		/* The classid values of TC_H_MIN_PRIORITY through
+		 * TC_H_MIN_PRIORITY + PRESTERA_DEFAULT_TC_NUM - 1 represents
+		 * the hardware traffic classes.
+		 */
+		hwtc = TC_H_MIN(f->classid) - TC_H_MIN_PRIORITY;
+		if (hwtc >= PRESTERA_DEFAULT_TC_NUM) {
+			NL_SET_ERR_MSG_MOD(f->common.extack,
+					   "Unsupported HW TC");
+			return -EINVAL;
+		}
+		prestera_acl_rule_hw_tc_set(rule, hwtc);
+	}
+
 	prestera_acl_rule_priority_set(rule, f->common.prio);
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_META)) {
-		err = prestera_flower_parse_meta(rule, f, block);
+		err = mvsw_pr_flower_parse_meta(rule, f, block);
 		if (err)
 			return err;
 	}
 
+	err = prestera_ct_match_parse(f, f->common.extack);
+	if (err)
+		return err;
+
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_CONTROL)) {
 		struct flow_match_control match;
 
@@ -129,32 +275,19 @@ static int prestera_flower_parse(struct prestera_flow_block *block,
 		struct flow_match_basic match;
 
 		flow_rule_match_basic(f_rule, &match);
-		n_proto_key = ntohs(match.key->n_proto);
-		n_proto_mask = ntohs(match.mask->n_proto);
+		n_proto_key = match.key->n_proto;
+		n_proto_mask = match.mask->n_proto;
 
-		if (n_proto_key == ETH_P_ALL) {
+		if (ntohs(match.key->n_proto) == ETH_P_ALL) {
 			n_proto_key = 0;
 			n_proto_mask = 0;
 		}
 
-		/* add eth type key,mask */
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE;
-		m_entry.keymask.u16.key = n_proto_key;
-		m_entry.keymask.u16.mask = n_proto_mask;
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
-
-		/* add ip proto key,mask */
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO;
-		m_entry.keymask.u8.key = match.key->ip_proto;
-		m_entry.keymask.u8.mask = match.mask->ip_proto;
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		rule_match_set(r_match->key, ETH_TYPE, n_proto_key);
+		rule_match_set(r_match->mask, ETH_TYPE, n_proto_mask);
 
+		rule_match_set(r_match->key, IP_PROTO, match.key->ip_proto);
+		rule_match_set(r_match->mask, IP_PROTO, match.mask->ip_proto);
 		ip_proto = match.key->ip_proto;
 	}
 
@@ -163,27 +296,27 @@ static int prestera_flower_parse(struct prestera_flow_block *block,
 
 		flow_rule_match_eth_addrs(f_rule, &match);
 
-		/* add ethernet dst key,mask */
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC;
-		memcpy(&m_entry.keymask.mac.key,
-		       &match.key->dst, sizeof(match.key->dst));
-		memcpy(&m_entry.keymask.mac.mask,
-		       &match.mask->dst, sizeof(match.mask->dst));
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
-
-		/* add ethernet src key,mask */
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC;
-		memcpy(&m_entry.keymask.mac.key,
-		       &match.key->src, sizeof(match.key->src));
-		memcpy(&m_entry.keymask.mac.mask,
-		       &match.mask->src, sizeof(match.mask->src));
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		/* DA key, mask */
+		rule_match_set_n(r_match->key,
+				 ETH_DMAC_0, &match.key->dst[0], 4);
+		rule_match_set_n(r_match->key,
+				 ETH_DMAC_1, &match.key->dst[4], 2);
+
+		rule_match_set_n(r_match->mask,
+				 ETH_DMAC_0, &match.mask->dst[0], 4);
+		rule_match_set_n(r_match->mask,
+				 ETH_DMAC_1, &match.mask->dst[4], 2);
+
+		/* SA key, mask */
+		rule_match_set_n(r_match->key,
+				 ETH_SMAC_0, &match.key->src[0], 4);
+		rule_match_set_n(r_match->key,
+				 ETH_SMAC_1, &match.key->src[4], 2);
+
+		rule_match_set_n(r_match->mask,
+				 ETH_SMAC_0, &match.mask->src[0], 4);
+		rule_match_set_n(r_match->mask,
+				 ETH_SMAC_1, &match.mask->src[4], 2);
 	}
 
 	if (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {
@@ -191,25 +324,11 @@ static int prestera_flower_parse(struct prestera_flow_block *block,
 
 		flow_rule_match_ipv4_addrs(f_rule, &match);
 
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC;
-		memcpy(&m_entry.keymask.u32.key,
-		       &match.key->src, sizeof(match.key->src));
-		memcpy(&m_entry.keymask.u32.mask,
-		       &match.mask->src, sizeof(match.mask->src));
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		rule_match_set(r_match->key, IP_SRC, match.key->src);
+		rule_match_set(r_match->mask, IP_SRC, match.mask->src);
 
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST;
-		memcpy(&m_entry.keymask.u32.key,
-		       &match.key->dst, sizeof(match.key->dst));
-		memcpy(&m_entry.keymask.u32.mask,
-		       &match.mask->dst, sizeof(match.mask->dst));
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		rule_match_set(r_match->key, IP_DST, match.key->dst);
+		rule_match_set(r_match->mask, IP_DST, match.mask->dst);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_PORTS)) {
@@ -224,21 +343,34 @@ static int prestera_flower_parse(struct prestera_flow_block *block,
 
 		flow_rule_match_ports(f_rule, &match);
 
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC;
-		m_entry.keymask.u16.key = ntohs(match.key->src);
-		m_entry.keymask.u16.mask = ntohs(match.mask->src);
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		rule_match_set(r_match->key, L4_PORT_SRC, match.key->src);
+		rule_match_set(r_match->mask, L4_PORT_SRC, match.mask->src);
 
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST;
-		m_entry.keymask.u16.key = ntohs(match.key->dst);
-		m_entry.keymask.u16.mask = ntohs(match.mask->dst);
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		rule_match_set(r_match->key, L4_PORT_DST, match.key->dst);
+		rule_match_set(r_match->mask, L4_PORT_DST, match.mask->dst);
+	}
+
+	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_PORTS_RANGE)) {
+		struct flow_match_ports_range match;
+		__be32 tp_key, tp_mask;
+
+		flow_rule_match_ports_range(f_rule, &match);
+
+		/* src port range (min, max) */
+		tp_key = htonl(ntohs(match.key->tp_min.src) |
+			       (ntohs(match.key->tp_max.src) << 16));
+		tp_mask = htonl(ntohs(match.mask->tp_min.src) |
+				(ntohs(match.mask->tp_max.src) << 16));
+		rule_match_set(r_match->key, L4_PORT_RANGE_SRC, tp_key);
+		rule_match_set(r_match->mask, L4_PORT_RANGE_SRC, tp_mask);
+
+		/* dst port range (min, max) */
+		tp_key = htonl(ntohs(match.key->tp_min.dst) |
+			       (ntohs(match.key->tp_max.dst) << 16));
+		tp_mask = htonl(ntohs(match.mask->tp_min.dst) |
+				(ntohs(match.mask->tp_max.dst) << 16));
+		rule_match_set(r_match->key, L4_PORT_RANGE_DST, tp_key);
+		rule_match_set(r_match->mask, L4_PORT_RANGE_DST, tp_mask);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_VLAN)) {
@@ -247,22 +379,15 @@ static int prestera_flower_parse(struct prestera_flow_block *block,
 		flow_rule_match_vlan(f_rule, &match);
 
 		if (match.mask->vlan_id != 0) {
-			memset(&m_entry, 0, sizeof(m_entry));
-			m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID;
-			m_entry.keymask.u16.key = match.key->vlan_id;
-			m_entry.keymask.u16.mask = match.mask->vlan_id;
-			err = prestera_acl_rule_match_add(rule, &m_entry);
-			if (err)
-				return err;
+			__be16 key = cpu_to_be16(match.key->vlan_id);
+			__be16 mask = cpu_to_be16(match.mask->vlan_id);
+
+			rule_match_set(r_match->key, VLAN_ID, key);
+			rule_match_set(r_match->mask, VLAN_ID, mask);
 		}
 
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID;
-		m_entry.keymask.u16.key = ntohs(match.key->vlan_tpid);
-		m_entry.keymask.u16.mask = ntohs(match.mask->vlan_tpid);
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		rule_match_set(r_match->key, VLAN_TPID, match.key->vlan_tpid);
+		rule_match_set(r_match->mask, VLAN_TPID, match.mask->vlan_tpid);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_ICMP)) {
@@ -270,90 +395,231 @@ static int prestera_flower_parse(struct prestera_flow_block *block,
 
 		flow_rule_match_icmp(f_rule, &match);
 
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE;
-		m_entry.keymask.u8.key = match.key->type;
-		m_entry.keymask.u8.mask = match.mask->type;
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		rule_match_set(r_match->key, ICMP_TYPE, match.key->type);
+		rule_match_set(r_match->mask, ICMP_TYPE, match.mask->type);
 
-		memset(&m_entry, 0, sizeof(m_entry));
-		m_entry.type = PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE;
-		m_entry.keymask.u8.key = match.key->code;
-		m_entry.keymask.u8.mask = match.mask->code;
-		err = prestera_acl_rule_match_add(rule, &m_entry);
-		if (err)
-			return err;
+		rule_match_set(r_match->key, ICMP_CODE, match.key->code);
+		rule_match_set(r_match->mask, ICMP_CODE, match.mask->code);
 	}
 
-	return prestera_flower_parse_actions(block, rule,
-					     &f->rule->action,
-					     f->common.extack);
+	return mvsw_pr_flower_parse_actions(block, rule, &f->rule->action,
+					    f->common.chain_index,
+					    f->common.extack);
+}
+
+static int prestera_flower_prio_check(struct prestera_flow_block *block,
+				      struct flow_cls_offload *f)
+{
+	u32 mall_prio;
+	int err;
+
+	err = prestera_mall_prio_get(block, &mall_prio);
+	if (err == -ENOENT)
+		return 0;
+	if (err)
+		return err;
+
+	if (f->common.prio <= mall_prio)
+		return -EOPNOTSUPP;
+
+	return 0;
 }
 
-int prestera_flower_replace(struct prestera_flow_block *block,
+int prestera_flower_prio_get(struct prestera_flow_block *block,
+			     u32 *prio)
+{
+	if (!prestera_acl_block_rule_count(block))
+		return -ENOENT;
+
+	*prio = block->flower_min_prio;
+	return 0;
+}
+
+static void prestera_flower_prio_update(struct prestera_flow_block *block,
+					u32 prio)
+{
+	if (prio < block->flower_min_prio)
+		block->flower_min_prio = prio;
+}
+
+int prestera_flower_replace(struct prestera_switch *sw,
+			    struct prestera_flow_block *block,
 			    struct flow_cls_offload *f)
 {
-	struct prestera_switch *sw = prestera_acl_block_sw(block);
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl *acl = sw->acl;
 	struct prestera_acl_rule *rule;
 	int err;
 
-	rule = prestera_acl_rule_create(block, f->cookie);
-	if (IS_ERR(rule))
-		return PTR_ERR(rule);
+	err = prestera_flower_prio_check(block, f);
+	if (err)
+		return err;
+
+	ruleset = prestera_acl_ruleset_get(acl, block, f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
+
+	/* increments the ruleset reference */
+	rule = prestera_acl_rule_create(ruleset, f->cookie,
+					f->common.chain_index);
+	if (IS_ERR(rule)) {
+		err = PTR_ERR(rule);
+		goto err_rule_create;
+	}
 
-	err = prestera_flower_parse(block, rule, f);
+	err = mvsw_pr_flower_parse(block, rule, f);
 	if (err)
-		goto err_flower_parse;
+		goto err_rule_add;
+
+	if (!prestera_acl_ruleset_is_offload(ruleset)) {
+		err = prestera_acl_ruleset_offload(ruleset);
+		if (err)
+			goto err_ruleset_offload;
+	}
 
 	err = prestera_acl_rule_add(sw, rule);
 	if (err)
 		goto err_rule_add;
 
+	prestera_flower_prio_update(block, f->common.prio);
+
+	prestera_acl_ruleset_put(ruleset);
 	return 0;
 
+err_ruleset_offload:
 err_rule_add:
-err_flower_parse:
 	prestera_acl_rule_destroy(rule);
+err_rule_create:
+	prestera_acl_ruleset_put(ruleset);
 	return err;
 }
 
-void prestera_flower_destroy(struct prestera_flow_block *block,
+void prestera_flower_destroy(struct prestera_switch *sw,
+			     struct prestera_flow_block *block,
 			     struct flow_cls_offload *f)
 {
+	struct prestera_acl_ruleset *ruleset;
 	struct prestera_acl_rule *rule;
-	struct prestera_switch *sw;
 
-	rule = prestera_acl_rule_lookup(prestera_acl_block_ruleset_get(block),
-					f->cookie);
+	ruleset = prestera_acl_ruleset_lookup(sw->acl, block,
+					      f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return;
+
+	rule = prestera_acl_rule_lookup(ruleset, f->cookie);
 	if (rule) {
-		sw = prestera_acl_block_sw(block);
 		prestera_acl_rule_del(sw, rule);
 		prestera_acl_rule_destroy(rule);
 	}
+	prestera_acl_ruleset_put(ruleset);
+}
+
+int prestera_flower_tmplt_create(struct prestera_switch *sw,
+				 struct prestera_flow_block *block,
+				 struct flow_cls_offload *f)
+{
+	struct prestera_flower_template *template;
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl_rule rule;
+	int err;
+
+	memset(&rule, 0, sizeof(rule));
+	err = mvsw_pr_flower_parse(block, &rule, f);
+	if (err)
+		return err;
+
+	template = kmalloc(sizeof(*template), GFP_KERNEL);
+	if (!template) {
+		err = -ENOMEM;
+		goto err_malloc;
+	}
+
+	prestera_acl_rule_keymask_pcl_id_set(&rule, 0);
+	ruleset = prestera_acl_ruleset_get(sw->acl, block,
+					   f->common.chain_index);
+	if (IS_ERR_OR_NULL(ruleset)) {
+		err = -EINVAL;
+		goto err_ruleset_get;
+	}
+
+	/* preserve keymask/template to this ruleset */
+	err = prestera_acl_ruleset_keymask_set(ruleset, rule.re_key.match.mask);
+	if (err)
+		goto err_ruleset_offload;
+
+	/* skip error, as it is not possible to reject template operation,
+	 * so, keep the reference to the ruleset for rules to be added
+	 * to that ruleset later. In case of offload fail, the ruleset
+	 * will be offloaded again during adding a new rule. Also,
+	 * unlikly possble that ruleset is already offloaded at this staage.
+	 */
+	prestera_acl_ruleset_offload(ruleset);
+
+	/* keep the reference to the ruleset */
+	template->ruleset = ruleset;
+	template->chain_index = f->common.chain_index;
+	list_add_rcu(&template->list, &block->template_list);
+	return 0;
+
+err_ruleset_offload:
+	prestera_acl_ruleset_put(ruleset);
+err_ruleset_get:
+	kfree(template);
+err_malloc:
+	MVSW_LOG_ERROR("Create chain template failed");
+	return err;
 }
 
-int prestera_flower_stats(struct prestera_flow_block *block,
+void prestera_flower_tmplt_destroy(struct prestera_switch *sw,
+				   struct prestera_flow_block *block,
+				   struct flow_cls_offload *f)
+{
+	struct prestera_flower_template *template;
+	struct list_head *pos, *n;
+
+	list_for_each_safe(pos, n, &block->template_list) {
+		template = list_entry(pos, typeof(*template), list);
+		if (template->chain_index == f->common.chain_index) {
+			/* put the reference to the ruleset kept in create */
+			prestera_acl_ruleset_put(template->ruleset);
+			list_del(&template->list);
+			kfree(template);
+			return;
+		}
+	}
+}
+
+int prestera_flower_stats(struct prestera_switch *sw,
+			  struct prestera_flow_block *block,
 			  struct flow_cls_offload *f)
 {
-	struct prestera_switch *sw = prestera_acl_block_sw(block);
+	struct prestera_acl_ruleset *ruleset;
 	struct prestera_acl_rule *rule;
 	u64 packets;
 	u64 lastuse;
 	u64 bytes;
 	int err;
 
-	rule = prestera_acl_rule_lookup(prestera_acl_block_ruleset_get(block),
-					f->cookie);
-	if (!rule)
-		return -EINVAL;
+	ruleset = prestera_acl_ruleset_lookup(sw->acl, block,
+					      f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
+
+	rule = prestera_acl_rule_lookup(ruleset, f->cookie);
+	if (!rule) {
+		err = -EINVAL;
+		goto err_rule_get_stats;
+	}
 
-	err = prestera_acl_rule_get_stats(sw, rule, &packets, &bytes, &lastuse);
+	err = prestera_acl_rule_get_stats(sw->acl, rule, &packets,
+					  &bytes, &lastuse);
 	if (err)
-		return err;
+		goto err_rule_get_stats;
 
 	flow_stats_update(&f->stats, bytes, packets, 0, lastuse,
-			  FLOW_ACTION_HW_STATS_IMMEDIATE);
-	return 0;
+			  FLOW_ACTION_HW_STATS_DELAYED);
+
+err_rule_get_stats:
+	prestera_acl_ruleset_put(ruleset);
+	return err;
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_fw.c b/drivers/net/ethernet/marvell/prestera/prestera_fw.c
new file mode 100644
index 000000000000..6da3aa8efa99
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_fw.c
@@ -0,0 +1,445 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/circ_buf.h>
+
+#include "prestera.h"
+#include "prestera_fw.h"
+
+#define PRESTERA_FW_READY_MAGIC	0xcafebabe
+
+/* Firmware registers: */
+#define PRESTERA_FW_READY_REG		PRESTERA_FW_REG_OFFSET(fw_ready)
+
+#define PRESTERA_CMDQ_REG_OFFSET(q, f)			\
+	(PRESTERA_FW_REG_OFFSET(cmdq_list) +		\
+	 (q) * sizeof(struct prestera_fw_cmdq_regs) +	\
+	 offsetof(struct prestera_fw_cmdq_regs, f))
+
+#define PRESTERA_CMD_BUF_OFFS_REG	PRESTERA_FW_REG_OFFSET(cmd_offs)
+#define PRESTERA_CMD_BUF_LEN_REG	PRESTERA_FW_REG_OFFSET(cmd_len)
+#define PRESTERA_CMD_QNUM_REG		PRESTERA_FW_REG_OFFSET(cmd_qnum)
+#define PRESTERA_EVT_BUF_OFFS_REG	PRESTERA_FW_REG_OFFSET(evt_offs)
+#define PRESTERA_EVT_QNUM_REG		PRESTERA_FW_REG_OFFSET(evt_qnum)
+
+#define PRESTERA_CMDQ_REQ_CTL_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_req_ctl)
+#define PRESTERA_CMDQ_REQ_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_req_len)
+#define PRESTERA_CMDQ_RCV_CTL_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_rcv_ctl)
+#define PRESTERA_CMDQ_RCV_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_rcv_len)
+#define PRESTERA_CMDQ_OFFS_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, offs)
+#define PRESTERA_CMDQ_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, len)
+
+/* PRESTERA_CMDQ_REQ_CTL_REG flags */
+#define PRESTERA_CMD_F_REQ_SENT		BIT(0)
+#define PRESTERA_CMD_F_REPL_RCVD	BIT(1)
+
+/* PRESTERA_CMDQ_RCV_CTL_REG flags */
+#define PRESTERA_CMD_F_REPL_SENT	BIT(0)
+
+/* PRESTERA_FW_STATUS_REG flags */
+#define PRESTERA_STATUS_F_EVT_OFF	BIT(0)
+
+#define PRESTERA_EVTQ_REG_OFFSET(q, f)			\
+	(PRESTERA_FW_REG_OFFSET(evtq_list) +		\
+	 (q) * sizeof(struct prestera_fw_evtq_regs) +	\
+	 offsetof(struct prestera_fw_evtq_regs, f))
+
+#define PRESTERA_EVTQ_RD_IDX_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, rd_idx)
+#define PRESTERA_EVTQ_WR_IDX_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, wr_idx)
+#define PRESTERA_EVTQ_OFFS_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, offs)
+#define PRESTERA_EVTQ_LEN_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, len)
+
+#define FW_VER_MAJ_MUL 1000000
+#define FW_VER_MIN_MUL 1000
+
+static int fw_ver_maj(int v)
+{
+	return ((v) / FW_VER_MAJ_MUL);
+}
+
+static int fw_ver_min(int v)
+{
+	int vv = fw_ver_maj(v) * FW_VER_MAJ_MUL;
+
+	return (((v) - vv) / FW_VER_MIN_MUL);
+}
+
+static int fw_ver_patch(int v)
+{
+	int vv, vvv;
+
+	vv = (fw_ver_maj(v) * FW_VER_MAJ_MUL);
+	vvv = (fw_ver_min(v) * FW_VER_MIN_MUL);
+	return ((v) - vv - vvv);
+}
+
+static void prestera_fw_cmdq_lock(struct prestera_fw *fw, u8 qid)
+{
+	mutex_lock(&fw->cmd_queue[qid].cmd_mtx);
+}
+
+static void prestera_fw_cmdq_unlock(struct prestera_fw *fw, u8 qid)
+{
+	mutex_unlock(&fw->cmd_queue[qid].cmd_mtx);
+}
+
+static u32 prestera_fw_cmdq_len(struct prestera_fw *fw, u8 qid)
+{
+	return fw->cmd_queue[qid].len;
+}
+
+static u8 __iomem *prestera_fw_cmdq_buf(struct prestera_fw *fw, u8 qid)
+{
+	return fw->cmd_queue[qid].addr;
+}
+
+static u32 prestera_fw_evtq_len(struct prestera_fw *fw, u8 qid)
+{
+	return fw->evt_queue[qid].len;
+}
+
+static u32 prestera_fw_evtq_avail(struct prestera_fw *fw, u8 qid)
+{
+	u32 wr_idx = prestera_fw_read(fw, PRESTERA_EVTQ_WR_IDX_REG(qid));
+	u32 rd_idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
+
+	return CIRC_CNT(wr_idx, rd_idx, prestera_fw_evtq_len(fw, qid));
+}
+
+static void prestera_fw_evtq_rd_set(struct prestera_fw *fw, u8 qid, u32 idx)
+{
+	u32 rd_idx = idx & (prestera_fw_evtq_len(fw, qid) - 1);
+
+	prestera_fw_write(fw, PRESTERA_EVTQ_RD_IDX_REG(qid), rd_idx);
+}
+
+static u8 __iomem *prestera_fw_evtq_buf(struct prestera_fw *fw, u8 qid)
+{
+	return fw->evt_queue[qid].addr;
+}
+
+static u32 prestera_fw_evtq_read32(struct prestera_fw *fw, u8 qid)
+{
+	u32 rd_idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
+	u32 val;
+
+	val = readl(prestera_fw_evtq_buf(fw, qid) + rd_idx);
+	prestera_fw_evtq_rd_set(fw, qid, rd_idx + 4);
+	return val;
+}
+
+static ssize_t prestera_fw_evtq_read_buf(struct prestera_fw *fw, u8 qid,
+					 u8 *buf, size_t len)
+{
+	u32 idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
+	u8 __iomem *evtq_addr = prestera_fw_evtq_buf(fw, qid);
+	u32 *buf32 = (u32 *)buf;
+	int i;
+
+	for (i = 0; i < len / 4; buf32++, i++) {
+		*buf32 = readl_relaxed(evtq_addr + idx);
+		idx = (idx + 4) & (prestera_fw_evtq_len(fw, qid) - 1);
+	}
+
+	prestera_fw_evtq_rd_set(fw, qid, idx);
+
+	return i;
+}
+
+static u8 prestera_fw_evtq_pick(struct prestera_fw *fw)
+{
+	int qid;
+
+	for (qid = 0; qid < fw->evt_qnum; qid++) {
+		if (prestera_fw_evtq_avail(fw, qid) >= 4)
+			return qid;
+	}
+
+	return PRESTERA_EVT_QNUM_MAX;
+}
+
+static void prestera_fw_status_set(struct prestera_fw *fw, unsigned int val)
+{
+	u32 status = prestera_fw_read(fw, PRESTERA_FW_STATUS_REG);
+
+	status |= val;
+
+	prestera_fw_write(fw, PRESTERA_FW_STATUS_REG, status);
+}
+
+static void prestera_fw_status_clear(struct prestera_fw *fw, u32 val)
+{
+	u32 status = prestera_fw_read(fw, PRESTERA_FW_STATUS_REG);
+
+	status &= ~val;
+
+	prestera_fw_write(fw, PRESTERA_FW_STATUS_REG, status);
+}
+
+void prestera_fw_handle_event(struct prestera_fw *fw)
+{
+	u8 *msg;
+	u8 qid;
+
+	msg = fw->evt_msg;
+
+	prestera_fw_status_set(fw, PRESTERA_STATUS_F_EVT_OFF);
+
+	while ((qid = prestera_fw_evtq_pick(fw)) < PRESTERA_EVT_QNUM_MAX) {
+		u32 idx;
+		u32 len;
+
+		len = prestera_fw_evtq_read32(fw, qid);
+		idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
+
+		WARN_ON(prestera_fw_evtq_avail(fw, qid) < len);
+
+		if (WARN_ON(len > PRESTERA_MSG_MAX_SIZE)) {
+			prestera_fw_evtq_rd_set(fw, qid, idx + len);
+			continue;
+		}
+
+		prestera_fw_evtq_read_buf(fw, qid, msg, len);
+
+		if (fw->dev.recv_msg)
+			fw->dev.recv_msg(&fw->dev, msg, len);
+	}
+
+	prestera_fw_status_clear(fw, PRESTERA_STATUS_F_EVT_OFF);
+}
+EXPORT_SYMBOL(prestera_fw_handle_event);
+
+static void prestera_fw_evt_work_fn(struct work_struct *work)
+{
+	struct prestera_fw *fw;
+
+	fw = container_of(work, struct prestera_fw, evt_work);
+
+	prestera_fw_handle_event(fw);
+}
+
+void prestera_fw_queue_work(struct prestera_fw *fw)
+{
+	queue_work(fw->wq, &fw->evt_work);
+}
+EXPORT_SYMBOL(prestera_fw_queue_work);
+
+static int prestera_fw_wait_reg32(struct prestera_fw *fw, u32 reg, u32 val,
+				  unsigned int wait)
+{
+	if (prestera_wait(prestera_fw_read(fw, reg) == val || !fw->dev.running,
+			  wait))
+		return fw->dev.running ? 0 : -ENODEV;
+
+	return -EBUSY;
+}
+
+static void prestera_pci_copy_to(u8 __iomem *dst, u8 *src, size_t len)
+{
+	u32 __iomem *dst32 = (u32 __iomem *)dst;
+	u32 *src32 = (u32 *)src;
+	int i;
+
+	for (i = 0; i < (len / 4); dst32++, src32++, i++)
+		writel_relaxed(*src32, dst32);
+}
+
+static void prestera_pci_copy_from(u8 *dst, u8 __iomem *src, size_t len)
+{
+	u32 *dst32 = (u32 *)dst;
+	u32 __iomem *src32 = (u32 __iomem *)src;
+	int i;
+
+	for (i = 0; i < (len / 4); dst32++, src32++, i++)
+		*dst32 = readl_relaxed(src32);
+}
+
+static int prestera_fw_cmd_send(struct prestera_fw *fw, int qid,
+				u8 *in_msg, size_t in_size,
+				u8 *out_msg, size_t out_size,
+				unsigned int wait)
+{
+	u32 ret_size = 0;
+	int err = 0;
+
+	if (!wait)
+		wait = 30000;
+
+	if (ALIGN(in_size, 4) > prestera_fw_cmdq_len(fw, qid))
+		return -EMSGSIZE;
+
+	/* wait for finish previous reply from FW */
+	err = prestera_fw_wait_reg32(fw, PRESTERA_CMDQ_RCV_CTL_REG(qid),
+				     0, 1000);
+	if (err) {
+		dev_err(prestera_fw_dev(fw),
+			"finish reply from FW is timed out\n");
+		return err;
+	}
+
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_LEN_REG(qid), in_size);
+	prestera_pci_copy_to(prestera_fw_cmdq_buf(fw, qid), in_msg, in_size);
+
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_CTL_REG(qid),
+			  PRESTERA_CMD_F_REQ_SENT);
+
+	/* wait for reply from FW */
+	err = prestera_fw_wait_reg32(fw, PRESTERA_CMDQ_RCV_CTL_REG(qid),
+				     PRESTERA_CMD_F_REPL_SENT, wait);
+	if (err) {
+		dev_err(prestera_fw_dev(fw),
+			"reply from FW is timed out\n");
+		goto cmd_exit;
+	}
+
+	ret_size = prestera_fw_read(fw, PRESTERA_CMDQ_RCV_LEN_REG(qid));
+	if (ret_size > out_size) {
+		dev_err(prestera_fw_dev(fw), "ret_size (%u) > out_len(%zu)\n",
+			ret_size, out_size);
+		err = -EMSGSIZE;
+		goto cmd_exit;
+	}
+
+	prestera_pci_copy_from(out_msg, prestera_fw_cmdq_buf(fw, qid) + in_size,
+			       ret_size);
+
+cmd_exit:
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_CTL_REG(qid),
+			  PRESTERA_CMD_F_REPL_RCVD);
+	return err;
+}
+
+int prestera_fw_send_req(struct prestera_device *pr_dev, int qid,
+			 u8 *in_msg, size_t in_size, u8 *out_msg,
+			 size_t out_size, unsigned int wait)
+{
+	struct prestera_fw *fw;
+	ssize_t ret;
+
+	fw = container_of(pr_dev, struct prestera_fw, dev);
+
+	if (!fw->dev.running)
+		return -ENODEV;
+
+	prestera_fw_cmdq_lock(fw, qid);
+	ret = prestera_fw_cmd_send(fw, qid, in_msg, in_size, out_msg, out_size,
+				   wait);
+	prestera_fw_cmdq_unlock(fw, qid);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(prestera_fw_send_req);
+
+int prestera_fw_rev_check(struct prestera_fw *fw)
+{
+	struct prestera_fw_rev *rev = &fw->dev.fw_rev;
+
+	dev_info(prestera_fw_dev(fw), "FW version '%u.%u.%u'\n",
+		 rev->maj, rev->min, rev->sub);
+	dev_info(prestera_fw_dev(fw), "Driver version '%u.%u.%u'\n",
+		 PRESTERA_SUPP_FW_MAJ_VER, PRESTERA_SUPP_FW_MIN_VER,
+		 PRESTERA_SUPP_FW_PATCH_VER);
+
+	if (rev->maj == PRESTERA_SUPP_FW_MAJ_VER &&
+	    rev->min == PRESTERA_SUPP_FW_MIN_VER) {
+		return 0;
+	}
+
+	dev_err(prestera_fw_dev(fw),
+		"Driver is incomatible with FW: version mismatch");
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(prestera_fw_rev_check);
+
+void prestera_fw_rev_parse(const struct prestera_fw_header *hdr,
+			   struct prestera_fw_rev *rev)
+{
+	u32 version = be32_to_cpu(hdr->version_value);
+
+	rev->maj = fw_ver_maj(version);
+	rev->min = fw_ver_min(version);
+	rev->sub = fw_ver_patch(version);
+}
+EXPORT_SYMBOL_GPL(prestera_fw_rev_parse);
+
+void prestera_fw_rev_parse_int(unsigned int firmware_version,
+			       struct prestera_fw_rev *rev)
+{
+	u32 version = firmware_version;
+
+	rev->maj = fw_ver_maj(version);
+	rev->min = fw_ver_min(version);
+	rev->sub = fw_ver_patch(version);
+}
+EXPORT_SYMBOL_GPL(prestera_fw_rev_parse_int);
+
+int prestera_fw_init(struct prestera_fw *fw)
+{
+	u8 __iomem *base;
+	int err;
+	u8 qid;
+
+	err = prestera_fw_wait_reg32(fw, PRESTERA_FW_READY_REG,
+				     PRESTERA_FW_READY_MAGIC, 20000);
+	if (err) {
+		dev_err(prestera_fw_dev(fw), "FW failed to start\n");
+		return err;
+	}
+
+	base = fw->mem_addr;
+
+	fw->cmd_mbox = base + prestera_fw_read(fw, PRESTERA_CMD_BUF_OFFS_REG);
+	fw->cmd_mbox_len = prestera_fw_read(fw, PRESTERA_CMD_BUF_LEN_REG);
+	fw->cmd_qnum = prestera_fw_read(fw, PRESTERA_CMD_QNUM_REG);
+
+	for (qid = 0; qid < fw->cmd_qnum; qid++) {
+		u32 offs = prestera_fw_read(fw, PRESTERA_CMDQ_OFFS_REG(qid));
+		struct prestera_fw_cmdq *cmdq = &fw->cmd_queue[qid];
+
+		cmdq->len = prestera_fw_read(fw, PRESTERA_CMDQ_LEN_REG(qid));
+		cmdq->addr = fw->cmd_mbox + offs;
+		mutex_init(&cmdq->cmd_mtx);
+	}
+
+	fw->evt_buf = base + prestera_fw_read(fw, PRESTERA_EVT_BUF_OFFS_REG);
+	fw->evt_qnum = prestera_fw_read(fw, PRESTERA_EVT_QNUM_REG);
+	fw->evt_msg = kmalloc(PRESTERA_MSG_MAX_SIZE, GFP_KERNEL);
+	if (!fw->evt_msg)
+		return -ENOMEM;
+
+	for (qid = 0; qid < fw->evt_qnum; qid++) {
+		u32 offs = prestera_fw_read(fw, PRESTERA_EVTQ_OFFS_REG(qid));
+		struct prestera_fw_evtq *evtq = &fw->evt_queue[qid];
+
+		evtq->len = prestera_fw_read(fw, PRESTERA_EVTQ_LEN_REG(qid));
+		evtq->addr = fw->evt_buf + offs;
+	}
+
+	fw->wq = alloc_workqueue("prestera_fw_wq", WQ_HIGHPRI, 1);
+	if (!fw->wq)
+		goto err_wq_alloc;
+
+	INIT_WORK(&fw->evt_work, prestera_fw_evt_work_fn);
+
+	return 0;
+
+err_wq_alloc:
+	kfree(fw->evt_msg);
+	return -ENOMEM;
+}
+EXPORT_SYMBOL_GPL(prestera_fw_init);
+
+void prestera_fw_uninit(struct prestera_fw *fw)
+{
+	kfree(fw->evt_msg);
+	flush_workqueue(fw->wq);
+	destroy_workqueue(fw->wq);
+}
+EXPORT_SYMBOL_GPL(prestera_fw_uninit);
+
+MODULE_AUTHOR("Marvell Semi.");
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Marvell Prestera switch Firmware Agent interface");
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_fw.h b/drivers/net/ethernet/marvell/prestera/prestera_fw.h
new file mode 100644
index 000000000000..9a5f91533e55
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_fw.h
@@ -0,0 +1,127 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#ifndef PRESTERA_FW_H
+#define PRESTERA_FW_H_
+
+#define PRESTERA_EVT_QNUM_MAX	4
+#define PRESTERA_CMD_QNUM_MAX	4
+
+struct prestera_fw_evtq_regs {
+	u32 rd_idx;
+	u32 pad1;
+	u32 wr_idx;
+	u32 pad2;
+	u32 offs;
+	u32 len;
+};
+
+struct prestera_fw_cmdq_regs {
+	u32 cmd_req_ctl;
+	u32 cmd_req_len;
+	u32 cmd_rcv_ctl;
+	u32 cmd_rcv_len;
+	u32 offs;
+	u32 len;
+};
+
+struct prestera_fw_regs {
+	u32 fw_ready;
+	u32 cmd_offs;
+	u32 cmd_len;
+	u32 cmd_qnum;
+	u32 evt_offs;
+	u32 evt_qnum;
+
+	u32 fw_status;
+	u32 rx_status;
+
+	struct prestera_fw_cmdq_regs cmdq_list[PRESTERA_CMD_QNUM_MAX];
+	struct prestera_fw_evtq_regs evtq_list[PRESTERA_EVT_QNUM_MAX];
+};
+
+#define prestera_wait(cond, waitms) \
+({ \
+	unsigned long __wait_end = jiffies + msecs_to_jiffies(waitms); \
+	bool __wait_ret = false; \
+	do { \
+		if (cond) { \
+			__wait_ret = true; \
+			break; \
+		} \
+		cond_resched(); \
+	} while (time_before(jiffies, __wait_end)); \
+	__wait_ret; \
+})
+
+#define prestera_fw_dev(fw)	((fw)->dev.dev)
+
+/* Firmware registers: */
+#define PRESTERA_FW_REG_OFFSET(f)	offsetof(struct prestera_fw_regs, f)
+
+#define PRESTERA_FW_STATUS_REG		PRESTERA_FW_REG_OFFSET(fw_status)
+#define PRESTERA_RX_STATUS_REG		PRESTERA_FW_REG_OFFSET(rx_status)
+
+#define prestera_fw_write(fw, reg, val)	writel(val, (fw)->hw_regs + (reg))
+#define prestera_fw_read(fw, reg)	readl((fw)->hw_regs + (reg))
+
+#define PRESTERA_SUPP_FW_MAJ_VER	3
+#define PRESTERA_SUPP_FW_MIN_VER	1
+#define PRESTERA_SUPP_FW_PATCH_VER	1
+
+struct prestera_fw_evtq {
+	u8 __iomem *addr;
+	size_t len;
+};
+
+struct prestera_fw_cmdq {
+	/* serialize access to dev->send_req */
+	struct mutex cmd_mtx;
+	u8 __iomem *addr;
+	size_t len;
+};
+
+struct prestera_fw_header {
+	__be32 magic_number;
+	__be32 version_value;
+	u8 reserved[8];
+} __packed;
+
+struct prestera_fw {
+	struct workqueue_struct *wq;
+	struct prestera_device dev;
+	struct pci_dev *pci_dev;
+	u8 __iomem *mem_addr;
+
+	u8 __iomem *ldr_regs;
+	u8 __iomem *hw_regs;
+
+	u8 __iomem *ldr_ring_buf;
+	u32 ldr_buf_len;
+	u32 ldr_wr_idx;
+
+	size_t cmd_mbox_len;
+	u8 __iomem *cmd_mbox;
+	struct prestera_fw_cmdq cmd_queue[PRESTERA_CMD_QNUM_MAX];
+	u8 cmd_qnum;
+	struct prestera_fw_evtq evt_queue[PRESTERA_EVT_QNUM_MAX];
+	u8 evt_qnum;
+	struct work_struct evt_work;
+	u8 __iomem *evt_buf;
+	u8 *evt_msg;
+};
+
+int prestera_fw_rev_check(struct prestera_fw *fw);
+void prestera_fw_rev_parse_int(unsigned int firmware_version,
+			       struct prestera_fw_rev *rev);
+void prestera_fw_rev_parse(const struct prestera_fw_header *hdr,
+			   struct prestera_fw_rev *rev);
+void prestera_fw_uninit(struct prestera_fw *fw);
+int prestera_fw_init(struct prestera_fw *fw);
+int prestera_fw_send_req(struct prestera_device *dev, int qid,
+			 u8 *in_msg, size_t in_size, u8 *out_msg,
+			 size_t out_size, unsigned int wait);
+void prestera_fw_handle_event(struct prestera_fw *fw);
+void prestera_fw_queue_work(struct prestera_fw *fw);
+
+#endif
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
new file mode 100644
index 000000000000..64cb88aa9ba0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
@@ -0,0 +1,429 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/sysfs.h>
+#include <linux/fs.h>
+#include <linux/etherdevice.h>
+#include <linux/string.h>
+#include <linux/ctype.h>
+#include <linux/debugfs.h>
+
+#include "prestera.h"
+#include "prestera_hw.h"
+#include "prestera_log.h"
+#include "prestera_fw_log.h"
+
+#define FW_LOG_DBGFS_CFG_DIR	"mvsw_pr_fw_log"
+#define FW_LOG_DBGFS_CFG_NAME	"cfg"
+#define FW_LOG_DBGFS_MAX_STR_LEN	64
+#define FW_LOG_PR_LOG_PREFIX	"[mvsw_pr_fw_log]"
+#define FW_LOG_PR_LIB_SIZE	32
+#define FW_LOG_PR_READ_BUF_SIZE	8192
+#define MVSW_FW_LOG_INFO(fmt, ...)	\
+	pr_info(fmt, ##__VA_ARGS__)
+
+#define FW_LOG_READ_TABLE_FMT	"%-23s"
+
+#define mvsw_dev(sw)		((sw)->dev->dev)
+
+static void mvsw_pr_fw_log_evt_handler(struct prestera_switch *,
+				       struct prestera_event *,
+				       void *);
+static ssize_t mvsw_pr_fw_log_debugfs_read(struct file *file,
+					   char __user *ubuf,
+					   size_t count, loff_t *ppos);
+static ssize_t mvsw_pr_fw_log_debugfs_write(struct file *file,
+					    const char __user *ubuf,
+					    size_t count, loff_t *ppos);
+static inline int mvsw_pr_fw_log_get_type_from_str(const char *str);
+static inline int mvsw_pr_fw_log_get_lib_from_str(const char *str);
+
+static int mvsw_pr_fw_log_event_handler_register(struct prestera_switch *sw);
+static void mvsw_pr_fw_log_event_handler_unregister(struct prestera_switch *sw);
+
+struct mvsw_pr_fw_log_prv_debugfs {
+	struct dentry *cfg_dir;
+	struct dentry *cfg;
+	const struct file_operations cfg_fops;
+	char *read_buf;
+};
+
+static u8 fw_log_lib_type_config[PRESTERA_FW_LOG_LIB_MAX] = { 0 };
+
+static struct mvsw_pr_fw_log_prv_debugfs fw_log_debugfs_handle = {
+	.cfg_dir = NULL,
+	.cfg_fops = {
+		.read = mvsw_pr_fw_log_debugfs_read,
+		.write = mvsw_pr_fw_log_debugfs_write,
+		.open = simple_open,
+		.llseek = default_llseek,
+	}
+};
+
+static const char *mvsw_pr_fw_log_lib_id2name[PRESTERA_FW_LOG_LIB_MAX] = {
+	[PRESTERA_FW_LOG_LIB_ALL] =  "all",
+	[PRESTERA_FW_LOG_LIB_BRIDGE] =  "bridge",
+	[PRESTERA_FW_LOG_LIB_CNC] =  "cnc",
+	[PRESTERA_FW_LOG_LIB_CONFIG] =  "config",
+	[PRESTERA_FW_LOG_LIB_COS] =  "cos",
+	[PRESTERA_FW_LOG_LIB_CSCD] =  "cscd",
+	[PRESTERA_FW_LOG_LIB_CUT_THROUGH] =  "cut-through",
+	[PRESTERA_FW_LOG_LIB_DIAG] =  "diag",
+	[PRESTERA_FW_LOG_LIB_DRAGONITE] =  "dragonite",
+	[PRESTERA_FW_LOG_LIB_EGRESS] =  "egress",
+	[PRESTERA_FW_LOG_LIB_EXACT_MATCH] =  "exact-match",
+	[PRESTERA_FW_LOG_LIB_FABRIC] =  "fabric",
+	[PRESTERA_FW_LOG_LIB_BRIDGE_FDB_MANAGER] =  "fdb-manager",
+	[PRESTERA_FW_LOG_LIB_FLOW_MANAGER] =  "flow-manager",
+	[PRESTERA_FW_LOG_LIB_HW_INIT] =  "hw-init",
+	[PRESTERA_FW_LOG_LIB_I2C] =  "i2c",
+	[PRESTERA_FW_LOG_LIB_INGRESS] =  "ingress",
+	[PRESTERA_FW_LOG_LIB_INIT] =  "init",
+	[PRESTERA_FW_LOG_LIB_IPFIX] =  "ipfix",
+	[PRESTERA_FW_LOG_LIB_IP] =  "ip",
+	[PRESTERA_FW_LOG_LIB_IP_LPM] =  "ip-lpm",
+	[PRESTERA_FW_LOG_LIB_L2_MLL] =  "l2-mll",
+	[PRESTERA_FW_LOG_LIB_LATENCY_MONITORING] =  "latency-monitoring",
+	[PRESTERA_FW_LOG_LIB_LOGICAL_TARGET] =  "logical-target",
+	[PRESTERA_FW_LOG_LIB_LPM] =  "lpm",
+	[PRESTERA_FW_LOG_LIB_MIRROR] =  "mirror",
+	[PRESTERA_FW_LOG_LIB_MULTI_PORT_GROUP] =  "multi-port-group",
+	[PRESTERA_FW_LOG_LIB_NETWORK_IF] =  "network-if",
+	[PRESTERA_FW_LOG_LIB_NST] =  "nst",
+	[PRESTERA_FW_LOG_LIB_OAM] =  "oam",
+	[PRESTERA_FW_LOG_LIB_PACKET_ANALYZER] =  "packet-analyzer",
+	[PRESTERA_FW_LOG_LIB_PCL] =  "pcl",
+	[PRESTERA_FW_LOG_LIB_PHA] =  "pha",
+	[PRESTERA_FW_LOG_LIB_PHY] =  "phy",
+	[PRESTERA_FW_LOG_LIB_POLICER] =  "policer",
+	[PRESTERA_FW_LOG_LIB_PROTECTION] =  "protection",
+	[PRESTERA_FW_LOG_LIB_PTP] =  "ptp",
+	[PRESTERA_FW_LOG_LIB_RESOURCE_MANAGER] =  "resource-manager",
+	[PRESTERA_FW_LOG_LIB_SMI] =  "smi",
+	[PRESTERA_FW_LOG_LIB_SYSTEM_RECOVERY] =  "system-recovery",
+	[PRESTERA_FW_LOG_LIB_TAM] =  "tam",
+	[PRESTERA_FW_LOG_LIB_TCAM] =  "tcam",
+	[PRESTERA_FW_LOG_LIB_TM] =  "tm",
+	[PRESTERA_FW_LOG_LIB_TM_GLUE] =  "tm-glue",
+	[PRESTERA_FW_LOG_LIB_TRUNK] =  "trunk",
+	[PRESTERA_FW_LOG_LIB_TTI] =  "tti",
+	[PRESTERA_FW_LOG_LIB_TUNNEL] =  "tunnel",
+	[PRESTERA_FW_LOG_LIB_VERSION] =  "version",
+	[PRESTERA_FW_LOG_LIB_VIRTUAL_TCAM] =  "virtual-tcam",
+	[PRESTERA_FW_LOG_LIB_VNT] =  "vnt",
+	[PRESTERA_FW_LOG_LIB_PPU] = "ppu",
+	[PRESTERA_FW_LOG_LIB_EXACT_MATCH_MANAGER] = "exact-match-manager",
+	[PRESTERA_FW_LOG_LIB_MAC_SEC] = "mac-sec",
+	[PRESTERA_FW_LOG_LIB_PTP_MANAGER] = "ptp-manager",
+	[PRESTERA_FW_LOG_LIB_HSR_PRP] = "hsr-prp",
+	[PRESTERA_FW_LOG_LIB_STREAM] = "stream",
+	[PRESTERA_FW_LOG_LIB_IPFIX_MANAGER] = "ipfix_manager",
+};
+
+static const char *mvsw_pr_fw_log_prv_type_id2name[PRESTERA_FW_LOG_TYPE_MAX] = {
+	[PRESTERA_FW_LOG_TYPE_INFO] = "info",
+	[PRESTERA_FW_LOG_TYPE_ENTRY_LEVEL_FUNCTION] = "entry-level-function",
+	[PRESTERA_FW_LOG_TYPE_ERROR] = "error",
+	[PRESTERA_FW_LOG_TYPE_ALL] = "all",
+	[PRESTERA_FW_LOG_TYPE_NONE]  = "none",
+};
+
+static void mvsw_pr_fw_log_evt_handler(struct prestera_switch *sw,
+				       struct prestera_event *evt, void *arg)
+{
+	u32 log_len = evt->fw_log_evt.log_len;
+	u8 *buf = evt->fw_log_evt.data;
+
+	buf[log_len] = '\0';
+
+	MVSW_FW_LOG_INFO(FW_LOG_PR_LOG_PREFIX "%s\n", buf);
+}
+
+static ssize_t mvsw_pr_fw_log_format_str(void)
+{
+	char *buf = fw_log_debugfs_handle.read_buf;
+	int chars_written = 0;
+	int lib, type;
+	int ret;
+
+	memset(buf, 0, FW_LOG_PR_READ_BUF_SIZE);
+
+	ret = snprintf(buf, FW_LOG_PR_READ_BUF_SIZE, FW_LOG_READ_TABLE_FMT,
+		       " ");
+	if (ret < 0)
+		return ret;
+
+	chars_written += ret;
+
+	for (type = 0; type < PRESTERA_FW_LOG_TYPE_MAX; ++type) {
+		if (type == PRESTERA_FW_LOG_TYPE_NONE ||
+		    type == PRESTERA_FW_LOG_TYPE_ALL)
+			continue;
+
+		ret = snprintf(buf + chars_written,
+			       FW_LOG_PR_READ_BUF_SIZE - chars_written,
+			       FW_LOG_READ_TABLE_FMT,
+			       mvsw_pr_fw_log_prv_type_id2name[type]);
+		if (ret < 0)
+			return ret;
+
+		chars_written += ret;
+	}
+
+	strcat(buf, "\n");
+	++chars_written;
+
+	for (lib = 0; lib < PRESTERA_FW_LOG_LIB_MAX; ++lib) {
+		if (lib == PRESTERA_FW_LOG_LIB_ALL ||
+		    !mvsw_pr_fw_log_lib_id2name[lib])
+			continue;
+
+		ret = snprintf(buf + chars_written,
+			       FW_LOG_PR_READ_BUF_SIZE - chars_written,
+			       FW_LOG_READ_TABLE_FMT,
+			       mvsw_pr_fw_log_lib_id2name[lib]);
+		if (ret < 0)
+			return ret;
+
+		chars_written += ret;
+
+		for (type = 0; type < PRESTERA_FW_LOG_TYPE_MAX; ++type) {
+			if (type == PRESTERA_FW_LOG_TYPE_NONE ||
+			    type == PRESTERA_FW_LOG_TYPE_ALL)
+				continue;
+
+			ret = snprintf(buf + chars_written,
+				       FW_LOG_PR_READ_BUF_SIZE - chars_written,
+				       FW_LOG_READ_TABLE_FMT,
+				       fw_log_lib_type_config[lib] & BIT(type)
+						? "+" : "-");
+			if (ret < 0)
+				return ret;
+
+			chars_written += ret;
+		}
+		strlcat(buf, "\n", FW_LOG_PR_READ_BUF_SIZE);
+		++chars_written;
+	}
+
+	return chars_written;
+}
+
+static ssize_t mvsw_pr_fw_log_debugfs_read(struct file *file,
+					   char __user *ubuf,
+					   size_t count, loff_t *ppos)
+{
+	char *buf = fw_log_debugfs_handle.read_buf;
+
+	return simple_read_from_buffer(ubuf, count, ppos, buf,
+				       FW_LOG_PR_READ_BUF_SIZE);
+}
+
+static int mvsw_pr_fw_log_parse_usr_input(int *name, int *type,
+					  const char __user *ubuf, size_t count)
+{
+	u8 tmp_buf[FW_LOG_DBGFS_MAX_STR_LEN] = { 0 };
+	u8 lib_str[FW_LOG_PR_LIB_SIZE] = { 0 };
+	u8 type_str[FW_LOG_PR_LIB_SIZE] = { 0 };
+	ssize_t len_to_copy = count - 1;
+	u8 *ppos_lib, *ppos_type;
+	char *end = tmp_buf;
+	int err;
+
+	if (len_to_copy > FW_LOG_DBGFS_MAX_STR_LEN) {
+		MVSW_LOG_ERROR("Len is > than max(%zu vs max possible %d)\n",
+			       count, FW_LOG_DBGFS_MAX_STR_LEN);
+		return -EMSGSIZE;
+	}
+
+	err = copy_from_user(tmp_buf, ubuf, len_to_copy);
+	if (err)
+		return -EINVAL;
+
+	ppos_lib  = strsep(&end, " \t");
+	ppos_type = strsep(&end, " \t\0");
+
+	if (!ppos_lib || !ppos_type)
+		return -EINVAL;
+
+	strcpy(lib_str, ppos_lib);
+
+	strcpy(type_str, ppos_type);
+
+	if (iscntrl(lib_str[0]) || isspace(lib_str[0]) || lib_str[0] == '\0' ||
+	    iscntrl(type_str[0]) || isspace(type_str[0]) ||
+	    type_str[0] == '\0') {
+		return -EINVAL;
+	}
+
+	*name = mvsw_pr_fw_log_get_lib_from_str(lib_str);
+	*type = mvsw_pr_fw_log_get_type_from_str(type_str);
+
+	if (*name >= PRESTERA_FW_LOG_LIB_MAX ||
+	    *type >= PRESTERA_FW_LOG_TYPE_MAX ||
+	    (*name != PRESTERA_FW_LOG_LIB_ALL &&
+	     *type == PRESTERA_FW_LOG_TYPE_NONE))
+		return -EINVAL;
+
+	return 0;
+}
+
+static ssize_t mvsw_pr_fw_log_debugfs_write(struct file *file,
+					    const char __user *ubuf,
+					    size_t count, loff_t *ppos)
+{
+	struct prestera_switch *sw = file->private_data;
+	int lib, type;
+	int i, j;
+	int err;
+
+	err = mvsw_pr_fw_log_parse_usr_input(&lib, &type, ubuf, count);
+	if (err)
+		goto error;
+
+	err = prestera_hw_fw_log_level_set(sw, lib, type);
+	if (err) {
+		dev_err(mvsw_dev(sw), "Failed to send request to firmware\n");
+		return err;
+	}
+
+	/* specific lib and specific type */
+	if (lib != PRESTERA_FW_LOG_LIB_ALL &&
+	    type != PRESTERA_FW_LOG_TYPE_ALL) {
+		/* special type 'NONE' to disable feature */
+		if (type == PRESTERA_FW_LOG_TYPE_NONE)
+			memset(fw_log_lib_type_config, 0,
+			       sizeof(fw_log_lib_type_config));
+		/* Actual type should be switched */
+		else
+			fw_log_lib_type_config[lib] ^= (1 << type);
+	/* specific lib but all types */
+	} else if (lib != PRESTERA_FW_LOG_LIB_ALL &&
+		   type == PRESTERA_FW_LOG_TYPE_ALL) {
+		for (j = 0; j < PRESTERA_FW_LOG_TYPE_ALL; ++j)
+			fw_log_lib_type_config[lib] ^= (1 << j);
+	/* specific type but all libs */
+	} else if (lib == PRESTERA_FW_LOG_LIB_ALL &&
+		   type != PRESTERA_FW_LOG_TYPE_ALL) {
+		for (i = 0; i < PRESTERA_FW_LOG_LIB_ALL; ++i)
+			fw_log_lib_type_config[i] |= (1 << type);
+	/* all libs and all types */
+	} else {
+		for (i = 0; i < PRESTERA_FW_LOG_LIB_ALL; ++i) {
+			for (j = 0; j < PRESTERA_FW_LOG_TYPE_ALL; ++j)
+				fw_log_lib_type_config[i] |= (1 << j);
+		}
+	}
+
+	err = mvsw_pr_fw_log_format_str();
+	if (err <= 0) {
+		dev_err(mvsw_dev(sw), "Failed to form output string\n");
+		return err;
+	}
+
+	return count;
+
+error:
+	dev_warn(mvsw_dev(sw),
+		 "Invalid str received, make sure request is valid\n");
+	dev_warn(mvsw_dev(sw),
+		 "Valid fmt consists of: \"lib type\" string, e.g:\n");
+	dev_warn(mvsw_dev(sw),
+		 "\"phy error\" for 'phy' lib 'error' logs enabled\n");
+
+	return err;
+}
+
+static inline int mvsw_pr_fw_log_get_type_from_str(const char *str)
+{
+	int i;
+
+	for (i = 0; i < PRESTERA_FW_LOG_TYPE_MAX; ++i) {
+		if (!mvsw_pr_fw_log_prv_type_id2name[i])
+			continue;
+
+		if (strcmp(mvsw_pr_fw_log_prv_type_id2name[i], str) == 0)
+			return i;
+	}
+
+	return PRESTERA_FW_LOG_TYPE_MAX;
+}
+
+static inline int mvsw_pr_fw_log_get_lib_from_str(const char *str)
+{
+	int i;
+
+	for (i = 0; i < PRESTERA_FW_LOG_LIB_MAX; ++i) {
+		if (!mvsw_pr_fw_log_lib_id2name[i])
+			continue;
+
+		if (strcmp(mvsw_pr_fw_log_lib_id2name[i], str) == 0)
+			return i;
+	}
+
+	return PRESTERA_FW_LOG_LIB_MAX;
+}
+
+static int mvsw_pr_fw_log_event_handler_register(struct prestera_switch *sw)
+{
+	return prestera_hw_event_handler_register(sw,
+						  PRESTERA_EVENT_TYPE_FW_LOG,
+						  mvsw_pr_fw_log_evt_handler,
+						  NULL);
+}
+
+static void mvsw_pr_fw_log_event_handler_unregister(struct prestera_switch *sw)
+{
+	prestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_FW_LOG);
+}
+
+int mvsw_pr_fw_log_init(struct prestera_switch *sw)
+{
+	fw_log_debugfs_handle.cfg_dir =
+		debugfs_create_dir(FW_LOG_DBGFS_CFG_DIR, NULL);
+
+	if (!fw_log_debugfs_handle.cfg_dir) {
+		MVSW_LOG_ERROR("Failed to create debugfs dir entry");
+		return -1;
+	}
+
+	fw_log_debugfs_handle.cfg =
+		debugfs_create_file(FW_LOG_DBGFS_CFG_NAME, 0644,
+				    fw_log_debugfs_handle.cfg_dir, sw,
+				    &fw_log_debugfs_handle.cfg_fops);
+
+	if (!fw_log_debugfs_handle.cfg) {
+		MVSW_LOG_ERROR("Failed to create debugfs dir entry");
+		debugfs_remove(fw_log_debugfs_handle.cfg_dir);
+		return -1;
+	}
+
+	if (mvsw_pr_fw_log_event_handler_register(sw))
+		goto error;
+
+	fw_log_debugfs_handle.read_buf =
+		kzalloc(FW_LOG_PR_READ_BUF_SIZE, GFP_KERNEL);
+
+	if (!fw_log_debugfs_handle.read_buf)
+		goto error;
+
+	prestera_hw_fw_log_level_set(sw, PRESTERA_FW_LOG_LIB_ALL,
+				     PRESTERA_FW_LOG_TYPE_NONE);
+	mvsw_pr_fw_log_format_str();
+
+	return 0;
+error:
+	debugfs_remove(fw_log_debugfs_handle.cfg);
+	debugfs_remove(fw_log_debugfs_handle.cfg_dir);
+	return -1;
+}
+
+void mvsw_pr_fw_log_fini(struct prestera_switch *sw)
+{
+	mvsw_pr_fw_log_event_handler_unregister(sw);
+
+	kfree(fw_log_debugfs_handle.read_buf);
+
+	debugfs_remove(fw_log_debugfs_handle.cfg);
+	debugfs_remove(fw_log_debugfs_handle.cfg_dir);
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
new file mode 100644
index 000000000000..ac5f64fb30e3
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
@@ -0,0 +1,12 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _MVSW_PRESTERA_FW_LOG_H_
+#define _MVSW_PRESTERA_FW_LOG_H_
+
+#include "prestera.h"
+
+int  mvsw_pr_fw_log_init(struct prestera_switch *sw);
+void mvsw_pr_fw_log_fini(struct prestera_switch *sw);
+
+#endif /* _MVSW_PRESTERA_FW_LOG_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_hw.c b/drivers/net/ethernet/marvell/prestera/prestera_hw.c
index c1297859e471..fac76765aa55 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_hw.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_hw.c
@@ -1,26 +1,42 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <linux/etherdevice.h>
-#include <linux/if_bridge.h>
 #include <linux/ethtool.h>
+#include <linux/netdevice.h>
 #include <linux/list.h>
+#include <net/dcbnl.h>
 
 #include "prestera.h"
 #include "prestera_hw.h"
 #include "prestera_acl.h"
+#include "prestera_log.h"
+#include "prestera_fw_log.h"
+#include "prestera_counter.h"
+#include "prestera_rxtx.h"
 
-#define PRESTERA_SWITCH_INIT_TIMEOUT_MS (30 * 1000)
+#define PRESTERA_HW_INIT_TIMEOUT 30000000	/* 30sec */
+#define PRESTERA_HW_MIN_MTU 64
 
-#define PRESTERA_MIN_MTU 64
+#ifndef PRESTERA_FW_WD_KICK_TIMEOUT
+#define PRESTERA_FW_WD_KICK_TIMEOUT		1000
+#endif /* PRESTERA_FW_WD_KICK_TIMEOUT */
+
+#ifndef PRESTERA_FW_KEEPALIVE_WD_MAX_KICKS
+#define PRESTERA_FW_KEEPALIVE_WD_MAX_KICKS	15
+#endif /* PRESTERA_FW_KEEPALIVE_WD_MAX_KICKS */
 
 enum prestera_cmd_type_t {
 	PRESTERA_CMD_TYPE_SWITCH_INIT = 0x1,
 	PRESTERA_CMD_TYPE_SWITCH_ATTR_SET = 0x2,
 
+	PRESTERA_CMD_TYPE_KEEPALIVE_INIT = 0x3,
+	PRESTERA_CMD_TYPE_SWITCH_RESET = 0x4,
+
 	PRESTERA_CMD_TYPE_PORT_ATTR_SET = 0x100,
 	PRESTERA_CMD_TYPE_PORT_ATTR_GET = 0x101,
 	PRESTERA_CMD_TYPE_PORT_INFO_GET = 0x110,
+	PRESTERA_CMD_TYPE_PORT_RATE_LIMIT_MODE_SET = 0x111,
 
 	PRESTERA_CMD_TYPE_VLAN_CREATE = 0x200,
 	PRESTERA_CMD_TYPE_VLAN_DELETE = 0x201,
@@ -32,34 +48,78 @@ enum prestera_cmd_type_t {
 	PRESTERA_CMD_TYPE_FDB_FLUSH_PORT = 0x310,
 	PRESTERA_CMD_TYPE_FDB_FLUSH_VLAN = 0x311,
 	PRESTERA_CMD_TYPE_FDB_FLUSH_PORT_VLAN = 0x312,
+	PRESTERA_CMD_TYPE_FDB_MACVLAN_ADD = 0x320,
+	PRESTERA_CMD_TYPE_FDB_MACVLAN_DEL = 0x321,
+
+	PRESTERA_CMD_TYPE_LOG_LEVEL_SET,
 
 	PRESTERA_CMD_TYPE_BRIDGE_CREATE = 0x400,
 	PRESTERA_CMD_TYPE_BRIDGE_DELETE = 0x401,
 	PRESTERA_CMD_TYPE_BRIDGE_PORT_ADD = 0x402,
 	PRESTERA_CMD_TYPE_BRIDGE_PORT_DELETE = 0x403,
 
-	PRESTERA_CMD_TYPE_ACL_RULE_ADD = 0x500,
-	PRESTERA_CMD_TYPE_ACL_RULE_DELETE = 0x501,
-	PRESTERA_CMD_TYPE_ACL_RULE_STATS_GET = 0x510,
-	PRESTERA_CMD_TYPE_ACL_RULESET_CREATE = 0x520,
-	PRESTERA_CMD_TYPE_ACL_RULESET_DELETE = 0x521,
-	PRESTERA_CMD_TYPE_ACL_PORT_BIND = 0x530,
-	PRESTERA_CMD_TYPE_ACL_PORT_UNBIND = 0x531,
+	PRESTERA_CMD_TYPE_COUNTER_GET = 0x510,
+	PRESTERA_CMD_TYPE_COUNTER_ABORT = 0x511,
+	PRESTERA_CMD_TYPE_COUNTER_TRIGGER = 0x512,
+	PRESTERA_CMD_TYPE_COUNTER_BLOCK_GET = 0x513,
+	PRESTERA_CMD_TYPE_COUNTER_BLOCK_RELEASE = 0x514,
+	PRESTERA_CMD_TYPE_COUNTER_CLEAR = 0x515,
+
+	PRESTERA_CMD_TYPE_VTCAM_CREATE = 0x540,
+	PRESTERA_CMD_TYPE_VTCAM_DESTROY = 0x541,
+	PRESTERA_CMD_TYPE_VTCAM_RULE_ADD = 0x550,
+	PRESTERA_CMD_TYPE_VTCAM_RULE_DELETE = 0x551,
+	PRESTERA_CMD_TYPE_VTCAM_IFACE_BIND = 0x560,
+	PRESTERA_CMD_TYPE_VTCAM_IFACE_UNBIND = 0x561,
+
+	PRESTERA_CMD_TYPE_ROUTER_RIF_CREATE = 0x600,
+	PRESTERA_CMD_TYPE_ROUTER_RIF_DELETE = 0x601,
+	PRESTERA_CMD_TYPE_ROUTER_RIF_SET = 0x602,
+	PRESTERA_CMD_TYPE_ROUTER_LPM_ADD = 0x610,
+	PRESTERA_CMD_TYPE_ROUTER_LPM_DELETE = 0x611,
+	PRESTERA_CMD_TYPE_ROUTER_NH_GRP_SET = 0x622,
+	PRESTERA_CMD_TYPE_ROUTER_NH_GRP_GET = 0x644,
+	PRESTERA_CMD_TYPE_ROUTER_NH_GRP_BLK_GET = 0x645,
+	PRESTERA_CMD_TYPE_ROUTER_NH_GRP_ADD = 0x623,
+	PRESTERA_CMD_TYPE_ROUTER_NH_GRP_DELETE = 0x624,
+	PRESTERA_CMD_TYPE_ROUTER_VR_CREATE = 0x630,
+	PRESTERA_CMD_TYPE_ROUTER_VR_DELETE = 0x631,
+	PRESTERA_CMD_TYPE_ROUTER_VR_ABORT = 0x632,
+	PRESTERA_CMD_TYPE_ROUTER_MP_HASH_SET = 0x650,
+
+	PRESTERA_CMD_TYPE_FLOOD_DOMAIN_CREATE = 0x700,
+	PRESTERA_CMD_TYPE_FLOOD_DOMAIN_DESTROY = 0x701,
+	PRESTERA_CMD_TYPE_FLOOD_DOMAIN_PORTS_SET = 0x702,
+	PRESTERA_CMD_TYPE_FLOOD_DOMAIN_PORTS_RESET = 0x703,
+
+	PRESTERA_CMD_TYPE_MDB_CREATE = 0x704,
+	PRESTERA_CMD_TYPE_MDB_DESTROY = 0x705,
 
 	PRESTERA_CMD_TYPE_RXTX_INIT = 0x800,
-	PRESTERA_CMD_TYPE_RXTX_PORT_INIT = 0x801,
 
-	PRESTERA_CMD_TYPE_LAG_MEMBER_ADD = 0x900,
-	PRESTERA_CMD_TYPE_LAG_MEMBER_DELETE = 0x901,
-	PRESTERA_CMD_TYPE_LAG_MEMBER_ENABLE = 0x902,
-	PRESTERA_CMD_TYPE_LAG_MEMBER_DISABLE = 0x903,
+	PRESTERA_CMD_TYPE_LAG_ADD = 0x900,
+	PRESTERA_CMD_TYPE_LAG_DELETE = 0x901,
+	PRESTERA_CMD_TYPE_LAG_ENABLE = 0x902,
+	PRESTERA_CMD_TYPE_LAG_DISABLE = 0x903,
+	PRESTERA_CMD_TYPE_LAG_ROUTER_LEAVE = 0x904,
 
 	PRESTERA_CMD_TYPE_STP_PORT_SET = 0x1000,
 
-	PRESTERA_CMD_TYPE_SPAN_GET = 0x1100,
-	PRESTERA_CMD_TYPE_SPAN_BIND = 0x1101,
-	PRESTERA_CMD_TYPE_SPAN_UNBIND = 0x1102,
-	PRESTERA_CMD_TYPE_SPAN_RELEASE = 0x1103,
+	PRESTERA_CMD_TYPE_SPAN_GET = 0X1100,
+	PRESTERA_CMD_TYPE_SPAN_BIND = 0X1101,
+	PRESTERA_CMD_TYPE_SPAN_UNBIND = 0X1102,
+	PRESTERA_CMD_TYPE_SPAN_RELEASE = 0X1103,
+
+	PRESTERA_CMD_TYPE_NAT_PORT_NEIGH_UPDATE = 0X1200,
+
+	PRESTERA_CMD_TYPE_NAT_NH_MANGLE_ADD = 0X1211,
+	PRESTERA_CMD_TYPE_NAT_NH_MANGLE_SET = 0X1212,
+	PRESTERA_CMD_TYPE_NAT_NH_MANGLE_DEL = 0X1213,
+	PRESTERA_CMD_TYPE_NAT_NH_MANGLE_GET = 0X1214,
+
+	PRESTERA_CMD_TYPE_QOS_DSCP_PRIO_MAP_UPDATE = 0X1301,
+	PRESTERA_CMD_TYPE_QOS_TRUST_MODE_SET = 0X1302,
+	PRESTERA_CMD_TYPE_QOS_DEFAULT_PRIO_SET = 0X1303,
 
 	PRESTERA_CMD_TYPE_CPU_CODE_COUNTERS_GET = 0x2000,
 
@@ -68,62 +128,46 @@ enum prestera_cmd_type_t {
 };
 
 enum {
-	PRESTERA_CMD_PORT_ATTR_ADMIN_STATE = 1,
 	PRESTERA_CMD_PORT_ATTR_MTU = 3,
 	PRESTERA_CMD_PORT_ATTR_MAC = 4,
-	PRESTERA_CMD_PORT_ATTR_SPEED = 5,
 	PRESTERA_CMD_PORT_ATTR_ACCEPT_FRAME_TYPE = 6,
 	PRESTERA_CMD_PORT_ATTR_LEARNING = 7,
 	PRESTERA_CMD_PORT_ATTR_FLOOD = 8,
 	PRESTERA_CMD_PORT_ATTR_CAPABILITY = 9,
-	PRESTERA_CMD_PORT_ATTR_REMOTE_CAPABILITY = 10,
-	PRESTERA_CMD_PORT_ATTR_REMOTE_FC = 11,
-	PRESTERA_CMD_PORT_ATTR_LINK_MODE = 12,
-	PRESTERA_CMD_PORT_ATTR_TYPE = 13,
-	PRESTERA_CMD_PORT_ATTR_FEC = 14,
-	PRESTERA_CMD_PORT_ATTR_AUTONEG = 15,
-	PRESTERA_CMD_PORT_ATTR_DUPLEX = 16,
+	PRESTERA_CMD_PORT_ATTR_PHY_MODE = 12,
 	PRESTERA_CMD_PORT_ATTR_STATS = 17,
-	PRESTERA_CMD_PORT_ATTR_MDIX = 18,
-	PRESTERA_CMD_PORT_ATTR_AUTONEG_RESTART = 19,
+	PRESTERA_CMD_PORT_ATTR_MAC_AUTONEG_RESTART = 18,
+	PRESTERA_CMD_PORT_ATTR_PHY_AUTONEG_RESTART = 19,
+	PRESTERA_CMD_PORT_ATTR_SOURCE_ID_DEFAULT = 20,
+	PRESTERA_CMD_PORT_ATTR_SOURCE_ID_FILTER = 21,
+	PRESTERA_CMD_PORT_ATTR_MAC_MODE = 22,
+	PRESTERA_CMD_PORT_ATTR_MAX
 };
 
 enum {
 	PRESTERA_CMD_SWITCH_ATTR_MAC = 1,
 	PRESTERA_CMD_SWITCH_ATTR_AGEING = 2,
+	PRESTERA_CMD_SWITCH_ATTR_TRAP_POLICER = 3,
 };
 
 enum {
 	PRESTERA_CMD_ACK_OK,
 	PRESTERA_CMD_ACK_FAILED,
-
 	PRESTERA_CMD_ACK_MAX
 };
 
-enum {
-	PRESTERA_PORT_TP_NA,
-	PRESTERA_PORT_TP_MDI,
-	PRESTERA_PORT_TP_MDIX,
-	PRESTERA_PORT_TP_AUTO,
-};
-
-enum {
-	PRESTERA_PORT_FLOOD_TYPE_UC = 0,
-	PRESTERA_PORT_FLOOD_TYPE_MC = 1,
-};
-
 enum {
 	PRESTERA_PORT_GOOD_OCTETS_RCV_CNT,
 	PRESTERA_PORT_BAD_OCTETS_RCV_CNT,
 	PRESTERA_PORT_MAC_TRANSMIT_ERR_CNT,
 	PRESTERA_PORT_BRDC_PKTS_RCV_CNT,
 	PRESTERA_PORT_MC_PKTS_RCV_CNT,
-	PRESTERA_PORT_PKTS_64L_CNT,
-	PRESTERA_PORT_PKTS_65TO127L_CNT,
-	PRESTERA_PORT_PKTS_128TO255L_CNT,
-	PRESTERA_PORT_PKTS_256TO511L_CNT,
-	PRESTERA_PORT_PKTS_512TO1023L_CNT,
-	PRESTERA_PORT_PKTS_1024TOMAXL_CNT,
+	PRESTERA_PORT_PKTS_64_OCTETS_CNT,
+	PRESTERA_PORT_PKTS_65TO127_OCTETS_CNT,
+	PRESTERA_PORT_PKTS_128TO255_OCTETS_CNT,
+	PRESTERA_PORT_PKTS_256TO511_OCTETS_CNT,
+	PRESTERA_PORT_PKTS_512TO1023_OCTETS_CNT,
+	PRESTERA_PORT_PKTS_1024TOMAX_OCTETS_CNT,
 	PRESTERA_PORT_EXCESSIVE_COLLISIONS_CNT,
 	PRESTERA_PORT_MC_PKTS_SENT_CNT,
 	PRESTERA_PORT_BRDC_PKTS_SENT_CNT,
@@ -143,8 +187,7 @@ enum {
 	PRESTERA_PORT_MULTIPLE_PKTS_SENT_CNT,
 	PRESTERA_PORT_DEFERRED_PKTS_SENT_CNT,
 	PRESTERA_PORT_GOOD_OCTETS_SENT_CNT,
-
-	PRESTERA_PORT_CNT_MAX
+	PRESTERA_PORT_CNT_MAX,
 };
 
 enum {
@@ -154,27 +197,38 @@ enum {
 	PRESTERA_FC_SYMM_ASYMM,
 };
 
+enum {
+	PRESTERA_PORT_TP_NA,
+	PRESTERA_PORT_TP_MDI,
+	PRESTERA_PORT_TP_MDIX,
+	PRESTERA_PORT_TP_AUTO
+};
+
 enum {
 	PRESTERA_HW_FDB_ENTRY_TYPE_REG_PORT = 0,
 	PRESTERA_HW_FDB_ENTRY_TYPE_LAG = 1,
 	PRESTERA_HW_FDB_ENTRY_TYPE_MAX = 2,
 };
 
-struct prestera_fw_event_handler {
-	struct list_head list;
-	struct rcu_head rcu;
-	enum prestera_event_type type;
-	prestera_event_cb_t func;
-	void *arg;
+enum {
+	PRESTERA_PORT_FLOOD_TYPE_UC = 0,
+	PRESTERA_PORT_FLOOD_TYPE_MC = 1,
+	PRESTERA_PORT_FLOOD_TYPE_BC = 2,
+};
+
+enum {
+	PRESTERA_HW_FLOOD_DOMAIN_PORT_TYPE_REG_PORT = 0,
+	PRESTERA_HW_FLOOD_DOMAIN_PORT_TYPE_LAG = 1,
+	PRESTERA_HW_FLOOD_DOMAIN_PORT_TYPE_MAX = 2,
 };
 
 struct prestera_msg_cmd {
-	u32 type;
+	__le32 type;
 };
 
 struct prestera_msg_ret {
 	struct prestera_msg_cmd cmd;
-	u32 status;
+	__le32 status;
 };
 
 struct prestera_msg_common_req {
@@ -185,74 +239,115 @@ struct prestera_msg_common_resp {
 	struct prestera_msg_ret ret;
 };
 
-union prestera_msg_switch_param {
-	u8 mac[ETH_ALEN];
-	u32 ageing_timeout_ms;
-};
-
 struct prestera_msg_switch_attr_req {
 	struct prestera_msg_cmd cmd;
-	u32 attr;
-	union prestera_msg_switch_param param;
+	__le32 attr;
+	union {
+		__le32 ageing_timeout_ms;
+		__le32 trap_policer_profile;
+		struct {
+			u8 mac[ETH_ALEN];
+			u8 __pad[2];
+		};
+	} param;
 };
 
 struct prestera_msg_switch_init_resp {
 	struct prestera_msg_ret ret;
-	u32 port_count;
-	u32 mtu_max;
-	u8  switch_id;
-	u8  lag_max;
-	u8  lag_member_max;
+	__le32 port_count;
+	__le32 mtu_max;
+	__le32 size_tbl_router_nexthop;
+	u8 switch_id;
+	u8 lag_max;
+	u8 lag_member_max;
 };
 
-struct prestera_msg_port_autoneg_param {
-	u64 link_mode;
-	u8  enable;
-	u8  fec;
+struct prestera_msg_event_port_param {
+	union {
+		struct {
+			__le32 mode;
+			__le32 speed;
+			u8 oper;
+			u8 duplex;
+			u8 fc;
+			u8 fec;
+		} __packed mac; /* make sure always 12 bytes size */
+		struct {
+			__le64 lmode_bmap;
+			u8 mdix;
+			u8 fc;
+			u8 __pad[2];
+		} __packed phy; /* make sure always 12 bytes size */
+	};
 };
 
 struct prestera_msg_port_cap_param {
-	u64 link_mode;
+	__le64 link_mode;
 	u8  type;
 	u8  fec;
+	u8  fc;
 	u8  transceiver;
 };
 
-struct prestera_msg_port_mdix_param {
-	u8 status;
-	u8 admin_mode;
-};
-
 struct prestera_msg_port_flood_param {
 	u8 type;
 	u8 enable;
+	u8 __pad[2];
 };
 
 union prestera_msg_port_param {
-	u8  admin_state;
-	u8  oper_state;
-	u32 mtu;
-	u8  mac[ETH_ALEN];
-	u8  accept_frm_type;
-	u32 speed;
+	__le32 source_id_default;
+	__le32 source_id_filter;
+	__le32 mtu;
+	u8 oper_state;
+	u8 mac[ETH_ALEN];
+	u8 accept_frm_type;
 	u8 learning;
-	u8 flood;
-	u32 link_mode;
-	u8  type;
-	u8  duplex;
-	u8  fec;
-	u8  fc;
-	struct prestera_msg_port_mdix_param mdix;
-	struct prestera_msg_port_autoneg_param autoneg;
+	u8 type;
+	union {
+		struct {
+			u8 admin;
+			u8 fc;
+			u8 ap_enable;
+			u8 __reserved[5];
+			union {
+				struct {
+					__le32 mode;
+					__le32 speed;
+					u8 inband;
+					u8 duplex;
+					u8 fec;
+					u8 fec_supp;
+				} reg_mode;
+				struct {
+					__le32 mode;
+					__le32 speed;
+					u8 fec;
+					u8 fec_supp;
+					u8 __pad[2];
+				} ap_modes[PRESTERA_AP_PORT_MAX];
+			};
+		} mac;
+		struct {
+			__le64 modes;
+			__le32 mode;
+			u8 admin;
+			u8 adv_enable;
+			u8 mdix;
+			u8 __pad;
+		} phy;
+	} link;
+
 	struct prestera_msg_port_cap_param cap;
 	struct prestera_msg_port_flood_param flood_ext;
+	struct prestera_msg_event_port_param link_evt;
 };
 
 struct prestera_msg_port_attr_req {
 	struct prestera_msg_cmd cmd;
-	u32 attr;
-	u32 port;
-	u32 dev;
+	__le32 attr;
+	__le32 port;
+	__le32 dev;
 	union prestera_msg_port_param param;
 };
 
@@ -263,300 +358,737 @@ struct prestera_msg_port_attr_resp {
 
 struct prestera_msg_port_stats_resp {
 	struct prestera_msg_ret ret;
-	u64 stats[PRESTERA_PORT_CNT_MAX];
+	__le64 stats[PRESTERA_PORT_CNT_MAX];
 };
 
 struct prestera_msg_port_info_req {
 	struct prestera_msg_cmd cmd;
-	u32 port;
+	__le32 port;
 };
 
 struct prestera_msg_port_info_resp {
 	struct prestera_msg_ret ret;
-	u32 hw_id;
-	u32 dev_id;
-	u16 fp_id;
+	__le32 hw_id;
+	__le32 dev_id;
+	__le16 fp_id;
+	u8 pad[2];
+};
+
+struct prestera_msg_port_storm_control_cfg_set_req {
+	struct prestera_msg_cmd cmd;
+	__le32 port;
+	__le32 dev;
+	__le32 storm_type;
+	__le32 kbyte_per_sec_rate;
 };
 
 struct prestera_msg_vlan_req {
 	struct prestera_msg_cmd cmd;
-	u32 port;
-	u32 dev;
-	u16 vid;
+	__le32 port;
+	__le32 dev;
+	__le16 vid;
 	u8  is_member;
 	u8  is_tagged;
 };
 
 struct prestera_msg_fdb_req {
 	struct prestera_msg_cmd cmd;
-	u8 dest_type;
+	__le32 flush_mode;
 	union {
 		struct {
-			u32 port;
-			u32 dev;
+			__le32 port;
+			__le32 dev;
 		};
-		u16 lag_id;
+		__le16 lag_id;
 	} dest;
-	u8  mac[ETH_ALEN];
-	u16 vid;
-	u8  dynamic;
-	u32 flush_mode;
+	__le16 vid;
+	u8 dest_type;
+	u8 dynamic;
+	u8 mac[ETH_ALEN];
+	u8 __pad[2];
 };
 
-struct prestera_msg_bridge_req {
+struct prestera_msg_log_lvl_set_req {
 	struct prestera_msg_cmd cmd;
-	u32 port;
-	u32 dev;
-	u16 bridge;
+	__le32 lib;
+	__le32 type;
 };
 
-struct prestera_msg_bridge_resp {
-	struct prestera_msg_ret ret;
-	u16 bridge;
+struct prestera_msg_iface {
+	union {
+		struct {
+			__le32 dev;
+			__le32 port;
+		};
+		__le16 lag_id;
+	};
+	__le16 vr_id;
+	__le16 vid;
+	u8 type;
+	u8 pad[3];
 };
 
-struct prestera_msg_acl_action {
-	u32 id;
+struct prestera_msg_ip_addr {
+	union {
+		__be32 ipv6[4];
+		__be32 ipv4;
+	} u;
+	u8 v; /* e.g. PRESTERA_IPV4 */
+	u8 pad[3];
+};
+
+struct prestera_msg_nh {
+	struct prestera_msg_iface oif;
+	__le32 hw_id;
+	u8 mac[ETH_ALEN];
+	u8 is_active;
+	u8 pad;
+};
+
+struct prestera_msg_nh_mangle_info {
+	struct prestera_msg_nh nh;
+	__be32 sip;
+	__be32 dip;
+	__be16 l4_src;
+	__be16 l4_dst;
+	u8 l4_src_valid:1;
+	u8 l4_dst_valid:1;
+	u8 sip_valid:1;
+	u8 dip_valid:1;
+	u8 pad[3];
+};
+
+struct prestera_msg_nh_mangle_req {
+	struct prestera_msg_cmd cmd;
+	struct prestera_msg_nh_mangle_info info;
+	__le32 nh_id;
+};
+
+struct prestera_msg_nh_mangle_resp {
+	struct prestera_msg_ret ret;
+	struct prestera_msg_nh_mangle_info info;
+	__le32 nh_id;
 };
 
-struct prestera_msg_acl_match {
-	u32 type;
+struct prestera_msg_acl_action {
+	__le32 id;
+	__le32 __reserved;
 	union {
 		struct {
-			u8 key;
-			u8 mask;
-		} u8;
+			u8 hw_tc;
+		} trap;
 		struct {
-			u16 key;
-			u16 mask;
-		} u16;
+			__le64 rate;
+			__le64 burst;
+		} police;
 		struct {
-			u32 key;
-			u32 mask;
-		} u32;
+			__le32 nh_id;
+		} nh;
 		struct {
-			u64 key;
-			u64 mask;
-		} u64;
+			__be32 old_addr;
+			__be32 new_addr;
+			__le32 port;
+			__le32 dev;
+			__le32 flags;
+			__le32 __pad;
+		} nat;
 		struct {
-			u8 key[ETH_ALEN];
-			u8 mask[ETH_ALEN];
-		} mac;
-	} __packed keymask;
+			__le32 index;
+		} jump;
+		struct {
+			__le32 id;
+		} count;
+	};
 };
 
-struct prestera_msg_acl_rule_req {
+struct prestera_msg_vtcam_create_req {
 	struct prestera_msg_cmd cmd;
-	u32 id;
-	u32 priority;
-	u16 ruleset_id;
-	u8 n_actions;
-	u8 n_matches;
+	__le32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	u8 direction;
+	u8 lookup;
+	u8 pad[2];
 };
 
-struct prestera_msg_acl_rule_resp {
-	struct prestera_msg_ret ret;
-	u32 id;
+struct prestera_msg_vtcam_destroy_req {
+	struct prestera_msg_cmd cmd;
+	__le32 vtcam_id;
 };
 
-struct prestera_msg_acl_rule_stats_resp {
-	struct prestera_msg_ret ret;
-	u64 packets;
-	u64 bytes;
+struct prestera_msg_vtcam_rule_add_req {
+	struct prestera_msg_cmd cmd;
+	__le32 key[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	__le32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	__le32 vtcam_id;
+	__le32 prio;
+	__le32 n_act;
 };
 
-struct prestera_msg_acl_ruleset_bind_req {
+struct prestera_msg_vtcam_rule_del_req {
 	struct prestera_msg_cmd cmd;
-	u32 port;
-	u32 dev;
-	u16 ruleset_id;
+	__le32 vtcam_id;
+	__le32 id;
+};
+
+struct prestera_msg_vtcam_bind_req {
+	struct prestera_msg_cmd cmd;
+	union {
+		struct {
+			__le32 hw_id;
+			__le32 dev_id;
+		} port;
+		__le32 index;
+	};
+	__le32 vtcam_id;
+	__le16 pcl_id;
+	__le16 type;
+};
+
+struct prestera_msg_vtcam_resp {
+	struct prestera_msg_ret ret;
+	__le32 vtcam_id;
+	__le32 rule_id;
 };
 
-struct prestera_msg_acl_ruleset_req {
+struct prestera_msg_counter_req {
 	struct prestera_msg_cmd cmd;
-	u16 id;
+	__le32 client;
+	__le32 block_id;
+	__le32 num_counters;
+};
+
+struct prestera_msg_counter_stats {
+	__le64 packets;
+	__le64 bytes;
 };
 
-struct prestera_msg_acl_ruleset_resp {
+struct prestera_msg_counter_resp {
 	struct prestera_msg_ret ret;
-	u16 id;
+	__le32 block_id;
+	__le32 offset;
+	__le32 num_counters;
+	__le32 done;
+	struct prestera_msg_counter_stats stats[0];
+};
+
+struct prestera_msg_nat_port_req {
+	struct prestera_msg_cmd cmd;
+	__le32 port;
+	__le32 dev;
+	u8 neigh_mac[ETH_ALEN];
+	u8 __pad[2];
 };
 
 struct prestera_msg_span_req {
 	struct prestera_msg_cmd cmd;
-	u32 port;
-	u32 dev;
+	__le32 port;
+	__le32 dev;
 	u8 id;
-} __packed __aligned(4);
+	u8 pad[3];
+};
 
 struct prestera_msg_span_resp {
 	struct prestera_msg_ret ret;
 	u8 id;
-} __packed __aligned(4);
+	u8 pad[3];
+};
+
+struct prestera_msg_event {
+	__le16 type;
+	__le16 id;
+};
+
+struct prestera_msg_event_log {
+	struct prestera_msg_event id;
+	__le32 log_string_size;
+	u8 log_string[0];
+};
+
+union prestera_msg_event_fdb_param {
+	u8 mac[ETH_ALEN];
+};
+
+struct prestera_msg_event_fdb {
+	struct prestera_msg_event id;
+	__le32 vid;
+	union {
+		__le32 port_id;
+		__le16 lag_id;
+	} dest;
+	union prestera_msg_event_fdb_param param;
+	u8 dest_type;
+};
+
+struct prestera_msg_event_port {
+	struct prestera_msg_event id;
+	__le32 port_id;
+	struct prestera_msg_event_port_param param;
+};
+
+struct prestera_msg_bridge_req {
+	struct prestera_msg_cmd cmd;
+	__le32 port;
+	__le32 dev;
+	__le16 bridge;
+	u8 pad[2];
+};
+
+struct prestera_msg_bridge_resp {
+	struct prestera_msg_ret ret;
+	__le16 bridge;
+	u8 pad[2];
+};
+
+struct prestera_msg_macvlan_req {
+	struct prestera_msg_cmd cmd;
+	__le16 vr_id;
+	__le16 vid;
+	u8 mac[ETH_ALEN];
+	u8 pad[2];
+};
 
 struct prestera_msg_stp_req {
 	struct prestera_msg_cmd cmd;
-	u32 port;
-	u32 dev;
-	u16 vid;
+	__le32 port;
+	__le32 dev;
+	__le16 vid;
 	u8  state;
+	u8 __pad;
+};
+
+struct prestera_msg_rif_req {
+	struct prestera_msg_cmd cmd;
+	struct prestera_msg_iface iif;
+	__le32 mtu;
+	__le16 rif_id;
+	__le16 __reserved;
+	u8 mac[ETH_ALEN];
+	u8 __pad[2];
+};
+
+struct prestera_msg_rif_resp {
+	struct prestera_msg_ret ret;
+	__le16 rif_id;
+	__le16 __pad;
+};
+
+struct prestera_msg_lpm_req {
+	struct prestera_msg_cmd cmd;
+	struct prestera_msg_ip_addr dst;
+	__le32 grp_id;
+	__le32 dst_len;
+	__le16 vr_id;
+	__le16 __pad;
+};
+
+struct prestera_msg_nh_req {
+	struct prestera_msg_cmd cmd;
+	struct prestera_msg_nh nh[PRESTERA_NHGR_SIZE_MAX];
+	__le32 size;
+	__le32 grp_id;
+};
+
+struct prestera_msg_nh_resp {
+	struct prestera_msg_ret ret;
+	struct prestera_msg_nh nh[PRESTERA_NHGR_SIZE_MAX];
+};
+
+struct prestera_msg_nh_chunk_req {
+	struct prestera_msg_cmd cmd;
+	__le32 offset;
+};
+
+struct prestera_msg_nh_chunk_resp {
+	struct prestera_msg_ret ret;
+	u8 hw_state[PRESTERA_MSG_CHUNK_SIZE];
+};
+
+struct prestera_msg_nh_grp_req {
+	struct prestera_msg_cmd cmd;
+	__le32 grp_id;
+	__le32 size;
+};
+
+struct prestera_msg_nh_grp_resp {
+	struct prestera_msg_ret ret;
+	__le32 grp_id;
+};
+
+struct prestera_msg_mp_req {
+	struct prestera_msg_cmd cmd;
+	u8 hash_policy;
+	u8 __pad[3];
 };
 
 struct prestera_msg_rxtx_req {
 	struct prestera_msg_cmd cmd;
 	u8 use_sdma;
+	u8 pad[3];
 };
 
 struct prestera_msg_rxtx_resp {
 	struct prestera_msg_ret ret;
-	u32 map_addr;
+	__le32 map_addr;
 };
 
-struct prestera_msg_rxtx_port_req {
+struct prestera_msg_vr_req {
 	struct prestera_msg_cmd cmd;
-	u32 port;
-	u32 dev;
+	__le16 vr_id;
+	__le16 __pad;
+};
+
+struct prestera_msg_vr_resp {
+	struct prestera_msg_ret ret;
+	__le16 vr_id;
+	__le16 __pad;
 };
 
 struct prestera_msg_lag_req {
 	struct prestera_msg_cmd cmd;
-	u32 port;
-	u32 dev;
-	u16 lag_id;
+	__le32 port;
+	__le32 dev;
+	__le16 lag_id;
+	__le16 vr_id;
+};
+
+struct prestera_msg_keepalive_init_req {
+	struct prestera_msg_cmd cmd;
+	__le32 pulse_timeout_ms;
 };
 
 struct prestera_msg_cpu_code_counter_req {
 	struct prestera_msg_cmd cmd;
 	u8 counter_type;
 	u8 code;
+	u8 pad[2];
 };
 
-struct mvsw_msg_cpu_code_counter_ret {
+struct prestera_msg_cpu_code_counter_resp {
 	struct prestera_msg_ret ret;
-	u64 packet_count;
+	__le64 packet_count;
 };
 
-struct prestera_msg_event {
-	u16 type;
-	u16 id;
+struct prestera_msg_flood_domain_create_req {
+	struct prestera_msg_cmd cmd;
 };
 
-union prestera_msg_event_port_param {
-	u32 oper_state;
+struct prestera_msg_flood_domain_create_resp {
+	struct prestera_msg_ret ret;
+	__le32 flood_domain_idx;
 };
 
-struct prestera_msg_event_port {
-	struct prestera_msg_event id;
-	u32 port_id;
-	union prestera_msg_event_port_param param;
+struct prestera_msg_flood_domain_destroy_req {
+	struct prestera_msg_cmd cmd;
+	__le32 flood_domain_idx;
 };
 
-union prestera_msg_event_fdb_param {
-	u8 mac[ETH_ALEN];
+struct prestera_msg_flood_domain_ports_set_req {
+	struct prestera_msg_cmd cmd;
+	__le32 flood_domain_idx;
+	__le32 ports_num;
 };
 
-struct prestera_msg_event_fdb {
-	struct prestera_msg_event id;
-	u8 dest_type;
-	union {
-		u32 port_id;
-		u16 lag_id;
-	} dest;
-	u32 vid;
-	union prestera_msg_event_fdb_param param;
+struct prestera_msg_flood_domain_ports_reset_req {
+	struct prestera_msg_cmd cmd;
+	__le32 flood_domain_idx;
 };
 
-static int __prestera_cmd_ret(struct prestera_switch *sw,
-			      enum prestera_cmd_type_t type,
-			      struct prestera_msg_cmd *cmd, size_t clen,
-			      struct prestera_msg_ret *ret, size_t rlen,
-			      int waitms)
-{
-	struct prestera_device *dev = sw->dev;
-	int err;
+struct prestera_msg_flood_domain_port {
+	union {
+		struct {
+			__le32 port_num;
+			__le32 dev_num;
+		};
+		__le16 lag_id;
+	};
+	__le16 vid;
+	__le16 port_type;
+};
 
-	cmd->type = type;
+struct prestera_msg_mdb_create_req {
+	struct prestera_msg_cmd cmd;
+	__le32 flood_domain_idx;
+	__le16 vid;
+	u8 mac[ETH_ALEN];
+};
 
-	err = dev->send_req(dev, cmd, clen, ret, rlen, waitms);
-	if (err)
-		return err;
+struct prestera_msg_mdb_destroy_req {
+	struct prestera_msg_cmd cmd;
+	__le32 flood_domain_idx;
+	__le16 vid;
+	u8 mac[ETH_ALEN];
+};
 
-	if (ret->cmd.type != PRESTERA_CMD_TYPE_ACK)
-		return -EBADE;
-	if (ret->status != PRESTERA_CMD_ACK_OK)
-		return -EINVAL;
+struct prestera_msg_qos_req {
+	struct prestera_msg_cmd cmd;
+	u32 port;
+	u32 dev;
+	u32 priority;
+	u32 mode;
+	u8  dscp[64];
+};
 
-	return 0;
+static void prestera_hw_build_tests(void)
+{
+	/* check requests */
+	BUILD_BUG_ON(sizeof(struct prestera_msg_common_req) != 4);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_switch_attr_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_port_attr_req) != 144);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_port_info_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vlan_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_fdb_req) != 28);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_bridge_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_span_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_stp_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_rxtx_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_lag_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_cpu_code_counter_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vtcam_create_req) != 84);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vtcam_destroy_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vtcam_rule_add_req) != 168);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vtcam_rule_del_req) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vtcam_bind_req) != 20);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_counter_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_counter_stats) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_mangle_req) != 52);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nat_port_req) != 20);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_macvlan_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_rif_req) != 36);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_lpm_req) != 36);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_req) != 124);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_chunk_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_grp_req) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_mp_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vr_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_keepalive_init_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_flood_domain_create_req) != 4);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_flood_domain_destroy_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_flood_domain_ports_set_req) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_flood_domain_ports_reset_req) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_mdb_create_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_mdb_destroy_req) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_qos_req) != 84);
+
+	/* structure that are part of req/resp fw messages */
+	BUILD_BUG_ON(sizeof(struct prestera_msg_acl_action) != 32);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_iface) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_ip_addr) != 20);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh) != 28);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_mangle_info) != 44);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_flood_domain_port) != 12);
+
+	/* check responses */
+	BUILD_BUG_ON(sizeof(struct prestera_msg_common_resp) != 8);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_switch_init_resp) != 24);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_port_attr_resp) != 136);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_port_stats_resp) != 248);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_port_info_resp) != 20);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_bridge_resp) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_span_resp) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_rxtx_resp) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vtcam_resp) != 16);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_counter_resp) != 24);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_mangle_resp) != 56);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_rif_resp) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_resp) != 120);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_chunk_resp) != 1032);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_nh_grp_resp) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_vr_resp) != 12);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_flood_domain_create_resp) != 12);
+
+	/* check events */
+	BUILD_BUG_ON(sizeof(struct prestera_msg_event_port) != 20);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_event_fdb) != 20);
+	BUILD_BUG_ON(sizeof(struct prestera_msg_event_log) != 8);
+}
+
+static void fw_reset_wdog(struct prestera_device *dev);
+
+static int prestera_cmd_qid_by_req_type(enum prestera_cmd_type_t type)
+{
+	switch (type) {
+	case PRESTERA_CMD_TYPE_COUNTER_GET:
+	case PRESTERA_CMD_TYPE_COUNTER_ABORT:
+	case PRESTERA_CMD_TYPE_COUNTER_TRIGGER:
+	case PRESTERA_CMD_TYPE_COUNTER_BLOCK_GET:
+	case PRESTERA_CMD_TYPE_COUNTER_BLOCK_RELEASE:
+	case PRESTERA_CMD_TYPE_COUNTER_CLEAR:
+		return 1;
+	default:
+		return 0;
+	}
 }
 
-static int prestera_cmd_ret(struct prestera_switch *sw,
-			    enum prestera_cmd_type_t type,
-			    struct prestera_msg_cmd *cmd, size_t clen,
-			    struct prestera_msg_ret *ret, size_t rlen)
-{
-	return __prestera_cmd_ret(sw, type, cmd, clen, ret, rlen, 0);
-}
+#define fw_check_resp(_response)							\
+({											\
+	int __er = 0;									\
+	typeof(_response) __r = (_response);						\
+	if (__r->ret.cmd.type != __cpu_to_le32((u32)PRESTERA_CMD_TYPE_ACK))		\
+		__er = -EBADE;								\
+	else if (__r->ret.status != __cpu_to_le32((u32)PRESTERA_CMD_ACK_OK))		\
+		__er = -EINVAL;								\
+	(__er);										\
+})
+
+#define __fw_send_req_resp(_switch, _type, _request, _req_size,	\
+_response, _resp_size, _wait)					\
+({								\
+	int __e;						\
+	typeof(_switch) __sw = (_switch);			\
+	typeof(_request) __req = (_request);			\
+	typeof(_response) __resp = (_response);			\
+	typeof(_type) __type = (_type);				\
+	__req->cmd.type = __cpu_to_le32(__type);			\
+	__e = __sw->dev->send_req(__sw->dev,			\
+	prestera_cmd_qid_by_req_type(__type),			\
+		(u8 *)__req, _req_size,				\
+		(u8 *)__resp, _resp_size,			\
+		_wait);						\
+	if (__e != -EBUSY && __e != -ENODEV)			\
+		fw_reset_wdog(_switch->dev);			\
+	if (!__e)						\
+		__e = fw_check_resp(__resp);			\
+	(__e);							\
+})
+
+#define fw_send_nreq_nresp(_sw, _t, _req, _req_size, _resp, _resp_size)	\
+	__fw_send_req_resp(_sw, _t, _req, _req_size, _resp, _resp_size, 0)
+
+#define fw_send_nreq_resp(_sw, _t, _req, _req_size, _resp)	\
+({								\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _req, _req_size,		\
+			    _res, sizeof(*_res), 0));		\
+})
+
+#define fw_send_req_resp(_sw, _t, _req, _resp)			\
+({								\
+	typeof(_req) _re = (_req);				\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _re, sizeof(*_re),		\
+			    _res, sizeof(*_res), 0));		\
+})
+
+#define fw_send_req_resp_wait(_sw, _t, _req, _resp, _wait)	\
+({								\
+	typeof(_req) _re = (_req);				\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _re, sizeof(*_re),		\
+			    _res, sizeof(*_res), _wait));	\
+})
+
+#define fw_send_req(_sw, _t, _req)	\
+({							\
+	struct prestera_msg_common_resp __re;		\
+	(fw_send_req_resp(_sw, _t, _req, &__re));	\
+})
 
-static int prestera_cmd_ret_wait(struct prestera_switch *sw,
-				 enum prestera_cmd_type_t type,
-				 struct prestera_msg_cmd *cmd, size_t clen,
-				 struct prestera_msg_ret *ret, size_t rlen,
-				 int waitms)
-{
-	return __prestera_cmd_ret(sw, type, cmd, clen, ret, rlen, waitms);
-}
+struct prestera_fw_event_handler {
+	struct list_head list;
+	enum prestera_event_type type;
+	void (*func)(struct prestera_switch *sw,
+		     struct prestera_event *evt,
+		     void *arg);
+	void *arg;
+};
 
-static int prestera_cmd(struct prestera_switch *sw,
-			enum prestera_cmd_type_t type,
-			struct prestera_msg_cmd *cmd, size_t clen)
-{
-	struct prestera_msg_common_resp resp;
+static void prestera_hw_remote_fc_to_eth(u8 fc, bool *pause, bool *asym_pause);
+static u8 prestera_hw_mdix_to_eth(u8 mode);
 
-	return prestera_cmd_ret(sw, type, cmd, clen, &resp.ret, sizeof(resp));
+static void prestera_fw_wdog_restart(struct prestera_device *dev)
+{
+	queue_delayed_work(system_long_wq,
+			   &dev->keepalive_wdog_work,
+			   msecs_to_jiffies(PRESTERA_FW_WD_KICK_TIMEOUT));
 }
 
-static int prestera_fw_parse_port_evt(void *msg, struct prestera_event *evt)
+static void prestera_fw_keepalive_wd_work_fn(struct work_struct *work)
 {
-	struct prestera_msg_event_port *hw_evt = msg;
+	struct delayed_work *dl_work =
+		container_of(work, struct delayed_work, work);
+	struct prestera_device *dev =
+		container_of(dl_work, struct prestera_device,
+			     keepalive_wdog_work);
 
-	if (evt->id != PRESTERA_PORT_EVENT_STATE_CHANGED)
-		return -EINVAL;
+	atomic_t *ctr = &dev->keepalive_wdog_counter;
 
-	evt->port_evt.data.oper_state = hw_evt->param.oper_state;
-	evt->port_evt.port_id = hw_evt->port_id;
+	if (atomic_add_unless(ctr, 1, PRESTERA_FW_KEEPALIVE_WD_MAX_KICKS)) {
+		prestera_fw_wdog_restart(dev);
+		return;
+	}
 
-	return 0;
+	pr_err("fw_keepalive_wdog: Fw is stuck and became non-operational\n");
+
+	dev->running = false;
 }
 
-static int prestera_fw_parse_fdb_evt(void *msg, struct prestera_event *evt)
+static int fw_parse_port_evt(u8 *msg, struct prestera_event *evt)
 {
-	struct prestera_msg_event_fdb *hw_evt = msg;
+	struct prestera_msg_event_port *hw_evt;
+
+	hw_evt = (struct prestera_msg_event_port *)msg;
+
+	evt->port_evt.port_id = __le32_to_cpu(hw_evt->port_id);
+
+	if (evt->id == PRESTERA_PORT_EVENT_MAC_STATE_CHANGED) {
+		evt->port_evt.data.mac.oper = hw_evt->param.mac.oper;
+		evt->port_evt.data.mac.mode = __le32_to_cpu(hw_evt->param.mac.mode);
+		evt->port_evt.data.mac.speed = __le32_to_cpu(hw_evt->param.mac.speed);
+		evt->port_evt.data.mac.duplex = hw_evt->param.mac.duplex;
+		evt->port_evt.data.mac.fc = hw_evt->param.mac.fc;
+		evt->port_evt.data.mac.fec = hw_evt->param.mac.fec;
+	} else {
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int fw_parse_fdb_evt(u8 *msg, struct prestera_event *evt)
+{
+	struct prestera_msg_event_fdb *hw_evt;
+
+	hw_evt = (struct prestera_msg_event_fdb *)msg;
 
 	switch (hw_evt->dest_type) {
 	case PRESTERA_HW_FDB_ENTRY_TYPE_REG_PORT:
 		evt->fdb_evt.type = PRESTERA_FDB_ENTRY_TYPE_REG_PORT;
-		evt->fdb_evt.dest.port_id = hw_evt->dest.port_id;
+		evt->fdb_evt.dest.port_id = __le32_to_cpu(hw_evt->dest.port_id);
 		break;
 	case PRESTERA_HW_FDB_ENTRY_TYPE_LAG:
 		evt->fdb_evt.type = PRESTERA_FDB_ENTRY_TYPE_LAG;
-		evt->fdb_evt.dest.lag_id = hw_evt->dest.lag_id;
+		evt->fdb_evt.dest.lag_id = __le16_to_cpu(hw_evt->dest.lag_id);
 		break;
 	default:
 		return -EINVAL;
 	}
 
-	evt->fdb_evt.vid = hw_evt->vid;
+	evt->fdb_evt.vid = __le32_to_cpu(hw_evt->vid);
+
+	memcpy(&evt->fdb_evt.data, &hw_evt->param, sizeof(u8) * ETH_ALEN);
+
+	return 0;
+}
+
+static int fw_parse_log_evt(u8 *msg, struct prestera_event *evt)
+{
+	struct prestera_msg_event_log *hw_evt;
+
+	hw_evt = (struct prestera_msg_event_log *)msg;
 
-	ether_addr_copy(evt->fdb_evt.data.mac, hw_evt->param.mac);
+	evt->fw_log_evt.log_len	= __le32_to_cpu(hw_evt->log_string_size);
+	evt->fw_log_evt.data	= hw_evt->log_string;
 
 	return 0;
 }
 
-static struct prestera_fw_evt_parser {
-	int (*func)(void *msg, struct prestera_event *evt);
-} fw_event_parsers[PRESTERA_EVENT_TYPE_MAX] = {
-	[PRESTERA_EVENT_TYPE_PORT] = { .func = prestera_fw_parse_port_evt },
-	[PRESTERA_EVENT_TYPE_FDB] = { .func = prestera_fw_parse_fdb_evt },
+struct prestera_fw_evt_parser {
+	int (*func)(u8 *msg, struct prestera_event *evt);
+};
+
+static struct prestera_fw_evt_parser fw_event_parsers[PRESTERA_EVENT_TYPE_MAX] = {
+	[PRESTERA_EVENT_TYPE_PORT] = {.func = fw_parse_port_evt},
+	[PRESTERA_EVENT_TYPE_FDB] = {.func = fw_parse_fdb_evt},
+	[PRESTERA_EVENT_TYPE_FW_LOG] = {.func = fw_parse_log_evt}
 };
 
 static struct prestera_fw_event_handler *
@@ -585,41 +1117,49 @@ static int prestera_find_event_handler(const struct prestera_switch *sw,
 	if (tmp)
 		*eh = *tmp;
 	else
-		err = -ENOENT;
+		err = -EEXIST;
 	rcu_read_unlock();
 
 	return err;
 }
 
-static int prestera_evt_recv(struct prestera_device *dev, void *buf, size_t size)
+static void fw_reset_wdog(struct prestera_device *dev)
 {
+	if (dev->running)
+		atomic_set(&dev->keepalive_wdog_counter, 0);
+}
+
+static int fw_event_recv(struct prestera_device *dev, u8 *buf, size_t size)
+{
+	struct prestera_msg_event *msg = (struct prestera_msg_event *)buf;
 	struct prestera_switch *sw = dev->priv;
-	struct prestera_msg_event *msg = buf;
 	struct prestera_fw_event_handler eh;
 	struct prestera_event evt;
+	u16 msg_type;
 	int err;
 
-	if (msg->type >= PRESTERA_EVENT_TYPE_MAX)
+	fw_reset_wdog(dev);
+	msg_type = __le16_to_cpu(msg->type);
+	if (msg_type >= PRESTERA_EVENT_TYPE_MAX)
 		return -EINVAL;
-	if (!fw_event_parsers[msg->type].func)
+	if (!fw_event_parsers[msg_type].func)
 		return -ENOENT;
 
-	err = prestera_find_event_handler(sw, msg->type, &eh);
-	if (err)
-		return err;
+	err = prestera_find_event_handler(sw, msg_type, &eh);
 
-	evt.id = msg->id;
+	if (err || !fw_event_parsers[msg_type].func)
+		return 0;
 
-	err = fw_event_parsers[msg->type].func(buf, &evt);
-	if (err)
-		return err;
+	evt.id = __le16_to_cpu(msg->id);
 
-	eh.func(sw, &evt, eh.arg);
+	err = fw_event_parsers[msg_type].func(buf, &evt);
+	if (!err)
+		eh.func(sw, &evt, eh.arg);
 
-	return 0;
+	return err;
 }
 
-static void prestera_pkt_recv(struct prestera_device *dev)
+static void fw_pkt_recv(struct prestera_device *dev)
 {
 	struct prestera_switch *sw = dev->priv;
 	struct prestera_fw_event_handler eh;
@@ -636,547 +1176,442 @@ static void prestera_pkt_recv(struct prestera_device *dev)
 }
 
 int prestera_hw_port_info_get(const struct prestera_port *port,
-			      u32 *dev_id, u32 *hw_id, u16 *fp_id)
+			      u16 *fp_id, u32 *hw_id, u32 *dev_id)
 {
+	struct prestera_msg_port_info_resp resp;
 	struct prestera_msg_port_info_req req = {
-		.port = port->id,
+		.port = __cpu_to_le32(port->id)
 	};
-	struct prestera_msg_port_info_resp resp;
 	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_INFO_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = fw_send_req_resp(port->sw, PRESTERA_CMD_TYPE_PORT_INFO_GET,
+			&req, &resp);
+
 	if (err)
 		return err;
 
-	*dev_id = resp.dev_id;
-	*hw_id = resp.hw_id;
-	*fp_id = resp.fp_id;
+	*hw_id = __le32_to_cpu(resp.hw_id);
+	*dev_id = __le32_to_cpu(resp.dev_id);
+	*fp_id = __le16_to_cpu(resp.fp_id);
 
 	return 0;
 }
 
-int prestera_hw_switch_mac_set(struct prestera_switch *sw, const char *mac)
-{
-	struct prestera_msg_switch_attr_req req = {
-		.attr = PRESTERA_CMD_SWITCH_ATTR_MAC,
-	};
-
-	ether_addr_copy(req.param.mac, mac);
-
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_SWITCH_ATTR_SET,
-			    &req.cmd, sizeof(req));
-}
-
 int prestera_hw_switch_init(struct prestera_switch *sw)
 {
+	struct prestera_msg_keepalive_init_req keepalive_init_req = {
+		.pulse_timeout_ms = __cpu_to_le32(PRESTERA_FW_WD_KICK_TIMEOUT)
+	};
 	struct prestera_msg_switch_init_resp resp;
 	struct prestera_msg_common_req req;
-	int err;
+	int err = 0;
 
 	INIT_LIST_HEAD(&sw->event_handlers);
 
-	err = prestera_cmd_ret_wait(sw, PRESTERA_CMD_TYPE_SWITCH_INIT,
-				    &req.cmd, sizeof(req),
-				    &resp.ret, sizeof(resp),
-				    PRESTERA_SWITCH_INIT_TIMEOUT_MS);
+	prestera_hw_build_tests();
+
+	err = fw_send_req_resp_wait(sw, PRESTERA_CMD_TYPE_SWITCH_INIT,
+				    &req, &resp, PRESTERA_HW_INIT_TIMEOUT);
 	if (err)
 		return err;
 
-	sw->dev->recv_msg = prestera_evt_recv;
-	sw->dev->recv_pkt = prestera_pkt_recv;
-	sw->port_count = resp.port_count;
-	sw->mtu_min = PRESTERA_MIN_MTU;
-	sw->mtu_max = resp.mtu_max;
 	sw->id = resp.switch_id;
-	sw->lag_member_max = resp.lag_member_max;
+	sw->port_count = __le32_to_cpu(resp.port_count);
+	sw->mtu_min = PRESTERA_HW_MIN_MTU;
+	sw->mtu_max = __le32_to_cpu(resp.mtu_max);
 	sw->lag_max = resp.lag_max;
+	sw->lag_member_max = resp.lag_member_max;
+	sw->size_tbl_router_nexthop = __le32_to_cpu(resp.size_tbl_router_nexthop);
+	sw->dev->recv_msg = fw_event_recv;
+	sw->dev->recv_pkt = fw_pkt_recv;
 
-	return 0;
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_KEEPALIVE_INIT,
+			       &keepalive_init_req, &resp);
+	if (err)
+		return err;
+
+	INIT_DELAYED_WORK(&sw->dev->keepalive_wdog_work,
+			  prestera_fw_keepalive_wd_work_fn);
+
+	prestera_fw_wdog_restart(sw->dev);
+
+	return err;
 }
 
-void prestera_hw_switch_fini(struct prestera_switch *sw)
+void prestera_hw_keepalive_fini(const struct prestera_switch *sw)
 {
-	WARN_ON(!list_empty(&sw->event_handlers));
+	if (sw->dev->running)
+		cancel_delayed_work_sync(&sw->dev->keepalive_wdog_work);
 }
 
-int prestera_hw_switch_ageing_set(struct prestera_switch *sw, u32 ageing_ms)
+int prestera_hw_switch_ageing_set(const struct prestera_switch *sw,
+				  u32 ageing_time)
 {
 	struct prestera_msg_switch_attr_req req = {
-		.attr = PRESTERA_CMD_SWITCH_ATTR_AGEING,
-		.param = {
-			.ageing_timeout_ms = ageing_ms,
-		},
+		.param = {.ageing_timeout_ms = __cpu_to_le32(ageing_time)},
+		.attr = __cpu_to_le32(PRESTERA_CMD_SWITCH_ATTR_AGEING),
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_SWITCH_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int prestera_hw_port_state_set(const struct prestera_port *port,
-			       bool admin_state)
+int prestera_hw_switch_mac_set(const struct prestera_switch *sw, const u8 *mac)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_ADMIN_STATE,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.admin_state = admin_state,
-		}
+	struct prestera_msg_switch_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_SWITCH_ATTR_MAC),
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
-}
-
-int prestera_hw_port_mtu_set(const struct prestera_port *port, u32 mtu)
-{
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_MTU,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.mtu = mtu,
-		}
-	};
+	memcpy(req.param.mac, mac, sizeof(req.param.mac));
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int prestera_hw_port_mac_set(const struct prestera_port *port, const char *mac)
+int prestera_hw_switch_trap_policer_set(const struct prestera_switch *sw,
+					u8 profile)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_MAC,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_switch_attr_req req = {
+		.param = {.trap_policer_profile = __cpu_to_le32(profile)},
+		.attr = __cpu_to_le32(PRESTERA_CMD_SWITCH_ATTR_TRAP_POLICER),
 	};
 
-	ether_addr_copy(req.param.mac, mac);
-
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int prestera_hw_port_accept_frm_type(struct prestera_port *port,
-				     enum prestera_accept_frm_type type)
+int prestera_hw_port_mtu_set(const struct prestera_port *port, u32 mtu)
 {
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_ACCEPT_FRAME_TYPE,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.accept_frm_type = type,
-		}
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_MTU),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.param = {.mtu = __cpu_to_le32(mtu)}
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-int prestera_hw_port_cap_get(const struct prestera_port *port,
-			     struct prestera_port_caps *caps)
+int prestera_hw_port_mtu_get(const struct prestera_port *port, u32 *mtu)
 {
+	struct prestera_msg_port_attr_resp resp;
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_CAPABILITY,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_MTU),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
 	};
-	struct prestera_msg_port_attr_resp resp;
 	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = fw_send_req_resp(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
+			       &req, &resp);
 	if (err)
 		return err;
 
-	caps->supp_link_modes = resp.param.cap.link_mode;
-	caps->transceiver = resp.param.cap.transceiver;
-	caps->supp_fec = resp.param.cap.fec;
-	caps->type = resp.param.cap.type;
+	*mtu = __le32_to_cpu(resp.param.mtu);
 
 	return err;
 }
 
-int prestera_hw_port_remote_cap_get(const struct prestera_port *port,
-				    u64 *link_mode_bitmap)
+int prestera_hw_port_mac_set(const struct prestera_port *port, char *mac)
 {
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_REMOTE_CAPABILITY,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_MAC),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
 	};
-	struct prestera_msg_port_attr_resp resp;
-	int err;
-
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
-	if (err)
-		return err;
+	memcpy(&req.param.mac, mac, sizeof(req.param.mac));
 
-	*link_mode_bitmap = resp.param.cap.link_mode;
-
-	return 0;
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-int prestera_hw_port_remote_fc_get(const struct prestera_port *port,
-				   bool *pause, bool *asym_pause)
+int prestera_hw_port_mac_get(const struct prestera_port *port, char *mac)
 {
+	struct prestera_msg_port_attr_resp resp;
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_REMOTE_FC,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_MAC),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
 	};
-	struct prestera_msg_port_attr_resp resp;
 	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = fw_send_req_resp(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
+			       &req, &resp);
 	if (err)
 		return err;
 
-	switch (resp.param.fc) {
-	case PRESTERA_FC_SYMMETRIC:
-		*pause = true;
-		*asym_pause = false;
-		break;
-	case PRESTERA_FC_ASYMMETRIC:
-		*pause = false;
-		*asym_pause = true;
-		break;
-	case PRESTERA_FC_SYMM_ASYMM:
-		*pause = true;
-		*asym_pause = true;
-		break;
-	default:
-		*pause = false;
-		*asym_pause = false;
-	}
+	memcpy(mac, resp.param.mac, sizeof(resp.param.mac));
 
-	return 0;
+	return err;
 }
 
-int prestera_hw_acl_ruleset_create(struct prestera_switch *sw, u16 *ruleset_id)
+int prestera_hw_port_accept_frame_type_set(const struct prestera_port *port,
+					   enum prestera_accept_frame_type type)
 {
-	struct prestera_msg_acl_ruleset_resp resp;
-	struct prestera_msg_acl_ruleset_req req;
-	int err;
-
-	err = prestera_cmd_ret(sw, PRESTERA_CMD_TYPE_ACL_RULESET_CREATE,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
-	if (err)
-		return err;
-
-	*ruleset_id = resp.id;
+	struct prestera_msg_port_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_ACCEPT_FRAME_TYPE),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.param = {.accept_frm_type = type}
+	};
 
-	return 0;
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-int prestera_hw_acl_ruleset_del(struct prestera_switch *sw, u16 ruleset_id)
+int prestera_hw_port_learning_set(const struct prestera_port *port, bool enable)
 {
-	struct prestera_msg_acl_ruleset_req req = {
-		.id = ruleset_id,
+	struct prestera_msg_port_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_LEARNING),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.param = {.learning = enable ? 1 : 0}
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_ACL_RULESET_DELETE,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-static int prestera_hw_acl_actions_put(struct prestera_msg_acl_action *action,
-				       struct prestera_acl_rule *rule)
+int prestera_hw_event_handler_register(struct prestera_switch *sw,
+				       enum prestera_event_type type,
+				       void (*cb)(struct prestera_switch *sw,
+						  struct prestera_event *evt,
+						  void *arg),
+				       void *arg)
 {
-	struct list_head *a_list = prestera_acl_rule_action_list_get(rule);
-	struct prestera_acl_rule_action_entry *a_entry;
-	int i = 0;
+	struct prestera_fw_event_handler *eh;
 
-	list_for_each_entry(a_entry, a_list, list) {
-		action[i].id = a_entry->id;
+	eh = __find_event_handler(sw, type);
+	if (eh)
+		return -EEXIST;
+	eh = kmalloc(sizeof(*eh), GFP_KERNEL);
+	if (!eh)
+		return -ENOMEM;
 
-		switch (a_entry->id) {
-		case PRESTERA_ACL_RULE_ACTION_ACCEPT:
-		case PRESTERA_ACL_RULE_ACTION_DROP:
-		case PRESTERA_ACL_RULE_ACTION_TRAP:
-			/* just rule action id, no specific data */
-			break;
-		default:
-			return -EINVAL;
-		}
+	eh->type = type;
+	eh->func = cb;
+	eh->arg = arg;
 
-		i++;
-	}
+	INIT_LIST_HEAD(&eh->list);
+
+	list_add_rcu(&eh->list, &sw->event_handlers);
 
 	return 0;
 }
 
-static int prestera_hw_acl_matches_put(struct prestera_msg_acl_match *match,
-				       struct prestera_acl_rule *rule)
+void prestera_hw_event_handler_unregister(struct prestera_switch *sw,
+					  enum prestera_event_type type)
 {
-	struct list_head *m_list = prestera_acl_rule_match_list_get(rule);
-	struct prestera_acl_rule_match_entry *m_entry;
-	int i = 0;
-
-	list_for_each_entry(m_entry, m_list, list) {
-		match[i].type = m_entry->type;
-
-		switch (m_entry->type) {
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID:
-			match[i].keymask.u16.key = m_entry->keymask.u16.key;
-			match[i].keymask.u16.mask = m_entry->keymask.u16.mask;
-			break;
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO:
-			match[i].keymask.u8.key = m_entry->keymask.u8.key;
-			match[i].keymask.u8.mask = m_entry->keymask.u8.mask;
-			break;
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC:
-			memcpy(match[i].keymask.mac.key,
-			       m_entry->keymask.mac.key,
-			       sizeof(match[i].keymask.mac.key));
-			memcpy(match[i].keymask.mac.mask,
-			       m_entry->keymask.mac.mask,
-			       sizeof(match[i].keymask.mac.mask));
-			break;
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC:
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST:
-			match[i].keymask.u32.key = m_entry->keymask.u32.key;
-			match[i].keymask.u32.mask = m_entry->keymask.u32.mask;
-			break;
-		case PRESTERA_ACL_RULE_MATCH_ENTRY_TYPE_PORT:
-			match[i].keymask.u64.key = m_entry->keymask.u64.key;
-			match[i].keymask.u64.mask = m_entry->keymask.u64.mask;
-			break;
-		default:
-			return -EINVAL;
-		}
+	struct prestera_fw_event_handler *eh;
 
-		i++;
-	}
+	eh = __find_event_handler(sw, type);
+	if (!eh)
+		return;
 
-	return 0;
+	list_del_rcu(&eh->list);
+	synchronize_rcu();
+	kfree(eh);
 }
 
-int prestera_hw_acl_rule_add(struct prestera_switch *sw,
-			     struct prestera_acl_rule *rule,
-			     u32 *rule_id)
+int prestera_hw_vlan_create(const struct prestera_switch *sw, u16 vid)
 {
-	struct prestera_msg_acl_action *actions;
-	struct prestera_msg_acl_match *matches;
-	struct prestera_msg_acl_rule_resp resp;
-	struct prestera_msg_acl_rule_req *req;
-	u8 n_actions;
-	u8 n_matches;
-	void *buff;
-	u32 size;
-	int err;
-
-	n_actions = prestera_acl_rule_action_len(rule);
-	n_matches = prestera_acl_rule_match_len(rule);
-
-	size = sizeof(*req) + sizeof(*actions) * n_actions +
-		sizeof(*matches) * n_matches;
-
-	buff = kzalloc(size, GFP_KERNEL);
-	if (!buff)
-		return -ENOMEM;
-
-	req = buff;
-	actions = buff + sizeof(*req);
-	matches = buff + sizeof(*req) + sizeof(*actions) * n_actions;
-
-	/* put acl actions into the message */
-	err = prestera_hw_acl_actions_put(actions, rule);
-	if (err)
-		goto free_buff;
-
-	/* put acl matches into the message */
-	err = prestera_hw_acl_matches_put(matches, rule);
-	if (err)
-		goto free_buff;
-
-	req->ruleset_id = prestera_acl_rule_ruleset_id_get(rule);
-	req->priority = prestera_acl_rule_priority_get(rule);
-	req->n_actions = prestera_acl_rule_action_len(rule);
-	req->n_matches = prestera_acl_rule_match_len(rule);
-
-	err = prestera_cmd_ret(sw, PRESTERA_CMD_TYPE_ACL_RULE_ADD,
-			       &req->cmd, size, &resp.ret, sizeof(resp));
-	if (err)
-		goto free_buff;
+	struct prestera_msg_vlan_req req = {
+		.vid = __cpu_to_le16(vid),
+	};
 
-	*rule_id = resp.id;
-free_buff:
-	kfree(buff);
-	return err;
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_VLAN_CREATE, &req);
 }
 
-int prestera_hw_acl_rule_del(struct prestera_switch *sw, u32 rule_id)
+int prestera_hw_vlan_delete(const struct prestera_switch *sw, u16 vid)
 {
-	struct prestera_msg_acl_rule_req req = {
-		.id = rule_id
+	struct prestera_msg_vlan_req req = {
+		.vid = __cpu_to_le16(vid),
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_ACL_RULE_DELETE,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_VLAN_DELETE, &req);
 }
 
-int prestera_hw_acl_rule_stats_get(struct prestera_switch *sw, u32 rule_id,
-				   u64 *packets, u64 *bytes)
+int prestera_hw_vlan_port_set(const struct prestera_port *port,
+			      u16 vid, bool is_member, bool untagged)
 {
-	struct prestera_msg_acl_rule_stats_resp resp;
-	struct prestera_msg_acl_rule_req req = {
-		.id = rule_id
+	struct prestera_msg_vlan_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.vid = __cpu_to_le16(vid),
+		.is_member = is_member ? 1 : 0,
+		.is_tagged = untagged ? 0 : 1
 	};
-	int err;
-
-	err = prestera_cmd_ret(sw, PRESTERA_CMD_TYPE_ACL_RULE_STATS_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
-	if (err)
-		return err;
-
-	*packets = resp.packets;
-	*bytes = resp.bytes;
 
-	return 0;
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_VLAN_PORT_SET, &req);
 }
 
-int prestera_hw_acl_port_bind(const struct prestera_port *port, u16 ruleset_id)
+int prestera_hw_vlan_port_vid_set(const struct prestera_port *port, u16 vid)
 {
-	struct prestera_msg_acl_ruleset_bind_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.ruleset_id = ruleset_id,
+	struct prestera_msg_vlan_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.vid = __cpu_to_le16(vid)
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_ACL_PORT_BIND,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_VLAN_PVID_SET, &req);
 }
 
-int prestera_hw_acl_port_unbind(const struct prestera_port *port,
-				u16 ruleset_id)
+int prestera_hw_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state)
 {
-	struct prestera_msg_acl_ruleset_bind_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.ruleset_id = ruleset_id,
+	struct prestera_msg_stp_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.vid = __cpu_to_le16(vid),
+		.state = state
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_ACL_PORT_UNBIND,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_STP_PORT_SET, &req);
 }
 
-int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id)
+int prestera_hw_port_uc_flood_set(const struct prestera_port *port, bool flood)
 {
-	struct prestera_msg_span_resp resp;
-	struct prestera_msg_span_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_port_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_FLOOD),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.param = {
+			.flood_ext = {
+				.type = PRESTERA_PORT_FLOOD_TYPE_UC,
+				.enable = flood,
+			}
+		}
 	};
-	int err;
-
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_SPAN_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
-	if (err)
-		return err;
-
-	*span_id = resp.id;
 
-	return 0;
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-int prestera_hw_span_bind(const struct prestera_port *port, u8 span_id)
+int prestera_hw_port_mc_flood_set(const struct prestera_port *port, bool flood)
 {
-	struct prestera_msg_span_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.id = span_id,
+	struct prestera_msg_port_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_FLOOD),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.param = {
+			.flood_ext = {
+				.type = PRESTERA_PORT_FLOOD_TYPE_MC,
+				.enable = flood,
+			}
+		}
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_SPAN_BIND,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-int prestera_hw_span_unbind(const struct prestera_port *port)
+int prestera_hw_port_srcid_default_set(const struct prestera_port *port,
+				       u32 sourceid)
 {
-	struct prestera_msg_span_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_port_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_SOURCE_ID_DEFAULT),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.param = {
+			.source_id_default = __cpu_to_le32(sourceid)
+		}
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_SPAN_UNBIND,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-int prestera_hw_span_release(struct prestera_switch *sw, u8 span_id)
+int prestera_hw_port_srcid_filter_set(const struct prestera_port *port,
+				      u32 sourceid)
 {
-	struct prestera_msg_span_req req = {
-		.id = span_id
+	struct prestera_msg_port_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_SOURCE_ID_FILTER),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.param = {
+			.source_id_filter = __cpu_to_le32(sourceid)
+		}
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_SPAN_RELEASE,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-int prestera_hw_port_type_get(const struct prestera_port *port, u8 *type)
+int prestera_hw_fdb_add(const struct prestera_port *port,
+			const unsigned char *mac, u16 vid, bool dynamic)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_TYPE,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_fdb_req req = {
+		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_REG_PORT,
+		.dest = {
+			.dev = __cpu_to_le32(port->dev_id),
+			.port = __cpu_to_le32(port->hw_id),
+		},
+		.vid = __cpu_to_le16(vid),
+		.dynamic = dynamic
 	};
-	struct prestera_msg_port_attr_resp resp;
-	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
-	if (err)
-		return err;
+	memcpy(req.mac, mac, sizeof(req.mac));
 
-	*type = resp.param.type;
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_FDB_ADD, &req);
+}
 
-	return 0;
+int prestera_hw_lag_fdb_add(const struct prestera_switch *sw, u16 lag_id,
+			    const unsigned char *mac, u16 vid, bool dynamic)
+{
+	struct prestera_msg_fdb_req req = {
+		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_LAG,
+		.dest = { .lag_id = __cpu_to_le16(lag_id) },
+		.vid = __cpu_to_le16(vid),
+		.dynamic = dynamic
+	};
+
+	memcpy(req.mac, mac, sizeof(req.mac));
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_FDB_ADD, &req);
 }
 
-int prestera_hw_port_fec_get(const struct prestera_port *port, u8 *fec)
+int prestera_hw_fdb_del(const struct prestera_port *port,
+			const unsigned char *mac, u16 vid)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_FEC,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_fdb_req req = {
+		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_REG_PORT,
+		.dest = {
+			.dev = __cpu_to_le32(port->dev_id),
+			.port = __cpu_to_le32(port->hw_id),
+		},
+		.vid = __cpu_to_le16(vid)
 	};
-	struct prestera_msg_port_attr_resp resp;
-	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
-	if (err)
-		return err;
+	memcpy(req.mac, mac, sizeof(req.mac));
+
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_FDB_DELETE, &req);
+}
 
-	*fec = resp.param.fec;
+int prestera_hw_lag_fdb_del(const struct prestera_switch *sw, u16 lag_id,
+			    const unsigned char *mac, u16 vid)
+{
+	struct prestera_msg_fdb_req req = {
+		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_LAG,
+		.dest = { .lag_id = __cpu_to_le16(lag_id) },
+		.vid = __cpu_to_le16(vid)
+	};
 
-	return 0;
+	memcpy(req.mac, mac, sizeof(req.mac));
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_FDB_DELETE, &req);
 }
 
-int prestera_hw_port_fec_set(const struct prestera_port *port, u8 fec)
+int prestera_hw_port_cap_get(const struct prestera_port *port,
+			     struct prestera_port_caps *caps)
 {
+	struct prestera_msg_port_attr_resp resp;
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_FEC,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.fec = fec,
-		}
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_CAPABILITY),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
 	};
+	int err;
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	err = fw_send_req_resp(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	caps->supp_link_modes = __le64_to_cpu(resp.param.cap.link_mode);
+	caps->supp_fec = resp.param.cap.fec;
+	caps->type = resp.param.cap.type;
+	caps->transceiver = resp.param.cap.transceiver;
+
+	return err;
 }
 
 static u8 prestera_hw_mdix_to_eth(u8 mode)
@@ -1188,9 +1623,9 @@ static u8 prestera_hw_mdix_to_eth(u8 mode)
 		return ETH_TP_MDI_X;
 	case PRESTERA_PORT_TP_AUTO:
 		return ETH_TP_MDI_AUTO;
-	default:
-		return ETH_TP_MDI_INVALID;
 	}
+
+	return ETH_TP_MDI_INVALID;
 }
 
 static u8 prestera_hw_mdix_from_eth(u8 mode)
@@ -1202,687 +1637,1298 @@ static u8 prestera_hw_mdix_from_eth(u8 mode)
 		return PRESTERA_PORT_TP_MDIX;
 	case ETH_TP_MDI_AUTO:
 		return PRESTERA_PORT_TP_AUTO;
-	default:
-		return PRESTERA_PORT_TP_NA;
 	}
+
+	return PRESTERA_PORT_TP_NA;
 }
 
-int prestera_hw_port_mdix_get(const struct prestera_port *port, u8 *status,
-			      u8 *admin_mode)
+static void prestera_hw_remote_fc_to_eth(u8 fc, bool *pause, bool *asym_pause)
 {
+	switch (fc) {
+	case PRESTERA_FC_SYMMETRIC:
+		*pause = true;
+		*asym_pause = false;
+		break;
+	case PRESTERA_FC_ASYMMETRIC:
+		*pause = false;
+		*asym_pause = true;
+		break;
+	case PRESTERA_FC_SYMM_ASYMM:
+		*pause = true;
+		*asym_pause = true;
+		break;
+	default:
+		*pause = false;
+		*asym_pause = false;
+	};
+}
+
+int prestera_hw_fw_log_level_set(const struct prestera_switch *sw,
+				 u32 lib, u32 type)
+{
+	struct prestera_msg_log_lvl_set_req req = {
+		.lib = __cpu_to_le32(lib),
+		.type = __cpu_to_le32(type)
+	};
+	int err;
+
+	err = fw_send_req(sw, PRESTERA_CMD_TYPE_LOG_LEVEL_SET, &req);
+	if (err)
+		return err;
+
+	return 0;
+}
+
+int prestera_hw_port_stats_get(const struct prestera_port *port,
+			       struct prestera_port_stats *stats)
+{
+	struct prestera_msg_port_stats_resp resp;
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_MDIX,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_STATS),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
 	};
-	struct prestera_msg_port_attr_resp resp;
 	int err;
+	__le64 *hw_val = resp.stats;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = fw_send_req_resp(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
+			       &req, &resp);
 	if (err)
 		return err;
 
-	*status = prestera_hw_mdix_to_eth(resp.param.mdix.status);
-	*admin_mode = prestera_hw_mdix_to_eth(resp.param.mdix.admin_mode);
+	stats->good_octets_received = __le64_to_cpu(hw_val[PRESTERA_PORT_GOOD_OCTETS_RCV_CNT]);
+	stats->bad_octets_received = __le64_to_cpu(hw_val[PRESTERA_PORT_BAD_OCTETS_RCV_CNT]);
+	stats->mac_trans_error = __le64_to_cpu(hw_val[PRESTERA_PORT_MAC_TRANSMIT_ERR_CNT]);
+	stats->broadcast_frames_received =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_BRDC_PKTS_RCV_CNT]);
+	stats->multicast_frames_received =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_MC_PKTS_RCV_CNT]);
+	stats->frames_64_octets = __le64_to_cpu(hw_val[PRESTERA_PORT_PKTS_64_OCTETS_CNT]);
+	stats->frames_65_to_127_octets =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_PKTS_65TO127_OCTETS_CNT]);
+	stats->frames_128_to_255_octets =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_PKTS_128TO255_OCTETS_CNT]);
+	stats->frames_256_to_511_octets =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_PKTS_256TO511_OCTETS_CNT]);
+	stats->frames_512_to_1023_octets =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_PKTS_512TO1023_OCTETS_CNT]);
+	stats->frames_1024_to_max_octets =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_PKTS_1024TOMAX_OCTETS_CNT]);
+	stats->excessive_collision =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_EXCESSIVE_COLLISIONS_CNT]);
+	stats->multicast_frames_sent = __le64_to_cpu(hw_val[PRESTERA_PORT_MC_PKTS_SENT_CNT]);
+	stats->broadcast_frames_sent = __le64_to_cpu(hw_val[PRESTERA_PORT_BRDC_PKTS_SENT_CNT]);
+	stats->fc_sent = __le64_to_cpu(hw_val[PRESTERA_PORT_FC_SENT_CNT]);
+	stats->fc_received = __le64_to_cpu(hw_val[PRESTERA_PORT_GOOD_FC_RCV_CNT]);
+	stats->buffer_overrun = __le64_to_cpu(hw_val[PRESTERA_PORT_DROP_EVENTS_CNT]);
+	stats->undersize = __le64_to_cpu(hw_val[PRESTERA_PORT_UNDERSIZE_PKTS_CNT]);
+	stats->fragments = __le64_to_cpu(hw_val[PRESTERA_PORT_FRAGMENTS_PKTS_CNT]);
+	stats->oversize = __le64_to_cpu(hw_val[PRESTERA_PORT_OVERSIZE_PKTS_CNT]);
+	stats->jabber = __le64_to_cpu(hw_val[PRESTERA_PORT_JABBER_PKTS_CNT]);
+	stats->rx_error_frame_received =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_MAC_RCV_ERROR_CNT]);
+	stats->bad_crc = __le64_to_cpu(hw_val[PRESTERA_PORT_BAD_CRC_CNT]);
+	stats->collisions = __le64_to_cpu(hw_val[PRESTERA_PORT_COLLISIONS_CNT]);
+	stats->late_collision = __le64_to_cpu(hw_val[PRESTERA_PORT_LATE_COLLISIONS_CNT]);
+	stats->unicast_frames_received =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_GOOD_UC_PKTS_RCV_CNT]);
+	stats->unicast_frames_sent =
+		__le64_to_cpu(hw_val[PRESTERA_PORT_GOOD_UC_PKTS_SENT_CNT]);
+	stats->sent_multiple = __le64_to_cpu(hw_val[PRESTERA_PORT_MULTIPLE_PKTS_SENT_CNT]);
+	stats->sent_deferred = __le64_to_cpu(hw_val[PRESTERA_PORT_DEFERRED_PKTS_SENT_CNT]);
+	stats->good_octets_sent = __le64_to_cpu(hw_val[PRESTERA_PORT_GOOD_OCTETS_SENT_CNT]);
 
 	return 0;
 }
 
-int prestera_hw_port_mdix_set(const struct prestera_port *port, u8 mode)
+int prestera_hw_bridge_create(const struct prestera_switch *sw, u16 *bridge_id)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_MDIX,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_bridge_req req;
+	struct prestera_msg_bridge_resp resp;
+	int err;
+
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_BRIDGE_CREATE,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	*bridge_id = __le16_to_cpu(resp.bridge);
+	return err;
+}
+
+int prestera_hw_bridge_delete(const struct prestera_switch *sw, u16 bridge_id)
+{
+	struct prestera_msg_bridge_req req = {
+		.bridge = __cpu_to_le16(bridge_id)
 	};
 
-	req.param.mdix.admin_mode = prestera_hw_mdix_from_eth(mode);
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_BRIDGE_DELETE, &req);
+}
+
+int prestera_hw_bridge_port_add(const struct prestera_port *port, u16 bridge_id)
+{
+	struct prestera_msg_bridge_req req = {
+		.bridge = __cpu_to_le16(bridge_id),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
+	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_BRIDGE_PORT_ADD, &req);
 }
 
-int prestera_hw_port_link_mode_set(const struct prestera_port *port, u32 mode)
+int prestera_hw_bridge_port_delete(const struct prestera_port *port,
+				   u16 bridge_id)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_LINK_MODE,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.link_mode = mode,
-		}
+	struct prestera_msg_bridge_req req = {
+		.bridge = __cpu_to_le16(bridge_id),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_BRIDGE_PORT_DELETE,
+			   &req);
 }
 
-int prestera_hw_port_link_mode_get(const struct prestera_port *port, u32 *mode)
+int prestera_hw_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
+			    const u8 *mac, u16 vid)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_LINK_MODE,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_macvlan_req req = {
+		.vr_id = __cpu_to_le16(vr_id),
+		.vid = __cpu_to_le16(vid)
+	};
+
+	memcpy(req.mac, mac, ETH_ALEN);
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_FDB_MACVLAN_ADD, &req);
+}
+
+int prestera_hw_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
+			    const u8 *mac, u16 vid)
+{
+	struct prestera_msg_macvlan_req req = {
+		.vr_id = __cpu_to_le16(vr_id),
+		.vid = __cpu_to_le16(vid)
+	};
+
+	memcpy(req.mac, mac, ETH_ALEN);
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_FDB_MACVLAN_DEL, &req);
+}
+
+int prestera_hw_fdb_flush_port(const struct prestera_port *port, u32 mode)
+{
+	struct prestera_msg_fdb_req req = {
+		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_REG_PORT,
+		.dest = {
+			.dev = __cpu_to_le32(port->dev_id),
+			.port = __cpu_to_le32(port->hw_id),
+		},
+		.flush_mode = __cpu_to_le32(mode),
+	};
+
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_FDB_FLUSH_PORT, &req);
+}
+
+int prestera_hw_fdb_flush_lag(const struct prestera_switch *sw, u16 lag_id,
+			      u32 mode)
+{
+	struct prestera_msg_fdb_req req = {
+		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_LAG,
+		.dest = { .lag_id = __cpu_to_le16(lag_id) },
+		.flush_mode = __cpu_to_le32(mode),
+	};
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_FDB_FLUSH_PORT, &req);
+}
+
+int prestera_hw_fdb_flush_vlan(const struct prestera_switch *sw, u16 vid,
+			       u32 mode)
+{
+	struct prestera_msg_fdb_req req = {
+		.vid = __cpu_to_le16(vid),
+		.flush_mode = __cpu_to_le32(mode),
 	};
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_FDB_FLUSH_VLAN, &req);
+}
+
+int prestera_hw_fdb_flush_port_vlan(const struct prestera_port *port, u16 vid,
+				    u32 mode)
+{
+	struct prestera_msg_fdb_req req = {
+		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_REG_PORT,
+		.dest = {
+			.dev = __cpu_to_le32(port->dev_id),
+			.port = __cpu_to_le32(port->hw_id),
+		},
+		.vid = __cpu_to_le16(vid),
+		.flush_mode = __cpu_to_le32(mode),
+	};
+
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_FDB_FLUSH_PORT_VLAN,
+			   &req);
+}
+
+int prestera_hw_fdb_flush_lag_vlan(const struct prestera_switch *sw,
+				   u16 lag_id, u16 vid, u32 mode)
+{
+	struct prestera_msg_fdb_req req = {
+		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_LAG,
+		.dest = { .lag_id = __cpu_to_le16(lag_id) },
+		.vid = __cpu_to_le16(vid),
+		.flush_mode = __cpu_to_le32(mode),
+	};
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_FDB_FLUSH_PORT_VLAN, &req);
+}
+
+int prestera_hw_port_mac_mode_get(const struct prestera_port *port,
+				  u32 *mode, u32 *speed, u8 *duplex, u8 *fec)
+{
 	struct prestera_msg_port_attr_resp resp;
+	struct prestera_msg_port_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_MAC_MODE),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
+	};
 	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = fw_send_req_resp(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
+			       &req, &resp);
 	if (err)
 		return err;
 
-	*mode = resp.param.link_mode;
+	if (mode)
+		*mode = __le32_to_cpu(resp.param.link_evt.mac.mode);
 
-	return 0;
+	if (speed)
+		*speed = __le32_to_cpu(resp.param.link_evt.mac.speed);
+
+	if (duplex)
+		*duplex = resp.param.link_evt.mac.duplex;
+
+	if (fec)
+		*fec = resp.param.link_evt.mac.fec;
+
+	return err;
 }
 
-int prestera_hw_port_speed_get(const struct prestera_port *port, u32 *speed)
+int prestera_hw_port_mac_mode_set(const struct prestera_port *port,
+				  bool admin, u32 mode, u8 inband,
+				  u32 speed, u8 duplex, u8 fec)
 {
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_SPEED,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_MAC_MODE),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.param = {
+			.link = {
+				.mac = {
+					.admin = admin,
+					.reg_mode.mode = __cpu_to_le32(mode),
+					.reg_mode.inband = inband,
+					.reg_mode.speed = __cpu_to_le32(speed),
+					.reg_mode.duplex = duplex,
+					.reg_mode.fec = fec
+				}
+			}
+		}
 	};
+
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
+}
+
+int prestera_hw_port_phy_mode_get(const struct prestera_port *port,
+				  u8 *mdix, u64 *lmode_bmap,
+				  bool *fc_pause, bool *fc_asym)
+{
 	struct prestera_msg_port_attr_resp resp;
+	struct prestera_msg_port_attr_req req = {
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_PHY_MODE),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id)
+	};
 	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = fw_send_req_resp(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
+			       &req, &resp);
 	if (err)
 		return err;
 
-	*speed = resp.param.speed;
+	if (mdix)
+		*mdix = prestera_hw_mdix_to_eth(resp.param.link_evt.phy.mdix);
 
-	return 0;
+	if (lmode_bmap)
+		*lmode_bmap = __le64_to_cpu(resp.param.link_evt.phy.lmode_bmap);
+
+	if (fc_pause && fc_asym)
+		prestera_hw_remote_fc_to_eth(resp.param.link_evt.phy.fc,
+					     fc_pause, fc_asym);
+
+	return err;
 }
 
-int prestera_hw_port_autoneg_set(const struct prestera_port *port,
-				 bool autoneg, u64 link_modes, u8 fec)
+int prestera_hw_port_phy_mode_set(const struct prestera_port *port,
+				  bool admin, bool adv, u32 mode, u64 modes,
+				  u8 mdix)
 {
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_AUTONEG,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_PHY_MODE),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
 		.param = {
-			.autoneg = {
-				.link_mode = link_modes,
-				.enable = autoneg,
-				.fec = fec,
+			.link = {
+				.phy = {
+					.admin = admin,
+					.adv_enable = adv ? 1 : 0,
+					.mode = __cpu_to_le32(mode),
+					.modes = __cpu_to_le64(modes),
+				}
 			}
 		}
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	req.param.link.phy.mdix = prestera_hw_mdix_from_eth(mdix);
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
 }
 
-int prestera_hw_port_autoneg_restart(struct prestera_port *port)
+int prestera_hw_port_storm_control_cfg_set(const struct prestera_port *port,
+					   u32 storm_type,
+					   u32 kbyte_per_sec_rate)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_AUTONEG_RESTART,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_port_storm_control_cfg_set_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.storm_type = __cpu_to_le32(storm_type),
+		.kbyte_per_sec_rate = __cpu_to_le32(kbyte_per_sec_rate)
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_RATE_LIMIT_MODE_SET,
+			   &req);
 }
 
-int prestera_hw_port_duplex_get(const struct prestera_port *port, u8 *duplex)
+static int prestera_iface_to_msg(struct prestera_iface *iface,
+				 struct prestera_msg_iface *msg_if)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_DUPLEX,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-	};
-	struct prestera_msg_port_attr_resp resp;
+	switch (iface->type) {
+	case PRESTERA_IF_PORT_E:
+	case PRESTERA_IF_VID_E:
+		msg_if->port = __cpu_to_le32(iface->dev_port.port_num);
+		msg_if->dev = __cpu_to_le32(iface->dev_port.hw_dev_num);
+		break;
+	case PRESTERA_IF_LAG_E:
+		msg_if->lag_id = __cpu_to_le16(iface->lag_id);
+		break;
+	default:
+		return -ENOTSUPP;
+	}
+
+	msg_if->vr_id = __cpu_to_le16(iface->vr_id);
+	msg_if->vid = __cpu_to_le16(iface->vlan_id);
+	msg_if->type = iface->type;
+	return 0;
+}
+
+int prestera_hw_rif_create(const struct prestera_switch *sw,
+			   struct prestera_iface *iif, u8 *mac, u16 *rif_id)
+{
+	struct prestera_msg_rif_req req;
+	struct prestera_msg_rif_resp resp;
 	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	memcpy(req.mac, mac, ETH_ALEN);
+
+	err = prestera_iface_to_msg(iif, &req.iif);
 	if (err)
 		return err;
 
-	*duplex = resp.param.duplex;
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_ROUTER_RIF_CREATE,
+			       &req, &resp);
+	if (err)
+		return err;
 
-	return 0;
+	*rif_id = __le16_to_cpu(resp.rif_id);
+	return err;
 }
 
-int prestera_hw_port_stats_get(const struct prestera_port *port,
-			       struct prestera_port_stats *st)
+int prestera_hw_rif_delete(const struct prestera_switch *sw, u16 rif_id,
+			   struct prestera_iface *iif)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_STATS,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_rif_req req = {
+		.rif_id = __cpu_to_le16(rif_id),
 	};
-	struct prestera_msg_port_stats_resp resp;
-	u64 *hw = resp.stats;
 	int err;
 
-	err = prestera_cmd_ret(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = prestera_iface_to_msg(iif, &req.iif);
 	if (err)
 		return err;
 
-	st->good_octets_received = hw[PRESTERA_PORT_GOOD_OCTETS_RCV_CNT];
-	st->bad_octets_received = hw[PRESTERA_PORT_BAD_OCTETS_RCV_CNT];
-	st->mac_trans_error = hw[PRESTERA_PORT_MAC_TRANSMIT_ERR_CNT];
-	st->broadcast_frames_received = hw[PRESTERA_PORT_BRDC_PKTS_RCV_CNT];
-	st->multicast_frames_received = hw[PRESTERA_PORT_MC_PKTS_RCV_CNT];
-	st->frames_64_octets = hw[PRESTERA_PORT_PKTS_64L_CNT];
-	st->frames_65_to_127_octets = hw[PRESTERA_PORT_PKTS_65TO127L_CNT];
-	st->frames_128_to_255_octets = hw[PRESTERA_PORT_PKTS_128TO255L_CNT];
-	st->frames_256_to_511_octets = hw[PRESTERA_PORT_PKTS_256TO511L_CNT];
-	st->frames_512_to_1023_octets = hw[PRESTERA_PORT_PKTS_512TO1023L_CNT];
-	st->frames_1024_to_max_octets = hw[PRESTERA_PORT_PKTS_1024TOMAXL_CNT];
-	st->excessive_collision = hw[PRESTERA_PORT_EXCESSIVE_COLLISIONS_CNT];
-	st->multicast_frames_sent = hw[PRESTERA_PORT_MC_PKTS_SENT_CNT];
-	st->broadcast_frames_sent = hw[PRESTERA_PORT_BRDC_PKTS_SENT_CNT];
-	st->fc_sent = hw[PRESTERA_PORT_FC_SENT_CNT];
-	st->fc_received = hw[PRESTERA_PORT_GOOD_FC_RCV_CNT];
-	st->buffer_overrun = hw[PRESTERA_PORT_DROP_EVENTS_CNT];
-	st->undersize = hw[PRESTERA_PORT_UNDERSIZE_PKTS_CNT];
-	st->fragments = hw[PRESTERA_PORT_FRAGMENTS_PKTS_CNT];
-	st->oversize = hw[PRESTERA_PORT_OVERSIZE_PKTS_CNT];
-	st->jabber = hw[PRESTERA_PORT_JABBER_PKTS_CNT];
-	st->rx_error_frame_received = hw[PRESTERA_PORT_MAC_RCV_ERROR_CNT];
-	st->bad_crc = hw[PRESTERA_PORT_BAD_CRC_CNT];
-	st->collisions = hw[PRESTERA_PORT_COLLISIONS_CNT];
-	st->late_collision = hw[PRESTERA_PORT_LATE_COLLISIONS_CNT];
-	st->unicast_frames_received = hw[PRESTERA_PORT_GOOD_UC_PKTS_RCV_CNT];
-	st->unicast_frames_sent = hw[PRESTERA_PORT_GOOD_UC_PKTS_SENT_CNT];
-	st->sent_multiple = hw[PRESTERA_PORT_MULTIPLE_PKTS_SENT_CNT];
-	st->sent_deferred = hw[PRESTERA_PORT_DEFERRED_PKTS_SENT_CNT];
-	st->good_octets_sent = hw[PRESTERA_PORT_GOOD_OCTETS_SENT_CNT];
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_ROUTER_RIF_DELETE, &req);
+}
 
-	return 0;
+int prestera_hw_rif_set(const struct prestera_switch *sw, u16 *rif_id,
+			struct prestera_iface *iif, u8 *mac)
+{
+	struct prestera_msg_rif_resp resp;
+	struct prestera_msg_rif_req req = {
+		.rif_id = __cpu_to_le16(*rif_id),
+	};
+	int err;
+
+	memcpy(req.mac, mac, ETH_ALEN);
+
+	err = prestera_iface_to_msg(iif, &req.iif);
+	if (err)
+		return err;
+
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_ROUTER_RIF_SET,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	*rif_id = __le16_to_cpu(resp.rif_id);
+	return err;
 }
 
-int prestera_hw_port_learning_set(struct prestera_port *port, bool enable)
+int prestera_hw_vr_create(const struct prestera_switch *sw, u16 *vr_id)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_LEARNING,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.learning = enable,
-		}
+	int err;
+	struct prestera_msg_vr_resp resp;
+	struct prestera_msg_vr_req req;
+
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_ROUTER_VR_CREATE,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	*vr_id = __le16_to_cpu(resp.vr_id);
+	return err;
+}
+
+int prestera_hw_vr_delete(const struct prestera_switch *sw, u16 vr_id)
+{
+	struct prestera_msg_vr_req req = {
+		.vr_id = __cpu_to_le16(vr_id),
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_ROUTER_VR_DELETE, &req);
 }
 
-static int prestera_hw_port_uc_flood_set(struct prestera_port *port, bool flood)
+int prestera_hw_vr_abort(const struct prestera_switch *sw, u16 vr_id)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_FLOOD,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.flood_ext = {
-				.type = PRESTERA_PORT_FLOOD_TYPE_UC,
-				.enable = flood,
-			}
-		}
+	struct prestera_msg_vr_req req = {
+		.vr_id = __cpu_to_le16(vr_id),
+	};
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_ROUTER_VR_ABORT, &req);
+}
+
+int prestera_hw_lpm_add(const struct prestera_switch *sw, u16 vr_id,
+			__be32 dst, u32 dst_len, u32 grp_id)
+{
+	struct prestera_msg_lpm_req req = {
+		.dst.v = PRESTERA_IPV4,
+		.dst.u.ipv4 = dst,
+		.dst_len = __cpu_to_le32(dst_len),
+		.vr_id = __cpu_to_le16(vr_id),
+		.grp_id = __cpu_to_le32(grp_id)
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_ROUTER_LPM_ADD, &req);
 }
 
-static int prestera_hw_port_mc_flood_set(struct prestera_port *port, bool flood)
+int prestera_hw_lpm_del(const struct prestera_switch *sw, u16 vr_id, __be32 dst,
+			u32 dst_len)
+{
+	struct prestera_msg_lpm_req req = {
+		.dst.v = PRESTERA_IPV4,
+		.dst.u.ipv4 = dst,
+		.dst_len = __cpu_to_le32(dst_len),
+		.vr_id = __cpu_to_le16(vr_id),
+	};
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_ROUTER_LPM_DELETE, &req);
+}
+
+int prestera_hw_nh_entries_set(const struct prestera_switch *sw, int count,
+			       struct prestera_neigh_info *nhs, u32 grp_id)
+{
+	struct prestera_msg_nh_req req = { .size = __cpu_to_le32((u32)count),
+			.grp_id = __cpu_to_le32(grp_id) };
+	int i, err;
+
+	for (i = 0; i < count; i++) {
+		req.nh[i].is_active = nhs[i].connected;
+		memcpy(&req.nh[i].mac, nhs[i].ha, ETH_ALEN);
+		err = prestera_iface_to_msg(&nhs[i].iface, &req.nh[i].oif);
+		if (err)
+			return err;
+	}
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_ROUTER_NH_GRP_SET, &req);
+}
+
+/* TODO: more than one nh */
+/* For now "count = 1" supported only */
+int prestera_hw_nh_entries_get(const struct prestera_switch *sw, int count,
+			       struct prestera_neigh_info *nhs, u32 grp_id)
+{
+	struct prestera_msg_nh_req req = { .size = __cpu_to_le32((u32)count),
+			.grp_id = __cpu_to_le32(grp_id) };
+	struct prestera_msg_nh_resp resp;
+	int err, i;
+
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_ROUTER_NH_GRP_GET,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	for (i = 0; i < count; i++)
+		nhs[i].connected = resp.nh[i].is_active;
+
+	return err;
+}
+
+int prestera_hw_nhgrp_blk_get(const struct prestera_switch *sw,
+			      u8 *hw_state, u32 buf_size /* Buffer in bytes */)
+{
+	struct prestera_msg_nh_chunk_req req;
+	static struct prestera_msg_nh_chunk_resp resp;
+	int err;
+	u32 buf_offset;
+
+	memset(&hw_state[0], 0, buf_size);
+	buf_offset = 0;
+	while (1) {
+		if (buf_offset >= buf_size)
+			break;
+
+		memset(&req, 0, sizeof(req));
+		req.offset = __cpu_to_le32(buf_offset * 8); /* 8 bits in u8 */
+		err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_ROUTER_NH_GRP_BLK_GET,
+				       &req, &resp);
+		if (err)
+			return err;
+
+		memcpy(&hw_state[buf_offset], &resp.hw_state[0],
+		       buf_offset + PRESTERA_MSG_CHUNK_SIZE > buf_size ?
+			buf_size - buf_offset : PRESTERA_MSG_CHUNK_SIZE);
+		buf_offset += PRESTERA_MSG_CHUNK_SIZE;
+	}
+
+	return err;
+}
+
+int prestera_hw_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
+				u32 *grp_id)
+{
+	struct prestera_msg_nh_grp_req req = { .size = __cpu_to_le32((u32)nh_count) };
+	struct prestera_msg_nh_grp_resp resp;
+	int err;
+
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_ROUTER_NH_GRP_ADD, &req,
+			       &resp);
+	if (err)
+		return err;
+
+	*grp_id = __le32_to_cpu(resp.grp_id);
+	return err;
+}
+
+int prestera_hw_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
+				u32 grp_id)
+{
+	struct prestera_msg_nh_grp_req req = {
+	    .grp_id = __cpu_to_le32(grp_id),
+	    .size = __cpu_to_le32(nh_count)
+	};
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_ROUTER_NH_GRP_DELETE, &req);
+}
+
+int prestera_hw_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy)
+{
+	struct prestera_msg_mp_req req = { .hash_policy = hash_policy};
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_ROUTER_MP_HASH_SET, &req);
+}
+
+int prestera_hw_rxtx_init(const struct prestera_switch *sw, bool use_sdma,
+			  u32 *map_addr)
+{
+	struct prestera_msg_rxtx_resp resp;
+	struct prestera_msg_rxtx_req req;
+	int err;
+
+	req.use_sdma = use_sdma;
+
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_RXTX_INIT, &req, &resp);
+	if (err)
+		return err;
+
+	if (map_addr)
+		*map_addr = __le32_to_cpu(resp.map_addr);
+
+	return 0;
+}
+
+int prestera_hw_port_autoneg_restart(struct prestera_port *port)
 {
 	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_FLOOD,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.flood_ext = {
-				.type = PRESTERA_PORT_FLOOD_TYPE_MC,
-				.enable = flood,
-			}
-		}
+		.attr = __cpu_to_le32(PRESTERA_CMD_PORT_ATTR_PHY_AUTONEG_RESTART),
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET, &req);
+}
+
+/* ACL API */
+static int acl_rule_add_put_action(struct prestera_msg_acl_action *action,
+				   struct prestera_acl_hw_action_info *info)
+{
+	action->id = __cpu_to_le32(info->id);
+
+	switch (info->id) {
+	case PRESTERA_ACL_RULE_ACTION_ACCEPT:
+	case PRESTERA_ACL_RULE_ACTION_DROP:
+		/* just rule action id, no specific data */
+		break;
+	case PRESTERA_ACL_RULE_ACTION_TRAP:
+		action->trap.hw_tc = info->trap.hw_tc;
+		break;
+	case PRESTERA_ACL_RULE_ACTION_JUMP:
+		action->jump.index = __cpu_to_le32(info->jump.index);
+		break;
+	case PRESTERA_ACL_RULE_ACTION_POLICE:
+		action->police.rate = __cpu_to_le64(info->police.rate);
+		action->police.burst = __cpu_to_le64(info->police.burst);
+		break;
+	case PRESTERA_ACL_RULE_ACTION_NH:
+		action->nh.nh_id = __cpu_to_le32(info->nh);
+		break;
+	case PRESTERA_ACL_RULE_ACTION_NAT:
+		action->nat.old_addr = info->nat.old_addr;
+		action->nat.new_addr = info->nat.new_addr;
+		action->nat.flags = __cpu_to_le32(info->nat.flags);
+		action->nat.port = __cpu_to_le32(info->nat.port);
+		action->nat.dev = __cpu_to_le32(info->nat.dev);
+		break;
+	case PRESTERA_ACL_RULE_ACTION_COUNT:
+		action->count.id = __cpu_to_le32(info->count.id);
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
 }
 
-static int prestera_hw_port_flood_set_v2(struct prestera_port *port, bool flood)
+int prestera_hw_counter_trigger(const struct prestera_switch *sw, u32 block_id)
 {
-	struct prestera_msg_port_attr_req req = {
-		.attr = PRESTERA_CMD_PORT_ATTR_FLOOD,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {
-			.flood = flood,
-		}
+	struct prestera_msg_counter_req req = {
+		.block_id = __cpu_to_le32(block_id)
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_PORT_ATTR_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_COUNTER_TRIGGER, &req);
 }
 
-int prestera_hw_port_flood_set(struct prestera_port *port, unsigned long mask,
-			       unsigned long val)
+int prestera_hw_counter_abort(const struct prestera_switch *sw)
 {
-	int err;
+	struct prestera_msg_counter_req req;
 
-	if (port->sw->dev->fw_rev.maj <= 2) {
-		if (!(mask & BR_FLOOD))
-			return 0;
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_COUNTER_ABORT, &req);
+}
 
-		return prestera_hw_port_flood_set_v2(port, val & BR_FLOOD);
-	}
+int prestera_hw_counters_get(const struct prestera_switch *sw, u32 idx,
+			     u32 *len, bool *done,
+			     struct prestera_counter_stats *stats)
+{
+	struct prestera_msg_counter_resp *resp;
+	struct prestera_msg_counter_req req = {
+		.block_id = __cpu_to_le32(idx),
+		.num_counters = __cpu_to_le32(*len),
+	};
+	size_t size = sizeof(*resp) + sizeof(*resp->stats) * (*len);
+	int err, i;
 
-	if (mask & BR_FLOOD) {
-		err = prestera_hw_port_uc_flood_set(port, val & BR_FLOOD);
-		if (err)
-			goto err_uc_flood;
-	}
+	resp = kmalloc(size, GFP_KERNEL);
+	if (!resp)
+		return -ENOMEM;
 
-	if (mask & BR_MCAST_FLOOD) {
-		err = prestera_hw_port_mc_flood_set(port, val & BR_MCAST_FLOOD);
-		if (err)
-			goto err_mc_flood;
-	}
+	err = fw_send_nreq_nresp(sw, PRESTERA_CMD_TYPE_COUNTER_GET,
+				 &req, sizeof(req), resp, size);
+	if (err)
+		goto free_buff;
 
-	return 0;
+	for (i = 0; i < __le32_to_cpu(resp->num_counters); i++) {
+		stats[i].packets += __le64_to_cpu(resp->stats[i].packets);
+		stats[i].bytes += __le64_to_cpu(resp->stats[i].bytes);
+	}
 
-err_mc_flood:
-	prestera_hw_port_mc_flood_set(port, 0);
-err_uc_flood:
-	if (mask & BR_FLOOD)
-		prestera_hw_port_uc_flood_set(port, 0);
+	*len = __le32_to_cpu(resp->num_counters);
+	*done = resp->done;
 
+free_buff:
+	kfree(resp);
 	return err;
 }
 
-int prestera_hw_vlan_create(struct prestera_switch *sw, u16 vid)
+int prestera_hw_counter_block_get(const struct prestera_switch *sw,
+				  u32 client, u32 *block_id, u32 *offset,
+				  u32 *num_counters)
 {
-	struct prestera_msg_vlan_req req = {
-		.vid = vid,
+	struct prestera_msg_counter_resp resp;
+	struct prestera_msg_counter_req req = {
+		.client = __cpu_to_le32(client)
 	};
+	int err = 0;
+
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_COUNTER_BLOCK_GET,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	*block_id = __le32_to_cpu(resp.block_id);
+	*offset = __le32_to_cpu(resp.offset);
+	*num_counters = __le32_to_cpu(resp.num_counters);
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_VLAN_CREATE,
-			    &req.cmd, sizeof(req));
+	return 0;
 }
 
-int prestera_hw_vlan_delete(struct prestera_switch *sw, u16 vid)
+int prestera_hw_counter_block_release(const struct prestera_switch *sw,
+				      u32 block_id)
 {
-	struct prestera_msg_vlan_req req = {
-		.vid = vid,
+	struct prestera_msg_counter_req req = {
+		.block_id = __cpu_to_le32(block_id)
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_VLAN_DELETE,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_COUNTER_BLOCK_RELEASE, &req);
 }
 
-int prestera_hw_vlan_port_set(struct prestera_port *port, u16 vid,
-			      bool is_member, bool untagged)
+int prestera_hw_counter_clear(const struct prestera_switch *sw, u32 block_id,
+			      u32 counter_id)
 {
-	struct prestera_msg_vlan_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.vid = vid,
-		.is_member = is_member,
-		.is_tagged = !untagged,
+	struct prestera_msg_counter_req req = {
+		.block_id = __cpu_to_le32(block_id),
+		.num_counters = __cpu_to_le32(counter_id),
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_VLAN_PORT_SET,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_COUNTER_CLEAR, &req);
 }
 
-int prestera_hw_vlan_port_vid_set(struct prestera_port *port, u16 vid)
+int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
+				      unsigned char *mac)
 {
-	struct prestera_msg_vlan_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.vid = vid,
+	struct prestera_msg_nat_port_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
 	};
+	memcpy(req.neigh_mac, mac, sizeof(req.neigh_mac));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_NAT_PORT_NEIGH_UPDATE,
+			   &req);
+}
+
+int prestera_hw_nh_mangle_add(const struct prestera_switch *sw, u32 *nh_id)
+{
+	struct prestera_msg_nh_mangle_req req;
+	struct prestera_msg_nh_mangle_resp resp;
+	int err;
+
+	memset(&req, 0, sizeof(req));
+	memset(&resp, 0, sizeof(resp));
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_NAT_NH_MANGLE_ADD, &req,
+			       &resp);
+	if (err)
+		return err;
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_VLAN_PVID_SET,
-			    &req.cmd, sizeof(req));
+	*nh_id = __le32_to_cpu(resp.nh_id);
+	return 0;
 }
 
-int prestera_hw_vlan_port_stp_set(struct prestera_port *port, u16 vid, u8 state)
+int prestera_hw_nh_mangle_del(const struct prestera_switch *sw, u32 nh_id)
 {
-	struct prestera_msg_stp_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.vid = vid,
-		.state = state,
-	};
+	struct prestera_msg_nh_mangle_req req;
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_STP_PORT_SET,
-			    &req.cmd, sizeof(req));
+	memset(&req, 0, sizeof(req));
+	req.nh_id = __cpu_to_le32(nh_id);
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_NAT_NH_MANGLE_DEL, &req);
 }
 
-int prestera_hw_fdb_add(struct prestera_port *port, const unsigned char *mac,
-			u16 vid, bool dynamic)
+int prestera_hw_nh_mangle_set(const struct prestera_switch *sw, u32 nh_id,
+			      bool l4_src_valid, __be16 l4_src,
+			      bool l4_dst_valid, __be16 l4_dst,
+			      bool sip_valid, struct prestera_ip_addr sip,
+			      bool dip_valid, struct prestera_ip_addr dip,
+			      struct prestera_neigh_info nh)
 {
-	struct prestera_msg_fdb_req req = {
-		.dest = {
-			.dev = port->dev_id,
-			.port = port->hw_id,
-		},
-		.vid = vid,
-		.dynamic = dynamic,
-	};
+	struct prestera_msg_nh_mangle_req req;
+	int err;
+
+	if (sip.v != PRESTERA_IPV4 || dip.v != PRESTERA_IPV4)
+		return -EINVAL;
 
-	ether_addr_copy(req.mac, mac);
+	memset(&req, 0, sizeof(req));
+	req.nh_id = __cpu_to_le32(nh_id);
+	req.info.l4_src_valid = l4_src_valid;
+	req.info.l4_dst_valid = l4_dst_valid;
+	req.info.sip_valid = sip_valid;
+	req.info.dip_valid = dip_valid;
+	req.info.l4_src = l4_src;
+	req.info.l4_dst = l4_dst;
+	req.info.sip = sip.u.ipv4;
+	req.info.dip = dip.u.ipv4;
+	req.info.nh.is_active = nh.connected;
+	memcpy(&req.info.nh.mac, nh.ha, ETH_ALEN);
+	err = prestera_iface_to_msg(&nh.iface, &req.info.nh.oif);
+	if (err)
+		return err;
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_FDB_ADD,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_NAT_NH_MANGLE_SET, &req);
 }
 
-int prestera_hw_fdb_del(struct prestera_port *port, const unsigned char *mac,
-			u16 vid)
+int prestera_hw_nh_mangle_get(const struct prestera_switch *sw, u32 nh_id,
+			      bool *is_active)
 {
-	struct prestera_msg_fdb_req req = {
-		.dest = {
-			.dev = port->dev_id,
-			.port = port->hw_id,
-		},
-		.vid = vid,
-	};
+	struct prestera_msg_nh_mangle_req req;
+	struct prestera_msg_nh_mangle_resp resp;
+	int err;
 
-	ether_addr_copy(req.mac, mac);
+	memset(&req, 0, sizeof(req));
+	req.nh_id = __cpu_to_le32(nh_id);
+	memset(&resp, 0, sizeof(resp));
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_NAT_NH_MANGLE_GET, &req,
+			       &resp);
+	if (err)
+		return err;
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_FDB_DELETE,
-			    &req.cmd, sizeof(req));
+	*is_active = resp.info.nh.is_active;
+	return 0;
 }
 
-int prestera_hw_lag_fdb_add(struct prestera_switch *sw, u16 lag_id,
-			    const unsigned char *mac, u16 vid, bool dynamic)
+int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id)
 {
-	struct prestera_msg_fdb_req req = {
-		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_LAG,
-		.dest = {
-			.lag_id = lag_id,
-		},
-		.vid = vid,
-		.dynamic = dynamic,
+	int err;
+	struct prestera_msg_span_resp resp;
+	struct prestera_msg_span_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
 	};
 
-	ether_addr_copy(req.mac, mac);
+	err = fw_send_req_resp(port->sw, PRESTERA_CMD_TYPE_SPAN_GET,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	*span_id = resp.id;
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_FDB_ADD,
-			    &req.cmd, sizeof(req));
+	return 0;
 }
 
-int prestera_hw_lag_fdb_del(struct prestera_switch *sw, u16 lag_id,
-			    const unsigned char *mac, u16 vid)
+int prestera_hw_span_bind(const struct prestera_port *port, u8 span_id)
 {
-	struct prestera_msg_fdb_req req = {
-		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_LAG,
-		.dest = {
-			.lag_id = lag_id,
-		},
-		.vid = vid,
+	struct prestera_msg_span_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.id = span_id,
 	};
 
-	ether_addr_copy(req.mac, mac);
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_SPAN_BIND, &req);
+}
+
+int prestera_hw_span_unbind(const struct prestera_port *port)
+{
+	struct prestera_msg_span_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_FDB_DELETE,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_SPAN_UNBIND, &req);
 }
 
-int prestera_hw_fdb_flush_port(struct prestera_port *port, u32 mode)
+int prestera_hw_span_release(const struct prestera_switch *sw, u8 span_id)
 {
-	struct prestera_msg_fdb_req req = {
-		.dest = {
-			.dev = port->dev_id,
-			.port = port->hw_id,
-		},
-		.flush_mode = mode,
+	struct prestera_msg_span_req req = {
+		.id = span_id
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_FDB_FLUSH_PORT,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_SPAN_RELEASE, &req);
 }
 
-int prestera_hw_fdb_flush_vlan(struct prestera_switch *sw, u16 vid, u32 mode)
+int prestera_hw_lag_member_add(struct prestera_port *port, u16 lag_id)
 {
-	struct prestera_msg_fdb_req req = {
-		.vid = vid,
-		.flush_mode = mode,
+	struct prestera_msg_lag_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.lag_id = __cpu_to_le16(lag_id)
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_FDB_FLUSH_VLAN,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_LAG_ADD, &req);
 }
 
-int prestera_hw_fdb_flush_port_vlan(struct prestera_port *port, u16 vid,
-				    u32 mode)
+int prestera_hw_lag_member_del(struct prestera_port *port, u16 lag_id)
 {
-	struct prestera_msg_fdb_req req = {
-		.dest = {
-			.dev = port->dev_id,
-			.port = port->hw_id,
-		},
-		.vid = vid,
-		.flush_mode = mode,
+	struct prestera_msg_lag_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.lag_id = __cpu_to_le16(lag_id)
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_FDB_FLUSH_PORT_VLAN,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_LAG_DELETE, &req);
 }
 
-int prestera_hw_fdb_flush_lag(struct prestera_switch *sw, u16 lag_id,
-			      u32 mode)
+int prestera_hw_lag_member_enable(struct prestera_port *port, u16 lag_id,
+				  bool enable)
 {
-	struct prestera_msg_fdb_req req = {
-		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_LAG,
-		.dest = {
-			.lag_id = lag_id,
-		},
-		.flush_mode = mode,
+	u32 cmd;
+	struct prestera_msg_lag_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.lag_id = __cpu_to_le16(lag_id)
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_FDB_FLUSH_PORT,
-			    &req.cmd, sizeof(req));
+	cmd = enable ? PRESTERA_CMD_TYPE_LAG_ENABLE :
+			PRESTERA_CMD_TYPE_LAG_DISABLE;
+	return fw_send_req(port->sw, cmd, &req);
 }
 
-int prestera_hw_fdb_flush_lag_vlan(struct prestera_switch *sw,
-				   u16 lag_id, u16 vid, u32 mode)
+int prestera_hw_lag_member_rif_leave(const struct prestera_port *port,
+				     u16 lag_id, u16 vr_id)
 {
-	struct prestera_msg_fdb_req req = {
-		.dest_type = PRESTERA_HW_FDB_ENTRY_TYPE_LAG,
-		.dest = {
-			.lag_id = lag_id,
-		},
-		.vid = vid,
-		.flush_mode = mode,
+	struct prestera_msg_lag_req req = {
+		.port = __cpu_to_le32(port->hw_id),
+		.dev = __cpu_to_le32(port->dev_id),
+		.lag_id = __cpu_to_le16(lag_id),
+		.vr_id = __cpu_to_le16(vr_id)
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_FDB_FLUSH_PORT_VLAN,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_LAG_ROUTER_LEAVE, &req);
 }
 
-int prestera_hw_bridge_create(struct prestera_switch *sw, u16 *bridge_id)
+int
+prestera_hw_cpu_code_counters_get(const struct prestera_switch *sw, u8 code,
+				  enum prestera_hw_cpu_code_cnt_t counter_type,
+				  u64 *packet_count)
 {
-	struct prestera_msg_bridge_resp resp;
-	struct prestera_msg_bridge_req req;
+	struct prestera_msg_cpu_code_counter_req req = {
+		.counter_type = counter_type,
+		.code = code,
+	};
+	struct prestera_msg_cpu_code_counter_resp resp;
 	int err;
 
-	err = prestera_cmd_ret(sw, PRESTERA_CMD_TYPE_BRIDGE_CREATE,
-			       &req.cmd, sizeof(req),
-			       &resp.ret, sizeof(resp));
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_CPU_CODE_COUNTERS_GET,
+			       &req, &resp);
 	if (err)
 		return err;
 
-	*bridge_id = resp.bridge;
+	*packet_count = __le64_to_cpu(resp.packet_count);
 
 	return 0;
 }
 
-int prestera_hw_bridge_delete(struct prestera_switch *sw, u16 bridge_id)
+int prestera_hw_vtcam_create(const struct prestera_switch *sw,
+			     u8 lookup, const u32 *keymask, u32 *vtcam_id,
+			     u8 dir)
 {
-	struct prestera_msg_bridge_req req = {
-		.bridge = bridge_id,
+	int err;
+	struct prestera_msg_vtcam_resp resp;
+	struct prestera_msg_vtcam_create_req req = {
+		.lookup = lookup,
+		.direction = dir,
 	};
 
-	return prestera_cmd(sw, PRESTERA_CMD_TYPE_BRIDGE_DELETE,
-			    &req.cmd, sizeof(req));
-}
+	if (keymask)
+		memcpy(req.keymask, keymask, sizeof(req.keymask));
+	else
+		memset(req.keymask, 0, sizeof(req.keymask));
 
-int prestera_hw_bridge_port_add(struct prestera_port *port, u16 bridge_id)
-{
-	struct prestera_msg_bridge_req req = {
-		.bridge = bridge_id,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-	};
+	err = fw_send_req_resp(sw, PRESTERA_CMD_TYPE_VTCAM_CREATE, &req, &resp);
+	if (err)
+		return err;
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_BRIDGE_PORT_ADD,
-			    &req.cmd, sizeof(req));
+	*vtcam_id = __le32_to_cpu(resp.vtcam_id);
+	return 0;
 }
 
-int prestera_hw_bridge_port_delete(struct prestera_port *port, u16 bridge_id)
+int prestera_hw_vtcam_destroy(const struct prestera_switch *sw, u32 vtcam_id)
 {
-	struct prestera_msg_bridge_req req = {
-		.bridge = bridge_id,
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_vtcam_destroy_req req = {
+		.vtcam_id = __cpu_to_le32(vtcam_id),
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_BRIDGE_PORT_DELETE,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_VTCAM_DESTROY, &req);
 }
 
-int prestera_hw_rxtx_init(struct prestera_switch *sw,
-			  struct prestera_rxtx_params *params)
+int prestera_hw_vtcam_rule_add(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 prio, void *key, void *keymask,
+			       struct prestera_acl_hw_action_info *act,
+			       u8 n_act, u32 *rule_id)
 {
-	struct prestera_msg_rxtx_resp resp;
-	struct prestera_msg_rxtx_req req;
+	struct prestera_msg_acl_action *actions_msg;
+	struct prestera_msg_vtcam_rule_add_req *req;
+	struct prestera_msg_vtcam_resp resp;
+	void *buff;
+	u32 size;
 	int err;
+	u8 i;
+
+	size = sizeof(*req) + sizeof(*actions_msg) * n_act;
+
+	buff = kzalloc(size, GFP_KERNEL);
+	if (!buff)
+		return -ENOMEM;
+
+	req = buff;
+	req->n_act = __cpu_to_le32((u32)n_act);
+	actions_msg = buff + sizeof(*req);
+
+	/* put acl matches into the message */
+	memcpy(req->key, key, sizeof(req->key));
+	memcpy(req->keymask, keymask, sizeof(req->keymask));
+
+	/* put acl actions into the message */
+	for (i = 0; i < n_act; i++) {
+		err = acl_rule_add_put_action(&actions_msg[i], &act[i]);
+		if (err)
+			goto free_buff;
+	}
 
-	req.use_sdma = params->use_sdma;
+	req->vtcam_id = __cpu_to_le32(vtcam_id);
+	req->prio = __cpu_to_le32(prio);
 
-	err = prestera_cmd_ret(sw, PRESTERA_CMD_TYPE_RXTX_INIT,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = fw_send_nreq_resp(sw, PRESTERA_CMD_TYPE_VTCAM_RULE_ADD, req,
+				size, &resp);
 	if (err)
-		return err;
+		goto free_buff;
 
-	params->map_addr = resp.map_addr;
+	*rule_id = __le32_to_cpu(resp.rule_id);
+free_buff:
+	kfree(buff);
+	return err;
+}
 
-	return 0;
+int prestera_hw_vtcam_rule_del(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 rule_id)
+{
+	struct prestera_msg_vtcam_rule_del_req req = {
+		.vtcam_id = __cpu_to_le32(vtcam_id),
+		.id = __cpu_to_le32(rule_id)
+	};
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_VTCAM_RULE_DELETE, &req);
 }
 
-int prestera_hw_rxtx_port_init(struct prestera_port *port)
+int prestera_hw_vtcam_iface_bind(const struct prestera_switch *sw,
+				 struct prestera_acl_iface *iface,
+				 u32 vtcam_id, u16 pcl_id)
 {
-	struct prestera_msg_rxtx_port_req req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
+	struct prestera_msg_vtcam_bind_req req = {
+		.vtcam_id = __cpu_to_le32(vtcam_id),
+		.type = __cpu_to_le16(iface->type),
+		.pcl_id = __cpu_to_le16(pcl_id)
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_RXTX_PORT_INIT,
-			    &req.cmd, sizeof(req));
+	if (iface->type == PRESTERA_ACL_IFACE_TYPE_PORT) {
+		req.port.dev_id = __cpu_to_le32(iface->port->dev_id);
+		req.port.hw_id = __cpu_to_le32(iface->port->hw_id);
+	} else {
+		req.index = __cpu_to_le32(iface->index);
+	}
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_VTCAM_IFACE_BIND, &req);
 }
 
-int prestera_hw_lag_member_add(struct prestera_port *port, u16 lag_id)
+int prestera_hw_vtcam_iface_unbind(const struct prestera_switch *sw,
+				   struct prestera_acl_iface *iface,
+				   u32 vtcam_id)
 {
-	struct prestera_msg_lag_req req = {
+	struct prestera_msg_vtcam_bind_req req = {
+		.vtcam_id = __cpu_to_le32(vtcam_id),
+		.type = __cpu_to_le16(iface->type),
+	};
+
+	if (iface->type == PRESTERA_ACL_IFACE_TYPE_PORT) {
+		req.port.dev_id = __cpu_to_le32(iface->port->dev_id);
+		req.port.hw_id = __cpu_to_le32(iface->port->hw_id);
+	} else {
+		req.index = __cpu_to_le32(iface->index);
+	}
+
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_VTCAM_IFACE_UNBIND, &req);
+}
+
+int prestera_hw_port_qos_mapping_update(const struct prestera_port *port,
+					struct dcb_ieee_app_dscp_map *map)
+{
+	struct prestera_msg_qos_req req = {
 		.port = port->hw_id,
 		.dev = port->dev_id,
-		.lag_id = lag_id,
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_LAG_MEMBER_ADD,
-			    &req.cmd, sizeof(req));
+	memcpy(req.dscp, map->map, sizeof(req.dscp));
+
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_QOS_DSCP_PRIO_MAP_UPDATE,
+			   &req);
 }
 
-int prestera_hw_lag_member_del(struct prestera_port *port, u16 lag_id)
+int prestera_hw_port_qos_trust_mode_set(const struct prestera_port *port,
+					u8 mode)
 {
-	struct prestera_msg_lag_req req = {
+	struct prestera_msg_qos_req req = {
 		.port = port->hw_id,
 		.dev = port->dev_id,
-		.lag_id = lag_id,
+		.mode = mode,
 	};
 
-	return prestera_cmd(port->sw, PRESTERA_CMD_TYPE_LAG_MEMBER_DELETE,
-			    &req.cmd, sizeof(req));
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_QOS_TRUST_MODE_SET,
+			   &req);
 }
 
-int prestera_hw_lag_member_enable(struct prestera_port *port, u16 lag_id,
-				  bool enable)
+int prestera_hw_port_qos_default_prio_set(const struct prestera_port *port,
+					  u32 priority)
 {
-	struct prestera_msg_lag_req req = {
+	struct prestera_msg_qos_req req = {
 		.port = port->hw_id,
 		.dev = port->dev_id,
-		.lag_id = lag_id,
+		.priority = priority,
 	};
-	u32 cmd;
 
-	cmd = enable ? PRESTERA_CMD_TYPE_LAG_MEMBER_ENABLE :
-			PRESTERA_CMD_TYPE_LAG_MEMBER_DISABLE;
+	return fw_send_req(port->sw, PRESTERA_CMD_TYPE_QOS_DEFAULT_PRIO_SET,
+			   &req);
+}
+
+int prestera_hw_switch_reset(struct prestera_switch *sw)
+{
+	struct prestera_msg_common_req req;
 
-	return prestera_cmd(port->sw, cmd, &req.cmd, sizeof(req));
+	return fw_send_req(sw, PRESTERA_CMD_TYPE_SWITCH_RESET, &req);
 }
 
-int
-prestera_hw_cpu_code_counters_get(struct prestera_switch *sw, u8 code,
-				  enum prestera_hw_cpu_code_cnt_t counter_type,
-				  u64 *packet_count)
+int prestera_hw_flood_domain_create(struct prestera_flood_domain *domain)
 {
-	struct prestera_msg_cpu_code_counter_req req = {
-		.counter_type = counter_type,
-		.code = code,
-	};
-	struct mvsw_msg_cpu_code_counter_ret resp;
+	struct prestera_msg_flood_domain_create_resp resp;
+	struct prestera_msg_flood_domain_create_req req;
 	int err;
 
-	err = prestera_cmd_ret(sw, PRESTERA_CMD_TYPE_CPU_CODE_COUNTERS_GET,
-			       &req.cmd, sizeof(req), &resp.ret, sizeof(resp));
+	err = fw_send_req_resp(domain->sw,
+			       PRESTERA_CMD_TYPE_FLOOD_DOMAIN_CREATE, &req,
+			       &resp);
 	if (err)
 		return err;
 
-	*packet_count = resp.packet_count;
+	domain->idx = __le32_to_cpu(resp.flood_domain_idx);
 
 	return 0;
 }
 
-int prestera_hw_event_handler_register(struct prestera_switch *sw,
-				       enum prestera_event_type type,
-				       prestera_event_cb_t fn,
-				       void *arg)
+int prestera_hw_flood_domain_destroy(struct prestera_flood_domain *domain)
 {
-	struct prestera_fw_event_handler *eh;
+	struct prestera_msg_flood_domain_destroy_req req = {
+		.flood_domain_idx = __cpu_to_le32(domain->idx),
+	};
 
-	eh = __find_event_handler(sw, type);
-	if (eh)
-		return -EEXIST;
+	return fw_send_req(domain->sw, PRESTERA_CMD_TYPE_FLOOD_DOMAIN_DESTROY,
+			   &req);
+}
 
-	eh = kmalloc(sizeof(*eh), GFP_KERNEL);
-	if (!eh)
+int prestera_hw_flood_domain_ports_set(struct prestera_flood_domain *domain)
+{
+	struct prestera_flood_domain_port *flood_domain_port;
+	struct prestera_msg_flood_domain_ports_set_req *req;
+	struct prestera_msg_flood_domain_port *ports;
+	struct prestera_msg_common_resp resp = {0}; /* todo: generic macro to be used */
+	struct prestera_switch *sw = domain->sw;
+	struct prestera_port *port;
+	u32 ports_num = 0;
+	int buf_size;
+	void *buff;
+	u16 lag_id;
+	int err;
+
+	list_for_each_entry(flood_domain_port, &domain->flood_domain_port_list,
+			    flood_domain_port_node)
+		ports_num++;
+
+	if (!ports_num)
+		return -EINVAL;
+
+	buf_size = sizeof(*req) + sizeof(*ports) * ports_num;
+
+	buff = kmalloc(buf_size, GFP_KERNEL);
+	if (!buff)
 		return -ENOMEM;
 
-	eh->type = type;
-	eh->func = fn;
-	eh->arg = arg;
+	req = buff;
+	ports = buff + sizeof(*req);
+
+	req->flood_domain_idx = __cpu_to_le32(domain->idx);
+	req->ports_num = __cpu_to_le32(ports_num);
+
+	list_for_each_entry(flood_domain_port, &domain->flood_domain_port_list,
+			    flood_domain_port_node) {
+		if (netif_is_lag_master(flood_domain_port->dev)) {
+			if (prestera_lag_id_find(sw, flood_domain_port->dev,
+						 &lag_id)) {
+				kfree(buff);
+				return -EINVAL;
+			}
 
-	INIT_LIST_HEAD(&eh->list);
+			ports->port_type =
+				__cpu_to_le16(PRESTERA_HW_FLOOD_DOMAIN_PORT_TYPE_LAG);
+			ports->lag_id = __cpu_to_le16(lag_id);
+		} else {
+			port = prestera_port_dev_lower_find(flood_domain_port->dev);
 
-	list_add_rcu(&eh->list, &sw->event_handlers);
+			ports->port_type =
+				__cpu_to_le16(PRESTERA_HW_FDB_ENTRY_TYPE_REG_PORT);
+			ports->dev_num = __cpu_to_le32(port->dev_id);
+			ports->port_num = __cpu_to_le32(port->hw_id);
+		}
 
-	return 0;
+		ports->vid = __cpu_to_le16(flood_domain_port->vid);
+
+		ports++;
+	}
+
+	err = fw_send_nreq_resp(sw, PRESTERA_CMD_TYPE_FLOOD_DOMAIN_PORTS_SET,
+				req, buf_size, &resp);
+
+	kfree(buff);
+
+	return err;
 }
 
-void prestera_hw_event_handler_unregister(struct prestera_switch *sw,
-					  enum prestera_event_type type,
-					  prestera_event_cb_t fn)
+int prestera_hw_flood_domain_ports_reset(struct prestera_flood_domain *domain)
 {
-	struct prestera_fw_event_handler *eh;
+	struct prestera_msg_flood_domain_ports_reset_req req = {
+		.flood_domain_idx = __cpu_to_le32(domain->idx),
+	};
 
-	eh = __find_event_handler(sw, type);
-	if (!eh)
-		return;
+	return fw_send_req(domain->sw,
+			   PRESTERA_CMD_TYPE_FLOOD_DOMAIN_PORTS_RESET, &req);
+}
 
-	list_del_rcu(&eh->list);
-	kfree_rcu(eh, rcu);
+int prestera_hw_mdb_create(struct prestera_mdb_entry *mdb)
+{
+	struct prestera_msg_mdb_create_req req = {
+		.flood_domain_idx = __cpu_to_le32(mdb->flood_domain->idx),
+		.vid = __cpu_to_le16(mdb->vid),
+	};
+
+	memcpy(req.mac, mdb->addr, ETH_ALEN);
+
+	return fw_send_req(mdb->sw, PRESTERA_CMD_TYPE_MDB_CREATE, &req);
+}
+
+int prestera_hw_mdb_destroy(struct prestera_mdb_entry *mdb)
+{
+	struct prestera_msg_mdb_destroy_req req = {
+		.flood_domain_idx = __cpu_to_le32(mdb->flood_domain->idx),
+		.vid = __cpu_to_le16(mdb->vid),
+	};
+
+	memcpy(req.mac, mdb->addr, ETH_ALEN);
+
+	return fw_send_req(mdb->sw, PRESTERA_CMD_TYPE_MDB_DESTROY, &req);
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_hw.h b/drivers/net/ethernet/marvell/prestera/prestera_hw.h
index 546d5fd8240d..3bb50f71afd0 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_hw.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_hw.h
@@ -1,22 +1,31 @@
 /* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved. */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _PRESTERA_HW_H_
 #define _PRESTERA_HW_H_
 
 #include <linux/types.h>
 
-enum prestera_accept_frm_type {
+enum prestera_accept_frame_type {
 	PRESTERA_ACCEPT_FRAME_TYPE_TAGGED,
 	PRESTERA_ACCEPT_FRAME_TYPE_UNTAGGED,
-	PRESTERA_ACCEPT_FRAME_TYPE_ALL,
+	PRESTERA_ACCEPT_FRAME_TYPE_ALL
 };
 
-enum prestera_fdb_flush_mode {
-	PRESTERA_FDB_FLUSH_MODE_DYNAMIC = BIT(0),
-	PRESTERA_FDB_FLUSH_MODE_STATIC = BIT(1),
-	PRESTERA_FDB_FLUSH_MODE_ALL = PRESTERA_FDB_FLUSH_MODE_DYNAMIC
-					| PRESTERA_FDB_FLUSH_MODE_STATIC,
+enum {
+	PRESTERA_MAC_MODE_INTERNAL,
+	PRESTERA_MAC_MODE_SGMII,
+	PRESTERA_MAC_MODE_1000BASE_X,
+	PRESTERA_MAC_MODE_KR,
+	PRESTERA_MAC_MODE_KR2,
+	PRESTERA_MAC_MODE_KR4,
+	PRESTERA_MAC_MODE_CR,
+	PRESTERA_MAC_MODE_CR2,
+	PRESTERA_MAC_MODE_CR4,
+	PRESTERA_MAC_MODE_SR_LR,
+	PRESTERA_MAC_MODE_SR_LR2,
+	PRESTERA_MAC_MODE_SR_LR4,
+	PRESTERA_MAC_MODE_MAX
 };
 
 enum {
@@ -45,8 +54,7 @@ enum {
 	PRESTERA_LINK_MODE_100GbaseKR4_Full,
 	PRESTERA_LINK_MODE_100GbaseSR4_Full,
 	PRESTERA_LINK_MODE_100GbaseCR4_Full,
-
-	PRESTERA_LINK_MODE_MAX
+	PRESTERA_LINK_MODE_MAX,
 };
 
 enum {
@@ -58,35 +66,112 @@ enum {
 	PRESTERA_PORT_TYPE_BNC,
 	PRESTERA_PORT_TYPE_DA,
 	PRESTERA_PORT_TYPE_OTHER,
-
-	PRESTERA_PORT_TYPE_MAX
+	PRESTERA_PORT_TYPE_MAX,
 };
 
 enum {
 	PRESTERA_PORT_TCVR_COPPER,
 	PRESTERA_PORT_TCVR_SFP,
-
-	PRESTERA_PORT_TCVR_MAX
+	PRESTERA_PORT_TCVR_MAX,
 };
 
 enum {
 	PRESTERA_PORT_FEC_OFF,
 	PRESTERA_PORT_FEC_BASER,
 	PRESTERA_PORT_FEC_RS,
-
-	PRESTERA_PORT_FEC_MAX
+	PRESTERA_PORT_FEC_MAX,
 };
 
 enum {
 	PRESTERA_PORT_DUPLEX_HALF,
 	PRESTERA_PORT_DUPLEX_FULL,
+	PRESTERA_PORT_DUPLEX_MAX
 };
 
 enum {
 	PRESTERA_STP_DISABLED,
 	PRESTERA_STP_BLOCK_LISTEN,
 	PRESTERA_STP_LEARN,
-	PRESTERA_STP_FORWARD,
+	PRESTERA_STP_FORWARD
+};
+
+enum {
+	PRESTERA_FW_LOG_LIB_BRIDGE = 0,
+	PRESTERA_FW_LOG_LIB_CNC,
+	PRESTERA_FW_LOG_LIB_CONFIG,
+	PRESTERA_FW_LOG_LIB_COS,
+	PRESTERA_FW_LOG_LIB_HW_INIT,
+	PRESTERA_FW_LOG_LIB_CSCD,
+	PRESTERA_FW_LOG_LIB_CUT_THROUGH,
+	PRESTERA_FW_LOG_LIB_DIAG,
+	PRESTERA_FW_LOG_LIB_FABRIC,
+	PRESTERA_FW_LOG_LIB_IP,
+	PRESTERA_FW_LOG_LIB_IPFIX,
+	PRESTERA_FW_LOG_LIB_IP_LPM,
+	PRESTERA_FW_LOG_LIB_L2_MLL,
+	PRESTERA_FW_LOG_LIB_LOGICAL_TARGET,
+	PRESTERA_FW_LOG_LIB_LPM,
+	PRESTERA_FW_LOG_LIB_MIRROR,
+	PRESTERA_FW_LOG_LIB_MULTI_PORT_GROUP,
+	PRESTERA_FW_LOG_LIB_NETWORK_IF,
+	PRESTERA_FW_LOG_LIB_NST,
+	PRESTERA_FW_LOG_LIB_OAM,
+	PRESTERA_FW_LOG_LIB_PCL,
+	PRESTERA_FW_LOG_LIB_PHY,
+	PRESTERA_FW_LOG_LIB_POLICER,
+	PRESTERA_FW_LOG_LIB_PORT,
+	PRESTERA_FW_LOG_LIB_PROTECTION,
+	PRESTERA_FW_LOG_LIB_PTP,
+	PRESTERA_FW_LOG_LIB_SYSTEM_RECOVERY,
+	PRESTERA_FW_LOG_LIB_TCAM,
+	PRESTERA_FW_LOG_LIB_TM_GLUE,
+	PRESTERA_FW_LOG_LIB_TRUNK,
+	PRESTERA_FW_LOG_LIB_TTI,
+	PRESTERA_FW_LOG_LIB_TUNNEL,
+	PRESTERA_FW_LOG_LIB_VNT,
+	PRESTERA_FW_LOG_LIB_RESOURCE_MANAGER,
+	PRESTERA_FW_LOG_LIB_VERSION,
+	PRESTERA_FW_LOG_LIB_TM,
+	PRESTERA_FW_LOG_LIB_SMI,
+	PRESTERA_FW_LOG_LIB_INIT,
+	PRESTERA_FW_LOG_LIB_DRAGONITE,
+	PRESTERA_FW_LOG_LIB_VIRTUAL_TCAM,
+	PRESTERA_FW_LOG_LIB_INGRESS,
+	PRESTERA_FW_LOG_LIB_EGRESS,
+	PRESTERA_FW_LOG_LIB_LATENCY_MONITORING,
+	PRESTERA_FW_LOG_LIB_TAM,
+	PRESTERA_FW_LOG_LIB_EXACT_MATCH,
+	PRESTERA_FW_LOG_LIB_PHA,
+	PRESTERA_FW_LOG_LIB_PACKET_ANALYZER,
+	PRESTERA_FW_LOG_LIB_FLOW_MANAGER,
+	PRESTERA_FW_LOG_LIB_BRIDGE_FDB_MANAGER,
+	PRESTERA_FW_LOG_LIB_I2C,
+	PRESTERA_FW_LOG_LIB_PPU,
+	PRESTERA_FW_LOG_LIB_EXACT_MATCH_MANAGER,
+	PRESTERA_FW_LOG_LIB_MAC_SEC,
+	PRESTERA_FW_LOG_LIB_PTP_MANAGER,
+	PRESTERA_FW_LOG_LIB_HSR_PRP,
+	PRESTERA_FW_LOG_LIB_STREAM,
+	PRESTERA_FW_LOG_LIB_IPFIX_MANAGER,
+	PRESTERA_FW_LOG_LIB_ALL,
+
+	PRESTERA_FW_LOG_LIB_MAX
+};
+
+enum {
+	PRESTERA_FW_LOG_TYPE_INFO = 0,
+	PRESTERA_FW_LOG_TYPE_ENTRY_LEVEL_FUNCTION,
+	PRESTERA_FW_LOG_TYPE_ERROR,
+	PRESTERA_FW_LOG_TYPE_ALL,
+	PRESTERA_FW_LOG_TYPE_NONE,
+
+	PRESTERA_FW_LOG_TYPE_MAX
+};
+
+enum {
+	PRESTERA_PORT_STORM_CTL_TYPE_BC = 0,
+	PRESTERA_PORT_STORM_CTL_TYPE_UC_UNK = 1,
+	PRESTERA_PORT_STORM_CTL_TYPE_MC = 2
 };
 
 enum prestera_hw_cpu_code_cnt_t {
@@ -94,138 +179,260 @@ enum prestera_hw_cpu_code_cnt_t {
 	PRESTERA_HW_CPU_CODE_CNT_TYPE_TRAP = 1,
 };
 
+enum {
+	PRESTERA_HW_VTCAM_DIR_INGRESS = 0,
+	PRESTERA_HW_VTCAM_DIR_EGRESS = 1,
+};
+
+enum {
+	PRESTERA_HW_COUNTER_CLIENT_LOOKUP_0 = 0,
+	PRESTERA_HW_COUNTER_CLIENT_LOOKUP_1 = 1,
+	PRESTERA_HW_COUNTER_CLIENT_LOOKUP_2 = 2,
+};
+
+enum {
+	PRESTERA_HW_QOS_TRUST_MODE_L2 = 0,
+	PRESTERA_HW_QOS_TRUST_MODE_L3 = 1,
+};
+
 struct prestera_switch;
 struct prestera_port;
 struct prestera_port_stats;
 struct prestera_port_caps;
-enum prestera_event_type;
-struct prestera_event;
 struct prestera_acl_rule;
 
-typedef void (*prestera_event_cb_t)
-	(struct prestera_switch *sw, struct prestera_event *evt, void *arg);
+struct prestera_iface;
+struct prestera_neigh_info;
+struct prestera_counter_stats;
+struct prestera_acl_iface;
 
-struct prestera_rxtx_params;
+enum prestera_event_type;
+struct prestera_event;
 
 /* Switch API */
 int prestera_hw_switch_init(struct prestera_switch *sw);
-void prestera_hw_switch_fini(struct prestera_switch *sw);
-int prestera_hw_switch_ageing_set(struct prestera_switch *sw, u32 ageing_ms);
-int prestera_hw_switch_mac_set(struct prestera_switch *sw, const char *mac);
+int prestera_hw_switch_reset(struct prestera_switch *sw);
+int prestera_hw_switch_ageing_set(const struct prestera_switch *sw,
+				  u32 ageing_time);
+int prestera_hw_switch_mac_set(const struct prestera_switch *sw, const u8 *mac);
+int prestera_hw_switch_trap_policer_set(const struct prestera_switch *sw,
+					u8 profile);
 
 /* Port API */
 int prestera_hw_port_info_get(const struct prestera_port *port,
-			      u32 *dev_id, u32 *hw_id, u16 *fp_id);
-int prestera_hw_port_state_set(const struct prestera_port *port,
-			       bool admin_state);
+			      u16 *fp_id, u32 *hw_id, u32 *dev_id);
 int prestera_hw_port_mtu_set(const struct prestera_port *port, u32 mtu);
 int prestera_hw_port_mtu_get(const struct prestera_port *port, u32 *mtu);
-int prestera_hw_port_mac_set(const struct prestera_port *port, const char *mac);
+int prestera_hw_port_mac_set(const struct prestera_port *port, char *mac);
 int prestera_hw_port_mac_get(const struct prestera_port *port, char *mac);
+int prestera_hw_port_accept_frame_type_set(const struct prestera_port *port,
+					   enum prestera_accept_frame_type type);
+int prestera_hw_port_learning_set(const struct prestera_port *port,
+				  bool enable);
+int prestera_hw_port_uc_flood_set(const struct prestera_port *port, bool flood);
+int prestera_hw_port_mc_flood_set(const struct prestera_port *port, bool flood);
+int prestera_hw_port_srcid_default_set(const struct prestera_port *port,
+				       u32 sourceid);
+int prestera_hw_port_srcid_filter_set(const struct prestera_port *port,
+				      u32 sourceid);
 int prestera_hw_port_cap_get(const struct prestera_port *port,
 			     struct prestera_port_caps *caps);
-int prestera_hw_port_remote_cap_get(const struct prestera_port *port,
-				    u64 *link_mode_bitmap);
-int prestera_hw_port_remote_fc_get(const struct prestera_port *port,
-				   bool *pause, bool *asym_pause);
 int prestera_hw_port_type_get(const struct prestera_port *port, u8 *type);
-int prestera_hw_port_fec_get(const struct prestera_port *port, u8 *fec);
-int prestera_hw_port_fec_set(const struct prestera_port *port, u8 fec);
-int prestera_hw_port_autoneg_set(const struct prestera_port *port,
-				 bool autoneg, u64 link_modes, u8 fec);
-int prestera_hw_port_autoneg_restart(struct prestera_port *port);
-int prestera_hw_port_duplex_get(const struct prestera_port *port, u8 *duplex);
 int prestera_hw_port_stats_get(const struct prestera_port *port,
 			       struct prestera_port_stats *stats);
-int prestera_hw_port_link_mode_set(const struct prestera_port *port, u32 mode);
-int prestera_hw_port_link_mode_get(const struct prestera_port *port, u32 *mode);
-int prestera_hw_port_mdix_get(const struct prestera_port *port, u8 *status,
-			      u8 *admin_mode);
-int prestera_hw_port_mdix_set(const struct prestera_port *port, u8 mode);
-int prestera_hw_port_speed_get(const struct prestera_port *port, u32 *speed);
-int prestera_hw_port_learning_set(struct prestera_port *port, bool enable);
-int prestera_hw_port_flood_set(struct prestera_port *port, unsigned long mask,
-			       unsigned long val);
-int prestera_hw_port_accept_frm_type(struct prestera_port *port,
-				     enum prestera_accept_frm_type type);
+int prestera_hw_port_mac_mode_get(const struct prestera_port *port,
+				  u32 *mode, u32 *speed, u8 *duplex, u8 *fec);
+int prestera_hw_port_mac_mode_set(const struct prestera_port *port,
+				  bool admin, u32 mode, u8 inband,
+				  u32 speed, u8 duplex, u8 fec);
+int prestera_hw_port_phy_mode_get(const struct prestera_port *port,
+				  u8 *mdix, u64 *lmode_bmap,
+				  bool *fc_pause, bool *fc_asym);
+int prestera_hw_port_phy_mode_set(const struct prestera_port *port,
+				  bool admin, bool adv, u32 mode, u64 modes,
+				  u8 mdix);
+int prestera_hw_port_autoneg_restart(struct prestera_port *port);
+
+int prestera_hw_port_storm_control_cfg_set(const struct prestera_port *port,
+					   u32 storm_type,
+					   u32 kbyte_per_sec_rate);
+
 /* Vlan API */
-int prestera_hw_vlan_create(struct prestera_switch *sw, u16 vid);
-int prestera_hw_vlan_delete(struct prestera_switch *sw, u16 vid);
-int prestera_hw_vlan_port_set(struct prestera_port *port, u16 vid,
-			      bool is_member, bool untagged);
-int prestera_hw_vlan_port_vid_set(struct prestera_port *port, u16 vid);
-int prestera_hw_vlan_port_stp_set(struct prestera_port *port, u16 vid, u8 state);
+int prestera_hw_vlan_create(const struct prestera_switch *sw, u16 vid);
+int prestera_hw_vlan_delete(const struct prestera_switch *sw, u16 vid);
+int prestera_hw_vlan_port_set(const struct prestera_port *port,
+			      u16 vid, bool is_member, bool untagged);
+int prestera_hw_vlan_port_vid_set(const struct prestera_port *port, u16 vid);
 
 /* FDB API */
-int prestera_hw_fdb_add(struct prestera_port *port, const unsigned char *mac,
-			u16 vid, bool dynamic);
-int prestera_hw_fdb_del(struct prestera_port *port, const unsigned char *mac,
-			u16 vid);
-int prestera_hw_fdb_flush_port(struct prestera_port *port, u32 mode);
-int prestera_hw_fdb_flush_vlan(struct prestera_switch *sw, u16 vid, u32 mode);
-int prestera_hw_fdb_flush_port_vlan(struct prestera_port *port, u16 vid,
+int prestera_hw_fdb_add(const struct prestera_port *port,
+			const unsigned char *mac, u16 vid, bool dynamic);
+int prestera_hw_fdb_del(const struct prestera_port *port,
+			const unsigned char *mac, u16 vid);
+int prestera_hw_fdb_flush_port(const struct prestera_port *port, u32 mode);
+int prestera_hw_fdb_flush_vlan(const struct prestera_switch *sw, u16 vid,
+			       u32 mode);
+int prestera_hw_fdb_flush_port_vlan(const struct prestera_port *port, u16 vid,
 				    u32 mode);
+int prestera_hw_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
+			    const u8 *mac, u16 vid);
+int prestera_hw_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
+			    const u8 *mac, u16 vid);
 
 /* Bridge API */
-int prestera_hw_bridge_create(struct prestera_switch *sw, u16 *bridge_id);
-int prestera_hw_bridge_delete(struct prestera_switch *sw, u16 bridge_id);
-int prestera_hw_bridge_port_add(struct prestera_port *port, u16 bridge_id);
-int prestera_hw_bridge_port_delete(struct prestera_port *port, u16 bridge_id);
-
-/* ACL API */
-int prestera_hw_acl_ruleset_create(struct prestera_switch *sw,
-				   u16 *ruleset_id);
-int prestera_hw_acl_ruleset_del(struct prestera_switch *sw,
-				u16 ruleset_id);
-int prestera_hw_acl_rule_add(struct prestera_switch *sw,
-			     struct prestera_acl_rule *rule,
-			     u32 *rule_id);
-int prestera_hw_acl_rule_del(struct prestera_switch *sw, u32 rule_id);
-int prestera_hw_acl_rule_stats_get(struct prestera_switch *sw,
-				   u32 rule_id, u64 *packets, u64 *bytes);
-int prestera_hw_acl_port_bind(const struct prestera_port *port,
-			      u16 ruleset_id);
-int prestera_hw_acl_port_unbind(const struct prestera_port *port,
-				u16 ruleset_id);
+int prestera_hw_bridge_create(const struct prestera_switch *sw, u16 *bridge_id);
+int prestera_hw_bridge_delete(const struct prestera_switch *sw, u16 bridge_id);
+int prestera_hw_bridge_port_add(const struct prestera_port *port,
+				u16 bridge_id);
+int prestera_hw_bridge_port_delete(const struct prestera_port *port,
+				   u16 bridge_id);
+
+/* STP API */
+int prestera_hw_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state);
+
+/* Counter API */
+int prestera_hw_counter_trigger(const struct prestera_switch *sw, u32 block_id);
+int prestera_hw_counter_abort(const struct prestera_switch *sw);
+int prestera_hw_counters_get(const struct prestera_switch *sw, u32 idx,
+			     u32 *len, bool *done,
+			     struct prestera_counter_stats *stats);
+int prestera_hw_counter_block_get(const struct prestera_switch *sw, u32 client,
+				  u32 *block_id, u32 *offset, u32 *num_counters);
+int prestera_hw_counter_block_release(const struct prestera_switch *sw,
+				      u32 block_id);
+int prestera_hw_counter_clear(const struct prestera_switch *sw, u32 block_id,
+			      u32 counter_id);
+
+/* vTCAM API */
+int prestera_hw_vtcam_create(const struct prestera_switch *sw,
+			     u8 lookup, const u32 *keymask, u32 *vtcam_id,
+			     u8 direction);
+int prestera_hw_vtcam_rule_add(const struct prestera_switch *sw, u32 vtcam_id,
+			       u32 prio, void *key, void *keymask,
+			       struct prestera_acl_hw_action_info *act,
+			       u8 n_act, u32 *rule_id);
+int prestera_hw_vtcam_rule_del(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 rule_id);
+int prestera_hw_vtcam_destroy(const struct prestera_switch *sw, u32 vtcam_id);
+int prestera_hw_vtcam_iface_bind(const struct prestera_switch *sw,
+				 struct prestera_acl_iface *iface,
+				 u32 vtcam_id, u16 pcl_id);
+int prestera_hw_vtcam_iface_unbind(const struct prestera_switch *sw,
+				   struct prestera_acl_iface *iface,
+				   u32 vtcam_id);
+
+/* NAT API */
+int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
+				      unsigned char *mac);
+int prestera_hw_nh_mangle_add(const struct prestera_switch *sw, u32 *nh_id);
+int prestera_hw_nh_mangle_del(const struct prestera_switch *sw, u32 nh_id);
+int prestera_hw_nh_mangle_set(const struct prestera_switch *sw, u32 nh_id,
+			      bool l4_src_valid, __be16 l4_src,
+			      bool l4_dst_valid, __be16 l4_dst,
+			      bool sip_valid, struct prestera_ip_addr sip,
+			      bool dip_valid, struct prestera_ip_addr dip,
+			      struct prestera_neigh_info nh);
+int prestera_hw_nh_mangle_get(const struct prestera_switch *sw, u32 nh_id,
+			      bool *is_active);
 
 /* SPAN API */
 int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id);
 int prestera_hw_span_bind(const struct prestera_port *port, u8 span_id);
 int prestera_hw_span_unbind(const struct prestera_port *port);
-int prestera_hw_span_release(struct prestera_switch *sw, u8 span_id);
+int prestera_hw_span_release(const struct prestera_switch *sw, u8 span_id);
 
-/* Event handlers */
-int prestera_hw_event_handler_register(struct prestera_switch *sw,
-				       enum prestera_event_type type,
-				       prestera_event_cb_t fn,
-				       void *arg);
-void prestera_hw_event_handler_unregister(struct prestera_switch *sw,
-					  enum prestera_event_type type,
-					  prestera_event_cb_t fn);
+/* Router API */
+int prestera_hw_rif_create(const struct prestera_switch *sw,
+			   struct prestera_iface *iif, u8 *mac, u16 *rif_id);
+int prestera_hw_rif_delete(const struct prestera_switch *sw, u16 rif_id,
+			   struct prestera_iface *iif);
+int prestera_hw_rif_set(const struct prestera_switch *sw, u16 *rif_id,
+			struct prestera_iface *iif, u8 *mac);
+
+/* Virtual Router API */
+int prestera_hw_vr_create(const struct prestera_switch *sw, u16 *vr_id);
+int prestera_hw_vr_delete(const struct prestera_switch *sw, u16 vr_id);
+int prestera_hw_vr_abort(const struct prestera_switch *sw, u16 vr_id);
+
+/* LPM API */
+int prestera_hw_lpm_add(const struct prestera_switch *sw, u16 vr_id,
+			__be32 dst, u32 dst_len, u32 grp_id);
+int prestera_hw_lpm_del(const struct prestera_switch *sw, u16 vr_id, __be32 dst,
+			u32 dst_len);
 
-/* RX/TX */
-int prestera_hw_rxtx_init(struct prestera_switch *sw,
-			  struct prestera_rxtx_params *params);
-int prestera_hw_rxtx_port_init(struct prestera_port *port);
+/* NH API */
+int prestera_hw_nh_entries_set(const struct prestera_switch *sw, int count,
+			       struct prestera_neigh_info *nhs, u32 grp_id);
+int prestera_hw_nh_entries_get(const struct prestera_switch *sw, int count,
+			       struct prestera_neigh_info *nhs, u32 grp_id);
+int prestera_hw_nhgrp_blk_get(const struct prestera_switch *sw,
+			      u8 *hw_state, u32 buf_size /* Buffer in bytes */);
+int prestera_hw_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
+				u32 *grp_id);
+int prestera_hw_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
+				u32 grp_id);
+
+/* MP API */
+int prestera_hw_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy);
 
 /* LAG API */
 int prestera_hw_lag_member_add(struct prestera_port *port, u16 lag_id);
 int prestera_hw_lag_member_del(struct prestera_port *port, u16 lag_id);
 int prestera_hw_lag_member_enable(struct prestera_port *port, u16 lag_id,
 				  bool enable);
-int prestera_hw_lag_fdb_add(struct prestera_switch *sw, u16 lag_id,
+int prestera_hw_lag_fdb_add(const struct prestera_switch *sw, u16 lag_id,
 			    const unsigned char *mac, u16 vid, bool dynamic);
-int prestera_hw_lag_fdb_del(struct prestera_switch *sw, u16 lag_id,
+int prestera_hw_lag_fdb_del(const struct prestera_switch *sw, u16 lag_id,
 			    const unsigned char *mac, u16 vid);
-int prestera_hw_fdb_flush_lag(struct prestera_switch *sw, u16 lag_id,
+int prestera_hw_fdb_flush_lag(const struct prestera_switch *sw, u16 lag_id,
 			      u32 mode);
-int prestera_hw_fdb_flush_lag_vlan(struct prestera_switch *sw,
+int prestera_hw_fdb_flush_lag_vlan(const struct prestera_switch *sw,
 				   u16 lag_id, u16 vid, u32 mode);
+int prestera_hw_lag_member_rif_leave(const struct prestera_port *port,
+				     u16 lag_id, u16 vr_id);
+
+/* Event handlers */
+int prestera_hw_event_handler_register(struct prestera_switch *sw,
+				       enum prestera_event_type type,
+				       void (*cb)(struct prestera_switch *sw,
+						  struct prestera_event *evt,
+						  void *arg),
+				       void *arg);
+
+void prestera_hw_event_handler_unregister(struct prestera_switch *sw,
+					  enum prestera_event_type type);
+
+/* FW Log API */
+int prestera_hw_fw_log_level_set(const struct prestera_switch *sw, u32 lib,
+				 u32 type);
+
+int prestera_hw_rxtx_init(const struct prestera_switch *sw, bool use_sdma,
+			  u32 *map_addr);
+
+/* FW Keepalive/ Watchdog API */
+void prestera_hw_keepalive_fini(const struct prestera_switch *sw);
 
 /* HW trap/drop counters API */
 int
-prestera_hw_cpu_code_counters_get(struct prestera_switch *sw, u8 code,
+prestera_hw_cpu_code_counters_get(const struct prestera_switch *sw, u8 code,
 				  enum prestera_hw_cpu_code_cnt_t counter_type,
 				  u64 *packet_count);
 
+/* Flood domain / MDB API */
+int prestera_hw_flood_domain_create(struct prestera_flood_domain *domain);
+int prestera_hw_flood_domain_destroy(struct prestera_flood_domain *domain);
+int prestera_hw_flood_domain_ports_set(struct prestera_flood_domain *domain);
+int prestera_hw_flood_domain_ports_reset(struct prestera_flood_domain *domain);
+
+int prestera_hw_mdb_create(struct prestera_mdb_entry *mdb);
+int prestera_hw_mdb_destroy(struct prestera_mdb_entry *mdb);
+
+/* QoS */
+int prestera_hw_port_qos_mapping_update(const struct prestera_port *port,
+					struct dcb_ieee_app_dscp_map *map);
+int prestera_hw_port_qos_trust_mode_set(const struct prestera_port *port,
+					u8 mode);
+int prestera_hw_port_qos_default_prio_set(const struct prestera_port *port,
+					  u32 priority);
+
 #endif /* _PRESTERA_HW_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_log.c b/drivers/net/ethernet/marvell/prestera/prestera_log.c
new file mode 100644
index 000000000000..19f9bddf1b39
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_log.c
@@ -0,0 +1,201 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include "prestera_log.h"
+
+static const char unknown[] = "UNKNOWN";
+
+DEF_ENUM_MAP(netdev_cmd) = {
+	[NETDEV_UP] = "NETDEV_UP",
+	[NETDEV_DOWN] = "NETDEV_DOWN",
+	[NETDEV_REBOOT] = "NETDEV_REBOOT",
+	[NETDEV_CHANGE] = "NETDEV_CHANGE",
+	[NETDEV_REGISTER] = "NETDEV_REGISTER",
+	[NETDEV_UNREGISTER] = "NETDEV_UNREGISTER",
+	[NETDEV_CHANGEMTU] = "NETDEV_CHANGEMTU",
+	[NETDEV_CHANGEADDR] = "NETDEV_CHANGEADDR",
+	[NETDEV_PRE_CHANGEADDR] = "NETDEV_PRE_CHANGEADDR",
+	[NETDEV_GOING_DOWN] = "NETDEV_GOING_DOWN",
+	[NETDEV_CHANGENAME] = "NETDEV_CHANGENAME",
+	[NETDEV_FEAT_CHANGE] = "NETDEV_FEAT_CHANGE",
+	[NETDEV_BONDING_FAILOVER] = "NETDEV_BONDING_FAILOVER",
+	[NETDEV_PRE_UP] = "NETDEV_PRE_UP",
+	[NETDEV_PRE_TYPE_CHANGE] = "NETDEV_PRE_TYPE_CHANGE",
+	[NETDEV_POST_TYPE_CHANGE] = "NETDEV_POST_TYPE_CHANGE",
+	[NETDEV_POST_INIT] = "NETDEV_POST_INIT",
+	[NETDEV_RELEASE] = "NETDEV_RELEASE",
+	[NETDEV_NOTIFY_PEERS] = "NETDEV_NOTIFY_PEERS",
+	[NETDEV_JOIN] = "NETDEV_JOIN",
+	[NETDEV_CHANGEUPPER] = "NETDEV_CHANGEUPPER",
+	[NETDEV_RESEND_IGMP] = "NETDEV_RESEND_IGMP",
+	[NETDEV_PRECHANGEMTU] = "NETDEV_PRECHANGEMTU",
+	[NETDEV_CHANGEINFODATA] = "NETDEV_CHANGEINFODATA",
+	[NETDEV_BONDING_INFO] = "NETDEV_BONDING_INFO",
+	[NETDEV_PRECHANGEUPPER] = "NETDEV_PRECHANGEUPPER",
+	[NETDEV_CHANGELOWERSTATE] = "NETDEV_CHANGELOWERSTATE",
+	[NETDEV_UDP_TUNNEL_PUSH_INFO] = "NETDEV_UDP_TUNNEL_PUSH_INFO",
+	[NETDEV_UDP_TUNNEL_DROP_INFO] = "NETDEV_UDP_TUNNEL_DROP_INFO",
+	[NETDEV_CHANGE_TX_QUEUE_LEN] = "NETDEV_CHANGE_TX_QUEUE_LEN",
+	[NETDEV_CVLAN_FILTER_PUSH_INFO] = "NETDEV_CVLAN_FILTER_PUSH_INFO",
+	[NETDEV_CVLAN_FILTER_DROP_INFO] = "NETDEV_CVLAN_FILTER_DROP_INFO",
+	[NETDEV_SVLAN_FILTER_PUSH_INFO] = "NETDEV_SVLAN_FILTER_PUSH_INFO",
+	[NETDEV_SVLAN_FILTER_DROP_INFO] = "NETDEV_SVLAN_FILTER_DROP_INFO"
+};
+
+DEF_ENUM_MAP(switchdev_notifier_type) = {
+	[SWITCHDEV_FDB_ADD_TO_BRIDGE] = "SWITCHDEV_FDB_ADD_TO_BRIDGE",
+	[SWITCHDEV_FDB_DEL_TO_BRIDGE] = "SWITCHDEV_FDB_DEL_TO_BRIDGE",
+	[SWITCHDEV_FDB_ADD_TO_DEVICE] = "SWITCHDEV_FDB_ADD_TO_DEVICE",
+	[SWITCHDEV_FDB_DEL_TO_DEVICE] = "SWITCHDEV_FDB_DEL_TO_DEVICE",
+	[SWITCHDEV_FDB_OFFLOADED] = "SWITCHDEV_FDB_OFFLOADED",
+	[SWITCHDEV_PORT_OBJ_ADD] = "SWITCHDEV_PORT_OBJ_ADD",
+	[SWITCHDEV_PORT_OBJ_DEL] = "SWITCHDEV_PORT_OBJ_DEL",
+	[SWITCHDEV_PORT_ATTR_SET] = "SWITCHDEV_PORT_ATTR_SET",
+	[SWITCHDEV_VXLAN_FDB_ADD_TO_BRIDGE] =
+		"SWITCHDEV_VXLAN_FDB_ADD_TO_BRIDGE",
+	[SWITCHDEV_VXLAN_FDB_DEL_TO_BRIDGE] =
+		"SWITCHDEV_VXLAN_FDB_DEL_TO_BRIDGE",
+	[SWITCHDEV_VXLAN_FDB_ADD_TO_DEVICE] =
+		"SWITCHDEV_VXLAN_FDB_ADD_TO_DEVICE",
+	[SWITCHDEV_VXLAN_FDB_DEL_TO_DEVICE] =
+		"SWITCHDEV_VXLAN_FDB_DEL_TO_DEVICE",
+	[SWITCHDEV_VXLAN_FDB_OFFLOADED] = "SWITCHDEV_VXLAN_FDB_OFFLOADED"
+};
+
+DEF_ENUM_MAP(switchdev_attr_id) = {
+	[SWITCHDEV_ATTR_ID_UNDEFINED] =
+		"SWITCHDEV_ATTR_ID_UNDEFINED",
+	[SWITCHDEV_ATTR_ID_PORT_STP_STATE] =
+		"SWITCHDEV_ATTR_ID_PORT_STP_STATE",
+	[SWITCHDEV_ATTR_ID_PORT_BRIDGE_FLAGS] =
+		"SWITCHDEV_ATTR_ID_PORT_BRIDGE_FLAGS",
+	[SWITCHDEV_ATTR_ID_PORT_PRE_BRIDGE_FLAGS] =
+		"SWITCHDEV_ATTR_ID_PORT_PRE_BRIDGE_FLAGS",
+	[SWITCHDEV_ATTR_ID_PORT_MROUTER] =
+		"SWITCHDEV_ATTR_ID_PORT_MROUTER",
+	[SWITCHDEV_ATTR_ID_BRIDGE_AGEING_TIME] =
+		"SWITCHDEV_ATTR_ID_BRIDGE_AGEING_TIME",
+	[SWITCHDEV_ATTR_ID_BRIDGE_VLAN_FILTERING] =
+		"SWITCHDEV_ATTR_ID_BRIDGE_VLAN_FILTERING",
+	[SWITCHDEV_ATTR_ID_BRIDGE_MC_DISABLED] =
+		"SWITCHDEV_ATTR_ID_BRIDGE_MC_DISABLED",
+	[SWITCHDEV_ATTR_ID_BRIDGE_MROUTER] =
+		"SWITCHDEV_ATTR_ID_BRIDGE_MROUTER"
+};
+
+DEF_ENUM_MAP(switchdev_obj_id) = {
+	[SWITCHDEV_OBJ_ID_UNDEFINED] = "SWITCHDEV_OBJ_ID_UNDEFINED",
+	[SWITCHDEV_OBJ_ID_PORT_VLAN] = "SWITCHDEV_OBJ_ID_PORT_VLAN",
+	[SWITCHDEV_OBJ_ID_PORT_MDB] = "SWITCHDEV_OBJ_ID_PORT_MDB",
+	[SWITCHDEV_OBJ_ID_HOST_MDB] = "SWITCHDEV_OBJ_ID_HOST_MDB",
+};
+
+DEF_ENUM_MAP(fib_event_type) = {
+	[FIB_EVENT_ENTRY_REPLACE] = "FIB_EVENT_ENTRY_REPLACE",
+	[FIB_EVENT_ENTRY_APPEND] = "FIB_EVENT_ENTRY_APPEND",
+	[FIB_EVENT_ENTRY_ADD] = "FIB_EVENT_ENTRY_ADD",
+	[FIB_EVENT_ENTRY_DEL] = "FIB_EVENT_ENTRY_DEL",
+	[FIB_EVENT_RULE_ADD] = "FIB_EVENT_RULE_ADD",
+	[FIB_EVENT_RULE_DEL] = "FIB_EVENT_RULE_DEL",
+	[FIB_EVENT_NH_ADD] = "FIB_EVENT_NH_ADD",
+	[FIB_EVENT_NH_DEL] = "FIB_EVENT_NH_DEL",
+	[FIB_EVENT_VIF_ADD] = "FIB_EVENT_VIF_ADD",
+	[FIB_EVENT_VIF_DEL] = "FIB_EVENT_VIF_DEL",
+};
+
+DEF_ENUM_MAP(netevent_notif_type) = {
+	[NETEVENT_NEIGH_UPDATE] = "NETEVENT_NEIGH_UPDATE",
+	[NETEVENT_REDIRECT] = "NETEVENT_REDIRECT",
+	[NETEVENT_DELAY_PROBE_TIME_UPDATE] =
+		"NETEVENT_DELAY_PROBE_TIME_UPDATE",
+	[NETEVENT_IPV4_MPATH_HASH_UPDATE] =
+		"NETEVENT_IPV4_MPATH_HASH_UPDATE",
+	[NETEVENT_IPV6_MPATH_HASH_UPDATE] =
+		"NETEVENT_IPV6_MPATH_HASH_UPDATE",
+	[NETEVENT_IPV4_FWD_UPDATE_PRIORITY_UPDATE] =
+		"NETEVENT_IPV4_FWD_UPDATE_PRIORITY_UPDATE",
+};
+
+DEF_ENUM_MAP(tc_setup_type) = {
+	[TC_SETUP_QDISC_MQPRIO] = "TC_SETUP_QDISC_MQPRIO",
+	[TC_SETUP_CLSU32] = "TC_SETUP_CLSU32",
+	[TC_SETUP_CLSFLOWER] = "TC_SETUP_CLSFLOWER",
+	[TC_SETUP_CLSMATCHALL] = "TC_SETUP_CLSMATCHALL",
+	[TC_SETUP_CLSBPF] = "TC_SETUP_CLSBPF",
+	[TC_SETUP_BLOCK] = "TC_SETUP_BLOCK",
+	[TC_SETUP_QDISC_CBS] = "TC_SETUP_QDISC_CBS",
+	[TC_SETUP_QDISC_RED] = "TC_SETUP_QDISC_RED",
+	[TC_SETUP_QDISC_PRIO] = "TC_SETUP_QDISC_PRIO",
+	[TC_SETUP_QDISC_MQ] = "TC_SETUP_QDISC_MQ",
+	[TC_SETUP_QDISC_ETF] = "TC_SETUP_QDISC_ETF",
+	[TC_SETUP_ROOT_QDISC] = "TC_SETUP_ROOT_QDISC",
+	[TC_SETUP_QDISC_GRED] = "TC_SETUP_QDISC_GRED",
+};
+
+DEF_ENUM_MAP(flow_block_binder_type) = {
+	[FLOW_BLOCK_BINDER_TYPE_UNSPEC] =
+		"FLOW_BLOCK_BINDER_TYPE_UNSPEC",
+	[FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS] =
+		"FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS",
+	[FLOW_BLOCK_BINDER_TYPE_CLSACT_EGRESS] =
+		"FLOW_BLOCK_BINDER_TYPE_CLSACT_EGRESS",
+};
+
+DEF_ENUM_MAP(tc_matchall_command) = {
+	[TC_CLSMATCHALL_REPLACE] = "TC_CLSMATCHALL_REPLACE",
+	[TC_CLSMATCHALL_DESTROY] = "TC_CLSMATCHALL_DESTROY",
+	[TC_CLSMATCHALL_STATS] = "TC_CLSMATCHALL_STATS",
+};
+
+DEF_ENUM_MAP(flow_cls_command) = {
+	[FLOW_CLS_REPLACE] = "FLOW_CLS_REPLACE",
+	[FLOW_CLS_DESTROY] = "FLOW_CLS_DESTROY",
+	[FLOW_CLS_STATS] = "FLOW_CLS_STATS",
+	[FLOW_CLS_TMPLT_CREATE] = "FLOW_CLS_TMPLT_CREATE",
+	[FLOW_CLS_TMPLT_DESTROY] = "FLOW_CLS_TMPLT_DESTROY",
+};
+
+DEF_ENUM_MAP(flow_action_id) = {
+	[FLOW_ACTION_ACCEPT] = "FLOW_ACTION_ACCEPT",
+	[FLOW_ACTION_DROP] = "FLOW_ACTION_DROP",
+	[FLOW_ACTION_TRAP] = "FLOW_ACTION_TRAP",
+	[FLOW_ACTION_GOTO] = "FLOW_ACTION_GOTO",
+	[FLOW_ACTION_REDIRECT] = "FLOW_ACTION_REDIRECT",
+	[FLOW_ACTION_MIRRED] = "FLOW_ACTION_MIRRED",
+	[FLOW_ACTION_VLAN_PUSH] = "FLOW_ACTION_VLAN_PUSH",
+	[FLOW_ACTION_VLAN_POP] = "FLOW_ACTION_VLAN_POP",
+	[FLOW_ACTION_VLAN_MANGLE] = "FLOW_ACTION_VLAN_MANGLE",
+	[FLOW_ACTION_TUNNEL_ENCAP] = "FLOW_ACTION_TUNNEL_ENCAP",
+	[FLOW_ACTION_TUNNEL_DECAP] = "FLOW_ACTION_TUNNEL_DECAP",
+	[FLOW_ACTION_MANGLE] = "FLOW_ACTION_MANGLE",
+	[FLOW_ACTION_ADD] = "FLOW_ACTION_ADD",
+	[FLOW_ACTION_CSUM] = "FLOW_ACTION_CSUM",
+	[FLOW_ACTION_MARK] = "FLOW_ACTION_MARK",
+	[FLOW_ACTION_WAKE] = "FLOW_ACTION_WAKE",
+	[FLOW_ACTION_QUEUE] = "FLOW_ACTION_QUEUE",
+	[FLOW_ACTION_SAMPLE] = "FLOW_ACTION_SAMPLE",
+	[FLOW_ACTION_POLICE] = "FLOW_ACTION_POLICE",
+	[FLOW_ACTION_CT] = "FLOW_ACTION_CT",
+};
+
+DEF_ENUM_FUNC(netdev_cmd, NETDEV_UP, NETDEV_SVLAN_FILTER_DROP_INFO)
+
+DEF_ENUM_FUNC(switchdev_notifier_type, SWITCHDEV_FDB_ADD_TO_BRIDGE,
+	      SWITCHDEV_VXLAN_FDB_OFFLOADED)
+DEF_ENUM_FUNC(switchdev_attr_id, SWITCHDEV_ATTR_ID_UNDEFINED,
+	      SWITCHDEV_ATTR_ID_BRIDGE_MROUTER)
+DEF_ENUM_FUNC(switchdev_obj_id, SWITCHDEV_OBJ_ID_UNDEFINED,
+	      SWITCHDEV_OBJ_ID_HOST_MDB)
+
+DEF_ENUM_FUNC(fib_event_type, FIB_EVENT_ENTRY_REPLACE, FIB_EVENT_VIF_DEL)
+
+DEF_ENUM_FUNC(netevent_notif_type, NETEVENT_NEIGH_UPDATE,
+	      NETEVENT_IPV4_FWD_UPDATE_PRIORITY_UPDATE)
+
+/* TC traffic control */
+DEF_ENUM_FUNC(tc_setup_type, TC_SETUP_QDISC_MQPRIO, TC_SETUP_QDISC_GRED)
+DEF_ENUM_FUNC(flow_block_binder_type, FLOW_BLOCK_BINDER_TYPE_UNSPEC,
+	      FLOW_BLOCK_BINDER_TYPE_CLSACT_EGRESS)
+DEF_ENUM_FUNC(tc_matchall_command, TC_CLSMATCHALL_REPLACE, TC_CLSMATCHALL_STATS)
+DEF_ENUM_FUNC(flow_cls_command, FLOW_CLS_REPLACE, FLOW_CLS_TMPLT_DESTROY)
+DEF_ENUM_FUNC(flow_action_id, FLOW_ACTION_ACCEPT, FLOW_ACTION_CT)
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_log.h b/drivers/net/ethernet/marvell/prestera/prestera_log.h
new file mode 100644
index 000000000000..6fc8aa2b409d
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_log.h
@@ -0,0 +1,55 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _MVSW_PRESTERA_LOG_H_
+#define _MVSW_PRESTERA_LOG_H_
+
+#ifdef CONFIG_MRVL_PRESTERA_DEBUG
+
+#include <linux/netdevice.h>
+#include <linux/version.h>
+#include <net/switchdev.h>
+#include <net/fib_notifier.h>
+#include <net/netevent.h>
+#include <net/pkt_cls.h>
+
+#define DEF_ENUM_MAP(enum_name) \
+static const char *enum_name##_map[]
+
+#define DEF_ENUM_FUNC(enum_name, enum_min, enum_max) \
+const char *enum_name##_to_name(enum enum_name val) \
+{ \
+	if (val < enum_min || val > enum_max) \
+		return unknown; \
+	return enum_name##_map[val]; \
+}
+
+#define DEC_ENUM_FUNC(enum_name) \
+const char *enum_name##_to_name(enum enum_name)
+
+#define ENUM_TO_NAME(enum_name, val) enum_name##_to_name(val)
+
+#define MVSW_LOG_INFO(fmt, ...) \
+	pr_info("%s:%d: " fmt "\n", __func__, __LINE__, ##__VA_ARGS__)
+
+#define MVSW_LOG_ERROR(fmt, ...) \
+	pr_err("%s:%d: " fmt "\n", __func__, __LINE__, ##__VA_ARGS__)
+
+DEC_ENUM_FUNC(netdev_cmd);
+DEC_ENUM_FUNC(switchdev_notifier_type);
+DEC_ENUM_FUNC(switchdev_attr_id);
+DEC_ENUM_FUNC(switchdev_obj_id);
+DEC_ENUM_FUNC(fib_event_type);
+DEC_ENUM_FUNC(netevent_notif_type);
+DEC_ENUM_FUNC(tc_setup_type);
+DEC_ENUM_FUNC(flow_block_binder_type);
+DEC_ENUM_FUNC(tc_matchall_command);
+DEC_ENUM_FUNC(flow_cls_command);
+DEC_ENUM_FUNC(flow_action_id);
+
+#else /* CONFIG_MRVL_PRESTERA_DEBUG */
+#define MVSW_LOG_INFO(...)
+#define MVSW_LOG_ERROR(...)
+#endif /* CONFIG_MRVL_PRESTERA_DEBUG */
+
+#endif /* _MVSW_PRESTERA_LOG_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_main.c b/drivers/net/ethernet/marvell/prestera/prestera_main.c
index 44c670807fb3..99a0ad3e1bbd 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_main.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_main.c
@@ -1,123 +1,182 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
-#include <linux/etherdevice.h>
-#include <linux/jiffies.h>
-#include <linux/list.h>
+#include <linux/kernel.h>
 #include <linux/module.h>
+#include <linux/list.h>
+#include <linux/netdevice.h>
 #include <linux/netdev_features.h>
+#include <linux/inetdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ethtool.h>
+#include <linux/jiffies.h>
+#include <linux/if_bridge.h>
+#include <linux/phylink.h>
+#include <linux/of.h>
+#include <net/switchdev.h>
 #include <linux/of.h>
 #include <linux/of_net.h>
-#include <linux/if_vlan.h>
 
 #include "prestera.h"
+#include "prestera_log.h"
 #include "prestera_hw.h"
-#include "prestera_acl.h"
-#include "prestera_flow.h"
-#include "prestera_span.h"
-#include "prestera_rxtx.h"
+#include "prestera_debugfs.h"
 #include "prestera_devlink.h"
 #include "prestera_ethtool.h"
+#include "prestera_dsa.h"
+#include "prestera_rxtx.h"
+#include "prestera_drv_ver.h"
+#include "prestera_counter.h"
 #include "prestera_switchdev.h"
+#include "prestera_dcb.h"
 
-#define PRESTERA_MTU_DEFAULT	1536
-
-#define PRESTERA_STATS_DELAY_MS	1000
+static u8 trap_policer_profile = 1;
 
-#define PRESTERA_MAC_ADDR_NUM_MAX	255
+#define PRESTERA_MTU_DEFAULT 1536
+#define PRESTERA_MAC_ADDR_OFFSET 4
 
-static struct workqueue_struct *prestera_wq;
+#define PORT_STATS_CACHE_TIMEOUT_MS	(msecs_to_jiffies(1000))
 
-int prestera_port_pvid_set(struct prestera_port *port, u16 vid)
-{
-	enum prestera_accept_frm_type frm_type;
-	int err;
+static struct list_head switches_registered;
 
-	frm_type = PRESTERA_ACCEPT_FRAME_TYPE_TAGGED;
+static const char prestera_driver_name[] = "mvsw_switchdev";
 
-	if (vid) {
-		err = prestera_hw_vlan_port_vid_set(port, vid);
-		if (err)
-			return err;
+#define prestera_dev(sw)	((sw)->dev->dev)
 
-		frm_type = PRESTERA_ACCEPT_FRAME_TYPE_ALL;
-	}
+static struct workqueue_struct *prestera_wq;
 
-	err = prestera_hw_port_accept_frm_type(port, frm_type);
-	if (err && frm_type == PRESTERA_ACCEPT_FRAME_TYPE_ALL)
-		prestera_hw_vlan_port_vid_set(port, port->pvid);
+struct prestera_span_entry {
+	struct list_head list;
+	struct prestera_port *port;
+	refcount_t ref_count;
+	u8 id;
+};
 
-	port->pvid = vid;
-	return 0;
-}
+struct prestera_span {
+	struct prestera_switch *sw;
+	struct list_head entries;
+};
 
-struct prestera_port *prestera_port_find_by_hwid(struct prestera_switch *sw,
-						 u32 dev_id, u32 hw_id)
+struct prestera_port *dev_to_prestera_port(struct device *dev)
 {
-	struct prestera_port *port = NULL;
+	struct net_device *net_dev;
 
-	read_lock(&sw->port_list_lock);
-	list_for_each_entry(port, &sw->port_list, list) {
-		if (port->dev_id == dev_id && port->hw_id == hw_id)
-			break;
-	}
-	read_unlock(&sw->port_list_lock);
+	net_dev = container_of(dev, struct net_device, dev);
 
-	return port;
+	return netdev_priv(net_dev);
 }
 
-struct prestera_port *prestera_find_port(struct prestera_switch *sw, u32 id)
+static struct prestera_port *__find_pr_port(const struct prestera_switch *sw,
+					    u32 port_id)
 {
-	struct prestera_port *port = NULL;
+	struct prestera_port *port;
 
-	read_lock(&sw->port_list_lock);
 	list_for_each_entry(port, &sw->port_list, list) {
-		if (port->id == id)
-			break;
+		if (port->id == port_id)
+			return port;
 	}
-	read_unlock(&sw->port_list_lock);
 
-	return port;
+	return NULL;
 }
 
 static int prestera_port_open(struct net_device *dev)
 {
 	struct prestera_port *port = netdev_priv(dev);
-	int err;
+	struct prestera_port_mac_config cfg_mac;
+	int err = 0;
 
-	err = prestera_hw_port_state_set(port, true);
-	if (err)
-		return err;
+#ifdef CONFIG_PHYLINK
+	if (port->phy_link) {
+		phylink_start(port->phy_link);
+	} else {
+#endif
+		if (port->caps.transceiver == PRESTERA_PORT_TCVR_SFP) {
+			prestera_port_cfg_mac_read(port, &cfg_mac);
+			cfg_mac.admin = true;
+			prestera_port_cfg_mac_write(port, &cfg_mac);
+		} else {
+			port->cfg_phy.admin = true;
+			err = prestera_hw_port_phy_mode_set(port, true, port->autoneg,
+							    port->cfg_phy.mode,
+							    port->adver_link_modes,
+							    port->cfg_phy.mdix);
+		}
+#ifdef CONFIG_PHYLINK
+	}
+#endif
 
 	netif_start_queue(dev);
-
-	return 0;
+	return err;
 }
 
 static int prestera_port_close(struct net_device *dev)
 {
 	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_port_mac_config cfg_mac;
+	int err = 0;
 
-	netif_stop_queue(dev);
+#ifdef CONFIG_PHYLINK
+	if (port->phy_link) {
+		phylink_stop(port->phy_link);
+		phylink_disconnect_phy(port->phy_link);
+	}
+#endif
+	if (port->caps.transceiver == PRESTERA_PORT_TCVR_SFP) {
+		/* TODO: can we use somethink, like phylink callback ? */
+		/* ensure, that link is down */
+		/* TODO: use macros for operations like admin down-up ? */
+		prestera_port_cfg_mac_read(port, &cfg_mac);
+		cfg_mac.admin = false;
+		prestera_port_cfg_mac_write(port, &cfg_mac);
+	} else {
+		port->cfg_phy.admin = false;
+		err = prestera_hw_port_phy_mode_set(port, false, port->autoneg,
+						    port->cfg_phy.mode,
+						    port->adver_link_modes,
+						    port->cfg_phy.mdix);
+	}
+
+	/* TODO: does it make any sense ? */
+	 /* should not FDB all be cleared */
+	prestera_bridge_port_down(port);
 
-	return prestera_hw_port_state_set(port, false);
+	netif_stop_queue(dev);
+	return err;
 }
 
 static netdev_tx_t prestera_port_xmit(struct sk_buff *skb,
 				      struct net_device *dev)
 {
-	return prestera_rxtx_xmit(netdev_priv(dev), skb);
+	return prestera_rxtx_xmit(skb, netdev_priv(dev));
+}
+
+static int prestera_setup_tc(struct net_device *dev, enum tc_setup_type type,
+			     void *type_data)
+{
+	struct prestera_port *port = netdev_priv(dev);
+
+	switch (type) {
+	case TC_SETUP_BLOCK:
+		return prestera_setup_tc_block(port, type_data);
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static void prestera_set_rx_mode(struct net_device *dev)
+{
+	/* TO DO: add implementation */
 }
 
-static int prestera_is_valid_mac_addr(struct prestera_port *port, u8 *addr)
+static int prestera_valid_mac_addr(struct prestera_port *port, u8 *addr)
 {
+	int err;
+
 	if (!is_valid_ether_addr(addr))
 		return -EADDRNOTAVAIL;
 
-	/* firmware requires that port's MAC address contains first 5 bytes
-	 * of the base MAC address
-	 */
-	if (memcmp(port->sw->base_mac, addr, ETH_ALEN - 1))
+	err = memcmp(port->sw->base_mac, addr, ETH_ALEN - 1);
+	if (err)
 		return -EINVAL;
 
 	return 0;
@@ -129,17 +188,15 @@ static int prestera_port_set_mac_address(struct net_device *dev, void *p)
 	struct sockaddr *addr = p;
 	int err;
 
-	err = prestera_is_valid_mac_addr(port, addr->sa_data);
+	err = prestera_valid_mac_addr(port, addr->sa_data);
 	if (err)
 		return err;
 
 	err = prestera_hw_port_mac_set(port, addr->sa_data);
-	if (err)
-		return err;
-
-	ether_addr_copy(dev->dev_addr, addr->sa_data);
+	if (!err)
+		memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
 
-	return 0;
+	return err;
 }
 
 static int prestera_port_change_mtu(struct net_device *dev, int mtu)
@@ -147,13 +204,15 @@ static int prestera_port_change_mtu(struct net_device *dev, int mtu)
 	struct prestera_port *port = netdev_priv(dev);
 	int err;
 
-	err = prestera_hw_port_mtu_set(port, mtu);
-	if (err)
-		return err;
+	if (port->sw->mtu_min <= mtu && mtu <= port->sw->mtu_max)
+		err = prestera_hw_port_mtu_set(port, mtu);
+	else
+		err = -EINVAL;
 
-	dev->mtu = mtu;
+	if (!err)
+		dev->mtu = mtu;
 
-	return 0;
+	return err;
 }
 
 static void prestera_port_get_stats64(struct net_device *dev,
@@ -162,11 +221,11 @@ static void prestera_port_get_stats64(struct net_device *dev,
 	struct prestera_port *port = netdev_priv(dev);
 	struct prestera_port_stats *port_stats = &port->cached_hw_stats.stats;
 
-	stats->rx_packets = port_stats->broadcast_frames_received +
+	stats->rx_packets =	port_stats->broadcast_frames_received +
 				port_stats->multicast_frames_received +
 				port_stats->unicast_frames_received;
 
-	stats->tx_packets = port_stats->broadcast_frames_sent +
+	stats->tx_packets =	port_stats->broadcast_frames_sent +
 				port_stats->multicast_frames_sent +
 				port_stats->unicast_frames_sent;
 
@@ -191,438 +250,1195 @@ static void prestera_port_get_hw_stats(struct prestera_port *port)
 	prestera_hw_port_stats_get(port, &port->cached_hw_stats.stats);
 }
 
-static void prestera_port_stats_update(struct work_struct *work)
+static void update_stats_cache(struct work_struct *work)
 {
 	struct prestera_port *port =
 		container_of(work, struct prestera_port,
 			     cached_hw_stats.caching_dw.work);
 
+	rtnl_lock();
 	prestera_port_get_hw_stats(port);
+	rtnl_unlock();
 
 	queue_delayed_work(prestera_wq, &port->cached_hw_stats.caching_dw,
-			   msecs_to_jiffies(PRESTERA_STATS_DELAY_MS));
+			   PORT_STATS_CACHE_TIMEOUT_MS);
 }
 
-static int prestera_port_setup_tc(struct net_device *dev,
-				  enum tc_setup_type type,
-				  void *type_data)
+static int prestera_port_get_stats_cpu_hit(const struct net_device *dev,
+					   struct rtnl_link_stats64 *stats)
 {
 	struct prestera_port *port = netdev_priv(dev);
-
-	switch (type) {
-	case TC_SETUP_BLOCK:
-		return prestera_flow_block_setup(port, type_data);
-	default:
-		return -EOPNOTSUPP;
+	u64 rx_packets, rx_bytes, tx_packets, tx_bytes;
+	struct prestera_rxtx_stats *p;
+	u32 tx_dropped = 0;
+	unsigned int start;
+	int i;
+
+	for_each_possible_cpu(i) {
+		p = per_cpu_ptr(port->rxtx_stats, i);
+		do {
+			start = u64_stats_fetch_begin_irq(&p->syncp);
+			rx_packets = p->rx_packets;
+			rx_bytes = p->rx_bytes;
+			tx_packets = p->tx_packets;
+			tx_bytes = p->tx_bytes;
+		} while (u64_stats_fetch_retry_irq(&p->syncp, start));
+
+		stats->rx_packets += rx_packets;
+		stats->rx_bytes += rx_bytes;
+		stats->tx_packets += tx_packets;
+		stats->tx_bytes += tx_bytes;
+		/* tx_dropped is u32, updated without syncp protection. */
+		tx_dropped += p->tx_dropped;
 	}
+	stats->tx_dropped = tx_dropped;
+	return 0;
 }
 
-static const struct net_device_ops prestera_netdev_ops = {
-	.ndo_open = prestera_port_open,
-	.ndo_stop = prestera_port_close,
-	.ndo_start_xmit = prestera_port_xmit,
-	.ndo_setup_tc = prestera_port_setup_tc,
-	.ndo_change_mtu = prestera_port_change_mtu,
-	.ndo_get_stats64 = prestera_port_get_stats64,
-	.ndo_set_mac_address = prestera_port_set_mac_address,
-	.ndo_get_devlink_port = prestera_devlink_get_port,
-};
-
-int prestera_port_autoneg_set(struct prestera_port *port, bool enable,
-			      u64 adver_link_modes, u8 adver_fec)
+static bool prestera_port_has_offload_stats(const struct net_device *dev,
+					    int attr_id)
 {
-	bool refresh = false;
-	u64 link_modes;
-	int err;
-	u8 fec;
-
-	if (port->caps.type != PRESTERA_PORT_TYPE_TP)
-		return enable ? -EINVAL : 0;
-
-	if (!enable)
-		goto set_autoneg;
-
-	link_modes = port->caps.supp_link_modes & adver_link_modes;
-	fec = port->caps.supp_fec & adver_fec;
-
-	if (!link_modes && !fec)
-		return -EOPNOTSUPP;
-
-	if (link_modes && port->adver_link_modes != link_modes) {
-		port->adver_link_modes = link_modes;
-		refresh = true;
-	}
-
-	if (fec && port->adver_fec != fec) {
-		port->adver_fec = fec;
-		refresh = true;
-	}
-
-set_autoneg:
-	if (port->autoneg == enable && !refresh)
-		return 0;
-
-	err = prestera_hw_port_autoneg_set(port, enable, port->adver_link_modes,
-					   port->adver_fec);
-	if (err)
-		return err;
-
-	port->autoneg = enable;
-
-	return 0;
+	return attr_id == IFLA_OFFLOAD_XSTATS_CPU_HIT;
 }
 
-static void prestera_port_list_add(struct prestera_port *port)
+static int prestera_port_get_offload_stats(int attr_id,
+					   const struct net_device *dev,
+					   void *sp)
 {
-	write_lock(&port->sw->port_list_lock);
-	list_add(&port->list, &port->sw->port_list);
-	write_unlock(&port->sw->port_list_lock);
+	if (attr_id == IFLA_OFFLOAD_XSTATS_CPU_HIT)
+		return prestera_port_get_stats_cpu_hit(dev, sp);
+
+	return -EINVAL;
 }
 
-static void prestera_port_list_del(struct prestera_port *port)
+static int prestera_feature_hw_tc(struct net_device *dev, bool enable)
 {
-	write_lock(&port->sw->port_list_lock);
-	list_del(&port->list);
-	write_unlock(&port->sw->port_list_lock);
+	struct prestera_port *port = netdev_priv(dev);
+
+	if (!enable) {
+		if (prestera_acl_block_rule_count(port->flow_block)) {
+			netdev_err(dev, "Active offloaded tc filters, can't turn hw_tc_offload off\n");
+			return -EINVAL;
+		}
+		prestera_acl_block_disable_inc(port->flow_block);
+	} else {
+		prestera_acl_block_disable_dec(port->flow_block);
+	}
+	return 0;
 }
 
-static int prestera_port_create(struct prestera_switch *sw, u32 id)
+static int
+prestera_handle_feature(struct net_device *dev,
+			netdev_features_t wanted_features,
+			netdev_features_t feature,
+			int (*feature_handler)(struct net_device *dev,
+					       bool enable))
 {
-	struct prestera_port *port;
-	struct net_device *dev;
+	netdev_features_t changes = wanted_features ^ dev->features;
+	bool enable = !!(wanted_features & feature);
 	int err;
 
-	dev = alloc_etherdev(sizeof(*port));
-	if (!dev)
-		return -ENOMEM;
-
-	port = netdev_priv(dev);
-
-	INIT_LIST_HEAD(&port->vlans_list);
-	port->pvid = PRESTERA_DEFAULT_VID;
-	port->lag = NULL;
-	port->dev = dev;
-	port->id = id;
-	port->sw = sw;
+	if (!(changes & feature))
+		return 0;
 
-	err = prestera_hw_port_info_get(port, &port->dev_id, &port->hw_id,
-					&port->fp_id);
+	err = feature_handler(dev, enable);
 	if (err) {
-		dev_err(prestera_dev(sw), "Failed to get port(%u) info\n", id);
-		goto err_port_info_get;
+		netdev_err(dev, "%s feature %pNF failed, err %d\n",
+			   enable ? "Enable" : "Disable", &feature, err);
+		return err;
 	}
 
-	err = prestera_devlink_port_register(port);
-	if (err)
-		goto err_dl_port_register;
+	if (enable)
+		dev->features |= feature;
+	else
+		dev->features &= ~feature;
 
-	dev->features |= NETIF_F_NETNS_LOCAL | NETIF_F_HW_TC;
-	dev->netdev_ops = &prestera_netdev_ops;
-	dev->ethtool_ops = &prestera_ethtool_ops;
+	return 0;
+}
 
-	netif_carrier_off(dev);
+static int prestera_set_features(struct net_device *dev,
+				 netdev_features_t features)
+{
+	netdev_features_t oper_features = dev->features;
+	int err = 0;
 
-	dev->mtu = min_t(unsigned int, sw->mtu_max, PRESTERA_MTU_DEFAULT);
-	dev->min_mtu = sw->mtu_min;
-	dev->max_mtu = sw->mtu_max;
+	err |= prestera_handle_feature(dev, features, NETIF_F_HW_TC,
+				       prestera_feature_hw_tc);
 
-	err = prestera_hw_port_mtu_set(port, dev->mtu);
 	if (err) {
-		dev_err(prestera_dev(sw), "Failed to set port(%u) mtu(%d)\n",
-			id, dev->mtu);
-		goto err_port_init;
-	}
-
-	if (port->fp_id >= PRESTERA_MAC_ADDR_NUM_MAX) {
-		err = -EINVAL;
-		goto err_port_init;
+		dev->features = oper_features;
+		return -EINVAL;
 	}
 
-	/* firmware requires that port's MAC address consist of the first
-	 * 5 bytes of the base MAC address
-	 */
-	memcpy(dev->dev_addr, sw->base_mac, dev->addr_len - 1);
-	dev->dev_addr[dev->addr_len - 1] = port->fp_id;
+	return 0;
+}
 
-	err = prestera_hw_port_mac_set(port, dev->dev_addr);
-	if (err) {
-		dev_err(prestera_dev(sw), "Failed to set port(%u) mac addr\n", id);
-		goto err_port_init;
-	}
+static const struct net_device_ops prestera_netdev_ops = {
+	.ndo_open = prestera_port_open,
+	.ndo_stop = prestera_port_close,
+	.ndo_start_xmit = prestera_port_xmit,
+	.ndo_setup_tc = prestera_setup_tc,
+	.ndo_change_mtu = prestera_port_change_mtu,
+	.ndo_set_rx_mode = prestera_set_rx_mode,
+	.ndo_get_stats64 = prestera_port_get_stats64,
+	.ndo_set_features = prestera_set_features,
+	.ndo_set_mac_address = prestera_port_set_mac_address,
+	.ndo_has_offload_stats = prestera_port_has_offload_stats,
+	.ndo_get_offload_stats = prestera_port_get_offload_stats,
+	.ndo_get_devlink_port = prestera_devlink_get_port,
+};
 
-	err = prestera_hw_port_cap_get(port, &port->caps);
-	if (err) {
-		dev_err(prestera_dev(sw), "Failed to get port(%u) caps\n", id);
-		goto err_port_init;
-	}
+bool prestera_netdev_check(const struct net_device *dev)
+{
+	return dev->netdev_ops == &prestera_netdev_ops;
+}
 
-	port->adver_fec = BIT(PRESTERA_PORT_FEC_OFF);
-	prestera_port_autoneg_set(port, true, port->caps.supp_link_modes,
-				  port->caps.supp_fec);
+static int prestera_lower_dev_walk(struct net_device *dev,
+				   struct netdev_nested_priv *priv)
+{
+	struct prestera_port **pport = (struct prestera_port **)priv->data;
 
-	err = prestera_hw_port_state_set(port, false);
-	if (err) {
-		dev_err(prestera_dev(sw), "Failed to set port(%u) down\n", id);
-		goto err_port_init;
+	if (prestera_netdev_check(dev)) {
+		*pport = netdev_priv(dev);
+		return 1;
 	}
 
-	err = prestera_rxtx_port_init(port);
-	if (err)
-		goto err_port_init;
-
-	INIT_DELAYED_WORK(&port->cached_hw_stats.caching_dw,
-			  &prestera_port_stats_update);
+	return 0;
+}
 
-	prestera_port_list_add(port);
+struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev)
+{
+	struct prestera_port *port = NULL;
+	struct netdev_nested_priv priv = {
+		.data = (void *)&port,
+	};
 
-	err = register_netdev(dev);
-	if (err)
-		goto err_register_netdev;
+	if (!dev)
+		return NULL;
 
-	prestera_devlink_port_set(port);
+	if (prestera_netdev_check(dev))
+		return netdev_priv(dev);
 
-	return 0;
+	netdev_walk_all_lower_dev(dev, prestera_lower_dev_walk, &priv);
 
-err_register_netdev:
-	prestera_port_list_del(port);
-err_port_init:
-	prestera_devlink_port_unregister(port);
-err_dl_port_register:
-err_port_info_get:
-	free_netdev(dev);
-	return err;
+	return port;
 }
 
-static void prestera_port_destroy(struct prestera_port *port)
+struct prestera_switch *prestera_switch_get(struct net_device *dev)
 {
-	struct net_device *dev = port->dev;
+	struct prestera_port *port;
 
-	cancel_delayed_work_sync(&port->cached_hw_stats.caching_dw);
-	prestera_devlink_port_clear(port);
-	unregister_netdev(dev);
-	prestera_port_list_del(port);
-	prestera_devlink_port_unregister(port);
-	free_netdev(dev);
+	port = prestera_port_dev_lower_find(dev);
+	return port ? port->sw : NULL;
 }
 
-static void prestera_destroy_ports(struct prestera_switch *sw)
+int prestera_port_cfg_mac_read(struct prestera_port *port,
+			       struct prestera_port_mac_config *cfg)
 {
-	struct prestera_port *port, *tmp;
-
-	list_for_each_entry_safe(port, tmp, &sw->port_list, list)
-		prestera_port_destroy(port);
+	*cfg = port->cfg_mac;
+	return 0;
 }
 
-static int prestera_create_ports(struct prestera_switch *sw)
+int prestera_port_cfg_mac_write(struct prestera_port *port,
+				struct prestera_port_mac_config *cfg)
 {
-	struct prestera_port *port, *tmp;
-	u32 port_idx;
 	int err;
 
-	for (port_idx = 0; port_idx < sw->port_count; port_idx++) {
-		err = prestera_port_create(sw, port_idx);
-		if (err)
-			goto err_port_create;
-	}
+	err = prestera_hw_port_mac_mode_set(port, cfg->admin,
+					    cfg->mode, cfg->inband, cfg->speed,
+					    cfg->duplex, cfg->fec);
+	if (err)
+		return err;
 
+	port->cfg_mac = *cfg;
 	return 0;
+}
 
-err_port_create:
-	list_for_each_entry_safe(port, tmp, &sw->port_list, list)
-		prestera_port_destroy(port);
+void prestera_port_mac_state_cache_read(struct prestera_port *port,
+					struct prestera_port_mac_state *state)
+{
+	read_lock(&port->state_mac_lock);
+	*state = port->state_mac;
+	read_unlock(&port->state_mac_lock);
+}
 
-	return err;
+void prestera_port_mac_state_cache_write(struct prestera_port *port,
+					 struct prestera_port_mac_state *state)
+{
+	write_lock(&port->state_mac_lock);
+	port->state_mac = *state;
+	write_unlock(&port->state_mac_lock);
 }
 
-static void prestera_port_handle_event(struct prestera_switch *sw,
-				       struct prestera_event *evt, void *arg)
+/* TODO:  Rename, that it only for integral */
+int prestera_port_autoneg_set(struct prestera_port *port, u64 link_modes)
 {
-	struct delayed_work *caching_dw;
-	struct prestera_port *port;
+	/* TODO: Need separate config flow
+	 * for MAC-PHY link and PHY-PARTNER link
+	 */
+	if (port->autoneg == true && port->adver_link_modes == link_modes)
+		return 0;
 
-	port = prestera_find_port(sw, evt->port_evt.port_id);
-	if (!port || !port->dev)
-		return;
+	if (prestera_hw_port_phy_mode_set(port, port->cfg_phy.admin,
+					  true, 0, link_modes,
+					  port->cfg_phy.mdix))
+		return -EINVAL;
 
-	caching_dw = &port->cached_hw_stats.caching_dw;
+	/* TODO: move all this parameters to cfg_phy */
+	port->autoneg = true;
+	port->cfg_phy.mode = 0;
+	port->adver_link_modes = link_modes;
+	port->adver_fec = BIT(PRESTERA_PORT_FEC_OFF);
+	return 0;
+}
 
-	if (evt->id == PRESTERA_PORT_EVENT_STATE_CHANGED) {
-		if (evt->port_evt.data.oper_state) {
-			netif_carrier_on(port->dev);
-			if (!delayed_work_pending(caching_dw))
-				queue_delayed_work(prestera_wq, caching_dw, 0);
-		} else if (netif_running(port->dev) &&
-			   netif_carrier_ok(port->dev)) {
-			netif_carrier_off(port->dev);
-			if (delayed_work_pending(caching_dw))
-				cancel_delayed_work(caching_dw);
-		}
-	}
+int prestera_port_learning_set(struct prestera_port *port, bool learn)
+{
+	return prestera_hw_port_learning_set(port, learn);
 }
 
-static int prestera_event_handlers_register(struct prestera_switch *sw)
+int prestera_port_uc_flood_set(struct prestera_port *port, bool flood)
 {
-	return prestera_hw_event_handler_register(sw, PRESTERA_EVENT_TYPE_PORT,
-						  prestera_port_handle_event,
-						  NULL);
+	return prestera_hw_port_uc_flood_set(port, flood);
 }
 
-static void prestera_event_handlers_unregister(struct prestera_switch *sw)
+int prestera_port_mc_flood_set(struct prestera_port *port, bool flood)
 {
-	prestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_PORT,
-					     prestera_port_handle_event);
+	return prestera_hw_port_mc_flood_set(port, flood);
 }
 
-static int prestera_switch_set_base_mac_addr(struct prestera_switch *sw)
+/* Isolation group - is set of ports,
+ *  which can't comunicate with each other (symmetric).
+ * On other hand - we can configure asymmetric isolation
+ *  (when "default" and "filter" are equal).
+ * But this feature (asymmetric) left for future.
+ */
+int prestera_port_isolation_grp_set(struct prestera_port *port,
+				    u32 sourceid)
 {
-	struct device_node *base_mac_np;
-	struct device_node *np;
-	int ret;
+	int err;
 
-	np = of_find_compatible_node(NULL, NULL, "marvell,prestera");
-	base_mac_np = of_parse_phandle(np, "base-mac-provider", 0);
+	err = prestera_hw_port_srcid_default_set(port, sourceid);
+	if (err)
+		goto err_out;
 
-	ret = of_get_mac_address(base_mac_np, sw->base_mac);
-	if (ret) {
-		eth_random_addr(sw->base_mac);
-		dev_info(prestera_dev(sw), "using random base mac address\n");
-	}
-	of_node_put(base_mac_np);
+	err = prestera_hw_port_srcid_filter_set(port, sourceid);
+	if (err)
+		goto err_out;
 
-	return prestera_hw_switch_mac_set(sw, sw->base_mac);
-}
+	return 0;
 
-struct prestera_lag *prestera_lag_by_id(struct prestera_switch *sw, u16 id)
-{
-	return id < sw->lag_max ? &sw->lags[id] : NULL;
+err_out:
+	prestera_hw_port_srcid_default_set(port, PRESTERA_PORT_SRCID_ZERO);
+	prestera_hw_port_srcid_filter_set(port, PRESTERA_PORT_SRCID_ZERO);
+	return err;
 }
 
-static struct prestera_lag *prestera_lag_by_dev(struct prestera_switch *sw,
-						struct net_device *dev)
+int prestera_port_pvid_set(struct prestera_port *port, u16 vid)
 {
-	struct prestera_lag *lag;
-	u16 id;
+	int err;
 
-	for (id = 0; id < sw->lag_max; id++) {
-		lag = &sw->lags[id];
-		if (lag->dev == dev)
-			return lag;
+	if (!vid) {
+		err = prestera_hw_port_accept_frame_type_set
+		    (port, PRESTERA_ACCEPT_FRAME_TYPE_TAGGED);
+		if (err)
+			return err;
+	} else {
+		err = prestera_hw_vlan_port_vid_set(port, vid);
+		if (err)
+			return err;
+		err = prestera_hw_port_accept_frame_type_set
+		    (port, PRESTERA_ACCEPT_FRAME_TYPE_ALL);
+		if (err)
+			goto err_port_allow_untagged_set;
 	}
 
-	return NULL;
+	port->pvid = vid;
+	return 0;
+
+err_port_allow_untagged_set:
+	prestera_hw_vlan_port_vid_set(port, port->pvid);
+	return err;
 }
 
-static struct prestera_lag *prestera_lag_create(struct prestera_switch *sw,
-						struct net_device *lag_dev)
+int prestera_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state)
 {
-	struct prestera_lag *lag = NULL;
-	u16 id;
+	u8 hw_state = state;
 
-	for (id = 0; id < sw->lag_max; id++) {
-		lag = &sw->lags[id];
-		if (!lag->dev)
-			break;
-	}
-	if (lag) {
-		INIT_LIST_HEAD(&lag->members);
-		lag->dev = lag_dev;
-	}
+	switch (state) {
+	case BR_STATE_DISABLED:
+		hw_state = PRESTERA_STP_DISABLED;
+		break;
 
-	return lag;
-}
+	case BR_STATE_BLOCKING:
+	case BR_STATE_LISTENING:
+		hw_state = PRESTERA_STP_BLOCK_LISTEN;
+		break;
 
-static void prestera_lag_destroy(struct prestera_switch *sw,
-				 struct prestera_lag *lag)
-{
-	WARN_ON(!list_empty(&lag->members));
-	lag->member_count = 0;
-	lag->dev = NULL;
-}
+	case BR_STATE_LEARNING:
+		hw_state = PRESTERA_STP_LEARN;
+		break;
 
-static int prestera_lag_port_add(struct prestera_port *port,
-				 struct net_device *lag_dev)
+	case BR_STATE_FORWARDING:
+		hw_state = PRESTERA_STP_FORWARD;
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	return prestera_hw_port_vid_stp_set(port, vid, hw_state);
+}
+
+struct prestera_port_vlan*
+prestera_port_vlan_find_by_vid(const struct prestera_port *port, u16 vid)
+{
+	struct prestera_port_vlan *port_vlan;
+
+	list_for_each_entry(port_vlan, &port->vlans_list, list) {
+		if (port_vlan->vid == vid)
+			return port_vlan;
+	}
+
+	return NULL;
+}
+
+struct prestera_port_vlan*
+prestera_port_vlan_create(struct prestera_port *port, u16 vid, bool untagged)
+{
+	struct prestera_port_vlan *port_vlan;
+	int err;
+
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
+	if (port_vlan)
+		return ERR_PTR(-EEXIST);
+
+	err = prestera_port_vlan_set(port, vid, true, untagged);
+	if (err)
+		return ERR_PTR(err);
+
+	port_vlan = kzalloc(sizeof(*port_vlan), GFP_KERNEL);
+	if (!port_vlan) {
+		err = -ENOMEM;
+		goto err_port_vlan_alloc;
+	}
+
+	port_vlan->port = port;
+	port_vlan->vid = vid;
+
+	list_add(&port_vlan->list, &port->vlans_list);
+
+	return port_vlan;
+
+err_port_vlan_alloc:
+	prestera_port_vlan_set(port, vid, false, false);
+	return ERR_PTR(err);
+}
+
+static void
+prestera_port_vlan_cleanup(struct prestera_port_vlan *port_vlan)
+{
+	if (port_vlan->bridge_port)
+		prestera_port_vlan_bridge_leave(port_vlan);
+}
+
+void prestera_port_vlan_destroy(struct prestera_port_vlan *port_vlan)
+{
+	struct prestera_port *port = port_vlan->port;
+	u16 vid = port_vlan->vid;
+
+	prestera_port_vlan_cleanup(port_vlan);
+	list_del(&port_vlan->list);
+	kfree(port_vlan);
+	prestera_hw_vlan_port_set(port, vid, false, false);
+}
+
+int prestera_port_vlan_set(struct prestera_port *port, u16 vid,
+			   bool is_member, bool untagged)
+{
+	return prestera_hw_vlan_port_set(port, vid, is_member, untagged);
+}
+
+#ifdef CONFIG_PHYLINK
+static void prestera_link_validate(struct phylink_config *config,
+				   unsigned long *supported,
+				   struct phylink_link_state *state)
+{
+	__ETHTOOL_DECLARE_LINK_MODE_MASK(mask) = {0,};
+
+	if (state->interface != PHY_INTERFACE_MODE_NA &&
+	    state->interface != PHY_INTERFACE_MODE_10GBASER &&
+	    state->interface != PHY_INTERFACE_MODE_SGMII &&
+	    !phy_interface_mode_is_8023z(state->interface)) {
+		bitmap_zero(supported, __ETHTOOL_LINK_MODE_MASK_NBITS);
+		return;
+	}
+
+	switch (state->interface) {
+	case PHY_INTERFACE_MODE_10GBASER:
+	case PHY_INTERFACE_MODE_NA:
+		phylink_set(mask, 10000baseT_Full);
+		phylink_set(mask, 10000baseCR_Full);
+		phylink_set(mask, 10000baseSR_Full);
+		phylink_set(mask, 10000baseLR_Full);
+		phylink_set(mask, 10000baseLRM_Full);
+		phylink_set(mask, 10000baseER_Full);
+		phylink_set(mask, 10000baseKR_Full);
+		phylink_set(mask, 10000baseKX4_Full);
+		phylink_set(mask, 10000baseR_FEC);
+
+		if (state->interface != PHY_INTERFACE_MODE_NA)
+			break;
+		/* Fall-through */
+	case PHY_INTERFACE_MODE_SGMII:
+		phylink_set(mask, 10baseT_Full);
+		phylink_set(mask, 100baseT_Full);
+		phylink_set(mask, 1000baseT_Full);
+		if (state->interface != PHY_INTERFACE_MODE_NA) {
+			phylink_set(mask, Autoneg);
+			break;
+		}
+		/* Fall-through */
+	case PHY_INTERFACE_MODE_2500BASEX:
+		phylink_set(mask, 2500baseT_Full);
+		phylink_set(mask, 2500baseX_Full);
+		if (state->interface != PHY_INTERFACE_MODE_NA)
+			break;
+		/* Fall-through */
+	case PHY_INTERFACE_MODE_1000BASEX:
+		phylink_set(mask, 1000baseT_Full);
+		phylink_set(mask, 1000baseX_Full);
+		if (state->interface != PHY_INTERFACE_MODE_NA)
+			phylink_set(mask, Autoneg);
+		break;
+	default:
+		goto empty_set;
+	}
+
+	phylink_set_port_modes(mask);
+
+	bitmap_and(supported, supported, mask,
+		__ETHTOOL_LINK_MODE_MASK_NBITS);
+	bitmap_and(state->advertising, state->advertising, mask,
+		__ETHTOOL_LINK_MODE_MASK_NBITS);
+
+	phylink_helper_basex_speed(state);
+
+	return;
+
+empty_set:
+	bitmap_zero(supported, __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static void prestera_mac_pcs_get_state(struct phylink_config *config,
+				       struct phylink_link_state *state)
+{
+	struct net_device *ndev = to_net_dev(config->dev);
+	struct prestera_port *port = netdev_priv(ndev);
+	struct prestera_port_mac_state smac;
+
+	prestera_port_mac_state_cache_read(port, &smac);
+
+	if (smac.valid) {
+		state->link = smac.oper;
+		state->pause = 0;
+		/* AN is completed, when port is up */
+		state->an_complete = smac.oper ? port->autoneg : false;
+		state->speed = smac.speed;
+		state->duplex = smac.duplex;
+	} else {
+		state->link = false;
+		state->pause = 0;
+		state->an_complete = false;
+		state->speed = SPEED_UNKNOWN;
+		state->duplex = DUPLEX_UNKNOWN;
+	}
+}
+
+static void prestera_mac_config(struct phylink_config *config,
+				unsigned int an_mode,
+				const struct phylink_link_state *state)
+{
+	struct net_device *ndev = to_net_dev(config->dev);
+	struct prestera_port *port = netdev_priv(ndev);
+	struct prestera_port_mac_config cfg_mac;
+
+	prestera_port_cfg_mac_read(port, &cfg_mac);
+	cfg_mac.admin = true;
+	cfg_mac.mode = PRESTERA_MAC_MODE_MAX;
+	cfg_mac.inband = false;
+	cfg_mac.speed = 0;
+	cfg_mac.duplex = DUPLEX_UNKNOWN;
+	cfg_mac.fec = PRESTERA_PORT_FEC_OFF;
+
+	/* See sfp_select_interface... fIt */
+	switch (state->interface) {
+	case PHY_INTERFACE_MODE_10GBASER:
+		cfg_mac.mode = PRESTERA_MAC_MODE_SR_LR;
+		cfg_mac.speed = SPEED_10000;
+		if (state->speed == SPEED_1000)
+			cfg_mac.mode = PRESTERA_MAC_MODE_1000BASE_X;
+		if (state->speed == SPEED_2500) {
+			cfg_mac.mode = PRESTERA_MAC_MODE_SGMII;
+			cfg_mac.inband = true;
+			cfg_mac.speed = SPEED_2500;
+			cfg_mac.duplex = DUPLEX_FULL;
+		}
+		break;
+	case PHY_INTERFACE_MODE_2500BASEX:
+		/* But it seems to be not supported in HW */
+		cfg_mac.mode = PRESTERA_MAC_MODE_SGMII;
+		cfg_mac.inband = true;
+		cfg_mac.speed = SPEED_2500;
+		cfg_mac.duplex = DUPLEX_FULL;
+		break;
+	case PHY_INTERFACE_MODE_SGMII:
+		cfg_mac.mode = PRESTERA_MAC_MODE_SGMII;
+		cfg_mac.inband = true;
+		break;
+	case PHY_INTERFACE_MODE_1000BASEX:
+		cfg_mac.mode = PRESTERA_MAC_MODE_1000BASE_X;
+		cfg_mac.inband = state->an_enabled;
+		break;
+	default:
+		cfg_mac.mode = PRESTERA_MAC_MODE_1000BASE_X;
+	}
+
+	prestera_port_cfg_mac_write(port, &cfg_mac);
+}
+
+int prestera_mac_finish(struct phylink_config *config, unsigned int mode,
+			phy_interface_t iface)
+{
+	return 0;
+}
+
+static void prestera_mac_an_restart(struct phylink_config *config)
+{
+	/* No need to restart autoneg as it is always with the same parameters,
+	 * because e.g. as for 1000baseX FC isn't supported. And for 1000baseT
+	 * autoneg provided by external tranciever
+	 */
+}
+
+static void prestera_mac_link_down(struct phylink_config *config,
+				   unsigned int mode, phy_interface_t interface)
+{
+	struct net_device *ndev = to_net_dev(config->dev);
+	struct prestera_port *port = netdev_priv(ndev);
+	struct prestera_port_mac_state state_mac;
+
+	/* Invalidate. Parameters will update on next link event. */
+	memset(&state_mac, 0, sizeof(state_mac));
+	state_mac.valid = false;
+	prestera_port_mac_state_cache_write(port, &state_mac);
+}
+
+static void prestera_mac_link_up(struct phylink_config *config,
+				 struct phy_device *phy,
+				 unsigned int mode, phy_interface_t interface,
+				 int speed, int duplex,
+				 bool tx_pause, bool rx_pause)
+{
+}
+
+static const struct phylink_mac_ops prestera_mac_ops = {
+	.validate = prestera_link_validate,
+	.mac_pcs_get_state = prestera_mac_pcs_get_state,
+	.mac_config = prestera_mac_config,
+	.mac_finish = prestera_mac_finish,
+	.mac_an_restart = prestera_mac_an_restart,
+	.mac_link_down = prestera_mac_link_down,
+	.mac_link_up = prestera_mac_link_up,
+};
+
+static int prestera_port_sfp_bind(struct prestera_port *port)
 {
 	struct prestera_switch *sw = port->sw;
-	struct prestera_lag *lag;
+	struct device_node *ports, *node;
+	struct fwnode_handle *fwnode;
+	struct phylink *phy_link;
+	int err;
+
+	if (!sw->np)
+		return 0;
+
+	of_node_get(sw->np);
+
+	ports = of_find_node_by_name(sw->np, "ports");
+
+	for_each_child_of_node(ports, node) {
+		int num;
+
+		err = of_property_read_u32(node, "prestera,port-num", &num);
+		if (err) {
+			dev_err(sw->dev->dev,
+				"device node %pOF has no valid reg property: %d\n",
+				node, err);
+			return err;
+		}
+
+		if (port->fp_id != num)
+			continue;
+
+		port->phy_config.dev = &port->net_dev->dev;
+		port->phy_config.type = PHYLINK_NETDEV;
+		port->phy_config.pcs_poll = false;
+
+		fwnode = of_fwnode_handle(node);
+
+		phy_link = phylink_create(&port->phy_config, fwnode,
+					  PHY_INTERFACE_MODE_INTERNAL,
+					  &prestera_mac_ops);
+		if (IS_ERR(phy_link)) {
+			netdev_err(port->net_dev, "failed to create phylink\n");
+			return PTR_ERR(phy_link);
+		}
+
+		port->phy_link = phy_link;
+		break;
+	}
+
+	return 0;
+}
+#else
+static int prestera_port_sfp_bind(struct prestera_port *port)
+{
+	return 0;
+}
+#endif
+
+static void __prestera_ports_free(struct prestera_switch *sw);
+static void __prestera_ports_unregister(struct prestera_switch *sw);
+
+/* alloc structures and configure HW */
+static int __prestera_ports_alloc(struct prestera_switch *sw)
+{
+	struct net_device *net_dev;
+	struct prestera_port *port;
+	struct prestera_port_mac_config cfg_mac;
+	char *mac;
+	int err;
+	u32 id;
+
+	for (id = 0; id < sw->port_count; id++) {
+		net_dev = alloc_etherdev(sizeof(*port));
+		if (!net_dev) {
+			err = -ENOMEM;
+			goto err_alloc_etherdev;
+		}
+
+		port = netdev_priv(net_dev);
+
+		port->rxtx_stats =
+			netdev_alloc_pcpu_stats(struct prestera_rxtx_stats);
+		if (!port->rxtx_stats) {
+			err = -ENOMEM;
+			goto err_alloc_stats;
+		}
+
+		INIT_LIST_HEAD(&port->vlans_list);
+		port->pvid = PRESTERA_DEFAULT_VID;
+		port->net_dev = net_dev;
+		port->id = id;
+		port->sw = sw;
+		port->lag_id = sw->lag_max;
+
+		err = prestera_hw_port_info_get(port, &port->fp_id,
+						&port->hw_id, &port->dev_id);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to get port(%u) info\n", id);
+			goto err_port_info_get;
+		}
+
+		net_dev->needed_headroom = MVSW_PR_DSA_HLEN + 4;
+
+		net_dev->features |= NETIF_F_NETNS_LOCAL | NETIF_F_HW_TC;
+		net_dev->hw_features |= NETIF_F_HW_TC;
+		net_dev->ethtool_ops = &prestera_ethtool_ops;
+		net_dev->netdev_ops = &prestera_netdev_ops;
+		SET_NETDEV_DEV(net_dev, sw->dev->dev);
+
+		net_dev->mtu = min_t(unsigned int, sw->mtu_max,
+				     PRESTERA_MTU_DEFAULT);
+		net_dev->min_mtu = sw->mtu_min;
+		net_dev->max_mtu = sw->mtu_max;
+
+		err = prestera_hw_port_mtu_set(port, net_dev->mtu);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to set port(%u) mtu\n", id);
+			goto err_mtu_set;
+		}
+
+		/* Only 0xFF mac addrs are supported */
+		if (port->fp_id >= 0xFF) {
+			err = -ENOTSUPP;
+			goto err_fp_check;
+		}
+
+		mac = net_dev->dev_addr;
+		memcpy(mac, sw->base_mac, net_dev->addr_len);
+		mac[net_dev->addr_len - 1] += port->fp_id +
+					      PRESTERA_MAC_ADDR_OFFSET;
+
+		err = prestera_hw_port_mac_set(port, mac);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to set port(%u) mac addr\n", id);
+			goto err_mac_set;
+		}
+
+		err = prestera_hw_port_cap_get(port, &port->caps);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to get port(%u) caps\n", id);
+			goto err_cap_set;
+		}
+
+#ifdef CONFIG_PHYLINK
+		if (port->caps.transceiver != PRESTERA_PORT_TCVR_SFP)
+			netif_carrier_off(net_dev);
+#else
+		netif_carrier_off(net_dev);
+#endif
+
+		/* TODO: this is related only for phy */
+		port->adver_link_modes = port->caps.supp_link_modes;
+		port->adver_fec = 0;
+		port->autoneg = true;
+
+		/* initialize config mac */
+		if (port->caps.transceiver != PRESTERA_PORT_TCVR_SFP) {
+			cfg_mac.admin = true;
+			cfg_mac.mode = PRESTERA_MAC_MODE_INTERNAL;
+		} else {
+			cfg_mac.admin = false;
+			cfg_mac.mode = PRESTERA_MAC_MODE_MAX;
+		}
+		cfg_mac.inband = false;
+		cfg_mac.speed = 0;
+		cfg_mac.duplex = DUPLEX_UNKNOWN;
+		cfg_mac.fec = PRESTERA_PORT_FEC_OFF;
+
+		err = prestera_port_cfg_mac_write(port, &cfg_mac);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to set port(%u) mac mode\n", id);
+			goto err_state_set;
+		}
+
+		/* initialize config phy (if this is inegral) */
+		if (port->caps.transceiver != PRESTERA_PORT_TCVR_SFP) {
+			/* TODO: another parameters init */
+			port->cfg_phy.mdix = ETH_TP_MDI_AUTO;
+			port->cfg_phy.admin = false;
+			err = prestera_hw_port_phy_mode_set(port,
+							    port->cfg_phy.admin,
+							    /* TODO: phy_cfg */
+							    false, 0, 0,
+							    port->cfg_phy.mdix);
+			if (err) {
+				dev_err(prestera_dev(sw),
+					"Failed to set port(%u) phy mode\n",
+					id);
+				goto err_state_set;
+			}
+		}
+
+		prestera_port_dcb_init(port);
+
+		/* initialize state_mac */
+		rwlock_init(&port->state_mac_lock);
+
+		/* TODO: initialize state_phy */
+
+		prestera_port_uc_flood_set(port, false);
+		prestera_port_mc_flood_set(port, false);
+
+		INIT_DELAYED_WORK(&port->cached_hw_stats.caching_dw,
+				  &update_stats_cache);
+
+		/* We can list_add before netdev_register,
+		 * as it done in deinit seq
+		 */
+		list_add_tail(&port->list, &sw->port_list);
+	}
+
+	return 0;
+
+	/* rollback */
+err_alloc_etherdev:
+	while (!list_empty(&sw->port_list)) {
+		port = list_last_entry(&sw->port_list, typeof(*port), list);
+		net_dev = port->net_dev;
+
+		list_del(&port->list);
+err_state_set:
+err_cap_set:
+err_mac_set:
+err_fp_check:
+err_mtu_set:
+err_port_info_get:
+		free_percpu(port->rxtx_stats);
+err_alloc_stats:
+		free_netdev(net_dev);
+	}
+
+	return err;
+}
+
+/* propagate port to kernel */
+static int __prestera_ports_register(struct prestera_switch *sw)
+{
+	struct prestera_port *port;
 	int err;
 
-	lag = prestera_lag_by_dev(sw, lag_dev);
-	if (!lag) {
-		lag = prestera_lag_create(sw, lag_dev);
-		if (!lag)
-			return -ENOSPC;
+	list_for_each_entry(port, &sw->port_list, list) {
+		/* Believe, that traffic cannot be received on port before
+		 * this point
+		 */
+		err = prestera_devlink_port_register(port);
+		if (err)
+			goto err_devlink_register;
+	}
+
+	rtnl_lock();
+	list_for_each_entry(port, &sw->port_list, list) {
+		err = register_netdevice(port->net_dev);
+		if (err)
+			goto err_register_netdevice;
+	}
+	rtnl_unlock();
+
+	list_for_each_entry(port, &sw->port_list, list) {
+		if (port->caps.transceiver == PRESTERA_PORT_TCVR_SFP) {
+			err = prestera_port_sfp_bind(port);
+			if (err)
+				goto err_sfp_bind;
+		}
+
+		prestera_devlink_port_set(port);
+	}
+
+	return 0;
+
+err_sfp_bind:
+	/* rollback */
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list)
+		prestera_devlink_port_clear(port);
+
+	rtnl_lock();
+err_register_netdevice:
+	/* rollback */
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list)
+		unregister_netdevice(port->net_dev);
+	rtnl_unlock();
+
+err_devlink_register:
+	/* rollback */
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list) {
+#ifdef CONFIG_PHYLINK
+		if (port->phy_link)
+			phylink_destroy(port->phy_link);
+#endif
+		prestera_devlink_port_unregister(port);
 	}
 
+	return -ENOTSUPP;
+}
+
+static int prestera_ports_create(struct prestera_switch *sw)
+{
+	int err;
+
+	err = __prestera_ports_alloc(sw);
+	if (err)
+		goto err_alloc;
+
+	err = __prestera_ports_register(sw);
+	if (err)
+		goto err_register;
+
+	return 0;
+
+err_register:
+	__prestera_ports_free(sw);
+err_alloc:
+	return err;
+}
+
+static void prestera_port_vlan_flush(struct prestera_port *port,
+				     bool flush_default)
+{
+	struct prestera_port_vlan *port_vlan, *tmp;
+
+	list_for_each_entry_safe(port_vlan, tmp, &port->vlans_list, list) {
+		if (!flush_default && port_vlan->vid == PRESTERA_DEFAULT_VID)
+			continue;
+
+		prestera_port_vlan_destroy(port_vlan);
+	}
+}
+
+struct prestera_port *prestera_port_find_by_fp_id(u32 fp_id)
+{
+	struct prestera_port *port = NULL;
+	struct prestera_switch *sw;
+
+	list_for_each_entry(sw, &switches_registered, list) {
+		list_for_each_entry(port, &sw->port_list, list) {
+			if (port->fp_id == fp_id)
+				return port;
+		}
+	}
+	return NULL;
+}
+
+int prestera_dev_if_type(const struct net_device *dev)
+{
+	struct macvlan_dev *vlan;
+
+	if (is_vlan_dev(dev) && netif_is_bridge_master(vlan_dev_real_dev(dev)))
+		return PRESTERA_IF_VID_E;
+	else if (netif_is_bridge_master(dev))
+		return PRESTERA_IF_VID_E;
+	else if (netif_is_lag_master(dev))
+		return PRESTERA_IF_LAG_E;
+	else if (netif_is_macvlan(dev)) {
+		vlan = netdev_priv(dev);
+		return prestera_dev_if_type(vlan->lowerdev);
+	}
+	else
+		return PRESTERA_IF_PORT_E;
+}
+
+int prestera_lpm_add(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct prestera_ip_addr *addr, u32 prefix_len, u32 grp_id)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	/* TODO: ipv6 key type check before call designated hw cb */
+	return prestera_hw_lpm_add(sw, hw_vr_id, addr->u.ipv4,
+				   prefix_len, grp_id);
+}
+
+int prestera_lpm_del(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct prestera_ip_addr *addr, u32 prefix_len)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	/* TODO: ipv6 key type check before call designated hw cb */
+	return prestera_hw_lpm_del(sw, hw_vr_id, addr->u.ipv4,
+				   prefix_len);
+}
+
+int prestera_nh_entries_set(const struct prestera_switch *sw, int count,
+			    struct prestera_neigh_info *nhs, u32 grp_id)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	return prestera_hw_nh_entries_set(sw, count, nhs, grp_id);
+}
+
+int prestera_nh_entries_get(const struct prestera_switch *sw, int count,
+			    struct prestera_neigh_info *nhs, u32 grp_id)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	return prestera_hw_nh_entries_get(sw, count, nhs, grp_id);
+}
+
+int prestera_nhgrp_blk_get(const struct prestera_switch *sw, u8 *hw_state,
+			   u32 buf_size)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	return prestera_hw_nhgrp_blk_get(sw, hw_state, buf_size);
+}
+
+int prestera_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
+			     u32 *grp_id)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	return prestera_hw_nh_group_create(sw, nh_count, grp_id);
+}
+
+int prestera_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
+			     u32 grp_id)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	return prestera_hw_nh_group_delete(sw, nh_count, grp_id);
+}
+
+int prestera_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy)
+{
+	return prestera_hw_mp4_hash_set(sw, hash_policy);
+}
+
+struct prestera_lag *prestera_lag_get(struct prestera_switch *sw, u8 id)
+{
+	return id < sw->lag_max ? &sw->lags[id] : NULL;
+}
+
+static void prestera_port_lag_create(struct prestera_switch *sw, u16 lag_id,
+				     struct net_device *lag_dev)
+{
+	INIT_LIST_HEAD(&sw->lags[lag_id].members);
+	sw->lags[lag_id].dev = lag_dev;
+}
+
+static void prestera_port_lag_destroy(struct prestera_switch *sw, u16 lag_id)
+{
+	WARN_ON(!list_empty(&sw->lags[lag_id].members));
+	sw->lags[lag_id].dev = NULL;
+	sw->lags[lag_id].member_count = 0;
+}
+
+int prestera_lag_member_add(struct prestera_port *port,
+			    struct net_device *lag_dev, u16 lag_id)
+{
+	struct prestera_switch *sw = port->sw;
+	struct prestera_lag_member *member;
+	struct prestera_lag *lag;
+
+	lag = prestera_lag_get(sw, lag_id);
+
 	if (lag->member_count >= sw->lag_member_max)
 		return -ENOSPC;
+	else if (!lag->member_count)
+		prestera_port_lag_create(sw, lag_id, lag_dev);
 
-	err = prestera_hw_lag_member_add(port, lag->lag_id);
-	if (err) {
+	member = kzalloc(sizeof(*member), GFP_KERNEL);
+	if (!member)
+		return -ENOMEM;
+
+	if (prestera_hw_lag_member_add(port, lag_id)) {
+		kfree(member);
 		if (!lag->member_count)
-			prestera_lag_destroy(sw, lag);
-		return err;
+			prestera_port_lag_destroy(sw, lag_id);
+		return -EBUSY;
 	}
 
-	list_add(&port->lag_member, &lag->members);
+	member->port = port;
+	list_add(&member->list, &lag->members);
 	lag->member_count++;
-	port->lag = lag;
-
+	port->lag_id = lag_id;
 	return 0;
 }
 
-static int prestera_lag_port_del(struct prestera_port *port)
+int prestera_lag_member_del(struct prestera_port *port)
 {
 	struct prestera_switch *sw = port->sw;
-	struct prestera_lag *lag = port->lag;
+	struct prestera_lag_member *member;
+	struct list_head *pos, *n;
+	u16 lag_id = port->lag_id;
+	struct prestera_lag *lag;
 	int err;
 
+	lag = prestera_lag_get(sw, lag_id);
 	if (!lag || !lag->member_count)
 		return -EINVAL;
 
-	err = prestera_hw_lag_member_del(port, lag->lag_id);
+	err = prestera_hw_lag_member_del(port, lag_id);
 	if (err)
 		return err;
 
-	list_del(&port->lag_member);
 	lag->member_count--;
-	port->lag = NULL;
-
-	if (netif_is_bridge_port(lag->dev)) {
-		struct net_device *br_dev;
+	port->lag_id = sw->lag_max;
 
-		br_dev = netdev_master_upper_dev_get(lag->dev);
-
-		prestera_bridge_port_leave(br_dev, port);
+	list_for_each_safe(pos, n, &lag->members) {
+		member = list_entry(pos, typeof(*member), list);
+		if (member->port->id == port->id) {
+			list_del(&member->list);
+			kfree(member);
+			break;
+		}
 	}
 
-	if (!lag->member_count)
-		prestera_lag_destroy(sw, lag);
+	if (!lag->member_count) {
+		prestera_lag_router_leave(sw, lag->dev);
+		prestera_port_lag_destroy(sw, lag_id);
+	}
 
 	return 0;
 }
 
-bool prestera_port_is_lag_member(const struct prestera_port *port)
+int prestera_lag_member_enable(struct prestera_port *port, bool enable)
 {
-	return !!port->lag;
+	return prestera_hw_lag_member_enable(port, port->lag_id, enable);
 }
 
-u16 prestera_port_lag_id(const struct prestera_port *port)
+bool prestera_port_is_lag_member(const struct prestera_port *port)
 {
-	return port->lag->lag_id;
+	return port->lag_id < port->sw->lag_max;
 }
 
-static int prestera_lag_init(struct prestera_switch *sw)
+int prestera_lag_id_find(struct prestera_switch *sw, struct net_device *lag_dev,
+			 u16 *lag_id)
 {
-	u16 id;
+	struct prestera_lag *lag;
+	int free_id = -1;
+	int id;
 
-	sw->lags = kcalloc(sw->lag_max, sizeof(*sw->lags), GFP_KERNEL);
-	if (!sw->lags)
-		return -ENOMEM;
+	for (id = 0; id < sw->lag_max; id++) {
+		lag = prestera_lag_get(sw, id);
+		if (lag->member_count) {
+			if (lag->dev == lag_dev) {
+				*lag_id = id;
+				return 0;
+			}
+		} else if (free_id < 0) {
+			free_id = id;
+		}
+	}
+	if (free_id < 0)
+		return -ENOSPC;
+	*lag_id = free_id;
+	return 0;
+}
 
-	for (id = 0; id < sw->lag_max; id++)
-		sw->lags[id].lag_id = id;
+void prestera_lag_member_rif_leave(const struct prestera_port *port,
+				   u16 lag_id, u16 vr_id)
+{
+	prestera_hw_lag_member_rif_leave(port, lag_id, vr_id);
+}
 
-	return 0;
+static int prestera_lag_init(struct prestera_switch *sw)
+{
+	sw->lags = kcalloc(sw->lag_max, sizeof(*sw->lags), GFP_KERNEL);
+	return sw->lags ? 0 : -ENOMEM;
 }
 
 static void prestera_lag_fini(struct prestera_switch *sw)
@@ -632,134 +1448,626 @@ static void prestera_lag_fini(struct prestera_switch *sw)
 	for (idx = 0; idx < sw->lag_max; idx++)
 		WARN_ON(sw->lags[idx].member_count);
 
-	kfree(sw->lags);
+	kfree(sw->lags);
+}
+
+static int prestera_span_init(struct prestera_switch *sw)
+{
+	struct prestera_span *span;
+
+	span = kzalloc(sizeof(*span), GFP_KERNEL);
+	if (!span)
+		return -ENOMEM;
+
+	INIT_LIST_HEAD(&span->entries);
+
+	sw->span = span;
+	span->sw = sw;
+
+	return 0;
+}
+
+static void prestera_span_fini(struct prestera_switch *sw)
+{
+	struct prestera_span *span = sw->span;
+
+	WARN_ON(!list_empty(&span->entries));
+	kfree(span);
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_create(struct prestera_port *port, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+
+	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
+	if (!entry)
+		return ERR_PTR(-ENOMEM);
+
+	refcount_set(&entry->ref_count, 1);
+	entry->port = port;
+	entry->id = span_id;
+	list_add_tail(&entry->list, &port->sw->span->entries);
+
+	return entry;
+}
+
+static void prestera_span_entry_del(struct prestera_span_entry *entry)
+{
+	list_del(&entry->list);
+	kfree(entry);
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_find_by_id(struct prestera_span *span, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+
+	list_for_each_entry(entry, &span->entries, list) {
+		if (entry->id == span_id)
+			return entry;
+	}
+
+	return NULL;
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_find_by_port(struct prestera_span *span,
+				 struct prestera_port *port)
+{
+	struct prestera_span_entry *entry;
+
+	list_for_each_entry(entry, &span->entries, list) {
+		if (entry->port == port)
+			return entry;
+	}
+
+	return NULL;
+}
+
+int prestera_span_get(struct prestera_port *port, u8 *span_id)
+{
+	u8 new_span_id;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_span_entry *entry;
+	int err;
+
+	entry = prestera_span_entry_find_by_port(sw->span, port);
+	if (entry) {
+		refcount_inc(&entry->ref_count);
+		*span_id = entry->id;
+		return 0;
+	}
+
+	err = prestera_hw_span_get(port, &new_span_id);
+	if (err)
+		return err;
+
+	entry = prestera_span_entry_create(port, new_span_id);
+	if (IS_ERR(entry)) {
+		prestera_hw_span_release(sw, new_span_id);
+		return PTR_ERR(entry);
+	}
+
+	*span_id = new_span_id;
+	return 0;
+}
+
+int prestera_span_put(const struct prestera_switch *sw, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+	int err;
+
+	entry = prestera_span_entry_find_by_id(sw->span, span_id);
+	if (!entry)
+		return false;
+
+	if (!refcount_dec_and_test(&entry->ref_count))
+		return 0;
+
+	err = prestera_hw_span_release(sw, span_id);
+	if (err)
+		return err;
+
+	prestera_span_entry_del(entry);
+	return 0;
+}
+
+/* "free" opposite to "alloc" */
+static void __prestera_ports_free(struct prestera_switch *sw)
+{
+	struct net_device *net_dev;
+	struct list_head *pos, *n;
+	struct prestera_port *port;
+
+	list_for_each_safe(pos, n, &sw->port_list) {
+		port = list_entry(pos, typeof(*port), list);
+		net_dev = port->net_dev;
+
+		/* This is assymetric to create */
+		prestera_port_vlan_flush(port, true);
+		WARN_ON_ONCE(!list_empty(&port->vlans_list));
+		prestera_port_router_leave(port);
+		prestera_port_dcb_fini(port);
+
+		list_del(pos);
+		free_percpu(port->rxtx_stats);
+		free_netdev(net_dev);
+	}
+	WARN_ON(!list_empty(&sw->port_list));
+}
+
+/* propagate port to kernel */
+static void __prestera_ports_unregister(struct prestera_switch *sw)
+{
+	struct prestera_port *port;
+
+	list_for_each_entry(port, &sw->port_list, list) {
+		/* assymetric to create */
+		cancel_delayed_work_sync(&port->cached_hw_stats.caching_dw);
+
+		prestera_devlink_port_clear(port);
+	}
+
+	rtnl_lock();
+	list_for_each_entry(port, &sw->port_list, list)
+		unregister_netdevice(port->net_dev);
+	rtnl_unlock();
+
+	list_for_each_entry(port, &sw->port_list, list) {
+#ifdef CONFIG_PHYLINK
+		if (port->phy_link)
+			phylink_destroy(port->phy_link);
+#endif
+		prestera_devlink_port_unregister(port);
+	}
+}
+
+static void prestera_clear_ports(struct prestera_switch *sw)
+{
+	__prestera_ports_unregister(sw);
+	__prestera_ports_free(sw);
+}
+
+static void prestera_port_handle_event(struct prestera_switch *sw,
+				       struct prestera_event *evt, void *arg)
+{
+	struct prestera_port *port;
+	struct delayed_work *caching_dw;
+	struct prestera_port_mac_state smac;
+	struct prestera_port_event *pevt;
+
+	switch (evt->id) {
+	case PRESTERA_PORT_EVENT_MAC_STATE_CHANGED:
+		pevt = &evt->port_evt;
+
+		port = __find_pr_port(sw, pevt->port_id);
+		if (!port)
+			return;
+
+		caching_dw = &port->cached_hw_stats.caching_dw;
+
+		memset(&smac, 0, sizeof(smac));
+		smac.valid = true;
+		smac.oper = pevt->data.mac.oper;
+		if (smac.oper) {
+			smac.mode = pevt->data.mac.mode;
+			smac.speed = pevt->data.mac.speed;
+			smac.duplex = pevt->data.mac.duplex;
+			smac.fc = pevt->data.mac.fc;
+			smac.fec = pevt->data.mac.fec;
+		}
+
+		prestera_port_mac_state_cache_write(port, &smac);
+
+		if (pevt->data.mac.oper) {
+#ifdef CONFIG_PHYLINK
+			if (port->phy_link)
+				phylink_mac_change(port->phy_link, true);
+			else
+				netif_carrier_on(port->net_dev);
+#else
+			netif_carrier_on(port->net_dev);
+#endif
+
+			if (!delayed_work_pending(caching_dw))
+				queue_delayed_work(prestera_wq, caching_dw, 0);
+		} else {
+#ifdef CONFIG_PHYLINK
+			if (port->phy_link)
+				phylink_mac_change(port->phy_link, false);
+			else
+				netif_carrier_off(port->net_dev);
+#else
+			netif_carrier_off(port->net_dev);
+#endif
+
+			if (delayed_work_pending(caching_dw))
+				cancel_delayed_work(caching_dw);
+		}
+		break;
+	}
+}
+
+static bool prestera_lag_exists(const struct prestera_switch *sw, u16 lag_id)
+{
+	return lag_id < sw->lag_max &&
+	       sw->lags[lag_id].member_count != 0;
+}
+
+static void prestera_fdb_handle_event(struct prestera_switch *sw,
+				      struct prestera_event *evt, void *arg)
+{
+	struct switchdev_notifier_fdb_info info;
+	struct net_device *dev = NULL;
+	struct prestera_port *port;
+	u16 lag_id;
+
+	switch (evt->fdb_evt.type) {
+	case PRESTERA_FDB_ENTRY_TYPE_REG_PORT:
+		port = __find_pr_port(sw, evt->fdb_evt.dest.port_id);
+		if (port)
+			dev = port->net_dev;
+		break;
+	case PRESTERA_FDB_ENTRY_TYPE_LAG:
+		lag_id = evt->fdb_evt.dest.lag_id;
+		if (prestera_lag_exists(sw, lag_id))
+			dev = sw->lags[lag_id].dev;
+		break;
+	default:
+		return;
+	}
+
+	if (!dev)
+		return;
+
+	info.addr = evt->fdb_evt.data.mac;
+	info.vid = evt->fdb_evt.vid;
+	info.offloaded = true;
+
+	rtnl_lock();
+	switch (evt->id) {
+	case PRESTERA_FDB_EVENT_LEARNED:
+		call_switchdev_notifiers(SWITCHDEV_FDB_ADD_TO_BRIDGE,
+					 dev, &info.info, NULL);
+		break;
+	case PRESTERA_FDB_EVENT_AGED:
+		call_switchdev_notifiers(SWITCHDEV_FDB_DEL_TO_BRIDGE,
+					 dev, &info.info, NULL);
+		break;
+	}
+	rtnl_unlock();
+}
+
+static void prestera_fdb_event_handler_unregister(struct prestera_switch *sw)
+{
+	prestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_FDB);
+}
+
+static void prestera_port_event_handler_unregister(struct prestera_switch *sw)
+{
+	prestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_PORT);
+}
+
+static void prestera_event_handlers_unregister(struct prestera_switch *sw)
+{
+	prestera_fdb_event_handler_unregister(sw);
+	prestera_port_event_handler_unregister(sw);
+}
+
+static int prestera_fdb_event_handler_register(struct prestera_switch *sw)
+{
+	return prestera_hw_event_handler_register(sw, PRESTERA_EVENT_TYPE_FDB,
+						  prestera_fdb_handle_event,
+						  NULL);
+}
+
+static int prestera_port_event_handler_register(struct prestera_switch *sw)
+{
+	return prestera_hw_event_handler_register(sw, PRESTERA_EVENT_TYPE_PORT,
+						  prestera_port_handle_event,
+						  NULL);
+}
+
+static int prestera_event_handlers_register(struct prestera_switch *sw)
+{
+	int err;
+
+	err = prestera_port_event_handler_register(sw);
+	if (err)
+		return err;
+
+	err = prestera_fdb_event_handler_register(sw);
+	if (err)
+		goto err_fdb_handler_register;
+
+	return 0;
+
+err_fdb_handler_register:
+	prestera_port_event_handler_unregister(sw);
+	return err;
+}
+
+struct prestera_port *prestera_port_find(u32 dev_hw_id, u32 port_hw_id)
+{
+	struct prestera_port *port = NULL;
+	struct prestera_switch *sw;
+
+	list_for_each_entry(sw, &switches_registered, list) {
+		list_for_each_entry(port, &sw->port_list, list) {
+			if (port->hw_id == port_hw_id &&
+			    port->dev_id == dev_hw_id)
+				return port;
+		}
+	}
+	return NULL;
+}
+
+static int prestera_sw_init_base_mac(struct prestera_switch *sw)
+{
+	struct device_node *mac_dev_np;
+	u32 lsb;
+	int err;
+
+	if (sw->np) {
+		mac_dev_np = of_parse_phandle(sw->np, "base-mac-provider", 0);
+		if (mac_dev_np) {
+			const char *base_mac;
+
+			base_mac = of_get_mac_address(mac_dev_np);
+			if (!IS_ERR(base_mac))
+				ether_addr_copy(sw->base_mac, base_mac);
+		}
+	}
+
+	if (!is_valid_ether_addr(sw->base_mac))
+		eth_random_addr(sw->base_mac);
+
+	lsb = sw->base_mac[ETH_ALEN - 1];
+	if (lsb + sw->port_count + PRESTERA_MAC_ADDR_OFFSET > 0xFF)
+		sw->base_mac[ETH_ALEN - 1] = 0;
+
+	err = prestera_hw_switch_mac_set(sw, sw->base_mac);
+	if (err)
+		return err;
+
+	return 0;
+}
+
+static bool prestera_is_vrf_event(unsigned long event, void *ptr)
+{
+	struct netdev_notifier_changeupper_info *info = ptr;
+
+	if (event != NETDEV_PRECHANGEUPPER && event != NETDEV_CHANGEUPPER)
+		return false;
+
+	return netif_is_l3_master(info->upper_dev);
+}
+
+static bool
+prestera_lag_master_check(struct prestera_switch *sw,
+			  struct net_device *lag_dev,
+			  struct netdev_lag_upper_info *upper_info,
+			  struct netlink_ext_ack *ext_ack)
+{
+	u16 lag_id;
+
+	if (prestera_lag_id_find(sw, lag_dev, &lag_id)) {
+		NL_SET_ERR_MSG_MOD(ext_ack,
+				   "Exceeded max supported LAG devices");
+		return false;
+	}
+	if (upper_info->tx_type != NETDEV_LAG_TX_TYPE_HASH) {
+		NL_SET_ERR_MSG_MOD(ext_ack, "Unsupported LAG Tx type");
+		return false;
+	}
+	return true;
+}
+
+static void prestera_port_lag_clean(struct prestera_port *port,
+				    struct net_device *lag_dev)
+{
+	struct net_device *br_dev = netdev_master_upper_dev_get(lag_dev);
+	struct prestera_port_vlan *port_vlan, *tmp;
+	struct net_device *upper_dev;
+	struct list_head *iter;
+
+	list_for_each_entry_safe(port_vlan, tmp, &port->vlans_list, list) {
+		prestera_port_vlan_bridge_leave(port_vlan);
+		prestera_port_vlan_destroy(port_vlan);
+	}
+
+	if (netif_is_bridge_port(lag_dev))
+		prestera_port_bridge_leave(port, lag_dev, br_dev);
+
+	netdev_for_each_upper_dev_rcu(lag_dev, upper_dev, iter) {
+		if (!netif_is_bridge_port(upper_dev))
+			continue;
+		br_dev = netdev_master_upper_dev_get(upper_dev);
+		prestera_port_bridge_leave(port, upper_dev, br_dev);
+	}
+
+	prestera_port_pvid_set(port, PRESTERA_DEFAULT_VID);
 }
 
-bool prestera_netdev_check(const struct net_device *dev)
+static int prestera_port_lag_join(struct prestera_port *port,
+				  struct net_device *lag_dev)
 {
-	return dev->netdev_ops == &prestera_netdev_ops;
+	u16 lag_id;
+	int err;
+
+	err = prestera_lag_id_find(port->sw, lag_dev, &lag_id);
+	if (err)
+		return err;
+
+	err = prestera_lag_member_add(port, lag_dev, lag_id);
+		return err;
+
+	/* TODO: Port should no be longer usable as a router interface */
+
+	return 0;
 }
 
-static int prestera_lower_dev_walk(struct net_device *dev,
-				   struct netdev_nested_priv *priv)
+static void prestera_port_lag_leave(struct prestera_port *port,
+				    struct net_device *lag_dev)
 {
-	struct prestera_port **pport = (struct prestera_port **)priv->data;
+	prestera_router_lag_member_leave(port, lag_dev);
 
-	if (prestera_netdev_check(dev)) {
-		*pport = netdev_priv(dev);
-		return 1;
-	}
+	if (prestera_lag_member_del(port))
+		return;
 
-	return 0;
+	prestera_port_lag_clean(port, lag_dev);
 }
 
-struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev)
+static int prestera_netdevice_port_upper_event(struct net_device *lower_dev,
+					       struct net_device *dev,
+					       unsigned long event, void *ptr)
 {
-	struct prestera_port *port = NULL;
-	struct netdev_nested_priv priv = {
-		.data = (void *)&port,
-	};
+	struct netdev_notifier_changeupper_info *info;
+	struct prestera_port *port;
+	struct netlink_ext_ack *extack;
+	struct net_device *upper_dev;
+	struct prestera_switch *sw;
+	int err = 0;
 
-	if (prestera_netdev_check(dev))
-		return netdev_priv(dev);
+	port = netdev_priv(dev);
+	sw = port->sw;
+	info = ptr;
+	extack = netdev_notifier_info_to_extack(&info->info);
 
-	netdev_walk_all_lower_dev(dev, prestera_lower_dev_walk, &priv);
+	switch (event) {
+	case NETDEV_PRECHANGEUPPER:
+		upper_dev = info->upper_dev;
+		if (!netif_is_bridge_master(upper_dev) &&
+		    !netif_is_lag_master(upper_dev) &&
+		    !netif_is_macvlan(upper_dev)) {
+			NL_SET_ERR_MSG_MOD(extack, "Unknown upper device type");
+			return -EINVAL;
+		}
+		if (!info->linking)
+			break;
+		if (netdev_has_any_upper_dev(upper_dev) &&
+		    (!netif_is_bridge_master(upper_dev) ||
+		     !prestera_bridge_is_offloaded(sw, upper_dev))) {
+			NL_SET_ERR_MSG_MOD(extack,
+					   "Enslaving a port to a device that already has an upper device is not supported");
+			return -EINVAL;
+		}
+		if (netif_is_lag_master(upper_dev) &&
+		    !prestera_lag_master_check(sw, upper_dev,
+					      info->upper_info, extack))
+			return -EINVAL;
+		if (netif_is_lag_master(upper_dev) && vlan_uses_dev(dev)) {
+			NL_SET_ERR_MSG_MOD(extack,
+					   "Master device is a LAG master and port has a VLAN");
+			return -EINVAL;
+		}
+		if (netif_is_lag_port(dev) && is_vlan_dev(upper_dev) &&
+		    !netif_is_lag_master(vlan_dev_real_dev(upper_dev))) {
+			NL_SET_ERR_MSG_MOD(extack,
+					   "Can not put a VLAN on a LAG port");
+			return -EINVAL;
+		}
+		if (netif_is_macvlan(upper_dev) &&
+		    !prestera_rif_exists(sw, lower_dev)) {
+			NL_SET_ERR_MSG_MOD(extack,
+					   "macvlan is only supported on top of router interfaces");
+			return -EOPNOTSUPP;
+		}
+		break;
+	case NETDEV_CHANGEUPPER:
+		upper_dev = info->upper_dev;
+		if (netif_is_bridge_master(upper_dev)) {
+			if (info->linking)
+				err = prestera_port_bridge_join(port,
+								lower_dev,
+								upper_dev,
+								extack);
+			else
+				prestera_port_bridge_leave(port,
+							   lower_dev,
+							   upper_dev);
+		} else if (netif_is_lag_master(upper_dev)) {
+			if (info->linking)
+				err = prestera_port_lag_join(port, upper_dev);
+			else
+				prestera_port_lag_leave(port, upper_dev);
+		}
+		break;
+	}
 
-	return port;
+	return err;
 }
 
-static int prestera_netdev_port_lower_event(struct net_device *dev,
-					    unsigned long event, void *ptr)
+static int prestera_netdevice_port_lower_event(struct net_device *dev,
+					       unsigned long event, void *ptr)
 {
 	struct netdev_notifier_changelowerstate_info *info = ptr;
 	struct netdev_lag_lower_state_info *lower_state_info;
 	struct prestera_port *port = netdev_priv(dev);
 	bool enabled;
 
+	if (event != NETDEV_CHANGELOWERSTATE)
+		return 0;
 	if (!netif_is_lag_port(dev))
 		return 0;
 	if (!prestera_port_is_lag_member(port))
 		return 0;
 
 	lower_state_info = info->lower_state_info;
-	enabled = lower_state_info->link_up && lower_state_info->tx_enabled;
-
-	return prestera_hw_lag_member_enable(port, port->lag->lag_id, enabled);
+	enabled = lower_state_info->tx_enabled;
+	return prestera_lag_member_enable(port, enabled);
 }
 
-static bool prestera_lag_master_check(struct net_device *lag_dev,
-				      struct netdev_lag_upper_info *info,
-				      struct netlink_ext_ack *ext_ack)
+static int prestera_netdevice_port_event(struct net_device *lower_dev,
+					 struct net_device *port_dev,
+					 unsigned long event, void *ptr)
 {
-	if (info->tx_type != NETDEV_LAG_TX_TYPE_HASH) {
-		NL_SET_ERR_MSG_MOD(ext_ack, "Unsupported LAG Tx type");
-		return false;
+	switch (event) {
+	case NETDEV_PRECHANGEUPPER:
+	case NETDEV_CHANGEUPPER:
+		return prestera_netdevice_port_upper_event(lower_dev, port_dev,
+							   event, ptr);
+	case NETDEV_CHANGELOWERSTATE:
+		return prestera_netdevice_port_lower_event(port_dev,
+							   event, ptr);
 	}
 
-	return true;
+	return 0;
 }
 
-static int prestera_netdev_port_event(struct net_device *lower,
-				      struct net_device *dev,
-				      unsigned long event, void *ptr)
+static int prestera_netdevice_bridge_event(struct net_device *br_dev,
+					   unsigned long event, void *ptr)
 {
+	struct prestera_switch *sw = prestera_switch_get(br_dev);
 	struct netdev_notifier_changeupper_info *info = ptr;
-	struct prestera_port *port = netdev_priv(dev);
 	struct netlink_ext_ack *extack;
-	struct net_device *upper;
+	struct net_device *upper_dev;
+
+	if (!sw)
+		return 0;
 
 	extack = netdev_notifier_info_to_extack(&info->info);
-	upper = info->upper_dev;
 
 	switch (event) {
 	case NETDEV_PRECHANGEUPPER:
-		if (!netif_is_bridge_master(upper) &&
-		    !netif_is_lag_master(upper)) {
+		upper_dev = info->upper_dev;
+		if (!is_vlan_dev(upper_dev) && !netif_is_macvlan(upper_dev)) {
 			NL_SET_ERR_MSG_MOD(extack, "Unknown upper device type");
-			return -EINVAL;
+			return -EOPNOTSUPP;
 		}
-
 		if (!info->linking)
 			break;
-
-		if (netdev_has_any_upper_dev(upper)) {
-			NL_SET_ERR_MSG_MOD(extack, "Upper device is already enslaved");
-			return -EINVAL;
-		}
-
-		if (netif_is_lag_master(upper) &&
-		    !prestera_lag_master_check(upper, info->upper_info, extack))
-			return -EOPNOTSUPP;
-		if (netif_is_lag_master(upper) && vlan_uses_dev(dev)) {
-			NL_SET_ERR_MSG_MOD(extack,
-					   "Master device is a LAG master and port has a VLAN");
-			return -EINVAL;
-		}
-		if (netif_is_lag_port(dev) && is_vlan_dev(upper) &&
-		    !netif_is_lag_master(vlan_dev_real_dev(upper))) {
+		if (netif_is_macvlan(upper_dev) &&
+		    !prestera_rif_exists(sw, br_dev)) {
 			NL_SET_ERR_MSG_MOD(extack,
-					   "Can not put a VLAN on a LAG port");
-			return -EINVAL;
+					   "macvlan is only supported on top of router interfaces");
+			return -EOPNOTSUPP;
 		}
 		break;
-
 	case NETDEV_CHANGEUPPER:
-		if (netif_is_bridge_master(upper)) {
-			if (info->linking)
-				return prestera_bridge_port_join(upper, port,
-								 extack);
-			else
-				prestera_bridge_port_leave(upper, port);
-		} else if (netif_is_lag_master(upper)) {
-			if (info->linking)
-				return prestera_lag_port_add(port, upper);
-			else
-				prestera_lag_port_del(port);
-		}
+		/* TODO:  */
 		break;
-
-	case NETDEV_CHANGELOWERSTATE:
-		return prestera_netdev_port_lower_event(dev, event, ptr);
 	}
 
 	return 0;
@@ -774,8 +2082,8 @@ static int prestera_netdevice_lag_event(struct net_device *lag_dev,
 
 	netdev_for_each_lower_dev(lag_dev, dev, iter) {
 		if (prestera_netdev_check(dev)) {
-			err = prestera_netdev_port_event(lag_dev, dev, event,
-							 ptr);
+			err = prestera_netdevice_port_event(lag_dev, dev, event,
+							    ptr);
 			if (err)
 				return err;
 		}
@@ -784,16 +2092,83 @@ static int prestera_netdevice_lag_event(struct net_device *lag_dev,
 	return 0;
 }
 
+static int prestera_netdevice_vlan_event(struct net_device *vlan_dev,
+					 unsigned long event, void *ptr)
+{
+	struct net_device *real_dev = vlan_dev_real_dev(vlan_dev);
+	struct prestera_switch *sw = prestera_switch_get(real_dev);
+	struct netdev_notifier_changeupper_info *info = ptr;
+	struct netlink_ext_ack *extack;
+	struct net_device *upper_dev;
+
+	if (!sw)
+		return 0;
+
+	extack = netdev_notifier_info_to_extack(&info->info);
+
+	switch (event) {
+	case NETDEV_PRECHANGEUPPER:
+		upper_dev = info->upper_dev;
+
+		if (!info->linking)
+			break;
+
+		if (prestera_bridge_is_offloaded(sw, real_dev) &&
+		    netif_is_bridge_master(upper_dev)) {
+			NL_SET_ERR_MSG_MOD(extack,
+					   "Enslaving offloaded bridge to a bridge is not supported");
+			return -EOPNOTSUPP;
+		}
+		break;
+	case NETDEV_CHANGEUPPER:
+		/* empty */
+		break;
+	}
+
+	return 0;
+}
+
+static int prestera_netdevice_macvlan_event(struct net_device *macvlan_dev,
+					    unsigned long event, void *ptr)
+{
+	struct prestera_switch *sw = prestera_switch_get(macvlan_dev);
+	struct netdev_notifier_changeupper_info *info = ptr;
+	struct netlink_ext_ack *extack;
+
+	if (!sw || event != NETDEV_PRECHANGEUPPER)
+		return 0;
+
+	extack = netdev_notifier_info_to_extack(&info->info);
+
+	NL_SET_ERR_MSG_MOD(extack, "Unknown upper device type");
+
+	return -EOPNOTSUPP;
+}
+
 static int prestera_netdev_event_handler(struct notifier_block *nb,
 					 unsigned long event, void *ptr)
 {
 	struct net_device *dev = netdev_notifier_info_to_dev(ptr);
+	struct prestera_switch *sw;
 	int err = 0;
 
-	if (prestera_netdev_check(dev))
-		err = prestera_netdev_port_event(dev, dev, event, ptr);
+	sw = container_of(nb, struct prestera_switch, netdev_nb);
+
+	if (event == NETDEV_PRE_CHANGEADDR ||
+	    event == NETDEV_CHANGEADDR)
+		err = prestera_netdevice_router_port_event(dev, event, ptr);
+	else if (prestera_is_vrf_event(event, ptr))
+		err = prestera_netdevice_vrf_event(dev, event, ptr);
+	else if (prestera_netdev_check(dev))
+		err = prestera_netdevice_port_event(dev, dev, event, ptr);
+	else if (netif_is_bridge_master(dev))
+		err = prestera_netdevice_bridge_event(dev, event, ptr);
 	else if (netif_is_lag_master(dev))
 		err = prestera_netdevice_lag_event(dev, event, ptr);
+	else if (is_vlan_dev(dev))
+		err = prestera_netdevice_vlan_event(dev, event, ptr);
+	else if (netif_is_macvlan(dev))
+		err = prestera_netdevice_macvlan_event(dev, event, ptr);
 
 	return notifier_from_errno(err);
 }
@@ -810,38 +2185,194 @@ static void prestera_netdev_event_handler_unregister(struct prestera_switch *sw)
 	unregister_netdevice_notifier(&sw->netdev_nb);
 }
 
-static int prestera_switch_init(struct prestera_switch *sw)
+struct prestera_mdb_entry *
+prestera_mdb_entry_create(struct prestera_switch *sw,
+			  const unsigned char *addr, u16 vid)
+{
+	struct prestera_flood_domain *flood_domain;
+	struct prestera_mdb_entry *mdb_entry;
+
+	mdb_entry = kzalloc(sizeof(*mdb_entry), GFP_KERNEL);
+	if (!mdb_entry)
+		goto err_mdb_alloc;
+
+	flood_domain = prestera_flood_domain_create(sw);
+	if (!flood_domain)
+		goto err_flood_domain_create;
+
+	mdb_entry->sw = sw;
+	mdb_entry->vid = vid;
+	mdb_entry->flood_domain = flood_domain;
+	ether_addr_copy(mdb_entry->addr, addr);
+
+	if (prestera_hw_mdb_create(mdb_entry))
+		goto err_mdb_hw_create;
+
+	return mdb_entry;
+
+err_mdb_hw_create:
+	prestera_hw_mdb_destroy(mdb_entry);
+err_flood_domain_create:
+	kfree(mdb_entry);
+err_mdb_alloc:
+	return NULL;
+}
+
+void prestera_mdb_entry_destroy(struct prestera_mdb_entry *mdb_entry)
+{
+	prestera_hw_mdb_destroy(mdb_entry);
+	prestera_flood_domain_destroy(mdb_entry->flood_domain);
+	kfree(mdb_entry);
+}
+
+struct prestera_flood_domain *
+prestera_flood_domain_create(struct prestera_switch *sw)
+{
+	struct prestera_flood_domain *domain;
+
+	domain = kzalloc(sizeof(domain), GFP_KERNEL);
+	if (!domain)
+		return NULL;
+
+	domain->sw = sw;
+
+	if (prestera_hw_flood_domain_create(domain)) {
+		kfree(domain);
+		return NULL;
+	}
+
+	INIT_LIST_HEAD(&domain->flood_domain_port_list);
+
+	return domain;
+}
+
+void prestera_flood_domain_destroy(struct prestera_flood_domain *flood_domain)
+{
+	WARN_ON(!list_empty(&flood_domain->flood_domain_port_list));
+	WARN_ON_ONCE(prestera_hw_flood_domain_destroy(flood_domain));
+	kfree(flood_domain);
+}
+
+int
+prestera_flood_domain_port_create(struct prestera_flood_domain *flood_domain,
+				  struct net_device *dev,
+				  u16 vid)
+{
+	struct prestera_flood_domain_port *flood_domain_port;
+	bool is_first_port_in_list = false;
+	int err;
+
+	flood_domain_port = kzalloc(sizeof(*flood_domain_port), GFP_KERNEL);
+	if (!flood_domain_port) {
+		err = -ENOMEM;
+		goto err_port_alloc;
+	}
+
+	flood_domain_port->vid = vid;
+
+	if (list_empty(&flood_domain->flood_domain_port_list))
+		is_first_port_in_list = true;
+
+	list_add(&flood_domain_port->flood_domain_port_node,
+		 &flood_domain->flood_domain_port_list);
+
+	flood_domain_port->flood_domain = flood_domain;
+	flood_domain_port->dev = dev;
+
+	if (!is_first_port_in_list) {
+		err = prestera_hw_flood_domain_ports_reset(flood_domain);
+		if (err)
+			goto err_prestera_mdb_port_create_hw;
+	}
+
+	err = prestera_hw_flood_domain_ports_set(flood_domain);
+	if (err)
+		goto err_prestera_mdb_port_create_hw;
+
+	return 0;
+
+err_prestera_mdb_port_create_hw:
+	list_del(&flood_domain_port->flood_domain_port_node);
+	kfree(flood_domain_port);
+err_port_alloc:
+	return err;
+}
+
+void
+prestera_flood_domain_port_destroy(struct prestera_flood_domain_port *port)
+{
+	struct prestera_flood_domain *flood_domain = port->flood_domain;
+
+	list_del(&port->flood_domain_port_node);
+
+	WARN_ON_ONCE(prestera_hw_flood_domain_ports_reset(flood_domain));
+
+	if (!list_empty(&flood_domain->flood_domain_port_list))
+		WARN_ON_ONCE(prestera_hw_flood_domain_ports_set(flood_domain));
+
+	kfree(port);
+}
+
+struct prestera_flood_domain_port *
+prestera_flood_domain_port_find(struct prestera_flood_domain *flood_domain,
+				struct net_device *dev, u16 vid)
+{
+	struct prestera_flood_domain_port *flood_domain_port;
+
+	list_for_each_entry(flood_domain_port,
+			    &flood_domain->flood_domain_port_list,
+			    flood_domain_port_node)
+		if (flood_domain_port->dev == dev &&
+		    vid == flood_domain_port->vid)
+			return flood_domain_port;
+
+	return NULL;
+}
+
+static int prestera_init(struct prestera_switch *sw)
 {
 	int err;
 
+	sw->np = of_find_compatible_node(NULL, NULL, "marvell,prestera");
+
 	err = prestera_hw_switch_init(sw);
 	if (err) {
 		dev_err(prestera_dev(sw), "Failed to init Switch device\n");
 		return err;
 	}
 
-	rwlock_init(&sw->port_list_lock);
-	INIT_LIST_HEAD(&sw->port_list);
+	err = prestera_hw_switch_trap_policer_set(sw, trap_policer_profile);
+	if (err) {
+		dev_err(prestera_dev(sw),
+			"Failed to set trap policer profile\n");
+		return err;
+	}
 
-	err = prestera_switch_set_base_mac_addr(sw);
+	err = prestera_sw_init_base_mac(sw);
 	if (err)
 		return err;
 
-	err = prestera_netdev_event_handler_register(sw);
+	dev_info(prestera_dev(sw), "Initialized Switch device\n");
+
+	err = prestera_lag_init(sw);
 	if (err)
-		return err;
+		goto err_lag_init;
+
+	err = prestera_router_init(sw);
+	if (err)
+		goto err_router_init;
 
 	err = prestera_switchdev_init(sw);
 	if (err)
-		goto err_swdev_register;
+		goto err_swdev_reg;
 
-	err = prestera_rxtx_switch_init(sw);
+	err = prestera_devlink_register(sw);
 	if (err)
-		goto err_rxtx_register;
+		goto err_devl_reg;
 
-	err = prestera_event_handlers_register(sw);
+	err = prestera_counter_init(sw);
 	if (err)
-		goto err_handlers_register;
+		goto err_counter_init;
 
 	err = prestera_acl_init(sw);
 	if (err)
@@ -851,53 +2382,74 @@ static int prestera_switch_init(struct prestera_switch *sw)
 	if (err)
 		goto err_span_init;
 
-	err = prestera_devlink_register(sw);
+	INIT_LIST_HEAD(&sw->port_list);
+
+	err = prestera_netdev_event_handler_register(sw);
 	if (err)
-		goto err_dl_register;
+		goto err_netdev_reg;
 
-	err = prestera_lag_init(sw);
+	err = prestera_ports_create(sw);
 	if (err)
-		goto err_lag_init;
+		goto err_ports_init;
+
+	err = prestera_rxtx_switch_init(sw);
+	if (err)
+		goto err_rxtx_init;
+
+	err = prestera_event_handlers_register(sw);
+	if (err)
+		goto err_event_handlers;
 
-	err = prestera_create_ports(sw);
+	err = prestera_debugfs_init(sw);
 	if (err)
-		goto err_ports_create;
+		goto err_debugfs_init;
 
 	return 0;
 
-err_ports_create:
-	prestera_lag_fini(sw);
-err_lag_init:
-	prestera_devlink_unregister(sw);
-err_dl_register:
+err_debugfs_init:
+	prestera_event_handlers_unregister(sw);
+err_event_handlers:
+	prestera_rxtx_switch_fini(sw);
+err_rxtx_init:
+	prestera_clear_ports(sw);
+err_ports_init:
 	prestera_span_fini(sw);
+err_netdev_reg:
 err_span_init:
 	prestera_acl_fini(sw);
 err_acl_init:
-	prestera_event_handlers_unregister(sw);
-err_handlers_register:
-	prestera_rxtx_switch_fini(sw);
-err_rxtx_register:
+	prestera_counter_fini(sw);
+err_counter_init:
+	prestera_devlink_unregister(sw);
+err_devl_reg:
 	prestera_switchdev_fini(sw);
-err_swdev_register:
+err_swdev_reg:
+	prestera_router_fini(sw);
+err_router_init:
+err_lag_init:
 	prestera_netdev_event_handler_unregister(sw);
-	prestera_hw_switch_fini(sw);
 
 	return err;
 }
 
-static void prestera_switch_fini(struct prestera_switch *sw)
+static void prestera_fini(struct prestera_switch *sw)
 {
-	prestera_destroy_ports(sw);
-	prestera_lag_fini(sw);
-	prestera_devlink_unregister(sw);
-	prestera_span_fini(sw);
-	prestera_acl_fini(sw);
+	prestera_debugfs_fini(sw);
 	prestera_event_handlers_unregister(sw);
 	prestera_rxtx_switch_fini(sw);
-	prestera_switchdev_fini(sw);
+	prestera_clear_ports(sw);
 	prestera_netdev_event_handler_unregister(sw);
-	prestera_hw_switch_fini(sw);
+	prestera_span_fini(sw);
+	prestera_acl_fini(sw);
+	prestera_counter_fini(sw);
+	prestera_devlink_unregister(sw);
+	prestera_switchdev_fini(sw);
+	prestera_router_fini(sw);
+	prestera_lag_fini(sw);
+
+	prestera_hw_keepalive_fini(sw);
+	prestera_hw_switch_reset(sw);
+	of_node_put(sw->np);
 }
 
 int prestera_device_register(struct prestera_device *dev)
@@ -905,19 +2457,21 @@ int prestera_device_register(struct prestera_device *dev)
 	struct prestera_switch *sw;
 	int err;
 
-	sw = prestera_devlink_alloc(dev);
+	sw = prestera_devlink_alloc();
 	if (!sw)
 		return -ENOMEM;
 
 	dev->priv = sw;
 	sw->dev = dev;
 
-	err = prestera_switch_init(sw);
+	err = prestera_init(sw);
 	if (err) {
 		prestera_devlink_free(sw);
 		return err;
 	}
 
+	list_add(&sw->list, &switches_registered);
+
 	return 0;
 }
 EXPORT_SYMBOL(prestera_device_register);
@@ -926,27 +2480,38 @@ void prestera_device_unregister(struct prestera_device *dev)
 {
 	struct prestera_switch *sw = dev->priv;
 
-	prestera_switch_fini(sw);
+	list_del(&sw->list);
+	prestera_fini(sw);
 	prestera_devlink_free(sw);
+	dev->priv = NULL;
 }
 EXPORT_SYMBOL(prestera_device_unregister);
 
 static int __init prestera_module_init(void)
 {
-	prestera_wq = alloc_workqueue("prestera", 0, 0);
+	INIT_LIST_HEAD(&switches_registered);
+
+	prestera_wq = alloc_workqueue(prestera_driver_name, 0, 0);
 	if (!prestera_wq)
 		return -ENOMEM;
 
+	pr_info("Loading Marvell Prestera Switch Driver\n");
 	return 0;
 }
 
 static void __exit prestera_module_exit(void)
 {
 	destroy_workqueue(prestera_wq);
+
+	pr_info("Unloading Marvell Prestera Switch Driver\n");
 }
 
 module_init(prestera_module_init);
 module_exit(prestera_module_exit);
 
-MODULE_LICENSE("Dual BSD/GPL");
+MODULE_AUTHOR("Marvell Semi.");
+MODULE_LICENSE("GPL");
 MODULE_DESCRIPTION("Marvell Prestera switch driver");
+MODULE_VERSION(PRESTERA_DRV_VER);
+
+module_param(trap_policer_profile, byte, 0444);
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_matchall.c b/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
new file mode 100644
index 000000000000..8272a9cb20e9
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
@@ -0,0 +1,146 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/kernel.h>
+#include <linux/list.h>
+
+#include "prestera.h"
+#include "prestera_hw.h"
+
+static int prestera_mall_rule_add(struct prestera_flow_block_binding *binding,
+				  struct prestera_port *to_port)
+{
+	int err;
+	u8 span_id;
+	struct prestera_switch *sw = binding->port->sw;
+
+	if (binding->span_id != PRESTERA_SPAN_INVALID_ID)
+		/* port already in mirroring */
+		return -EEXIST;
+
+	err = prestera_span_get(to_port, &span_id);
+	if (err)
+		return err;
+
+	err = prestera_hw_span_bind(binding->port, span_id);
+	if (err) {
+		prestera_span_put(sw, span_id);
+		return err;
+	}
+
+	binding->span_id = span_id;
+	return 0;
+}
+
+static int prestera_mall_rule_del(struct prestera_flow_block_binding *binding)
+{
+	int err;
+
+	err = prestera_hw_span_unbind(binding->port);
+	if (err)
+		return err;
+
+	err = prestera_span_put(binding->port->sw, binding->span_id);
+	if (err)
+		return err;
+
+	binding->span_id = PRESTERA_SPAN_INVALID_ID;
+	return 0;
+}
+
+static int prestera_mall_prio_check(struct prestera_flow_block *block,
+				    struct tc_cls_matchall_offload *f)
+{
+	u32 flower_prio;
+	int err;
+
+	err = prestera_flower_prio_get(block, &flower_prio);
+	if (err == -ENOENT)
+		return 0;
+	if (err)
+		return err;
+
+	if (f->common.prio >= flower_prio)
+		return -EOPNOTSUPP;
+
+	return 0;
+}
+
+int prestera_mall_prio_get(struct prestera_flow_block *block,
+			   u32 *prio)
+{
+	if (block->mall_prio == UINT_MAX)
+		return -ENOENT;
+
+	*prio = block->mall_prio;
+	return 0;
+}
+
+static void prestera_mall_prio_update(struct prestera_flow_block *block,
+				      struct tc_cls_matchall_offload *f)
+{
+	if (f->common.prio > block->mall_prio || block->mall_prio == UINT_MAX)
+		block->mall_prio = f->common.prio;
+}
+
+int prestera_mall_replace(struct prestera_flow_block *block,
+			  struct tc_cls_matchall_offload *f)
+{
+	struct prestera_flow_block_binding *binding;
+	__be16 protocol = f->common.protocol;
+	struct flow_action_entry *act;
+	struct prestera_port *port;
+	int err;
+
+	if (!flow_offload_has_one_action(&f->rule->action)) {
+		NL_SET_ERR_MSG(f->common.extack,
+			       "Only singular actions are supported");
+		return -EOPNOTSUPP;
+	}
+
+	act = &f->rule->action.entries[0];
+
+	if (act->id != FLOW_ACTION_MIRRED)
+		return -EOPNOTSUPP;
+
+	if (protocol != htons(ETH_P_ALL))
+		return -EOPNOTSUPP;
+
+	err = prestera_mall_prio_check(block, f);
+	if (err)
+		return err;
+
+	if (!prestera_netdev_check(act->dev)) {
+		NL_SET_ERR_MSG(f->common.extack,
+			       "Only switchdev port is supported");
+		return -EINVAL;
+	}
+
+	port = netdev_priv(act->dev);
+	list_for_each_entry(binding, &block->binding_list, list) {
+		err = prestera_mall_rule_add(binding, port);
+		if (err)
+			goto rollback;
+	}
+
+	prestera_mall_prio_update(block, f);
+
+	return 0;
+
+rollback:
+	list_for_each_entry_continue_reverse(binding,
+					     &block->binding_list, list)
+		prestera_mall_rule_del(binding);
+	return err;
+}
+
+void prestera_mall_destroy(struct prestera_flow_block *block)
+{
+	struct prestera_flow_block_binding *binding;
+
+	list_for_each_entry(binding, &block->binding_list, list)
+		prestera_mall_rule_del(binding);
+
+	block->mall_prio = UINT_MAX;
+}
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_pci.c b/drivers/net/ethernet/marvell/prestera/prestera_pci.c
index a250d394da38..cfdcd2039a69 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_pci.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_pci.c
@@ -1,54 +1,22 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
-#include <linux/bitfield.h>
-#include <linux/circ_buf.h>
-#include <linux/device.h>
-#include <linux/firmware.h>
-#include <linux/iopoll.h>
-#include <linux/kernel.h>
 #include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/device.h>
 #include <linux/pci.h>
+#include <linux/circ_buf.h>
+#include <linux/firmware.h>
 
 #include "prestera.h"
+#include "prestera_fw.h"
 
-#define PRESTERA_MSG_MAX_SIZE 1500
-
-#define PRESTERA_SUPP_FW_MAJ_VER	3
-#define PRESTERA_SUPP_FW_MIN_VER	0
-
-#define PRESTERA_PREV_FW_MAJ_VER	2
-#define PRESTERA_PREV_FW_MIN_VER	0
+#define PRESTERA_FW_DEFAULT_PATH	"marvell/mvsw_prestera_fw.img"
+#define PRESTERA_FW_ARM64_PATH		"marvell/mvsw_prestera_fw_arm64.img"
 
-#define PRESTERA_FW_PATH_FMT	"mrvl/prestera/mvsw_prestera_fw-v%u.%u.img"
-
-#define PRESTERA_FW_HDR_MAGIC		0x351D9D06
-#define PRESTERA_FW_DL_TIMEOUT_MS	50000
-#define PRESTERA_FW_BLK_SZ		1024
-
-#define PRESTERA_FW_VER_MAJ_MUL 1000000
-#define PRESTERA_FW_VER_MIN_MUL 1000
-
-#define PRESTERA_FW_VER_MAJ(v)	((v) / PRESTERA_FW_VER_MAJ_MUL)
-
-#define PRESTERA_FW_VER_MIN(v) \
-	(((v) - (PRESTERA_FW_VER_MAJ(v) * PRESTERA_FW_VER_MAJ_MUL)) / \
-			PRESTERA_FW_VER_MIN_MUL)
-
-#define PRESTERA_FW_VER_PATCH(v) \
-	((v) - (PRESTERA_FW_VER_MAJ(v) * PRESTERA_FW_VER_MAJ_MUL) - \
-			(PRESTERA_FW_VER_MIN(v) * PRESTERA_FW_VER_MIN_MUL))
-
-enum prestera_pci_bar_t {
-	PRESTERA_PCI_BAR_FW = 2,
-	PRESTERA_PCI_BAR_PP = 4,
-};
-
-struct prestera_fw_header {
-	__be32 magic_number;
-	__be32 version_value;
-	u8 reserved[8];
-};
+#define PRESTERA_FW_HDR_MAGIC	0x351D9D06
+#define PRESTERA_FW_DL_TIMEOUT	50000
+#define PRESTERA_FW_BLK_SZ	1024
 
 struct prestera_ldr_regs {
 	u32 ldr_ready;
@@ -65,7 +33,7 @@ struct prestera_ldr_regs {
 	u32 ldr_buf_wr;
 
 	u32 ldr_status;
-};
+} __packed __aligned(4);
 
 #define PRESTERA_LDR_REG_OFFSET(f)	offsetof(struct prestera_ldr_regs, f)
 
@@ -76,8 +44,10 @@ struct prestera_ldr_regs {
 #define PRESTERA_LDR_STATUS_INVALID_IMG	BIT(2)
 #define PRESTERA_LDR_STATUS_NOMEM	BIT(3)
 
-#define PRESTERA_LDR_REG_BASE(fw)	((fw)->ldr_regs)
-#define PRESTERA_LDR_REG_ADDR(fw, reg)	(PRESTERA_LDR_REG_BASE(fw) + (reg))
+#define prestera_ldr_write(fw, reg, val) \
+	writel(val, (fw)->ldr_regs + (reg))
+#define prestera_ldr_read(fw, reg)	\
+	readl((fw)->ldr_regs + (reg))
 
 /* fw loader registers */
 #define PRESTERA_LDR_READY_REG		PRESTERA_LDR_REG_OFFSET(ldr_ready)
@@ -91,682 +61,394 @@ struct prestera_ldr_regs {
 
 #define PRESTERA_LDR_CTL_DL_START	BIT(0)
 
-#define PRESTERA_EVT_QNUM_MAX	4
-
-struct prestera_fw_evtq_regs {
-	u32 rd_idx;
-	u32 pad1;
-	u32 wr_idx;
-	u32 pad2;
-	u32 offs;
-	u32 len;
-};
-
-struct prestera_fw_regs {
-	u32 fw_ready;
-	u32 pad;
-	u32 cmd_offs;
-	u32 cmd_len;
-	u32 evt_offs;
-	u32 evt_qnum;
-
-	u32 cmd_req_ctl;
-	u32 cmd_req_len;
-	u32 cmd_rcv_ctl;
-	u32 cmd_rcv_len;
-
-	u32 fw_status;
-	u32 rx_status;
-
-	struct prestera_fw_evtq_regs evtq_list[PRESTERA_EVT_QNUM_MAX];
-};
-
-#define PRESTERA_FW_REG_OFFSET(f)	offsetof(struct prestera_fw_regs, f)
-
-#define PRESTERA_FW_READY_MAGIC		0xcafebabe
-
-/* fw registers */
-#define PRESTERA_FW_READY_REG		PRESTERA_FW_REG_OFFSET(fw_ready)
-
-#define PRESTERA_CMD_BUF_OFFS_REG	PRESTERA_FW_REG_OFFSET(cmd_offs)
-#define PRESTERA_CMD_BUF_LEN_REG	PRESTERA_FW_REG_OFFSET(cmd_len)
-#define PRESTERA_EVT_BUF_OFFS_REG	PRESTERA_FW_REG_OFFSET(evt_offs)
-#define PRESTERA_EVT_QNUM_REG		PRESTERA_FW_REG_OFFSET(evt_qnum)
-
-#define PRESTERA_CMD_REQ_CTL_REG	PRESTERA_FW_REG_OFFSET(cmd_req_ctl)
-#define PRESTERA_CMD_REQ_LEN_REG	PRESTERA_FW_REG_OFFSET(cmd_req_len)
-
-#define PRESTERA_CMD_RCV_CTL_REG	PRESTERA_FW_REG_OFFSET(cmd_rcv_ctl)
-#define PRESTERA_CMD_RCV_LEN_REG	PRESTERA_FW_REG_OFFSET(cmd_rcv_len)
-#define PRESTERA_FW_STATUS_REG		PRESTERA_FW_REG_OFFSET(fw_status)
-#define PRESTERA_RX_STATUS_REG		PRESTERA_FW_REG_OFFSET(rx_status)
-
-/* PRESTERA_CMD_REQ_CTL_REG flags */
-#define PRESTERA_CMD_F_REQ_SENT		BIT(0)
-#define PRESTERA_CMD_F_REPL_RCVD	BIT(1)
-
-/* PRESTERA_CMD_RCV_CTL_REG flags */
-#define PRESTERA_CMD_F_REPL_SENT	BIT(0)
-
-#define PRESTERA_FW_EVT_CTL_STATUS_MASK	GENMASK(1, 0)
-
-#define PRESTERA_FW_EVT_CTL_STATUS_ON	0
-#define PRESTERA_FW_EVT_CTL_STATUS_OFF	1
-
-#define PRESTERA_EVTQ_REG_OFFSET(q, f)			\
-	(PRESTERA_FW_REG_OFFSET(evtq_list) +		\
-	 (q) * sizeof(struct prestera_fw_evtq_regs) +	\
-	 offsetof(struct prestera_fw_evtq_regs, f))
-
-#define PRESTERA_EVTQ_RD_IDX_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, rd_idx)
-#define PRESTERA_EVTQ_WR_IDX_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, wr_idx)
-#define PRESTERA_EVTQ_OFFS_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, offs)
-#define PRESTERA_EVTQ_LEN_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, len)
-
-#define PRESTERA_FW_REG_BASE(fw)	((fw)->dev.ctl_regs)
-#define PRESTERA_FW_REG_ADDR(fw, reg)	PRESTERA_FW_REG_BASE((fw)) + (reg)
-
-#define PRESTERA_FW_CMD_DEFAULT_WAIT_MS	30000
-#define PRESTERA_FW_READY_WAIT_MS	20000
-
-struct prestera_fw_evtq {
-	u8 __iomem *addr;
-	size_t len;
-};
-
-struct prestera_fw {
-	struct prestera_fw_rev rev_supp;
-	const struct firmware *bin;
-	struct workqueue_struct *wq;
-	struct prestera_device dev;
-	u8 __iomem *ldr_regs;
-	u8 __iomem *ldr_ring_buf;
-	u32 ldr_buf_len;
-	u32 ldr_wr_idx;
-	struct mutex cmd_mtx; /* serialize access to dev->send_req */
-	size_t cmd_mbox_len;
-	u8 __iomem *cmd_mbox;
-	struct prestera_fw_evtq evt_queue[PRESTERA_EVT_QNUM_MAX];
-	u8 evt_qnum;
-	struct work_struct evt_work;
-	u8 __iomem *evt_buf;
-	u8 *evt_msg;
+#define PRESTERA_LDR_WR_IDX_MOVE(fw, n) \
+do { \
+	typeof(fw) __fw = (fw); \
+	(__fw)->ldr_wr_idx = ((__fw)->ldr_wr_idx + (n)) & \
+				((__fw)->ldr_buf_len - 1); \
+} while (0)
+
+#define PRESTERA_LDR_WR_IDX_COMMIT(fw) \
+({ \
+	typeof(fw) __fw = (fw); \
+	prestera_ldr_write((__fw), PRESTERA_LDR_BUF_WR_REG, \
+			   (__fw)->ldr_wr_idx); \
+})
+
+#define PRESTERA_LDR_WR_PTR(fw) \
+({ \
+	typeof(fw) __fw = (fw); \
+	((__fw)->ldr_ring_buf + (__fw)->ldr_wr_idx); \
+})
+
+#define PRESTERA_DEVICE(id) PCI_VDEVICE(MARVELL, (id))
+
+#define PRESTERA_DEV_ID_AC3X_98DX_55	0xC804
+#define PRESTERA_DEV_ID_AC3X_98DX_65	0xC80C
+#define PRESTERA_DEV_ID_ALDRIN2		0xCC1E
+#define PRESTERA_DEV_ID_ALDRIN3S	0x981F
+#define PRESTERA_DEV_ID_98DX3500	0x9820
+#define PRESTERA_DEV_ID_98DX3501	0x9826
+#define PRESTERA_DEV_ID_98DX3510	0x9821
+#define PRESTERA_DEV_ID_98DX3520	0x9822
+
+static struct prestera_pci_match {
+	struct pci_driver driver;
+	const struct pci_device_id id;
+	bool registered;
+} prestera_devices[] = {
+	{
+		.driver = { .name = "AC3x B2B 98DX3255", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_AC3X_98DX_55), 0 },
+	},
+	{
+		.driver = { .name = "AC3x B2B 98DX3265", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_AC3X_98DX_65), 0 },
+	},
+	{
+		.driver = { .name = "Aldrin2", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_ALDRIN2), 0 },
+	},
+	{
+		.driver = { .name = "Aldrin3S", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_ALDRIN3S), 0 },
+	},
+	{
+		.driver = { .name = "AC5X 98DX3500", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_98DX3500), 0 },
+	},
+	{
+		.driver = { .name = "AC5X 98DX3501", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_98DX3501), 0 },
+	},
+	{
+		.driver = { .name = "AC5X 98DX3510", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_98DX3510), 0 },
+	},
+	{
+		.driver = { .name = "AC5X 98DX3520", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_98DX3520), 0 },
+	},
+	{{ }, }
 };
 
 static int prestera_fw_load(struct prestera_fw *fw);
 
-static void prestera_fw_write(struct prestera_fw *fw, u32 reg, u32 val)
-{
-	writel(val, PRESTERA_FW_REG_ADDR(fw, reg));
-}
-
-static u32 prestera_fw_read(struct prestera_fw *fw, u32 reg)
-{
-	return readl(PRESTERA_FW_REG_ADDR(fw, reg));
-}
-
-static u32 prestera_fw_evtq_len(struct prestera_fw *fw, u8 qid)
-{
-	return fw->evt_queue[qid].len;
-}
-
-static u32 prestera_fw_evtq_avail(struct prestera_fw *fw, u8 qid)
-{
-	u32 wr_idx = prestera_fw_read(fw, PRESTERA_EVTQ_WR_IDX_REG(qid));
-	u32 rd_idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
-
-	return CIRC_CNT(wr_idx, rd_idx, prestera_fw_evtq_len(fw, qid));
-}
-
-static void prestera_fw_evtq_rd_set(struct prestera_fw *fw,
-				    u8 qid, u32 idx)
-{
-	u32 rd_idx = idx & (prestera_fw_evtq_len(fw, qid) - 1);
-
-	prestera_fw_write(fw, PRESTERA_EVTQ_RD_IDX_REG(qid), rd_idx);
-}
-
-static u8 __iomem *prestera_fw_evtq_buf(struct prestera_fw *fw, u8 qid)
-{
-	return fw->evt_queue[qid].addr;
-}
-
-static u32 prestera_fw_evtq_read32(struct prestera_fw *fw, u8 qid)
-{
-	u32 rd_idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
-	u32 val;
-
-	val = readl(prestera_fw_evtq_buf(fw, qid) + rd_idx);
-	prestera_fw_evtq_rd_set(fw, qid, rd_idx + 4);
-	return val;
-}
-
-static ssize_t prestera_fw_evtq_read_buf(struct prestera_fw *fw,
-					 u8 qid, void *buf, size_t len)
-{
-	u32 idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
-	u8 __iomem *evtq_addr = prestera_fw_evtq_buf(fw, qid);
-	u32 *buf32 = buf;
-	int i;
-
-	for (i = 0; i < len / 4; buf32++, i++) {
-		*buf32 = readl_relaxed(evtq_addr + idx);
-		idx = (idx + 4) & (prestera_fw_evtq_len(fw, qid) - 1);
-	}
-
-	prestera_fw_evtq_rd_set(fw, qid, idx);
-
-	return i;
-}
-
-static u8 prestera_fw_evtq_pick(struct prestera_fw *fw)
-{
-	int qid;
-
-	for (qid = 0; qid < fw->evt_qnum; qid++) {
-		if (prestera_fw_evtq_avail(fw, qid) >= 4)
-			return qid;
-	}
-
-	return PRESTERA_EVT_QNUM_MAX;
-}
-
-static void prestera_fw_evt_ctl_status_set(struct prestera_fw *fw, u32 val)
-{
-	u32 status = prestera_fw_read(fw, PRESTERA_FW_STATUS_REG);
-
-	u32p_replace_bits(&status, val, PRESTERA_FW_EVT_CTL_STATUS_MASK);
-
-	prestera_fw_write(fw, PRESTERA_FW_STATUS_REG, status);
-}
-
-static void prestera_fw_evt_work_fn(struct work_struct *work)
-{
-	struct prestera_fw *fw;
-	void *msg;
-	u8 qid;
-
-	fw = container_of(work, struct prestera_fw, evt_work);
-	msg = fw->evt_msg;
-
-	prestera_fw_evt_ctl_status_set(fw, PRESTERA_FW_EVT_CTL_STATUS_OFF);
-
-	while ((qid = prestera_fw_evtq_pick(fw)) < PRESTERA_EVT_QNUM_MAX) {
-		u32 idx;
-		u32 len;
-
-		len = prestera_fw_evtq_read32(fw, qid);
-		idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
-
-		WARN_ON(prestera_fw_evtq_avail(fw, qid) < len);
-
-		if (WARN_ON(len > PRESTERA_MSG_MAX_SIZE)) {
-			prestera_fw_evtq_rd_set(fw, qid, idx + len);
-			continue;
-		}
-
-		prestera_fw_evtq_read_buf(fw, qid, msg, len);
-
-		if (fw->dev.recv_msg)
-			fw->dev.recv_msg(&fw->dev, msg, len);
-	}
-
-	prestera_fw_evt_ctl_status_set(fw, PRESTERA_FW_EVT_CTL_STATUS_ON);
-}
-
-static int prestera_fw_wait_reg32(struct prestera_fw *fw, u32 reg, u32 cmp,
-				  unsigned int waitms)
-{
-	u8 __iomem *addr = PRESTERA_FW_REG_ADDR(fw, reg);
-	u32 val;
-
-	return readl_poll_timeout(addr, val, cmp == val,
-				  1 * USEC_PER_MSEC, waitms * USEC_PER_MSEC);
-}
-
-static int prestera_fw_cmd_send(struct prestera_fw *fw,
-				void *in_msg, size_t in_size,
-				void *out_msg, size_t out_size,
-				unsigned int waitms)
-{
-	u32 ret_size;
-	int err;
-
-	if (!waitms)
-		waitms = PRESTERA_FW_CMD_DEFAULT_WAIT_MS;
-
-	if (ALIGN(in_size, 4) > fw->cmd_mbox_len)
-		return -EMSGSIZE;
-
-	/* wait for finish previous reply from FW */
-	err = prestera_fw_wait_reg32(fw, PRESTERA_CMD_RCV_CTL_REG, 0, 30);
-	if (err) {
-		dev_err(fw->dev.dev, "finish reply from FW is timed out\n");
-		return err;
-	}
-
-	prestera_fw_write(fw, PRESTERA_CMD_REQ_LEN_REG, in_size);
-	memcpy_toio(fw->cmd_mbox, in_msg, in_size);
-
-	prestera_fw_write(fw, PRESTERA_CMD_REQ_CTL_REG, PRESTERA_CMD_F_REQ_SENT);
-
-	/* wait for reply from FW */
-	err = prestera_fw_wait_reg32(fw, PRESTERA_CMD_RCV_CTL_REG,
-				     PRESTERA_CMD_F_REPL_SENT, waitms);
-	if (err) {
-		dev_err(fw->dev.dev, "reply from FW is timed out\n");
-		goto cmd_exit;
-	}
-
-	ret_size = prestera_fw_read(fw, PRESTERA_CMD_RCV_LEN_REG);
-	if (ret_size > out_size) {
-		dev_err(fw->dev.dev, "ret_size (%u) > out_len(%zu)\n",
-			ret_size, out_size);
-		err = -EMSGSIZE;
-		goto cmd_exit;
-	}
-
-	memcpy_fromio(out_msg, fw->cmd_mbox + in_size, ret_size);
-
-cmd_exit:
-	prestera_fw_write(fw, PRESTERA_CMD_REQ_CTL_REG, PRESTERA_CMD_F_REPL_RCVD);
-	return err;
-}
-
-static int prestera_fw_send_req(struct prestera_device *dev,
-				void *in_msg, size_t in_size, void *out_msg,
-				size_t out_size, unsigned int waitms)
-{
-	struct prestera_fw *fw;
-	ssize_t ret;
-
-	fw = container_of(dev, struct prestera_fw, dev);
-
-	mutex_lock(&fw->cmd_mtx);
-	ret = prestera_fw_cmd_send(fw, in_msg, in_size, out_msg, out_size, waitms);
-	mutex_unlock(&fw->cmd_mtx);
-
-	return ret;
-}
-
-static int prestera_fw_init(struct prestera_fw *fw)
-{
-	u8 __iomem *base;
-	int err;
-	u8 qid;
-
-	fw->dev.send_req = prestera_fw_send_req;
-	fw->ldr_regs = fw->dev.ctl_regs;
-
-	err = prestera_fw_load(fw);
-	if (err)
-		return err;
-
-	err = prestera_fw_wait_reg32(fw, PRESTERA_FW_READY_REG,
-				     PRESTERA_FW_READY_MAGIC,
-				     PRESTERA_FW_READY_WAIT_MS);
-	if (err) {
-		dev_err(fw->dev.dev, "FW failed to start\n");
-		return err;
-	}
-
-	base = fw->dev.ctl_regs;
-
-	fw->cmd_mbox = base + prestera_fw_read(fw, PRESTERA_CMD_BUF_OFFS_REG);
-	fw->cmd_mbox_len = prestera_fw_read(fw, PRESTERA_CMD_BUF_LEN_REG);
-	mutex_init(&fw->cmd_mtx);
-
-	fw->evt_buf = base + prestera_fw_read(fw, PRESTERA_EVT_BUF_OFFS_REG);
-	fw->evt_qnum = prestera_fw_read(fw, PRESTERA_EVT_QNUM_REG);
-	fw->evt_msg = kmalloc(PRESTERA_MSG_MAX_SIZE, GFP_KERNEL);
-	if (!fw->evt_msg)
-		return -ENOMEM;
-
-	for (qid = 0; qid < fw->evt_qnum; qid++) {
-		u32 offs = prestera_fw_read(fw, PRESTERA_EVTQ_OFFS_REG(qid));
-		struct prestera_fw_evtq *evtq = &fw->evt_queue[qid];
-
-		evtq->len = prestera_fw_read(fw, PRESTERA_EVTQ_LEN_REG(qid));
-		evtq->addr = fw->evt_buf + offs;
-	}
-
-	return 0;
-}
-
-static void prestera_fw_uninit(struct prestera_fw *fw)
-{
-	kfree(fw->evt_msg);
-}
-
-static irqreturn_t prestera_pci_irq_handler(int irq, void *dev_id)
+static irqreturn_t prestera_irq_handler(int irq, void *dev_id)
 {
 	struct prestera_fw *fw = dev_id;
 
 	if (prestera_fw_read(fw, PRESTERA_RX_STATUS_REG)) {
-		prestera_fw_write(fw, PRESTERA_RX_STATUS_REG, 0);
-
-		if (fw->dev.recv_pkt)
+		if (fw->dev.recv_pkt) {
+			prestera_fw_write(fw, PRESTERA_RX_STATUS_REG, 0);
 			fw->dev.recv_pkt(&fw->dev);
+		}
 	}
 
-	queue_work(fw->wq, &fw->evt_work);
+	prestera_fw_queue_work(fw);
 
 	return IRQ_HANDLED;
 }
 
-static void prestera_ldr_write(struct prestera_fw *fw, u32 reg, u32 val)
-{
-	writel(val, PRESTERA_LDR_REG_ADDR(fw, reg));
-}
-
-static u32 prestera_ldr_read(struct prestera_fw *fw, u32 reg)
-{
-	return readl(PRESTERA_LDR_REG_ADDR(fw, reg));
-}
-
-static int prestera_ldr_wait_reg32(struct prestera_fw *fw,
-				   u32 reg, u32 cmp, unsigned int waitms)
+static int prestera_ldr_wait_reg32(struct prestera_fw *fw, u32 reg, u32 val,
+				   unsigned int wait)
 {
-	u8 __iomem *addr = PRESTERA_LDR_REG_ADDR(fw, reg);
-	u32 val;
-
-	return readl_poll_timeout(addr, val, cmp == val,
-				  10 * USEC_PER_MSEC, waitms * USEC_PER_MSEC);
-}
-
-static u32 prestera_ldr_wait_buf(struct prestera_fw *fw, size_t len)
-{
-	u8 __iomem *addr = PRESTERA_LDR_REG_ADDR(fw, PRESTERA_LDR_BUF_RD_REG);
-	u32 buf_len = fw->ldr_buf_len;
-	u32 wr_idx = fw->ldr_wr_idx;
-	u32 rd_idx;
-
-	return readl_poll_timeout(addr, rd_idx,
-				 CIRC_SPACE(wr_idx, rd_idx, buf_len) >= len,
-				 1 * USEC_PER_MSEC, 100 * USEC_PER_MSEC);
-}
-
-static int prestera_ldr_wait_dl_finish(struct prestera_fw *fw)
-{
-	u8 __iomem *addr = PRESTERA_LDR_REG_ADDR(fw, PRESTERA_LDR_STATUS_REG);
-	unsigned long mask = ~(PRESTERA_LDR_STATUS_IMG_DL);
-	u32 val;
-	int err;
-
-	err = readl_poll_timeout(addr, val, val & mask, 10 * USEC_PER_MSEC,
-				 PRESTERA_FW_DL_TIMEOUT_MS * USEC_PER_MSEC);
-	if (err) {
-		dev_err(fw->dev.dev, "Timeout to load FW img [state=%d]",
-			prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG));
-		return err;
-	}
-
-	return 0;
-}
+	if (prestera_wait(prestera_ldr_read(fw, reg) == val, wait))
+		return 0;
 
-static void prestera_ldr_wr_idx_move(struct prestera_fw *fw, unsigned int n)
-{
-	fw->ldr_wr_idx = (fw->ldr_wr_idx + (n)) & (fw->ldr_buf_len - 1);
+	return -EBUSY;
 }
 
-static void prestera_ldr_wr_idx_commit(struct prestera_fw *fw)
+static u32 prestera_ldr_buf_avail(struct prestera_fw *fw)
 {
-	prestera_ldr_write(fw, PRESTERA_LDR_BUF_WR_REG, fw->ldr_wr_idx);
-}
+	u32 rd_idx = prestera_ldr_read(fw, PRESTERA_LDR_BUF_RD_REG);
 
-static u8 __iomem *prestera_ldr_wr_ptr(struct prestera_fw *fw)
-{
-	return fw->ldr_ring_buf + fw->ldr_wr_idx;
+	return CIRC_SPACE(fw->ldr_wr_idx, rd_idx, fw->ldr_buf_len);
 }
 
-static int prestera_ldr_send(struct prestera_fw *fw, const u8 *buf, size_t len)
+static int prestera_ldr_send_buf(struct prestera_fw *fw, const u8 *buf,
+				 size_t len)
 {
-	int err;
 	int i;
 
-	err = prestera_ldr_wait_buf(fw, len);
-	if (err) {
-		dev_err(fw->dev.dev, "failed wait for sending firmware\n");
-		return err;
+	if (!prestera_wait(prestera_ldr_buf_avail(fw) >= len, 100)) {
+		dev_err(prestera_fw_dev(fw),
+			"failed wait for sending firmware\n");
+		return -EBUSY;
 	}
 
 	for (i = 0; i < len; i += 4) {
-		writel_relaxed(*(u32 *)(buf + i), prestera_ldr_wr_ptr(fw));
-		prestera_ldr_wr_idx_move(fw, 4);
+		writel_relaxed(*(u32 *)(buf + i), PRESTERA_LDR_WR_PTR(fw));
+		PRESTERA_LDR_WR_IDX_MOVE(fw, 4);
 	}
 
-	prestera_ldr_wr_idx_commit(fw);
+	PRESTERA_LDR_WR_IDX_COMMIT(fw);
 	return 0;
 }
 
-static int prestera_ldr_fw_send(struct prestera_fw *fw,
-				const char *img, u32 fw_size)
+static int prestera_ldr_send(struct prestera_fw *fw, const char *img,
+			     u32 fw_size)
 {
+	unsigned long mask;
 	u32 status;
 	u32 pos;
 	int err;
 
-	err = prestera_ldr_wait_reg32(fw, PRESTERA_LDR_STATUS_REG,
-				      PRESTERA_LDR_STATUS_IMG_DL,
-				      5 * MSEC_PER_SEC);
-	if (err) {
-		dev_err(fw->dev.dev, "Loader is not ready to load image\n");
-		return err;
+	if (prestera_ldr_wait_reg32(fw, PRESTERA_LDR_STATUS_REG,
+				    PRESTERA_LDR_STATUS_IMG_DL, 1000)) {
+		dev_err(prestera_fw_dev(fw),
+			"Loader is not ready to load image\n");
+		return -EBUSY;
 	}
 
 	for (pos = 0; pos < fw_size; pos += PRESTERA_FW_BLK_SZ) {
 		if (pos + PRESTERA_FW_BLK_SZ > fw_size)
 			break;
 
-		err = prestera_ldr_send(fw, img + pos, PRESTERA_FW_BLK_SZ);
-		if (err)
+		err = prestera_ldr_send_buf(fw, img + pos, PRESTERA_FW_BLK_SZ);
+		if (err) {
+			if (prestera_fw_read(fw, PRESTERA_LDR_STATUS_REG) ==
+					     PRESTERA_LDR_STATUS_NOMEM) {
+				dev_err(prestera_fw_dev(fw),
+					"Fw image is too big or invalid\n");
+				return -EINVAL;
+			}
 			return err;
+		}
 	}
 
 	if (pos < fw_size) {
-		err = prestera_ldr_send(fw, img + pos, fw_size - pos);
+		err = prestera_ldr_send_buf(fw, img + pos, fw_size - pos);
 		if (err)
 			return err;
 	}
 
-	err = prestera_ldr_wait_dl_finish(fw);
-	if (err)
-		return err;
+	/* Waiting for status IMG_DOWNLOADING to change to something else */
+	mask = ~(PRESTERA_LDR_STATUS_IMG_DL);
 
-	status = prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG);
+	if (!prestera_wait(prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG) &
+			   mask, PRESTERA_FW_DL_TIMEOUT)) {
+		dev_err(prestera_fw_dev(fw),
+			"Timeout to load FW img [state=%d]",
+			prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG));
+		return -ETIMEDOUT;
+	}
 
-	switch (status) {
-	case PRESTERA_LDR_STATUS_INVALID_IMG:
-		dev_err(fw->dev.dev, "FW img has bad CRC\n");
-		return -EINVAL;
-	case PRESTERA_LDR_STATUS_NOMEM:
-		dev_err(fw->dev.dev, "Loader has no enough mem\n");
-		return -ENOMEM;
+	status = prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG);
+	if (status != PRESTERA_LDR_STATUS_START_FW) {
+		switch (status) {
+		case PRESTERA_LDR_STATUS_INVALID_IMG:
+			dev_err(prestera_fw_dev(fw), "FW img has bad crc\n");
+			return -EINVAL;
+		case PRESTERA_LDR_STATUS_NOMEM:
+			dev_err(prestera_fw_dev(fw),
+				"Loader has no enough mem\n");
+			return -ENOMEM;
+		default:
+			break;
+		}
 	}
 
 	return 0;
 }
 
-static void prestera_fw_rev_parse(const struct prestera_fw_header *hdr,
-				  struct prestera_fw_rev *rev)
-{
-	u32 version = be32_to_cpu(hdr->version_value);
-
-	rev->maj = PRESTERA_FW_VER_MAJ(version);
-	rev->min = PRESTERA_FW_VER_MIN(version);
-	rev->sub = PRESTERA_FW_VER_PATCH(version);
-}
-
-static int prestera_fw_rev_check(struct prestera_fw *fw)
+static bool prestera_ldr_is_ready(struct prestera_fw *fw)
 {
-	struct prestera_fw_rev *rev = &fw->dev.fw_rev;
-
-	if (rev->maj == fw->rev_supp.maj && rev->min >= fw->rev_supp.min)
-		return 0;
-
-	dev_err(fw->dev.dev, "Driver supports FW version only '%u.%u.x'",
-		fw->rev_supp.maj, fw->rev_supp.min);
-
-	return -EINVAL;
+	return prestera_ldr_read(fw, PRESTERA_LDR_READY_REG) ==
+				 PRESTERA_LDR_READY_MAGIC;
 }
 
-static int prestera_fw_hdr_parse(struct prestera_fw *fw)
+static int prestera_fw_hdr_parse(struct prestera_fw *fw,
+				 const struct firmware *img)
 {
+	struct prestera_fw_header *hdr = (struct prestera_fw_header *)img->data;
 	struct prestera_fw_rev *rev = &fw->dev.fw_rev;
-	struct prestera_fw_header *hdr;
 	u32 magic;
 
-	hdr = (struct prestera_fw_header *)fw->bin->data;
-
 	magic = be32_to_cpu(hdr->magic_number);
 	if (magic != PRESTERA_FW_HDR_MAGIC) {
-		dev_err(fw->dev.dev, "FW img hdr magic is invalid");
+		dev_err(prestera_fw_dev(fw), "FW img type is invalid");
 		return -EINVAL;
 	}
 
 	prestera_fw_rev_parse(hdr, rev);
 
-	dev_info(fw->dev.dev, "FW version '%u.%u.%u'\n",
+	dev_info(prestera_fw_dev(fw), "FW version '%u.%u.%u'\n",
 		 rev->maj, rev->min, rev->sub);
+	dev_info(prestera_fw_dev(fw), "Driver version '%u.%u.%u'\n",
+		 PRESTERA_SUPP_FW_MAJ_VER, PRESTERA_SUPP_FW_MIN_VER,
+		 PRESTERA_SUPP_FW_PATCH_VER);
 
-	return prestera_fw_rev_check(fw);
-}
-
-static int prestera_fw_get(struct prestera_fw *fw)
-{
-	int ver_maj = PRESTERA_SUPP_FW_MAJ_VER;
-	int ver_min = PRESTERA_SUPP_FW_MIN_VER;
-	char fw_path[128];
-	int err;
-
-pick_fw_ver:
-	snprintf(fw_path, sizeof(fw_path), PRESTERA_FW_PATH_FMT,
-		 ver_maj, ver_min);
-
-	err = request_firmware_direct(&fw->bin, fw_path, fw->dev.dev);
-	if (err) {
-		if (ver_maj == PRESTERA_SUPP_FW_MAJ_VER) {
-			ver_maj = PRESTERA_PREV_FW_MAJ_VER;
-			ver_min = PRESTERA_PREV_FW_MIN_VER;
-
-			dev_warn(fw->dev.dev,
-				 "missing latest %s firmware, fall-back to previous %u.%u version\n",
-				 fw_path, ver_maj, ver_min);
-
-			goto pick_fw_ver;
-		} else {
-			dev_err(fw->dev.dev, "failed to request previous firmware: %s\n",
-				fw_path);
-			return err;
-		}
+	if (prestera_fw_rev_check(fw)) {
+		dev_err(prestera_fw_dev(fw),
+			"Driver is incompatible with FW: version mismatch");
+		return -EINVAL;
 	}
 
-	dev_info(fw->dev.dev, "Loading %s ...", fw_path);
-
-	fw->rev_supp.maj = ver_maj;
-	fw->rev_supp.min = ver_min;
-	fw->rev_supp.sub = 0;
-
 	return 0;
 }
 
-static void prestera_fw_put(struct prestera_fw *fw)
+static const char *prestera_fw_path_get(struct prestera_fw *fw)
 {
-	release_firmware(fw->bin);
+	switch (fw->pci_dev->device) {
+	case PRESTERA_DEV_ID_98DX3500:
+	case PRESTERA_DEV_ID_98DX3501:
+	case PRESTERA_DEV_ID_98DX3510:
+	case PRESTERA_DEV_ID_98DX3520:
+		return PRESTERA_FW_ARM64_PATH;
+
+	default:
+		return PRESTERA_FW_DEFAULT_PATH;
+	}
 }
 
 static int prestera_fw_load(struct prestera_fw *fw)
 {
 	size_t hlen = sizeof(struct prestera_fw_header);
+	const char *fw_path = prestera_fw_path_get(fw);
+	const struct firmware *f;
+	bool has_ldr;
 	int err;
 
-	err = prestera_ldr_wait_reg32(fw, PRESTERA_LDR_READY_REG,
-				      PRESTERA_LDR_READY_MAGIC,
-				      5 * MSEC_PER_SEC);
-	if (err) {
-		dev_err(fw->dev.dev, "waiting for FW loader is timed out");
-		return err;
+	/* 10s delay is required for soft reset feature */
+	has_ldr = prestera_wait(prestera_ldr_is_ready(fw), 15000);
+	if (!has_ldr) {
+		dev_err(prestera_fw_dev(fw),
+			"waiting for FW loader is timed out");
+		return -ETIMEDOUT;
 	}
 
 	fw->ldr_ring_buf = fw->ldr_regs +
 		prestera_ldr_read(fw, PRESTERA_LDR_BUF_OFFS_REG);
 
-	fw->ldr_buf_len =
-		prestera_ldr_read(fw, PRESTERA_LDR_BUF_SIZE_REG);
+	fw->ldr_buf_len = prestera_ldr_read(fw, PRESTERA_LDR_BUF_SIZE_REG);
 
 	fw->ldr_wr_idx = 0;
 
-	err = prestera_fw_get(fw);
-	if (err)
+	err = request_firmware_direct(&f, fw_path, &fw->pci_dev->dev);
+	if (err) {
+		dev_err(prestera_fw_dev(fw),
+			"failed to request firmware file: %s\n", fw_path);
 		return err;
+	}
 
-	err = prestera_fw_hdr_parse(fw);
+	if (!IS_ALIGNED(f->size, 4)) {
+		dev_err(prestera_fw_dev(fw), "FW image file is not aligned");
+		release_firmware(f);
+		return -EINVAL;
+	}
+
+	err = prestera_fw_hdr_parse(fw, f);
 	if (err) {
-		dev_err(fw->dev.dev, "FW image header is invalid\n");
-		goto out_release;
+		dev_err(prestera_fw_dev(fw), "FW image is invalid\n");
+		release_firmware(f);
+		return err;
 	}
 
-	prestera_ldr_write(fw, PRESTERA_LDR_IMG_SIZE_REG, fw->bin->size - hlen);
+	prestera_ldr_write(fw, PRESTERA_LDR_IMG_SIZE_REG, f->size - hlen);
 	prestera_ldr_write(fw, PRESTERA_LDR_CTL_REG, PRESTERA_LDR_CTL_DL_START);
 
-	err = prestera_ldr_fw_send(fw, fw->bin->data + hlen,
-				   fw->bin->size - hlen);
+	dev_info(prestera_fw_dev(fw), "Loading prestera FW image ...");
 
-out_release:
-	prestera_fw_put(fw);
+	err = prestera_ldr_send(fw, f->data + hlen, f->size - hlen);
+
+	release_firmware(f);
 	return err;
 }
 
+static bool prestera_pci_pp_use_bar2(struct pci_dev *pdev)
+{
+	switch (pdev->device) {
+	case PRESTERA_DEV_ID_ALDRIN3S:
+	case PRESTERA_DEV_ID_98DX3500:
+	case PRESTERA_DEV_ID_98DX3501:
+	case PRESTERA_DEV_ID_98DX3510:
+	case PRESTERA_DEV_ID_98DX3520:
+		return true;
+
+	default:
+		return false;
+	}
+}
+
+static u32 prestera_pci_pp_bar2_offs(struct pci_dev *pdev)
+{
+	if (pci_resource_len(pdev, 2) == 0x1000000)
+		return 0x0;
+	else
+		return (pci_resource_len(pdev, 2) / 2);
+}
+
+static u32 prestera_pci_fw_bar2_offs(struct pci_dev *pdev)
+{
+	if (pci_resource_len(pdev, 2) == 0x1000000)
+		return 0x400000;
+	else
+		return 0x0;
+}
+
 static int prestera_pci_probe(struct pci_dev *pdev,
 			      const struct pci_device_id *id)
 {
 	const char *driver_name = pdev->driver->name;
+	u8 __iomem *mem_addr, *pp_addr = NULL;
 	struct prestera_fw *fw;
 	int err;
 
-	err = pcim_enable_device(pdev);
-	if (err)
-		return err;
-
-	err = pcim_iomap_regions(pdev, BIT(PRESTERA_PCI_BAR_FW) |
-				 BIT(PRESTERA_PCI_BAR_PP),
-				 pci_name(pdev));
-	if (err)
-		return err;
+	err = pci_enable_device(pdev);
+	if (err) {
+		dev_err(&pdev->dev, "pci_enable_device failed\n");
+		goto err_pci_enable_device;
+	}
 
-	err = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(30));
+	err = pci_request_regions(pdev, driver_name);
 	if (err) {
+		dev_err(&pdev->dev, "pci_request_regions failed\n");
+		goto err_pci_request_regions;
+	}
+
+	if (dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(30))) {
 		dev_err(&pdev->dev, "fail to set DMA mask\n");
 		goto err_dma_mask;
 	}
 
+	mem_addr = pcim_iomap(pdev, 2, 0);
+	if (!mem_addr) {
+		dev_err(&pdev->dev, "pci mem ioremap failed\n");
+		err = -EIO;
+		goto err_mem_ioremap;
+	}
+
+	/* Aldrin3S uses second half of BAR2 */
+	if (prestera_pci_pp_use_bar2(pdev)) {
+		pp_addr = mem_addr + prestera_pci_pp_bar2_offs(pdev);
+		mem_addr = mem_addr + prestera_pci_fw_bar2_offs(pdev);
+	} else {
+		pp_addr = pcim_iomap(pdev, 4, 0);
+		if (!pp_addr) {
+			dev_err(&pdev->dev, "pp regs ioremap failed\n");
+			err = -EIO;
+			goto err_pp_ioremap;
+		}
+	}
+
 	pci_set_master(pdev);
 
-	fw = devm_kzalloc(&pdev->dev, sizeof(*fw), GFP_KERNEL);
+	fw = kzalloc(sizeof(*fw), GFP_KERNEL);
 	if (!fw) {
 		err = -ENOMEM;
 		goto err_pci_dev_alloc;
 	}
 
-	fw->dev.ctl_regs = pcim_iomap_table(pdev)[PRESTERA_PCI_BAR_FW];
-	fw->dev.pp_regs = pcim_iomap_table(pdev)[PRESTERA_PCI_BAR_PP];
+	fw->pci_dev = pdev;
 	fw->dev.dev = &pdev->dev;
-
-	pci_set_drvdata(pdev, fw);
-
-	err = prestera_fw_init(fw);
-	if (err)
-		goto err_prestera_fw_init;
-
-	dev_info(fw->dev.dev, "Prestera FW is ready\n");
-
-	fw->wq = alloc_workqueue("prestera_fw_wq", WQ_HIGHPRI, 1);
-	if (!fw->wq) {
-		err = -ENOMEM;
-		goto err_wq_alloc;
-	}
-
-	INIT_WORK(&fw->evt_work, prestera_fw_evt_work_fn);
+	fw->dev.send_req = prestera_fw_send_req;
+	fw->dev.pp_regs = pp_addr;
+	fw->dev.dma_flags = GFP_DMA;
+	fw->dev.running = true;
+	fw->mem_addr = mem_addr;
+	fw->ldr_regs = mem_addr;
+	fw->hw_regs = mem_addr;
 
 	err = pci_alloc_irq_vectors(pdev, 1, 1, PCI_IRQ_MSI);
 	if (err < 0) {
@@ -774,13 +456,26 @@ static int prestera_pci_probe(struct pci_dev *pdev,
 		goto err_irq_alloc;
 	}
 
-	err = request_irq(pci_irq_vector(pdev, 0), prestera_pci_irq_handler,
+	pci_set_drvdata(pdev, fw);
+
+	err = prestera_fw_load(fw);
+
+	if (err)
+		goto err_fw_init;
+
+	err = prestera_fw_init(fw);
+	if (err)
+		goto err_fw_init;
+
+	err = request_irq(pci_irq_vector(pdev, 0), prestera_irq_handler,
 			  0, driver_name, fw);
 	if (err) {
 		dev_err(&pdev->dev, "fail to request IRQ\n");
 		goto err_request_irq;
 	}
 
+	dev_info(prestera_fw_dev(fw), "Prestera Switch FW is ready\n");
+
 	err = prestera_device_register(&fw->dev);
 	if (err)
 		goto err_prestera_dev_register;
@@ -790,14 +485,19 @@ static int prestera_pci_probe(struct pci_dev *pdev,
 err_prestera_dev_register:
 	free_irq(pci_irq_vector(pdev, 0), fw);
 err_request_irq:
+	prestera_fw_uninit(fw);
+err_fw_init:
 	pci_free_irq_vectors(pdev);
 err_irq_alloc:
-	destroy_workqueue(fw->wq);
-err_wq_alloc:
-	prestera_fw_uninit(fw);
-err_prestera_fw_init:
+
 err_pci_dev_alloc:
+err_pp_ioremap:
+err_mem_ioremap:
 err_dma_mask:
+	pci_release_regions(pdev);
+err_pci_request_regions:
+	pci_disable_device(pdev);
+err_pci_enable_device:
 	return err;
 }
 
@@ -805,27 +505,67 @@ static void prestera_pci_remove(struct pci_dev *pdev)
 {
 	struct prestera_fw *fw = pci_get_drvdata(pdev);
 
-	prestera_device_unregister(&fw->dev);
 	free_irq(pci_irq_vector(pdev, 0), fw);
 	pci_free_irq_vectors(pdev);
-	destroy_workqueue(fw->wq);
+	prestera_device_unregister(&fw->dev);
 	prestera_fw_uninit(fw);
+	pci_release_regions(pdev);
+	pci_disable_device(pdev);
+	kfree(fw);
 }
 
-static const struct pci_device_id prestera_pci_devices[] = {
-	{ PCI_DEVICE(PCI_VENDOR_ID_MARVELL, 0xC804) },
-	{ PCI_DEVICE(PCI_VENDOR_ID_MARVELL, 0xC80C) },
-	{ }
-};
-MODULE_DEVICE_TABLE(pci, prestera_pci_devices);
+static int __init prestera_pci_init(void)
+{
+	struct prestera_pci_match *match;
+	int err = 0;
 
-static struct pci_driver prestera_pci_driver = {
-	.name     = "Prestera DX",
-	.id_table = prestera_pci_devices,
-	.probe    = prestera_pci_probe,
-	.remove   = prestera_pci_remove,
-};
-module_pci_driver(prestera_pci_driver);
+	for (match = prestera_devices; match->driver.name; match++) {
+		match->driver.probe = prestera_pci_probe;
+		match->driver.remove = prestera_pci_remove;
+		match->driver.id_table = &match->id;
+
+		err = pci_register_driver(&match->driver);
+		if (err) {
+			pr_err("prestera_pci: failed to register %s\n",
+			       match->driver.name);
+			break;
+		}
+
+		match->registered = true;
+	}
+
+	if (err) {
+		for (match = prestera_devices; match->driver.name; match++) {
+			if (!match->registered)
+				break;
+
+			pci_unregister_driver(&match->driver);
+		}
+
+		return err;
+	}
+
+	pr_info("prestera_pci: Registered Marvell Prestera PCI driver\n");
+	return 0;
+}
+
+static void __exit prestera_pci_exit(void)
+{
+	struct prestera_pci_match *match;
+
+	for (match = prestera_devices; match->driver.name; match++) {
+		if (!match->registered)
+			break;
+
+		pci_unregister_driver(&match->driver);
+	}
+
+	pr_info("prestera_pci: Unregistered Marvell Prestera PCI driver\n");
+}
+
+module_init(prestera_pci_init);
+module_exit(prestera_pci_exit);
 
-MODULE_LICENSE("Dual BSD/GPL");
+MODULE_AUTHOR("Marvell Semi.");
+MODULE_LICENSE("GPL");
 MODULE_DESCRIPTION("Marvell Prestera switch PCI interface");
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_router.c b/drivers/net/ethernet/marvell/prestera/prestera_router.c
new file mode 100644
index 000000000000..32d0b120f3bb
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_router.c
@@ -0,0 +1,2809 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/notifier.h>
+#include <linux/sort.h>
+#include <linux/inetdevice.h>
+#include <linux/netdevice.h>
+#include <linux/if_bridge.h>
+#include <net/netevent.h>
+#include <net/neighbour.h>
+#include <net/addrconf.h>
+#include <net/fib_notifier.h>
+#include <net/switchdev.h>
+#include <net/arp.h>
+#include <net/nexthop.h>
+#include <linux/rhashtable.h>
+
+#include "prestera.h"
+#include "prestera_ct.h"
+#include "prestera_hw.h"
+#include "prestera_log.h"
+#include "prestera_router_hw.h"
+
+#define MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH
+#define MVSW_PR_NH_PROBE_INTERVAL 5000 /* ms */
+
+static const char mvsw_driver_name[] = "mrvl_switchdev";
+
+/* Represent kernel object */
+struct prestera_rif {
+	struct net_device *dev;
+	struct prestera_rif_entry_key rif_entry_key; /* Key to hw object */
+	unsigned char addr[ETH_ALEN];
+	u32 kern_tb_id; /* tb_id from kernel (not fixed) */
+	struct list_head router_node;
+	bool is_active;
+	unsigned int ref_cnt;
+};
+
+struct mvsw_pr_rif_params {
+	struct net_device *dev;
+	u16 vid;
+};
+
+struct prestera_fib {
+	struct prestera_switch *sw;
+	struct notifier_block fib_nb;
+	struct notifier_block netevent_nb;
+};
+
+enum mvsw_pr_mp_hash_policy {
+	MVSW_MP_L3_HASH_POLICY,
+	MVSW_MP_L4_HASH_POLICY,
+	MVSW_MP_HASH_POLICY_MAX,
+};
+
+struct prestera_kern_neigh_cache_key {
+	struct prestera_ip_addr addr;
+	struct prestera_rif *rif;
+};
+
+struct prestera_kern_neigh_cache {
+	struct prestera_kern_neigh_cache_key key;
+	struct rhash_head ht_node;
+	struct list_head kern_fib_cache_list;
+	/* Lock cache if neigh is present in kernel */
+	bool in_kernel;
+	/* Hold prepared nh_neigh info if is in_kernel */
+	struct prestera_neigh_info nh_neigh_info;
+	/* Indicate if neighbour is reachable by direct route */
+	bool reachable;
+};
+
+struct mvsw_pr_kern_fib_cache_key {
+	struct prestera_ip_addr addr;
+	u32 prefix_len;
+	u32 kern_tb_id; /* tb_id from kernel (not fixed) */
+};
+
+/* Subscribing on neighbours in kernel */
+struct mvsw_pr_kern_fib_cache {
+	struct mvsw_pr_kern_fib_cache_key key;
+	struct {
+		struct prestera_fib_key fib_key;
+		enum prestera_fib_type fib_type;
+		struct prestera_nexthop_group_key nh_grp_key;
+	} lpm_info; /* hold prepared lpm info */
+	/* Indicate if route is not overlapped by another table */
+	bool reachable;
+	bool allow_oflag;
+	struct rhash_head ht_node; /* node of mvsw_pr_router */
+	struct mvsw_pr_kern_neigh_cache_head {
+		struct mvsw_pr_kern_fib_cache *this;
+		struct list_head head;
+		struct prestera_kern_neigh_cache *n_cache;
+	} kern_neigh_cache_head[PRESTERA_NHGR_SIZE_MAX];
+	struct fib_info *fi;
+};
+
+static const struct rhashtable_params __mvsw_pr_kern_neigh_cache_ht_params = {
+	.key_offset  = offsetof(struct prestera_kern_neigh_cache, key),
+	.head_offset = offsetof(struct prestera_kern_neigh_cache, ht_node),
+	.key_len     = sizeof(struct prestera_kern_neigh_cache_key),
+	.automatic_shrinking = true,
+};
+
+static const struct rhashtable_params __mvsw_pr_kern_fib_cache_ht_params = {
+	.key_offset  = offsetof(struct mvsw_pr_kern_fib_cache, key),
+	.head_offset = offsetof(struct mvsw_pr_kern_fib_cache, ht_node),
+	.key_len     = sizeof(struct mvsw_pr_kern_fib_cache_key),
+	.automatic_shrinking = true,
+};
+
+static struct workqueue_struct *mvsw_r_wq;
+static struct workqueue_struct *mvsw_r_owq;
+
+static DEFINE_MUTEX(mvsw_owq_mutex_wip); /* owq function is in progress */
+static bool mvsw_owq_flushing;
+static void mvsw_owq_lock(void)
+{
+	while (true) {
+		if (!mutex_trylock(&mvsw_owq_mutex_wip))
+			goto wip_again;
+
+		if (!rtnl_trylock() && !READ_ONCE(mvsw_owq_flushing))
+			goto rtnl_again;
+
+		break;
+rtnl_again:
+		mutex_unlock(&mvsw_owq_mutex_wip);
+wip_again:
+		schedule();
+	}
+}
+
+static void mvsw_owq_unlock(void)
+{
+	if (!READ_ONCE(mvsw_owq_flushing))
+		rtnl_unlock();
+
+	mutex_unlock(&mvsw_owq_mutex_wip);
+}
+
+/* Must be called under rtnl_lock */
+static void mvsw_owq_flush(void)
+{
+	/* Sanity check */
+	if (rtnl_trylock())
+		panic("%s: called without rtnl_lock !", __func__);
+
+	mutex_lock(&mvsw_owq_mutex_wip);
+	WRITE_ONCE(mvsw_owq_flushing, true);
+	mutex_unlock(&mvsw_owq_mutex_wip);
+
+	flush_workqueue(mvsw_r_owq);
+
+	mutex_lock(&mvsw_owq_mutex_wip);
+	WRITE_ONCE(mvsw_owq_flushing, false);
+	mutex_unlock(&mvsw_owq_mutex_wip);
+}
+
+static const unsigned char mvsw_pr_mac_mask[ETH_ALEN] = {
+	0xff, 0xff, 0xff, 0xff, 0xfc, 0x00
+};
+
+static u32 mvsw_pr_fix_tb_id(u32 tb_id);
+static struct prestera_rif *
+prestera_rif_create(struct prestera_switch *sw,
+		    const struct mvsw_pr_rif_params *params,
+		    struct netlink_ext_ack *extack);
+static void mvsw_pr_rif_destroy(struct prestera_switch *sw,
+				struct prestera_rif *rif);
+static void mvsw_pr_rif_put(struct prestera_switch *sw,
+			    struct prestera_rif *rif);
+static int mvsw_pr_rif_update(struct prestera_switch *sw,
+			      struct prestera_rif *rif);
+static struct prestera_rif *mvsw_pr_rif_find(const struct prestera_switch *sw,
+					     const struct net_device *dev);
+static bool mvsw_pr_fi_is_direct(struct fib_info *fi);
+static bool mvsw_pr_fi_is_hw_direct(struct prestera_switch *sw,
+				    struct fib_info *fi);
+static bool mvsw_pr_fi_is_nh(struct fib_info *fi);
+static bool
+mvsw_pr_fib_node_util_is_neighbour(struct prestera_fib_node *fib_node);
+static int
+mvsw_pr_util_fi2nh_gr_key(struct prestera_switch *sw, struct fib_info *fi,
+			  size_t limit,
+			  struct prestera_nexthop_group_key *grp_key);
+
+static u16 mvsw_pr_nh_dev_to_vid(struct prestera_switch *sw,
+				 struct net_device *dev)
+{
+	struct macvlan_dev *vlan;
+	u16 vid = 0;
+
+	if (is_vlan_dev(dev) &&
+	    netif_is_bridge_master(vlan_dev_real_dev(dev))) {
+		vid = vlan_dev_vlan_id(dev);
+	} else if (netif_is_bridge_master(dev) && br_vlan_enabled(dev)) {
+		br_vlan_get_pvid(dev, &vid);
+	} else if (netif_is_bridge_master(dev)) {
+		vid = prestera_vlan_dev_vlan_id(sw, dev);
+	} else if (netif_is_macvlan(dev)) {
+		vlan = netdev_priv(dev);
+		return mvsw_pr_nh_dev_to_vid(sw, vlan->lowerdev);
+	}
+
+	return vid;
+}
+
+static struct net_device*
+mvsw_pr_nh_dev_egress(struct prestera_switch *sw, struct net_device *dev,
+		      u8 *ha)
+{
+	struct net_device *bridge_dev, *egress_dev = dev;
+	u16 vid = mvsw_pr_nh_dev_to_vid(sw, dev);
+	struct macvlan_dev *vlan;
+
+	if (is_vlan_dev(dev) &&
+	    netif_is_bridge_master(vlan_dev_real_dev(dev))) {
+		bridge_dev = vlan_dev_priv(dev)->real_dev;
+		egress_dev = br_fdb_find_port(bridge_dev, ha,
+					      vid);
+	} else if (netif_is_bridge_master(dev) && br_vlan_enabled(dev)) {
+		egress_dev = br_fdb_find_port(dev, ha, vid);
+	} else if (netif_is_bridge_master(dev)) {
+		/* vid in .1d bridge is 0 */
+		egress_dev = br_fdb_find_port(dev, ha, 0);
+	} else if (netif_is_macvlan(dev)) {
+		vlan = netdev_priv(dev);
+		return mvsw_pr_nh_dev_egress(sw, vlan->lowerdev, ha);
+	}
+
+	return egress_dev;
+}
+
+static int prestera_dev2iface(struct prestera_switch *sw,
+			      struct net_device *dev,
+			      struct prestera_iface *iface)
+{
+	struct prestera_port *port = netdev_priv(dev);
+
+	memset(iface, 0, sizeof(*iface));
+	iface->type = prestera_dev_if_type(dev);
+	switch (iface->type) {
+	case PRESTERA_IF_PORT_E:
+		iface->dev_port.hw_dev_num = port->dev_id;
+		iface->dev_port.port_num = port->hw_id;
+		break;
+	case PRESTERA_IF_LAG_E:
+		prestera_lag_id_find(sw, dev, &iface->lag_id);
+		break;
+	case PRESTERA_IF_VID_E:
+		iface->vlan_id = mvsw_pr_nh_dev_to_vid(sw, dev);
+		break;
+	default:
+		pr_err("Unsupported rif type");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int
+__mvsw_pr_neigh_iface_init(struct prestera_switch *sw,
+			   struct prestera_iface *iface,
+			   struct neighbour *n,
+			   struct net_device *dev)
+{
+	bool is_nud_perm = n->nud_state & NUD_PERMANENT;
+	struct net_device *egress_dev;
+	struct prestera_port *port;
+
+	iface->type = prestera_dev_if_type(dev);
+
+	switch (iface->type) {
+	case PRESTERA_IF_PORT_E:
+	case PRESTERA_IF_VID_E:
+		egress_dev = mvsw_pr_nh_dev_egress(sw, dev, n->ha);
+		if (!egress_dev && is_nud_perm) {
+		/* Permanent neighbours on a bridge are not bounded to any
+		 * of the ports which is needed by the hardware, therefore
+		 * use any valid lower
+		 */
+			port = prestera_port_dev_lower_find(dev);
+			egress_dev = port->net_dev;
+		}
+		if (!egress_dev)
+			return -ENOENT;
+
+		if (!prestera_netdev_check(egress_dev))
+			return __mvsw_pr_neigh_iface_init(sw, iface, n,
+							  egress_dev);
+
+		port = netdev_priv(egress_dev);
+		iface->dev_port.hw_dev_num = port->dev_id;
+		iface->dev_port.port_num = port->hw_id;
+		break;
+	case PRESTERA_IF_LAG_E:
+		prestera_lag_id_find(sw, dev, &iface->lag_id);
+		break;
+	default:
+		MVSW_LOG_ERROR("Unsupported nexthop device");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int
+mvsw_pr_neigh_iface_init(struct prestera_switch *sw,
+			 struct prestera_iface *iface,
+			 struct neighbour *n)
+{
+	/* TODO vr_id is obsolete in iface ? */
+	iface->vlan_id = mvsw_pr_nh_dev_to_vid(sw, n->dev);
+	return __mvsw_pr_neigh_iface_init(sw, iface, n, n->dev);
+}
+
+static void mvsw_pr_util_kern_set_neigh_offload(struct neighbour *n,
+						bool offloaded)
+{
+	if (offloaded)
+		n->flags |= NTF_OFFLOADED;
+	else
+		n->flags &= ~NTF_OFFLOADED;
+}
+
+static void
+mvsw_pr_util_kern_set_nh_offload(struct fib_nh *fib_nh, bool offloaded)
+{
+		if (offloaded)
+			fib_nh->fib_nh_flags |= RTNH_F_OFFLOAD;
+		else
+			fib_nh->fib_nh_flags &= ~RTNH_F_OFFLOAD;
+}
+
+/* must be called with rcu_read_lock() */
+static int mvsw_pr_util_kern_get_route(struct fib_result *res,
+				       u32 tb_id,
+				       struct prestera_ip_addr *addr)
+{
+	struct fib_table *tb;
+	struct flowi4 fl4;
+	int ret;
+
+	/* TODO: walkthrough appropriate tables in kernel
+	 * to know if the same prefix exists in several tables
+	 */
+	tb = fib_new_table(&init_net, tb_id);
+	if (!tb)
+		return -ENOENT;
+
+	memset(&fl4, 0, sizeof(fl4));
+	fl4.daddr = addr->u.ipv4;
+	ret = fib_table_lookup(tb, &fl4, res, FIB_LOOKUP_NOREF);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int prestera_util_kern_dip2nh_grp_key(struct prestera_switch *sw,
+				      u32 tb_id, struct prestera_ip_addr *addr,
+				      struct prestera_nexthop_group_key *res)
+{
+	int err;
+	struct fib_result fib_res;
+	struct fib_nh *fib_nh;
+	struct prestera_rif *rif;
+
+	err = mvsw_pr_util_kern_get_route(&fib_res, tb_id, addr);
+	if (err)
+		return 0;
+
+	if (mvsw_pr_fi_is_direct(fib_res.fi)) {
+		fib_nh = fib_info_nh(fib_res.fi, 0);
+		memset(res, 0, sizeof(*res));
+		res->neigh[0].addr = *addr;
+		rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+		if (!rif || !rif->is_active)
+			return 0;
+
+		res->neigh[0].rif = rif;
+		return 1;
+	}
+
+	return mvsw_pr_util_fi2nh_gr_key(sw, fib_res.fi,
+					 PRESTERA_NHGR_SIZE_MAX, res);
+}
+
+static void
+prestera_util_n_cache_key2nh_key(struct prestera_kern_neigh_cache_key *ck,
+				 struct prestera_nh_neigh_key *nk)
+{
+	memset(nk, 0, sizeof(*nk));
+	nk->addr = ck->addr;
+	nk->rif = (void *)ck->rif;
+}
+
+/* Check if neigh route is reachable */
+static bool
+mvsw_pr_util_kern_n_is_reachable(u32 tb_id,
+				 struct prestera_ip_addr *addr,
+				 struct net_device *dev)
+{
+	bool reachable;
+	struct fib_nh *fib_nh;
+	struct fib_result res;
+
+	reachable = false;
+
+	if (!mvsw_pr_util_kern_get_route(&res, tb_id, addr))
+		if (res.type == RTN_UNICAST &&
+		    mvsw_pr_fi_is_direct(res.fi)) {
+			fib_nh = fib_info_nh(res.fi, 0);
+			if (dev == fib_nh->fib_nh_dev)
+				reachable = true;
+		}
+
+	return reachable;
+}
+
+static bool
+mvsw_pr_util_fi_is_point2dev(struct fib_info *fi,
+			     const struct net_device *dev)
+{
+	int nhs, i;
+	struct fib_nh *fib_nh;
+
+	nhs = fib_info_num_path(fi);
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fi, i);
+		if (fib_nh->fib_nh_dev == dev)
+			return true;
+	}
+
+	return false;
+}
+
+static int
+mvsw_pr_util_fib_nh2nh_neigh_key(struct prestera_switch *sw,
+				 struct fib_nh *fib_nh,
+				 struct prestera_nh_neigh_key *nh_key)
+{
+	struct prestera_rif *rif;
+
+	memset(nh_key, 0, sizeof(*nh_key));
+	nh_key->addr.u.ipv4 = fib_nh->fib_nh_gw4;
+	rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+	if (!rif || !rif->is_active)
+		return -ENOENT;
+
+	nh_key->rif = rif;
+	return 0;
+}
+
+static int
+prestera_util_fc2nh_gr_key(struct prestera_switch *sw,
+			   struct mvsw_pr_kern_fib_cache *fc,
+			   struct prestera_nexthop_group_key *grp_key)
+{
+	int i;
+
+	memset(grp_key, 0, sizeof(*grp_key));
+	for (i = 0; i < PRESTERA_NHGR_SIZE_MAX; i++) {
+		if (!fc->kern_neigh_cache_head[i].n_cache)
+			break;
+
+		grp_key->neigh[i].addr =
+			fc->kern_neigh_cache_head[i].n_cache->key.addr;
+		grp_key->neigh[i].rif =
+			fc->kern_neigh_cache_head[i].n_cache->key.rif;
+	}
+
+	return i;
+}
+
+static int
+mvsw_pr_util_fi2nh_gr_key(struct prestera_switch *sw, struct fib_info *fi,
+			  size_t limit,
+			  struct prestera_nexthop_group_key *grp_key)
+{
+	int i, nhs, err;
+	struct fib_nh *fib_nh;
+
+	if (!mvsw_pr_fi_is_nh(fi))
+		return 0;
+
+	nhs = fib_info_num_path(fi);
+	if (nhs > limit)
+		return 0;
+
+	memset(grp_key, 0, sizeof(*grp_key));
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fi, i);
+		err = mvsw_pr_util_fib_nh2nh_neigh_key(sw,
+						       fib_nh,
+						       &grp_key->neigh[i]);
+		if (err)
+			return 0;
+	}
+
+	return nhs;
+}
+
+static void
+mvsw_pr_util_fen_info2fib_cache_key(struct fib_entry_notifier_info *fen_info,
+				    struct mvsw_pr_kern_fib_cache_key *key)
+{
+	memset(key, 0, sizeof(*key));
+	key->addr.u.ipv4 = cpu_to_be32(fen_info->dst);
+	key->prefix_len = fen_info->dst_len;
+	key->kern_tb_id = fen_info->tb_id;
+}
+
+static void
+mvsw_pr_util_fib_cache_key2fib_key(struct mvsw_pr_kern_fib_cache_key *ckey,
+				   struct prestera_fib_key *fkey)
+{
+	memset(fkey, 0, sizeof(*fkey));
+	fkey->addr = ckey->addr;
+	fkey->prefix_len = ckey->prefix_len;
+	fkey->tb_id = mvsw_pr_fix_tb_id(ckey->kern_tb_id);
+}
+
+static int
+prestera_util_fib_nh2n_cache_key(struct prestera_switch *sw,
+				 struct fib_nh *fib_nh,
+				 struct prestera_kern_neigh_cache_key *nk)
+{
+	struct prestera_rif *rif;
+
+	memset(nk, 0, sizeof(*nk));
+	nk->addr.u.ipv4 = fib_nh->fib_nh_gw4;
+	rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+	if (!rif || !rif->is_active)
+		return -ENOENT;
+
+	nk->rif = rif;
+	return 0;
+}
+
+static bool
+prestera_util_fib_nh_eq_n_cache_key(struct prestera_switch *sw,
+				    struct fib_nh *fib_nh,
+				    struct prestera_kern_neigh_cache_key *nk)
+{
+	int err;
+	struct prestera_kern_neigh_cache_key tk;
+
+	err = prestera_util_fib_nh2n_cache_key(sw, fib_nh, &tk);
+	if (err)
+		return false;
+
+	if (memcmp(&tk, nk, sizeof(tk)))
+		return false;
+
+	return true;
+}
+
+static int mvsw_pr_util_neigh2nh_neigh_key(struct prestera_switch *sw,
+					   struct neighbour *n,
+					   struct prestera_nh_neigh_key *key)
+{
+	memset(key, 0, sizeof(*key));
+	key->addr.u.ipv4 = *(__be32 *)n->primary_key;
+	key->rif = mvsw_pr_rif_find(sw, n->dev);
+	if (!key->rif)
+		return -ENOENT;
+
+	return 0;
+}
+
+static struct prestera_kern_neigh_cache *
+mvsw_pr_kern_neigh_cache_find(struct prestera_switch *sw,
+			      struct prestera_nh_neigh_key *key)
+{
+	struct prestera_kern_neigh_cache *n_cache;
+
+	n_cache =
+	 rhashtable_lookup_fast(&sw->router->kern_neigh_cache_ht, key,
+				__mvsw_pr_kern_neigh_cache_ht_params);
+	return IS_ERR(n_cache) ? NULL : n_cache;
+}
+
+static void
+__mvsw_pr_kern_neigh_cache_destroy(struct prestera_switch *sw,
+				   struct prestera_kern_neigh_cache *n_cache)
+{
+	n_cache->key.rif->ref_cnt--;
+	mvsw_pr_rif_put(sw, n_cache->key.rif);
+	rhashtable_remove_fast(&sw->router->kern_neigh_cache_ht,
+			       &n_cache->ht_node,
+			       __mvsw_pr_kern_neigh_cache_ht_params);
+	kfree(n_cache);
+}
+
+static struct prestera_kern_neigh_cache *
+__mvsw_pr_kern_neigh_cache_create(struct prestera_switch *sw,
+				  struct prestera_nh_neigh_key *key)
+{
+	struct prestera_kern_neigh_cache *n_cache;
+	int err;
+
+	n_cache = kzalloc(sizeof(*n_cache), GFP_KERNEL);
+	if (!n_cache)
+		goto err_kzalloc;
+
+	memcpy(&n_cache->key, key, sizeof(*key));
+	n_cache->key.rif->ref_cnt++;
+
+	INIT_LIST_HEAD(&n_cache->kern_fib_cache_list);
+	err = rhashtable_insert_fast(&sw->router->kern_neigh_cache_ht,
+				     &n_cache->ht_node,
+				     __mvsw_pr_kern_neigh_cache_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	return n_cache;
+
+err_ht_insert:
+	n_cache->key.rif->ref_cnt--;
+	mvsw_pr_rif_put(sw, n_cache->key.rif);
+	kfree(n_cache);
+err_kzalloc:
+	return NULL;
+}
+
+static struct prestera_kern_neigh_cache *
+mvsw_pr_kern_neigh_cache_get(struct prestera_switch *sw,
+			     struct prestera_nh_neigh_key *key)
+{
+	struct prestera_kern_neigh_cache *n_cache;
+
+	n_cache = mvsw_pr_kern_neigh_cache_find(sw, key);
+	if (!n_cache)
+		n_cache = __mvsw_pr_kern_neigh_cache_create(sw, key);
+
+	return n_cache;
+}
+
+static struct prestera_kern_neigh_cache *
+mvsw_pr_kern_neigh_cache_put(struct prestera_switch *sw,
+			     struct prestera_kern_neigh_cache *n_cache)
+{
+	if (!n_cache->in_kernel &&
+	    list_empty(&n_cache->kern_fib_cache_list)) {
+		__mvsw_pr_kern_neigh_cache_destroy(sw, n_cache);
+		return NULL;
+	}
+
+	return n_cache;
+}
+
+static struct mvsw_pr_kern_fib_cache *
+mvsw_pr_kern_fib_cache_find(struct prestera_switch *sw,
+			    struct mvsw_pr_kern_fib_cache_key *key)
+{
+	struct mvsw_pr_kern_fib_cache *fib_cache;
+
+	fib_cache =
+	 rhashtable_lookup_fast(&sw->router->kern_fib_cache_ht, key,
+				__mvsw_pr_kern_fib_cache_ht_params);
+	return IS_ERR(fib_cache) ? NULL : fib_cache;
+}
+
+static void
+mvsw_pr_kern_fib_cache_destroy(struct prestera_switch *sw,
+			       struct mvsw_pr_kern_fib_cache *fib_cache)
+{
+	int i;
+	struct prestera_kern_neigh_cache *n_cache;
+
+	for (i = 0; i < PRESTERA_NHGR_SIZE_MAX; i++) {
+		n_cache = fib_cache->kern_neigh_cache_head[i].n_cache;
+		if (n_cache) {
+			list_del(&fib_cache->kern_neigh_cache_head[i].head);
+			mvsw_pr_kern_neigh_cache_put(sw, n_cache);
+		}
+	}
+
+	fib_info_put(fib_cache->fi);
+	rhashtable_remove_fast(&sw->router->kern_fib_cache_ht,
+			       &fib_cache->ht_node,
+			       __mvsw_pr_kern_fib_cache_ht_params);
+	kfree(fib_cache);
+}
+
+/* Operations on fi (offload, etc) must be wrapped in utils.
+ * This function just create storage.
+ */
+static struct mvsw_pr_kern_fib_cache *
+prestera_kern_fib_cache_create(struct prestera_switch *sw,
+			       struct mvsw_pr_kern_fib_cache_key *key,
+			       struct fib_info *fi)
+{
+	struct mvsw_pr_kern_fib_cache *fib_cache;
+	struct prestera_kern_neigh_cache *n_cache;
+	struct prestera_nh_neigh_key nh_key;
+	int err, i, nhs;
+
+	fib_cache = kzalloc(sizeof(*fib_cache), GFP_KERNEL);
+	if (!fib_cache)
+		goto err_kzalloc;
+
+	memcpy(&fib_cache->key, key, sizeof(*key));
+	fib_info_hold(fi);
+	fib_cache->fi = fi;
+	/* This is for unnatural offload flag logic
+	 * to satisfy user expectations.
+	 */
+	fib_cache->allow_oflag |= !!mvsw_pr_fi_is_hw_direct(sw, fi);
+
+	err = rhashtable_insert_fast(&sw->router->kern_fib_cache_ht,
+				     &fib_cache->ht_node,
+				     __mvsw_pr_kern_fib_cache_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	/* Handle nexthops */
+
+	if (!mvsw_pr_fi_is_nh(fi))
+		goto out;
+
+	nhs = fib_info_num_path(fi);
+	if (nhs > PRESTERA_NHGR_SIZE_MAX)
+		goto out;
+
+	for (i = 0; i < nhs; i++) {
+		err = mvsw_pr_util_fib_nh2nh_neigh_key(sw, fib_info_nh(fi, i),
+						       &nh_key);
+		if (err)
+			goto out;
+
+		n_cache = mvsw_pr_kern_neigh_cache_get(sw, &nh_key);
+		if (!n_cache)
+			goto out;
+
+		fib_cache->kern_neigh_cache_head[i].this = fib_cache;
+		fib_cache->kern_neigh_cache_head[i].n_cache = n_cache;
+		list_add(&fib_cache->kern_neigh_cache_head[i].head,
+			 &n_cache->kern_fib_cache_list);
+	}
+
+	/* This is for unnatural offload flag logic
+	 * to satisfy user expectations.
+	 */
+	fib_cache->allow_oflag |= !!nhs;
+
+out:
+	return fib_cache;
+
+err_ht_insert:
+	fib_info_put(fi);
+	kfree(fib_cache);
+err_kzalloc:
+	return NULL;
+}
+
+static void
+__mvsw_pr_k_arb_fib_offload_set(struct prestera_switch *sw,
+				struct mvsw_pr_kern_fib_cache *fibc,
+				struct prestera_kern_neigh_cache *nc,
+				bool offloaded)
+{
+	int i, nhs;
+	struct fib_nh *fib_nh;
+
+	nhs = fib_info_num_path(fibc->fi);
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fibc->fi, i);
+		if (!nc) {
+			mvsw_pr_util_kern_set_nh_offload(fib_nh, offloaded);
+			continue;
+		}
+
+		if (prestera_util_fib_nh_eq_n_cache_key(sw, fib_nh, &nc->key)) {
+			mvsw_pr_util_kern_set_nh_offload(fib_nh, offloaded);
+			break;
+		}
+	}
+}
+
+static void
+__mvsw_pr_k_arb_n_offload_set(struct prestera_switch *sw,
+			      struct prestera_kern_neigh_cache *nc,
+			      bool offloaded)
+{
+	struct neighbour *n;
+
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+
+	if (!n)
+		return;
+
+	mvsw_pr_util_kern_set_neigh_offload(n, offloaded);
+	neigh_release(n);
+}
+
+static void
+__mvsw_pr_k_arb_n_lpm_set(struct prestera_switch *sw,
+			  struct prestera_kern_neigh_cache *n_cache,
+			  bool enabled)
+{
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+	struct mvsw_pr_kern_fib_cache *fib_cache;
+	struct prestera_fib_key fib_key;
+	struct prestera_fib_node *fib_node;
+	struct prestera_nexthop_group_key nh_grp_key;
+
+	/* Exception for fc with prefix 32: LPM entry is already used by fib */
+	memset(&fc_key, 0, sizeof(fc_key));
+	fc_key.addr = n_cache->key.addr;
+	fc_key.prefix_len = 32;
+	/* But better to use tb_id of route, which pointed to this neighbour. */
+	/* We take it from rif, because rif inconsistent.
+	 * Must be separated in_rif and out_rif.
+	 */
+	fc_key.kern_tb_id = n_cache->key.rif->kern_tb_id;
+	fib_cache = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	if (!fib_cache || !fib_cache->reachable) {
+		memset(&fib_key, 0, sizeof(fib_key));
+		fib_key.addr = n_cache->key.addr;
+		fib_key.prefix_len = 32;
+		fib_key.tb_id = mvsw_pr_fix_tb_id(n_cache->key.rif->kern_tb_id);
+		fib_node = prestera_fib_node_find(sw, &fib_key);
+		if (!enabled && fib_node) {
+			if (mvsw_pr_fib_node_util_is_neighbour(fib_node))
+				prestera_fib_node_destroy(sw, fib_node);
+			return;
+		}
+	}
+
+	if (enabled && !fib_node) {
+		memset(&nh_grp_key, 0, sizeof(nh_grp_key));
+		prestera_util_n_cache_key2nh_key(&n_cache->key,
+						 &nh_grp_key.neigh[0]);
+		fib_node = prestera_fib_node_create(sw, &fib_key,
+						    PRESTERA_FIB_TYPE_UC_NH,
+						    &nh_grp_key);
+		if (!fib_node)
+			MVSW_LOG_ERROR("%s failed ip=%pI4n",
+				       "prestera_fib_node_create",
+				       &fib_key.addr.u.ipv4);
+		return;
+	}
+}
+
+static void
+__mvsw_pr_k_arb_nc_kern_fib_fetch(struct prestera_switch *sw,
+				  struct prestera_kern_neigh_cache *nc)
+{
+	if (mvsw_pr_util_kern_n_is_reachable(nc->key.rif->kern_tb_id,
+					     &nc->key.addr,
+					     nc->key.rif->dev))
+		nc->reachable = true;
+	else
+		nc->reachable = false;
+}
+
+/* Kernel neighbour -> neigh_cache info */
+static void
+__mvsw_pr_k_arb_nc_kern_n_fetch(struct prestera_switch *sw,
+				struct prestera_kern_neigh_cache *nc)
+{
+	struct neighbour *n;
+	struct prestera_rif_entry *re;
+	int err;
+
+	memset(&nc->nh_neigh_info, 0, sizeof(nc->nh_neigh_info));
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+	if (!n)
+		goto out;
+
+	read_lock_bh(&n->lock);
+	if (n->nud_state & NUD_VALID && !n->dead) {
+		err = mvsw_pr_neigh_iface_init(sw, &nc->nh_neigh_info.iface, n);
+		if (err) {
+			MVSW_LOG_ERROR("Cannot initialize iface for %pI4n %pM",
+				       n->primary_key, &n->ha[0]);
+			goto n_read_out;
+		}
+		/* This line is dirty.
+		 * We add it, because there is vlan, wich mapped by vr_id.
+		 * But this is incorrect. Because nh is pointed to vlan, not vr!
+		 * If kernel will manage routing vlans - this will be more
+		 * logicaly.
+		 */
+		re = prestera_rif_entry_find(sw, &nc->key.rif->rif_entry_key);
+		if (re)
+			nc->nh_neigh_info.iface.vr_id = re->vr->hw_vr_id;
+		else
+			goto n_read_out;
+
+		memcpy(&nc->nh_neigh_info.ha[0], &n->ha[0], ETH_ALEN);
+		nc->nh_neigh_info.connected = true;
+	}
+n_read_out:
+	read_unlock_bh(&n->lock);
+out:
+	nc->in_kernel = nc->nh_neigh_info.connected;
+	if (n)
+		neigh_release(n);
+}
+
+/* neigh_cache info -> lpm update */
+static void
+__mvsw_pr_k_arb_nc_apply(struct prestera_switch *sw,
+			 struct prestera_kern_neigh_cache *nc)
+{
+	struct prestera_nh_neigh_key nh_key;
+	struct prestera_nh_neigh *nh_neigh;
+	struct mvsw_pr_kern_neigh_cache_head *nhead;
+	struct prestera_acl_nat_port *nat_port;
+	struct prestera_port *port;
+	u32 port_hw_id, port_dev_id;
+	int err;
+
+	__mvsw_pr_k_arb_n_lpm_set(sw, nc,
+				  nc->reachable && nc->in_kernel);
+	__mvsw_pr_k_arb_n_offload_set(sw, nc,
+				      nc->reachable && nc->in_kernel);
+
+	/* update NAT port on neighbour change */
+	/* Note: should be no such lines here. It's iincorrect static NAT. */
+	port_hw_id = nc->key.rif->rif_entry_key.iface.dev_port.port_num;
+	port_dev_id = nc->key.rif->rif_entry_key.iface.dev_port.hw_dev_num;
+	nat_port = prestera_acl_nat_port_get(sw->acl, port_hw_id,
+					     port_dev_id);
+	if (!nat_port)
+		goto skip_nat_port_update;
+
+	port = prestera_acl_nat_port_to_port(nat_port);
+	prestera_acl_nat_port_put(nat_port);
+
+	err = prestera_hw_nat_port_neigh_update(port,
+						nc->nh_neigh_info.ha);
+	if (err)
+		/* do not fail others, just print an error */
+		MVSW_LOG_ERROR("Update NAT neigh fail [%pI4n, %pM]",
+			       &nc->key.addr.u.ipv4,
+			       nc->nh_neigh_info.ha);
+
+skip_nat_port_update:
+	prestera_util_n_cache_key2nh_key(&nc->key, &nh_key);
+	nh_neigh = prestera_nh_neigh_find(sw, &nh_key);
+	if (!nh_neigh)
+		goto out;
+
+	/* Do hw update only if something changed to prevent nh flap */
+	if (memcmp(&nc->nh_neigh_info, &nh_neigh->info,
+		   sizeof(nh_neigh->info))) {
+		memcpy(&nh_neigh->info, &nc->nh_neigh_info,
+		       sizeof(nh_neigh->info));
+		err = prestera_nh_neigh_set(sw, nh_neigh);
+		if (err) {
+			MVSW_LOG_ERROR("%s failed with err=%d ip=%pI4n mac=%pM",
+				       "mvsw_pr_nh_neigh_set", err,
+				       &nh_neigh->key.addr.u.ipv4,
+				       &nh_neigh->info.ha[0]);
+			goto out;
+		}
+	}
+
+out:
+	list_for_each_entry(nhead, &nc->kern_fib_cache_list, head) {
+		__mvsw_pr_k_arb_fib_offload_set(sw, nhead->this, nc,
+						nc->in_kernel &&
+						nhead->this->reachable &&
+						nhead->this->allow_oflag);
+	}
+}
+
+static void __mvsw_pr_k_arb_hw_state_upd(struct prestera_switch *sw,
+					 struct prestera_kern_neigh_cache *nc)
+{
+	bool hw_active;
+	struct prestera_nh_neigh_key nh_key;
+	struct prestera_nh_neigh *nh_neigh;
+	struct neighbour *n;
+
+	prestera_util_n_cache_key2nh_key(&nc->key, &nh_key);
+	nh_neigh = prestera_nh_neigh_find(sw, &nh_key);
+	if (!nh_neigh) {
+		MVSW_LOG_ERROR("Cannot find nh_neigh for cached %pI4n",
+			       &nc->key.addr.u.ipv4);
+		return;
+	}
+
+	hw_active = prestera_nh_neigh_util_hw_state(sw, nh_neigh);
+
+#ifdef MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH
+	if (!hw_active && nc->in_kernel)
+		goto out;
+#else /* MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH */
+	if (!hw_active)
+		goto out;
+#endif /* MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH */
+
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+	if (!n) {
+		n = neigh_create(&arp_tbl, &nc->key.addr.u.ipv4,
+				 nc->key.rif->dev);
+		if (IS_ERR(n)) {
+			n = NULL;
+			MVSW_LOG_ERROR("Cannot create neighbour %pI4n",
+				       &nc->key.addr.u.ipv4);
+		}
+	}
+
+	if (n) {
+		neigh_event_send(n, NULL);
+		neigh_release(n);
+	}
+
+out:
+	return;
+}
+
+static int __mvsw_pr_k_arb_f_lpm_set(struct prestera_switch *sw,
+				     struct mvsw_pr_kern_fib_cache *fc,
+				     bool enabled)
+{
+	struct prestera_fib_node *fib_node;
+
+	fib_node = prestera_fib_node_find(sw, &fc->lpm_info.fib_key);
+	if (fib_node)
+		prestera_fib_node_destroy(sw, fib_node);
+
+	if (!enabled)
+		return 0;
+
+	fib_node = prestera_fib_node_create(sw, &fc->lpm_info.fib_key,
+					    fc->lpm_info.fib_type,
+					    &fc->lpm_info.nh_grp_key);
+
+	if (!fib_node) {
+		MVSW_LOG_ERROR("fib_node=NULL %pI4n/%d kern_tb_id = %d",
+			       &fc->key.addr.u.ipv4, fc->key.prefix_len,
+			       fc->key.kern_tb_id);
+		return -ENOENT;
+	}
+
+	return 0;
+}
+
+static int __mvsw_pr_k_arb_fc_apply(struct prestera_switch *sw,
+				    struct mvsw_pr_kern_fib_cache *fc)
+{
+	int err;
+	int nh_cnt;
+	struct prestera_rif *rif;
+	struct fib_nh *fib_nh;
+
+	memset(&fc->lpm_info, 0, sizeof(fc->lpm_info));
+
+	switch (fc->fi->fib_type) {
+	case RTN_UNICAST:
+		if (mvsw_pr_fi_is_direct(fc->fi) &&
+		    fc->key.prefix_len == 32 &&
+		    fc->key.addr.v == PRESTERA_IPV4) {
+			/* This is special case.
+			 * When prefix is 32. Than we will have conflict in lpm
+			 * for direct route - once TRAP added, there is no
+			 * place for neighbour entry. So represent direct route
+			 * with prefix 32, as NH. So neighbour will be resolved
+			 * as nexthop of this route.
+			 */
+			fib_nh = fib_info_nh(fc->fi, 0);
+			rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+			/* If we realy can access this route via HW */
+			if (!rif || !rif->is_active) {
+				fc->lpm_info.fib_type = PRESTERA_FIB_TYPE_TRAP;
+			} else {
+				fc->lpm_info.fib_type = PRESTERA_FIB_TYPE_UC_NH;
+				fc->lpm_info.nh_grp_key.neigh[0].addr =
+					fc->key.addr;
+				fc->lpm_info.nh_grp_key.neigh[0].rif = rif;
+			}
+
+			break;
+		}
+
+		/* We can also get nh_grp_key from fi. This will be correct to
+		 * because cache not always represent, what actually written to
+		 * lpm. But we use nh cache, as well for now (for this case).
+		 */
+		nh_cnt = prestera_util_fc2nh_gr_key(sw, fc,
+						    &fc->lpm_info.nh_grp_key);
+		fc->lpm_info.fib_type = nh_cnt ?
+					PRESTERA_FIB_TYPE_UC_NH :
+					PRESTERA_FIB_TYPE_TRAP;
+		break;
+	/* Unsupported. Leave it for kernel: */
+	case RTN_BROADCAST:
+	case RTN_MULTICAST:
+	/* Routes we must trap by design: */
+	case RTN_LOCAL:
+	case RTN_UNREACHABLE:
+	case RTN_PROHIBIT:
+		fc->lpm_info.fib_type = PRESTERA_FIB_TYPE_TRAP;
+		break;
+	case RTN_BLACKHOLE:
+		fc->lpm_info.fib_type = PRESTERA_FIB_TYPE_DROP;
+		break;
+	default:
+		MVSW_LOG_ERROR("Unsupported fib_type");
+		return -EOPNOTSUPP;
+	}
+
+	mvsw_pr_util_fib_cache_key2fib_key(&fc->key,
+					   &fc->lpm_info.fib_key);
+
+	/* 1. Update lpm */
+	err = __mvsw_pr_k_arb_f_lpm_set(sw, fc, fc->reachable);
+	if (err)
+		return err;
+
+	/* UC_NH offload flag is managed by neighbours cache */
+	if (fc->lpm_info.fib_type != PRESTERA_FIB_TYPE_UC_NH || !fc->reachable)
+		__mvsw_pr_k_arb_fib_offload_set(sw, fc, NULL, fc->reachable &&
+						fc->allow_oflag);
+
+	return 0;
+}
+
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_util_fib_overlaps(struct prestera_switch *sw,
+				  struct mvsw_pr_kern_fib_cache *fc)
+{
+	struct mvsw_pr_kern_fib_cache *rfc;
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+
+	/* TODO: parse kernel rules */
+	rfc = NULL;
+	if (fc->key.kern_tb_id == RT_TABLE_LOCAL) {
+		memcpy(&fc_key, &fc->key, sizeof(fc_key));
+		fc_key.kern_tb_id = RT_TABLE_MAIN;
+		rfc = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	}
+
+	return rfc;
+}
+
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_util_fib_overlapped(struct prestera_switch *sw,
+				    struct mvsw_pr_kern_fib_cache *fc)
+{
+	struct mvsw_pr_kern_fib_cache *rfc;
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+
+	/* TODO: parse kernel rules */
+	rfc = NULL;
+	if (fc->key.kern_tb_id == RT_TABLE_MAIN) {
+		memcpy(&fc_key, &fc->key, sizeof(fc_key));
+		fc_key.kern_tb_id = RT_TABLE_LOCAL;
+		rfc = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	}
+
+	return rfc;
+}
+
+static void __mvsw_pr_k_arb_abort_neigh(struct prestera_switch *sw)
+{
+	struct prestera_kern_neigh_cache *n_cache;
+	struct rhashtable_iter iter;
+
+	while (1) {
+		rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+		rhashtable_walk_start(&iter);
+
+		n_cache = rhashtable_walk_next(&iter);
+
+		rhashtable_walk_stop(&iter);
+		rhashtable_walk_exit(&iter);
+
+		if (!n_cache) {
+			break;
+		} else if (IS_ERR(n_cache)) {
+			continue;
+		} else if (n_cache) {
+			if (!list_empty(&n_cache->kern_fib_cache_list)) {
+				WARN_ON(1); /* BUG */
+				continue;
+			}
+			__mvsw_pr_k_arb_n_offload_set(sw, n_cache, false);
+			n_cache->in_kernel = false;
+			/* No need to destroy lpm.
+			 * It will be aborted by destroy_ht
+			 */
+			__mvsw_pr_kern_neigh_cache_destroy(sw, n_cache);
+		}
+	}
+}
+
+static void __mvsw_pr_k_arb_abort_fib(struct prestera_switch *sw)
+{
+	struct mvsw_pr_kern_fib_cache *fib_cache;
+	struct rhashtable_iter iter;
+
+	while (1) {
+		rhashtable_walk_enter(&sw->router->kern_fib_cache_ht, &iter);
+		rhashtable_walk_start(&iter);
+
+		fib_cache = rhashtable_walk_next(&iter);
+
+		rhashtable_walk_stop(&iter);
+		rhashtable_walk_exit(&iter);
+
+		if (!fib_cache) {
+			break;
+		} else if (IS_ERR(fib_cache)) {
+			continue;
+		} else if (fib_cache) {
+			__mvsw_pr_k_arb_fib_offload_set(sw, fib_cache, NULL,
+							false);
+			/* No need to destroy lpm.
+			 * It will be aborted by destroy_ht
+			 */
+			mvsw_pr_kern_fib_cache_destroy(sw, fib_cache);
+		}
+	}
+}
+
+static void mvsw_pr_k_arb_abort(struct prestera_switch *sw)
+{
+	__mvsw_pr_k_arb_abort_fib(sw);
+	__mvsw_pr_k_arb_abort_neigh(sw);
+}
+
+/* Make necesssary things  with neighbour, if FDB upupdated
+ * Known useacase for this function:
+ *  if FDB entry (which tied on neigh) updated - we need to reaply it in HW
+ */
+void prestera_k_arb_fdb_evt(struct prestera_switch *sw, struct net_device *dev)
+{
+	struct net_device *upper_dev;
+	struct list_head *list_iter;
+	struct prestera_rif *rif;
+	struct prestera_kern_neigh_cache *n_cache;
+	struct rhashtable_iter iter;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (rif) {
+		/* TODO: seems to be a lot of places, where such iteration used.
+		 * Maybe, make sense to write macros.
+		 */
+		rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+		rhashtable_walk_start(&iter);
+		while (1) {
+			n_cache = rhashtable_walk_next(&iter);
+
+			if (!n_cache)
+				break;
+
+			if (IS_ERR(n_cache))
+				continue;
+
+			if (n_cache->key.rif != rif)
+				continue;
+
+			rhashtable_walk_stop(&iter);
+			__mvsw_pr_k_arb_nc_kern_n_fetch(sw, n_cache);
+			__mvsw_pr_k_arb_nc_apply(sw, n_cache);
+			rhashtable_walk_start(&iter);
+		}
+		rhashtable_walk_stop(&iter);
+		rhashtable_walk_exit(&iter);
+	}
+
+	netdev_for_each_upper_dev_rcu(dev, upper_dev, list_iter)
+		prestera_k_arb_fdb_evt(sw, upper_dev);
+}
+
+/* Propagate kernel event to hw */
+static void mvsw_pr_k_arb_n_evt(struct prestera_switch *sw,
+				struct neighbour *n)
+{
+	struct prestera_kern_neigh_cache *n_cache;
+	struct prestera_nh_neigh_key n_key;
+	int err;
+
+	err = mvsw_pr_util_neigh2nh_neigh_key(sw, n, &n_key);
+	if (err)
+		return;
+
+	n_cache = mvsw_pr_kern_neigh_cache_find(sw, &n_key);
+	if (!n_cache) {
+		n_cache = mvsw_pr_kern_neigh_cache_get(sw, &n_key);
+		if (!n_cache)
+			return;
+		__mvsw_pr_k_arb_nc_kern_fib_fetch(sw, n_cache);
+	}
+
+	__mvsw_pr_k_arb_nc_kern_n_fetch(sw, n_cache);
+	__mvsw_pr_k_arb_nc_apply(sw, n_cache);
+
+	mvsw_pr_kern_neigh_cache_put(sw, n_cache);
+}
+
+/* Propagate hw state to kernel */
+static void mvsw_pr_k_arb_hw_evt(struct prestera_switch *sw)
+{
+	struct prestera_kern_neigh_cache *n_cache;
+	struct rhashtable_iter iter;
+
+	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		n_cache = rhashtable_walk_next(&iter);
+
+		if (!n_cache)
+			break;
+
+		if (IS_ERR(n_cache))
+			continue;
+
+		rhashtable_walk_stop(&iter);
+		__mvsw_pr_k_arb_hw_state_upd(sw, n_cache);
+		rhashtable_walk_start(&iter);
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+}
+
+static void __mvsw_pr_k_arb_fib_evt2nc(struct prestera_switch *sw)
+{
+	struct prestera_kern_neigh_cache *n_cache;
+	struct rhashtable_iter iter;
+
+	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		n_cache = rhashtable_walk_next(&iter);
+
+		if (!n_cache)
+			break;
+
+		if (IS_ERR(n_cache))
+			continue;
+
+		rhashtable_walk_stop(&iter);
+		__mvsw_pr_k_arb_nc_kern_fib_fetch(sw, n_cache);
+		__mvsw_pr_k_arb_nc_apply(sw, n_cache);
+		rhashtable_walk_start(&iter);
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+}
+
+/* Propagate fib changes to hw neighs */
+static int
+mvsw_pr_k_arb_fib_evt(struct prestera_switch *sw,
+		      bool replace, /* replace or del */
+		      struct fib_entry_notifier_info *fen_info)
+{
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+	struct mvsw_pr_kern_fib_cache *fib_cache;
+	struct mvsw_pr_kern_fib_cache *tfib_cache, *bfib_cache;
+	int err;
+
+	mvsw_pr_util_fen_info2fib_cache_key(fen_info, &fc_key);
+	fib_cache = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	if (fib_cache) {
+		fib_cache->reachable = false;
+		err = __mvsw_pr_k_arb_fc_apply(sw, fib_cache);
+		if (err)
+			MVSW_LOG_ERROR("Applying destroyed fib_cache failed");
+
+		bfib_cache = __mvsw_pr_k_arb_util_fib_overlaps(sw, fib_cache);
+		tfib_cache = __mvsw_pr_k_arb_util_fib_overlapped(sw, fib_cache);
+		if (!tfib_cache && bfib_cache) {
+			bfib_cache->reachable = true;
+			err = __mvsw_pr_k_arb_fc_apply(sw, bfib_cache);
+			if (err) {
+				MVSW_LOG_ERROR("Applying fib_cache btm failed");
+				return -ENOENT;
+			}
+		}
+
+		mvsw_pr_kern_fib_cache_destroy(sw, fib_cache);
+	}
+
+	if (replace) {
+		fib_cache = prestera_kern_fib_cache_create(sw, &fc_key,
+							   fen_info->fi);
+		if (!fib_cache) {
+			MVSW_LOG_ERROR("fib_cache == NULL");
+			return -ENOENT;
+		}
+
+		bfib_cache = __mvsw_pr_k_arb_util_fib_overlaps(sw, fib_cache);
+		tfib_cache = __mvsw_pr_k_arb_util_fib_overlapped(sw, fib_cache);
+		if (!tfib_cache)
+			fib_cache->reachable = true;
+
+		if (bfib_cache) {
+			bfib_cache->reachable = false;
+			err = __mvsw_pr_k_arb_fc_apply(sw, bfib_cache);
+			if (err)
+				MVSW_LOG_ERROR("Applying fib_cache btm failed");
+		}
+
+		err = __mvsw_pr_k_arb_fc_apply(sw, fib_cache);
+		if (err) {
+			MVSW_LOG_ERROR("Applying fib_cache failed");
+			return -ENOENT;
+		}
+	}
+
+	/* Update all neighs to resolve overlapped and apply related */
+	__mvsw_pr_k_arb_fib_evt2nc(sw);
+
+	return 0;
+}
+
+static void mvsw_pr_k_arb_nh_evt(struct prestera_switch *sw,
+				 bool replace,
+				 struct fib_nh *fib_nh)
+{
+	struct prestera_kern_neigh_cache *nc;
+	struct prestera_nh_neigh_key nkey;
+	int err;
+
+	err = mvsw_pr_util_fib_nh2nh_neigh_key(sw, fib_nh, &nkey);
+	if (err)
+		return;
+
+	nc = mvsw_pr_kern_neigh_cache_find(sw, &nkey);
+	if (!nc)
+		return;
+
+	/* NOTE: we also get from kernel n_evt after this one
+	 * mvsw_pr_k_arb_nh_evt is used only to speedup nh update after
+	 * linkdown on ECMP routes
+	 */
+	nc->nh_neigh_info.connected = false;
+	__mvsw_pr_k_arb_nc_apply(sw, nc);
+}
+
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_fc_rebuild(struct prestera_switch *sw,
+			   struct mvsw_pr_kern_fib_cache *fc)
+{
+	struct fib_info *fi;
+	struct mvsw_pr_kern_fib_cache_key key;
+	struct mvsw_pr_kern_fib_cache *new_fc;
+	bool reachable;
+
+	memcpy(&key, &fc->key, sizeof(key));
+	fi = fc->fi;
+	fib_info_hold(fi);
+	reachable = fc->reachable;
+
+	fc->reachable = false;
+	__mvsw_pr_k_arb_fc_apply(sw, fc);
+	mvsw_pr_kern_fib_cache_destroy(sw, fc);
+
+	new_fc = prestera_kern_fib_cache_create(sw, &key, fi);
+	fib_info_put(fi);
+	if (!new_fc)
+		return NULL;
+
+	new_fc->reachable = reachable;
+	__mvsw_pr_k_arb_fc_apply(sw, new_fc);
+
+	return new_fc;
+}
+
+static void mvsw_pr_k_arb_rif_evt(struct prestera_switch *sw,
+				  struct prestera_rif *rif)
+{
+	struct mvsw_pr_kern_fib_cache *fc, *tfc, *nfc;
+	struct prestera_kern_neigh_cache *nc, *tnc;
+	struct rhashtable_iter iter;
+
+	/* Walk every fc, which related to rif and set to trap */
+	tfc = NULL;
+	rhashtable_walk_enter(&sw->router->kern_fib_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		fc = rhashtable_walk_next(&iter);
+		if (tfc && mvsw_pr_util_fi_is_point2dev(tfc->fi, rif->dev)) {
+			rhashtable_walk_stop(&iter);
+			nfc = __mvsw_pr_k_arb_fc_rebuild(sw, tfc);
+			rhashtable_walk_start(&iter);
+			/* TODO: way to crash ? */
+			if (WARN_ON(!nfc))
+				MVSW_LOG_ERROR("Rebuild failed %pI4n/%d",
+					       &tfc->key.addr.u.ipv4,
+					       tfc->key.prefix_len);
+		}
+
+		if (!fc)
+			break;
+
+		tfc = NULL;
+		if (IS_ERR(fc))
+			continue;
+
+		tfc = fc;
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+
+	/* Destroy every nc, which related to rif */
+	tnc = NULL;
+	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		nc = rhashtable_walk_next(&iter);
+		if (tnc && tnc->key.rif == rif) {
+			tnc->in_kernel = false;
+			rhashtable_walk_stop(&iter);
+			__mvsw_pr_k_arb_nc_apply(sw, tnc);
+			WARN_ON(mvsw_pr_kern_neigh_cache_put(sw, tnc));
+			rhashtable_walk_start(&iter);
+		}
+
+		if (!nc)
+			break;
+
+		tnc = NULL;
+		if (IS_ERR(nc))
+			continue;
+
+		tnc = nc;
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+}
+
+struct mvsw_pr_netevent_work {
+	struct work_struct work;
+	struct prestera_switch *sw;
+	struct neighbour *n;
+};
+
+static void mvsw_pr_router_neigh_event_work(struct work_struct *work)
+{
+	struct mvsw_pr_netevent_work *net_work =
+		container_of(work, struct mvsw_pr_netevent_work, work);
+	struct prestera_switch *sw = net_work->sw;
+	struct neighbour *n = net_work->n;
+
+	/* neigh - its not hw related object. It stored only in kernel. So... */
+	mvsw_owq_lock();
+
+	if (sw->router->aborted)
+		goto out;
+
+	mvsw_pr_k_arb_n_evt(sw, n);
+
+out:
+	neigh_release(n);
+	mvsw_owq_unlock();
+	kfree(net_work);
+}
+
+static int mvsw_pr_router_netevent_event(struct notifier_block *nb,
+					 unsigned long event, void *ptr)
+{
+	struct mvsw_pr_netevent_work *net_work;
+	struct prestera_router *router;
+	struct prestera_rif *rif;
+	struct neighbour *n = ptr;
+
+	router = container_of(nb, struct prestera_router, netevent_nb);
+
+	switch (event) {
+	case NETEVENT_NEIGH_UPDATE:
+		if (n->tbl != &arp_tbl)
+			return NOTIFY_DONE;
+
+		rif = mvsw_pr_rif_find(router->sw, n->dev);
+		if (!rif)
+			return NOTIFY_DONE;
+
+		net_work = kzalloc(sizeof(*net_work), GFP_ATOMIC);
+		if (WARN_ON(!net_work))
+			return NOTIFY_BAD;
+
+		neigh_clone(n);
+		net_work->n = n;
+		net_work->sw = router->sw;
+		INIT_WORK(&net_work->work, mvsw_pr_router_neigh_event_work);
+		queue_work(mvsw_r_owq, &net_work->work);
+	}
+
+	return NOTIFY_DONE;
+}
+
+static void
+mvsw_pr_router_neighs_update_interval_init(struct prestera_router *router)
+{
+	router->neighs_update.interval = MVSW_PR_NH_PROBE_INTERVAL;
+}
+
+static void mvsw_pr_router_update_neighs_work(struct work_struct *work)
+{
+	struct prestera_router *router;
+
+	router = container_of(work, struct prestera_router,
+			      neighs_update.dw.work);
+	rtnl_lock();
+
+	if (router->aborted)
+		goto out;
+
+	mvsw_pr_k_arb_hw_evt(router->sw);
+
+out:
+	rtnl_unlock();
+	mvsw_pr_router_neighs_update_interval_init(router);
+	queue_delayed_work(mvsw_r_wq, &router->neighs_update.dw,
+			   msecs_to_jiffies(router->neighs_update.interval));
+}
+
+static int prestera_neigh_work_init(struct prestera_switch *sw)
+{
+	mvsw_pr_router_neighs_update_interval_init(sw->router);
+
+	INIT_DELAYED_WORK(&sw->router->neighs_update.dw,
+			  mvsw_pr_router_update_neighs_work);
+	queue_delayed_work(mvsw_r_wq, &sw->router->neighs_update.dw, 0);
+	return 0;
+}
+
+static void prestera_neigh_work_fini(struct prestera_switch *sw)
+{
+	cancel_delayed_work_sync(&sw->router->neighs_update.dw);
+}
+
+static struct prestera_rif*
+mvsw_pr_rif_find(const struct prestera_switch *sw,
+		 const struct net_device *dev)
+{
+	struct prestera_rif *rif;
+
+	list_for_each_entry(rif, &sw->router->rif_list, router_node) {
+		if (rif->dev == dev)
+			return rif;
+	}
+
+	return NULL;
+}
+
+bool prestera_rif_exists(const struct prestera_switch *sw,
+			 const struct net_device *dev)
+{
+	return !!mvsw_pr_rif_find(sw, dev);
+}
+
+static int
+mvsw_pr_port_vlan_router_join(struct prestera_port_vlan *mvsw_pr_port_vlan,
+			      struct net_device *dev,
+			      struct netlink_ext_ack *extack)
+{
+	struct prestera_port *port = mvsw_pr_port_vlan->port;
+	struct prestera_switch *sw = port->sw;
+
+	struct mvsw_pr_rif_params params = {
+		.dev = dev,
+	};
+	struct prestera_rif *rif;
+
+	MVSW_LOG_ERROR("NOT IMPLEMENTED!!!");
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (!rif)
+		rif = prestera_rif_create(sw, &params, extack);
+
+	if (IS_ERR(rif))
+		return PTR_ERR(rif);
+
+	rif->is_active = true;
+
+	/* TODO:
+	 * - vid learning set (false)
+	 * - stp state set (FORWARDING)
+	 */
+
+	return 0;
+}
+
+static void
+mvsw_pr_port_vlan_router_leave(struct prestera_port_vlan *mvsw_pr_port_vlan,
+			       struct net_device *dev)
+
+{
+	struct prestera_port *port = mvsw_pr_port_vlan->port;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_rif *rif;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+
+	if (rif)
+		rif->is_active = false;
+	/* TODO:
+	 * - stp state set (BLOCKING)
+	 * - vid learning set (true)
+	 */
+}
+
+static int
+mvsw_pr_port_router_join(struct prestera_port *port,
+			 struct net_device *dev,
+			 struct netlink_ext_ack *extack)
+{
+	struct prestera_switch *sw = port->sw;
+
+	struct mvsw_pr_rif_params params = {
+		.dev = dev,
+	};
+	struct prestera_rif *rif;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (!rif)
+		rif = prestera_rif_create(sw, &params, extack);
+
+	if (IS_ERR(rif))
+		return PTR_ERR(rif);
+
+	rif->is_active = true;
+
+	/* TODO:
+	 * - vid learning set (false)
+	 * - stp state set (FORWARDING)
+	 */
+
+	return 0;
+}
+
+void prestera_port_router_leave(struct prestera_port *port)
+{
+	struct prestera_rif *rif;
+
+	/* TODO:
+	 * - stp state set (BLOCKING)
+	 * - vid learning set (true)
+	 */
+
+	rif = mvsw_pr_rif_find(port->sw, port->net_dev);
+	if (rif) {
+		rif->is_active = false;
+		mvsw_pr_rif_put(port->sw, rif);
+	}
+}
+
+static int mvsw_pr_rif_macvlan_add(struct prestera_switch *sw,
+				   const struct net_device *macvlan_dev,
+				   struct netlink_ext_ack *extack)
+{
+	struct macvlan_dev *vlan = netdev_priv(macvlan_dev);
+	struct prestera_rif *rif;
+	struct prestera_rif_entry *re;
+	int err;
+
+	rif = mvsw_pr_rif_find(sw, vlan->lowerdev);
+	if (!rif) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "macvlan is only supported on top of RIF");
+		return -EOPNOTSUPP;
+	}
+
+	re = prestera_rif_entry_find(sw, &rif->rif_entry_key);
+	if (!re)
+		return -ENOENT;
+
+	err = prestera_rif_entry_set_macvlan(sw, re, true,
+					     macvlan_dev->dev_addr);
+	if (err)
+		return err;
+
+	return err;
+}
+
+static void __mvsw_pr_rif_macvlan_del(struct prestera_switch *sw,
+				      const struct net_device *macvlan_dev)
+{
+	struct macvlan_dev *vlan = netdev_priv(macvlan_dev);
+	struct prestera_rif *rif;
+	struct prestera_rif_entry *re;
+
+	rif = mvsw_pr_rif_find(sw, vlan->lowerdev);
+	if (!rif)
+		return;
+
+	re = prestera_rif_entry_find(sw, &rif->rif_entry_key);
+	if (!re)
+		return;
+
+	prestera_rif_entry_set_macvlan(sw, re, false, macvlan_dev->dev_addr);
+}
+
+static void mvsw_pr_rif_macvlan_del(struct prestera_switch *sw,
+				    const struct net_device *macvlan_dev)
+{
+	__mvsw_pr_rif_macvlan_del(sw, macvlan_dev);
+}
+
+static int mvsw_pr_inetaddr_macvlan_event(struct prestera_switch *sw,
+					  struct net_device *macvlan_dev,
+					  unsigned long event,
+					  struct netlink_ext_ack *extack)
+{
+	switch (event) {
+	case NETDEV_UP:
+		return mvsw_pr_rif_macvlan_add(sw, macvlan_dev, extack);
+	case NETDEV_DOWN:
+		mvsw_pr_rif_macvlan_del(sw, macvlan_dev);
+		break;
+	}
+
+	return 0;
+}
+
+static int mvsw_pr_router_port_check_rif_addr(struct prestera_switch *sw,
+					      struct net_device *dev,
+					      const unsigned char *dev_addr,
+					      struct netlink_ext_ack *extack)
+{
+	if (netif_is_macvlan(dev) || netif_is_l3_master(dev))
+		return 0;
+
+	if (!ether_addr_equal_masked(sw->base_mac, dev_addr,
+				     mvsw_pr_mac_mask)) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "RIF MAC must have the same prefix");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int mvsw_pr_inetaddr_port_event(struct net_device *port_dev,
+				       unsigned long event,
+				       struct netlink_ext_ack *extack)
+{
+	struct prestera_port *port = netdev_priv(port_dev);
+
+	MVSW_LOG_ERROR("dev=%s", port_dev->name);
+
+	switch (event) {
+	case NETDEV_UP:
+		if (netif_is_bridge_port(port_dev) ||
+		    netif_is_lag_port(port_dev) || netif_is_ovs_port(port_dev))
+			return 0;
+		return mvsw_pr_port_router_join(port, port_dev, extack);
+	case NETDEV_DOWN:
+		prestera_port_router_leave(port);
+		break;
+	}
+
+	return 0;
+}
+
+static int mvsw_pr_inetaddr_bridge_event(struct prestera_switch *sw,
+					 struct net_device *dev,
+					 unsigned long event,
+					 struct netlink_ext_ack *extack)
+{
+	struct mvsw_pr_rif_params params = {
+		.dev = dev,
+	};
+	struct prestera_rif *rif;
+
+	switch (event) {
+	case NETDEV_UP:
+		rif = mvsw_pr_rif_find(sw, dev);
+		if (!rif)
+			rif = prestera_rif_create(sw, &params, extack);
+
+		if (IS_ERR(rif))
+			return PTR_ERR(rif);
+		rif->is_active = true;
+		break;
+	case NETDEV_DOWN:
+		rif = mvsw_pr_rif_find(sw, dev);
+		rif->is_active = false;
+		mvsw_pr_rif_put(sw, rif);
+		break;
+	}
+
+	return 0;
+}
+
+static int mvsw_pr_inetaddr_port_vlan_event(struct net_device *l3_dev,
+					    struct net_device *port_dev,
+					    unsigned long event, u16 vid,
+					    struct netlink_ext_ack *extack)
+{
+	struct prestera_port *port = netdev_priv(port_dev);
+	struct prestera_port_vlan *mvsw_pr_port_vlan;
+
+	mvsw_pr_port_vlan = prestera_port_vlan_find_by_vid(port, vid);
+	if (WARN_ON(!mvsw_pr_port_vlan))
+		return -EINVAL;
+
+	switch (event) {
+	case NETDEV_UP:
+		return mvsw_pr_port_vlan_router_join(mvsw_pr_port_vlan,
+						     l3_dev, extack);
+	case NETDEV_DOWN:
+		mvsw_pr_port_vlan_router_leave(mvsw_pr_port_vlan, l3_dev);
+		break;
+	}
+
+	return 0;
+}
+
+static int mvsw_pr_inetaddr_vlan_event(struct prestera_switch *sw,
+				       struct net_device *vlan_dev,
+				       unsigned long event,
+				       struct netlink_ext_ack *extack)
+{
+	struct net_device *real_dev = vlan_dev_real_dev(vlan_dev);
+	u16 vid = vlan_dev_vlan_id(vlan_dev);
+
+	MVSW_LOG_ERROR("vlan_dev=%s, real_dev=%s", vlan_dev->name,
+		       real_dev->name);
+	if (netif_is_bridge_port(vlan_dev))
+		return 0;
+
+	if (prestera_netdev_check(real_dev))
+		return mvsw_pr_inetaddr_port_vlan_event(vlan_dev, real_dev,
+							event, vid, extack);
+	else if (netif_is_bridge_master(real_dev) && br_vlan_enabled(real_dev))
+		return mvsw_pr_inetaddr_bridge_event(sw, vlan_dev, event,
+						     extack);
+
+	return 0;
+}
+
+static int mvsw_pr_inetaddr_lag_event(struct prestera_switch *sw,
+				      struct net_device *lag_dev,
+				      unsigned long event,
+				      struct netlink_ext_ack *extack)
+{
+	struct mvsw_pr_rif_params params = {
+		.dev = lag_dev,
+	};
+	struct prestera_rif *rif;
+
+	MVSW_LOG_ERROR("lag_dev=%s", lag_dev->name);
+
+	switch (event) {
+	case NETDEV_UP:
+		rif = mvsw_pr_rif_find(sw, lag_dev);
+		if (!rif)
+			rif = prestera_rif_create(sw, &params, extack);
+
+		if (IS_ERR(rif))
+			return PTR_ERR(rif);
+		rif->is_active = true;
+		break;
+	case NETDEV_DOWN:
+		rif = mvsw_pr_rif_find(sw, lag_dev);
+		rif->is_active = false;
+		mvsw_pr_rif_put(sw, rif);
+		break;
+	}
+
+	return 0;
+}
+
+static int __mvsw_pr_inetaddr_event(struct prestera_switch *sw,
+				    struct net_device *dev,
+				    unsigned long event,
+				    struct netlink_ext_ack *extack)
+{
+	if (prestera_netdev_check(dev))
+		return mvsw_pr_inetaddr_port_event(dev, event, extack);
+	else if (is_vlan_dev(dev))
+		return mvsw_pr_inetaddr_vlan_event(sw, dev, event, extack);
+	else if (netif_is_bridge_master(dev))
+		return mvsw_pr_inetaddr_bridge_event(sw, dev, event, extack);
+	else if (netif_is_lag_master(dev))
+		return mvsw_pr_inetaddr_lag_event(sw, dev, event, extack);
+	else if (netif_is_macvlan(dev))
+		return mvsw_pr_inetaddr_macvlan_event(sw, dev, event, extack);
+	else
+		return 0;
+}
+
+static bool
+mvsw_pr_rif_should_config(struct prestera_rif *rif, struct net_device *dev,
+			  unsigned long event)
+{
+	bool addr_list_empty = true;
+	struct in_device *idev;
+
+	switch (event) {
+	case NETDEV_UP:
+		return !rif;
+	case NETDEV_DOWN:
+		idev = __in_dev_get_rtnl(dev);
+		if (idev && idev->ifa_list)
+			addr_list_empty = false;
+
+		if (netif_is_macvlan(dev) && addr_list_empty)
+			return true;
+
+		if (rif && addr_list_empty)
+			return true;
+
+		return false;
+	}
+
+	return false;
+}
+
+static int mvsw_pr_inetaddr_event(struct notifier_block *nb,
+				  unsigned long event, void *ptr)
+{
+	struct in_ifaddr *ifa = (struct in_ifaddr *)ptr;
+	struct net_device *dev = ifa->ifa_dev->dev;
+	struct prestera_router *router;
+	struct prestera_switch *sw;
+	struct prestera_rif *rif;
+	int err = 0;
+
+	/* Wait until previously created works finished (e.g. neigh events) */
+	mvsw_owq_flush();
+	/* NETDEV_UP event is handled by mvsw_pr_inetaddr_valid_event */
+	if (event == NETDEV_UP)
+		goto out;
+
+	MVSW_LOG_ERROR("dev=%s", dev->name);
+	router = container_of(nb, struct prestera_router, inetaddr_nb);
+	sw = router->sw;
+
+	if (netif_is_macvlan(dev))
+		goto mac_vlan;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (!rif)
+		goto out;
+
+	if (!mvsw_pr_rif_should_config(rif, dev, event))
+		goto out;
+mac_vlan:
+	err = __mvsw_pr_inetaddr_event(sw, dev, event, NULL);
+out:
+	return notifier_from_errno(err);
+}
+
+static int prestera_inetaddr_valid_event(struct notifier_block *unused,
+					 unsigned long event, void *ptr)
+{
+	struct in_validator_info *ivi = (struct in_validator_info *)ptr;
+	struct net_device *dev = ivi->ivi_dev->dev;
+	struct prestera_switch *sw;
+	struct prestera_rif *rif;
+	int err = 0;
+
+	sw = prestera_switch_get(dev);
+	if (!sw)
+		goto out;
+
+	/* Wait until previously created works finished (e.g. neigh events) */
+	mvsw_owq_flush();
+
+	if (ipv4_is_multicast(ivi->ivi_addr))
+		return notifier_from_errno(-EINVAL);
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (!mvsw_pr_rif_should_config(rif, dev, event))
+		goto out;
+
+	err = mvsw_pr_router_port_check_rif_addr(sw, dev, dev->dev_addr,
+						 ivi->extack);
+	if (err)
+		goto out;
+
+	err = __mvsw_pr_inetaddr_event(sw, dev, event, ivi->extack);
+out:
+	return notifier_from_errno(err);
+}
+
+static bool __mvsw_pr_fi_is_direct(struct fib_info *fi)
+{
+	struct fib_nh *fib_nh;
+
+	if (fib_info_num_path(fi) == 1) {
+		fib_nh = fib_info_nh(fi, 0);
+		if (fib_nh->fib_nh_scope == RT_SCOPE_HOST)
+			return true;
+	}
+
+	return false;
+}
+
+static bool mvsw_pr_fi_is_direct(struct fib_info *fi)
+{
+	if (fi->fib_type != RTN_UNICAST)
+		return false;
+
+	return __mvsw_pr_fi_is_direct(fi);
+}
+
+static bool mvsw_pr_fi_is_hw_direct(struct prestera_switch *sw,
+				    struct fib_info *fi)
+{
+	struct fib_nh *fib_nh;
+	struct prestera_rif *rif;
+
+	if (!mvsw_pr_fi_is_direct(fi))
+		return false;
+
+	fib_nh = fib_info_nh(fi, 0);
+	rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+	if (!rif || !rif->is_active)
+		return false;
+
+	return true;
+}
+
+static bool mvsw_pr_fi_is_nh(struct fib_info *fi)
+{
+	if (fi->fib_type != RTN_UNICAST)
+		return false;
+
+	return !__mvsw_pr_fi_is_direct(fi);
+}
+
+/* Decided, that uc_nh route with key==nh is obviously neighbour route */
+static bool
+mvsw_pr_fib_node_util_is_neighbour(struct prestera_fib_node *fib_node)
+{
+	if (fib_node->info.type != PRESTERA_FIB_TYPE_UC_NH)
+		return false;
+
+	if (fib_node->info.nh_grp->nh_neigh_head[1].neigh)
+		return false;
+
+	if (!fib_node->info.nh_grp->nh_neigh_head[0].neigh)
+		return false;
+
+	if (memcmp(&fib_node->info.nh_grp->nh_neigh_head[0].neigh->key.addr,
+		   &fib_node->key.addr, sizeof(struct prestera_ip_addr)))
+		return false;
+
+	return true;
+}
+
+static void mvsw_pr_router_fib_abort(struct prestera_switch *sw)
+{
+	prestera_vr_util_hw_abort(sw);
+	prestera_fib_node_destroy_ht(sw);
+	mvsw_pr_k_arb_abort(sw);
+}
+
+struct mvsw_pr_fib_event_work {
+	struct work_struct work;
+	struct prestera_switch *sw;
+	union {
+		struct fib_entry_notifier_info fen_info;
+		struct fib_nh_notifier_info fnh_info;
+	};
+	unsigned long event;
+};
+
+static void mvsw_pr_router_fib4_event_work(struct work_struct *work)
+{
+	struct mvsw_pr_fib_event_work *fib_work =
+			container_of(work, struct mvsw_pr_fib_event_work, work);
+	struct prestera_switch *sw = fib_work->sw;
+	int err;
+
+	mvsw_owq_lock();
+
+	if (sw->router->aborted)
+		goto out;
+
+	switch (fib_work->event) {
+	case FIB_EVENT_ENTRY_REPLACE:
+		err = mvsw_pr_k_arb_fib_evt(sw, true, &fib_work->fen_info);
+		if (err)
+			goto abort_out;
+
+		break;
+	case FIB_EVENT_ENTRY_DEL:
+		err = mvsw_pr_k_arb_fib_evt(sw, false, &fib_work->fen_info);
+		if (err)
+			MVSW_LOG_ERROR("Cant delete %pI4n/%d",
+				       &fib_work->fen_info.dst,
+				       fib_work->fen_info.dst_len);
+
+		break;
+	}
+
+	goto out;
+
+abort_out:
+	dev_err(sw->dev->dev, "Error when processing %pI4h/%d",
+		&fib_work->fen_info.dst,
+		fib_work->fen_info.dst_len);
+	sw->router->aborted = true;
+	mvsw_pr_router_fib_abort(sw);
+	dev_err(sw->dev->dev, "Abort. HW routing offloading disabled");
+out:
+	fib_info_put(fib_work->fen_info.fi);
+	mvsw_owq_unlock();
+	kfree(fib_work);
+}
+
+static void mvsw_pr_router_nh_update_event_work(struct work_struct *work)
+{
+	struct mvsw_pr_fib_event_work *fib_work =
+			container_of(work, struct mvsw_pr_fib_event_work, work);
+	struct prestera_switch *sw = fib_work->sw;
+	struct fib_nh *fib_nh = fib_work->fnh_info.fib_nh;
+
+	mvsw_owq_lock();
+
+	if (sw->router->aborted)
+		goto out;
+
+	/* For now provided only deletion */
+	if (fib_work->event == FIB_EVENT_NH_DEL)
+		mvsw_pr_k_arb_nh_evt(sw, false, fib_nh);
+
+out:
+	fib_info_put(fib_nh->nh_parent);
+	mvsw_owq_unlock();
+	kfree(fib_work);
+	return;
+}
+
+/* Called with rcu_read_lock() */
+static int mvsw_pr_router_fib_event(struct notifier_block *nb,
+				    unsigned long event, void *ptr)
+{
+	struct fib_entry_notifier_info *fen_info;
+	struct fib_nh_notifier_info *fnh_info;
+	struct fib_notifier_info *info = ptr;
+	struct mvsw_pr_fib_event_work *fib_work;
+	struct prestera_router *router;
+	struct fib_info *fi;
+
+	if (info->family != AF_INET)
+		return NOTIFY_DONE;
+
+	router = container_of(nb, struct prestera_router, fib_nb);
+
+	switch (event) {
+	case FIB_EVENT_ENTRY_REPLACE:
+	case FIB_EVENT_ENTRY_DEL:
+		fen_info = container_of(info, struct fib_entry_notifier_info,
+					info);
+		if (!fen_info->fi)
+			return NOTIFY_DONE;
+		else
+			fi = fen_info->fi;
+
+		/* Sanity */
+		if (event == FIB_EVENT_ENTRY_REPLACE) {
+			if (fi->nh)
+				return notifier_from_errno(-EINVAL);
+
+			if (fi->fib_nh_is_v6)
+				return notifier_from_errno(-EINVAL);
+
+			if (fib_info_num_path(fi) > PRESTERA_NHGR_SIZE_MAX) {
+				NL_SET_ERR_MSG_MOD(info->extack,
+						   "Exceeded number of nexthops per route"
+						   );
+				return notifier_from_errno(-EINVAL);
+			}
+		}
+
+		fib_work = kzalloc(sizeof(*fib_work), GFP_ATOMIC);
+		if (WARN_ON(!fib_work))
+			return NOTIFY_BAD;
+
+		fib_info_hold(fi);
+		fib_work->fen_info = *fen_info;
+		fib_work->event = event;
+		fib_work->sw = router->sw;
+		INIT_WORK(&fib_work->work, mvsw_pr_router_fib4_event_work);
+		queue_work(mvsw_r_owq, &fib_work->work);
+		break;
+	case FIB_EVENT_NH_DEL:
+		/* Set down nh as fast as possible */
+		fnh_info = container_of(info, struct fib_nh_notifier_info,
+					info);
+		if (!fnh_info->fib_nh->nh_parent)
+			return NOTIFY_DONE;
+
+		fi = fnh_info->fib_nh->nh_parent;
+
+		fib_work = kzalloc(sizeof(*fib_work), GFP_ATOMIC);
+		if (WARN_ON(!fib_work))
+			return NOTIFY_BAD;
+
+		fib_info_hold(fi);
+		fib_work->fnh_info = *fnh_info;
+		fib_work->event = event;
+		fib_work->sw = router->sw;
+		INIT_WORK(&fib_work->work, mvsw_pr_router_nh_update_event_work);
+		queue_work(mvsw_r_owq, &fib_work->work);
+		break;
+	default:
+		return NOTIFY_DONE;
+	}
+
+	return NOTIFY_DONE;
+}
+
+static void mvsw_pr_router_fib_dump_flush(struct notifier_block *nb)
+{
+	struct prestera_router *router;
+
+	/* Flush pending FIB notifications and then flush the device's
+	 * table before requesting another dump. The FIB notification
+	 * block is unregistered, so no need to take RTNL.
+	 * No neighbours are expected to be present since FIBs  are not
+	 * registered yet
+	 */
+	router = container_of(nb, struct prestera_router, fib_nb);
+	flush_workqueue(mvsw_r_owq);
+	flush_workqueue(mvsw_r_wq);
+	prestera_fib_node_destroy_ht(router->sw);
+}
+
+static int
+mvsw_pr_router_port_change(struct prestera_switch *sw,
+			   struct prestera_rif *rif)
+{
+	int err;
+
+	err = mvsw_pr_rif_update(sw, rif);
+	if (err)
+		return err;
+
+	netdev_dbg(rif->dev, "Update RIF\n");
+
+	return 0;
+}
+
+static int
+mvsw_pr_router_port_pre_change(struct prestera_switch *sw,
+			       struct prestera_rif *rif,
+			       struct netdev_notifier_pre_changeaddr_info *info)
+{
+	struct netlink_ext_ack *extack;
+
+	extack = netdev_notifier_info_to_extack(&info->info);
+	return mvsw_pr_router_port_check_rif_addr(sw, rif->dev, info->dev_addr,
+						  extack);
+}
+
+int prestera_netdevice_router_port_event(struct net_device *dev,
+					 unsigned long event, void *ptr)
+{
+	struct prestera_switch *sw;
+	struct prestera_rif *rif;
+
+	sw = prestera_switch_get(dev);
+	if (!sw)
+		return 0;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (!rif)
+		return 0;
+
+	switch (event) {
+	case NETDEV_CHANGEADDR:
+		return mvsw_pr_router_port_change(sw, rif);
+	case NETDEV_PRE_CHANGEADDR:
+		return mvsw_pr_router_port_pre_change(sw, rif, ptr);
+	}
+
+	return 0;
+}
+
+static int mvsw_pr_port_vrf_join(struct prestera_switch *sw,
+				 struct net_device *dev,
+				 struct netlink_ext_ack *extack)
+{
+	struct prestera_rif *rif;
+
+	/* If netdev is already associated with a RIF, then we need to
+	 * destroy it and create a new one with the new virtual router ID.
+	 */
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (rif)
+		__mvsw_pr_inetaddr_event(sw, dev, NETDEV_DOWN, extack);
+
+	__mvsw_pr_inetaddr_event(sw, dev, NETDEV_UP, extack);
+	rif = mvsw_pr_rif_find(sw, dev);
+	return mvsw_pr_rif_update(sw, rif);
+}
+
+static void mvsw_pr_port_vrf_leave(struct prestera_switch *sw,
+				   struct net_device *dev,
+				   struct netlink_ext_ack *extack)
+{
+	struct prestera_rif *rif;
+	struct in_device *idev;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (!rif)
+		return;
+
+	__mvsw_pr_inetaddr_event(sw, dev, NETDEV_DOWN, NULL);
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (rif)
+		mvsw_pr_rif_update(sw, rif);
+
+	idev = __in_dev_get_rtnl(dev);
+	/* Restore rif in the default vrf: do so only if IF address's present*/
+	if (idev && idev->ifa_list)
+		__mvsw_pr_inetaddr_event(sw, dev, NETDEV_UP, NULL);
+}
+
+int prestera_netdevice_vrf_event(struct net_device *dev, unsigned long event,
+				 struct netdev_notifier_changeupper_info *info)
+{
+	struct prestera_switch *sw = prestera_switch_get(dev);
+	struct netlink_ext_ack *extack = NULL;
+	int err = 0;
+
+	if (!sw || netif_is_macvlan(dev))
+		return 0;
+
+	mvsw_owq_flush();
+
+	switch (event) {
+	case NETDEV_PRECHANGEUPPER:
+		return 0;
+	case NETDEV_CHANGEUPPER:
+		extack = netdev_notifier_info_to_extack(&info->info);
+		if (info->linking)
+			err = mvsw_pr_port_vrf_join(sw, dev, extack);
+		else
+			mvsw_pr_port_vrf_leave(sw, dev, extack);
+		break;
+	}
+
+	return err;
+}
+
+#ifdef CONFIG_IP_ROUTE_MULTIPATH
+static int mvsw_pr_mp_hash_init(struct prestera_switch *sw)
+{
+	u8 hash_policy;
+
+	hash_policy = init_net.ipv4.sysctl_fib_multipath_hash_policy;
+	return  prestera_mp4_hash_set(sw, hash_policy);
+}
+#else
+static int mvsw_pr_mp_hash_init(struct prestera_switch *sw)
+{
+	return 0;
+}
+#endif
+
+static struct notifier_block mvsw_pr_inetaddr_valid_nb __read_mostly = {
+	.notifier_call = prestera_inetaddr_valid_event,
+};
+
+int prestera_router_init(struct prestera_switch *sw)
+{
+	struct prestera_router *router;
+	int err, nhgrp_cache_bytes;
+
+	router = kzalloc(sizeof(*sw->router), GFP_KERNEL);
+	if (!router)
+		return -ENOMEM;
+	sw->router = router;
+	router->sw = sw;
+
+	err = mvsw_pr_mp_hash_init(sw);
+	if (err)
+		goto err_mp_hash_init;
+
+	err = prestera_router_hw_init(sw);
+	if (err)
+		goto err_router_lib_init;
+
+	err = rhashtable_init(&router->kern_fib_cache_ht,
+			      &__mvsw_pr_kern_fib_cache_ht_params);
+	if (err)
+		goto err_kern_fib_cache_ht_init;
+
+	err = rhashtable_init(&router->kern_neigh_cache_ht,
+			      &__mvsw_pr_kern_neigh_cache_ht_params);
+	if (err)
+		goto err_kern_neigh_cache_ht_init;
+
+	nhgrp_cache_bytes = sw->size_tbl_router_nexthop / 8 + 1;
+	router->nhgrp_hw_state_cache = kzalloc(nhgrp_cache_bytes, GFP_KERNEL);
+	if (!router->nhgrp_hw_state_cache)
+		return -ENOMEM;
+
+	INIT_LIST_HEAD(&sw->router->rif_list);
+
+	mvsw_r_wq = alloc_workqueue(mvsw_driver_name, 0, 0);
+	if (!mvsw_r_wq) {
+		err = -ENOMEM;
+		goto err_alloc_workqueue;
+	}
+
+	mvsw_r_owq = alloc_ordered_workqueue("%s_ordered", 0, "mvsw_prestera");
+	if (!mvsw_r_owq) {
+		err = -ENOMEM;
+		goto err_alloc_oworkqueue;
+	}
+
+	err = register_inetaddr_validator_notifier(&mvsw_pr_inetaddr_valid_nb);
+	if (err)
+		goto err_register_inetaddr_validator_notifier;
+
+	router->inetaddr_nb.notifier_call = mvsw_pr_inetaddr_event;
+	err = register_inetaddr_notifier(&router->inetaddr_nb);
+	if (err)
+		goto err_register_inetaddr_notifier;
+
+	err = prestera_neigh_work_init(sw);
+	if (err)
+		goto err_neigh_init;
+
+	sw->router->netevent_nb.notifier_call = mvsw_pr_router_netevent_event;
+	err = register_netevent_notifier(&sw->router->netevent_nb);
+	if (err)
+		goto err_register_netevent_notifier;
+
+	sw->router->fib_nb.notifier_call = mvsw_pr_router_fib_event;
+	err = register_fib_notifier(&init_net, &sw->router->fib_nb,
+				    mvsw_pr_router_fib_dump_flush, NULL);
+	if (err)
+		goto err_register_fib_notifier;
+
+	return 0;
+
+err_register_fib_notifier:
+	unregister_netevent_notifier(&sw->router->netevent_nb);
+err_register_netevent_notifier:
+	prestera_neigh_work_fini(sw);
+err_neigh_init:
+	unregister_inetaddr_notifier(&router->inetaddr_nb);
+err_register_inetaddr_notifier:
+	unregister_inetaddr_validator_notifier(&mvsw_pr_inetaddr_valid_nb);
+err_register_inetaddr_validator_notifier:
+	destroy_workqueue(mvsw_r_owq);
+err_alloc_oworkqueue:
+	destroy_workqueue(mvsw_r_wq);
+err_alloc_workqueue:
+	rhashtable_destroy(&router->kern_neigh_cache_ht);
+err_kern_neigh_cache_ht_init:
+	rhashtable_destroy(&router->kern_fib_cache_ht);
+err_kern_fib_cache_ht_init:
+err_router_lib_init:
+err_mp_hash_init:
+	kfree(sw->router);
+	return err;
+}
+
+static void mvsw_pr_rifs_fini(struct prestera_switch *sw)
+{
+	struct prestera_rif *rif, *tmp;
+
+	list_for_each_entry_safe(rif, tmp, &sw->router->rif_list, router_node) {
+		/* We expect, that rif is holded by is_active.
+		 * ref_cnt must already became 0
+		 */
+		if (rif->ref_cnt || !rif->is_active) {
+			WARN_ON(1); /* BUG */
+			continue;
+		}
+		mvsw_pr_rif_destroy(sw, rif);
+	}
+}
+
+void prestera_router_fini(struct prestera_switch *sw)
+{
+	unregister_fib_notifier(&init_net, &sw->router->fib_nb);
+	unregister_netevent_notifier(&sw->router->netevent_nb);
+	unregister_inetaddr_notifier(&sw->router->inetaddr_nb);
+	unregister_inetaddr_validator_notifier(&mvsw_pr_inetaddr_valid_nb);
+	prestera_neigh_work_fini(sw);
+	destroy_workqueue(mvsw_r_wq);
+	destroy_workqueue(mvsw_r_owq);
+
+	/* I not sure, that unregistering notifiers is enough to prevent
+	 * arbiter events... We can receive it, e.g. from bridge routine.
+	 * So hold rtnl_lock()
+	 */
+	/* prestera_switchdev_fini() flushing WQ without mvsw_owq_flush().
+	 * So lock rtnl here to prevent deadlock.
+	 */
+	rtnl_lock();
+
+	/* TODO: check if vrs necessary ? */
+	mvsw_pr_k_arb_abort(sw);
+	mvsw_pr_rifs_fini(sw);
+	rhashtable_destroy(&sw->router->kern_neigh_cache_ht);
+	rhashtable_destroy(&sw->router->kern_fib_cache_ht);
+	WARN_ON(!list_empty(&sw->router->rif_list));
+
+	prestera_router_hw_fini(sw);
+
+	kfree(sw->router);
+	sw->router = NULL;
+
+	rtnl_unlock();
+}
+
+static u32 mvsw_pr_fix_tb_id(u32 tb_id)
+{
+	if (tb_id == RT_TABLE_UNSPEC ||
+	    tb_id == RT_TABLE_LOCAL ||
+	    tb_id == RT_TABLE_DEFAULT)
+		return tb_id = RT_TABLE_MAIN;
+
+	return tb_id;
+}
+
+static int
+__prestera_rif_macvlan_offload_cb(struct net_device *dev,
+				  struct netdev_nested_priv *priv)
+{
+	struct prestera_rif_entry *re = priv->data;
+	struct prestera_switch *sw = prestera_switch_get(dev);
+
+	if (!netif_is_macvlan(dev))
+		return 0;
+
+	return prestera_rif_entry_set_macvlan(sw, re, true, dev->dev_addr);
+}
+
+static int __prestera_rif_offload(struct prestera_switch *sw, bool replace,
+				  struct prestera_rif *rif)
+{
+	struct prestera_rif_entry *re;
+	struct netdev_nested_priv priv;
+
+	re = prestera_rif_entry_find(sw, &rif->rif_entry_key);
+	if (re)
+		prestera_rif_entry_destroy(sw, re);
+
+	if (!replace)
+		return 0;
+
+	re = prestera_rif_entry_create(sw, &rif->rif_entry_key,
+				       mvsw_pr_fix_tb_id(rif->kern_tb_id),
+				       rif->addr);
+	if (!re)
+		return -EINVAL;
+
+	priv.data = re;
+	if (netdev_walk_all_upper_dev_rcu(rif->dev,
+					  __prestera_rif_macvlan_offload_cb,
+					  &priv)) {
+		prestera_rif_entry_destroy(sw, re);
+		return -ENOENT;
+	}
+
+	return 0;
+}
+
+static struct prestera_rif *
+prestera_rif_create(struct prestera_switch *sw,
+		    const struct mvsw_pr_rif_params *params,
+		    struct netlink_ext_ack *extack)
+{
+	struct prestera_rif *rif;
+	int err;
+
+	rif = kzalloc(sizeof(*rif), GFP_KERNEL);
+	if (!rif) {
+		err = -ENOMEM;
+		goto err_rif_alloc;
+	}
+
+	rif->dev = params->dev;
+	dev_hold(rif->dev);
+
+	err = prestera_dev2iface(sw, rif->dev, &rif->rif_entry_key.iface);
+	if (err)
+		goto err_dev2iface;
+
+	ether_addr_copy(rif->addr, params->dev->dev_addr);
+	rif->kern_tb_id = l3mdev_fib_table(params->dev);
+
+	err = __prestera_rif_offload(sw, true, rif);
+	if (err)  {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "Exceeded number of supported rifs");
+		goto err_rif_offload;
+	}
+
+	list_add(&rif->router_node, &sw->router->rif_list);
+
+	return rif;
+
+err_rif_offload:
+err_dev2iface:
+	dev_put(rif->dev);
+	kfree(rif);
+err_rif_alloc:
+	return ERR_PTR(err);
+}
+
+static void mvsw_pr_rif_destroy(struct prestera_switch *sw,
+				struct prestera_rif *rif)
+{
+	list_del(&rif->router_node);
+	__prestera_rif_offload(sw, false, rif);
+	dev_put(rif->dev);
+	kfree(rif);
+}
+
+static void mvsw_pr_rif_put(struct prestera_switch *sw,
+			    struct prestera_rif *rif)
+{
+	if (!rif->ref_cnt && !rif->is_active)
+		mvsw_pr_rif_destroy(sw, rif);
+}
+
+void prestera_rif_enable(struct prestera_switch *sw,
+			 struct net_device *dev, bool enable)
+{
+	struct prestera_rif *rif;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (!rif)
+		return;
+
+	__prestera_rif_offload(sw, enable, rif);
+}
+
+static int mvsw_pr_rif_update(struct prestera_switch *sw,
+			      struct prestera_rif *rif)
+{
+	ether_addr_copy(rif->addr, rif->dev->dev_addr);
+	rif->kern_tb_id = l3mdev_fib_table(rif->dev);
+	return __prestera_rif_offload(sw, true, rif);
+}
+
+void prestera_router_lag_member_leave(const struct prestera_port *port,
+				      const struct net_device *dev)
+{
+	struct prestera_rif *rif;
+	u16 vr_id;
+
+	rif = mvsw_pr_rif_find(port->sw, dev);
+	if (!rif)
+		return;
+
+	vr_id = mvsw_pr_fix_tb_id(rif->kern_tb_id);
+	prestera_lag_member_rif_leave(port, port->lag_id, vr_id);
+}
+
+void prestera_lag_router_leave(struct prestera_switch *sw,
+			       struct net_device *lag_dev)
+{
+	struct prestera_rif *rif;
+
+	rif = mvsw_pr_rif_find(sw, lag_dev);
+	if (rif) {
+		rif->is_active = false;
+		mvsw_pr_rif_put(sw, rif);
+	}
+}
+
+static int mvsw_pr_bridge_device_rif_put(struct net_device *dev,
+					 struct netdev_nested_priv *priv)
+{
+	struct prestera_switch *sw = priv->data;
+	struct prestera_rif *rif;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (rif) {
+		/* Hold refcnt, because "is_active = false" may cause freeing */
+		rif->ref_cnt++;
+		rif->is_active = false;
+		mvsw_pr_k_arb_rif_evt(sw, rif);
+		rif->ref_cnt--;
+		mvsw_pr_rif_put(sw, rif);
+	}
+
+	return 0;
+}
+
+void prestera_bridge_rifs_destroy(struct prestera_switch *sw,
+				  struct net_device *bridge_dev)
+{
+	struct netdev_nested_priv priv = {
+		.data = (void *)sw,
+	};
+
+	mvsw_pr_bridge_device_rif_put(bridge_dev, &priv);
+	netdev_walk_all_upper_dev_rcu(bridge_dev,
+				      mvsw_pr_bridge_device_rif_put,
+				      &priv);
+}
+
+struct prestera_neigh_info *
+prestera_kern_neigh_cache_to_neigh_info(struct prestera_kern_neigh_cache *nc)
+{
+	return &nc->nh_neigh_info;
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_router_hw.c b/drivers/net/ethernet/marvell/prestera/prestera_router_hw.c
new file mode 100644
index 000000000000..0dad9929aba4
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_router_hw.c
@@ -0,0 +1,832 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/rhashtable.h>
+
+#include "prestera.h"
+#include "prestera_log.h"
+#include "prestera_hw.h"
+#include "prestera_router_hw.h"
+#include "prestera_acl.h"
+
+/*
+ *                                Nexthop is pointed
+ *                                to port (not rif)
+ *                                +-------+
+ *                              +>|nexthop|<--+
+ *                              | +-------+   |
+ *                              |             |
+ *            +--+        +-----++         +--+------+
+ *   +------->|vr|<-+   +>|nh_grp|         |nh_mangle|<-+
+ *   |        +--+  |   | +------+         +---------+  |
+ *   |              |   |                               |
+ * +-+-------+   +--+---+-+                   +---------+----+
+ * |rif_entry|   |fib_node|                   |acl_rule_entry|
+ * +---------+   +--------+                   +--------------+
+ *  Rif is        Fib - is exit point
+ *  used as
+ *  entry point
+ *  for vr in hw
+ */
+
+#define PRESTERA_NHGR_UNUSED (0)
+#define PRESTERA_NHGR_DROP (0xFFFFFFFF)
+/* Need to merge it with router_manager */
+#define PRESTERA_NH_ACTIVE_JIFFER_FILTER 3000 /* ms */
+
+static const struct rhashtable_params __prestera_fib_ht_params = {
+	.key_offset  = offsetof(struct prestera_fib_node, key),
+	.head_offset = offsetof(struct prestera_fib_node, ht_node),
+	.key_len     = sizeof(struct prestera_fib_key),
+	.automatic_shrinking = true,
+};
+
+static const struct rhashtable_params __prestera_nh_neigh_ht_params = {
+	.key_offset  = offsetof(struct prestera_nh_neigh, key),
+	.key_len     = sizeof(struct prestera_nh_neigh_key),
+	.head_offset = offsetof(struct prestera_nh_neigh, ht_node),
+};
+
+static const struct rhashtable_params __prestera_nexthop_group_ht_params = {
+	.key_offset  = offsetof(struct prestera_nexthop_group, key),
+	.key_len     = sizeof(struct prestera_nexthop_group_key),
+	.head_offset = offsetof(struct prestera_nexthop_group, ht_node),
+};
+
+static int prestera_nexthop_group_set(struct prestera_switch *sw,
+				      struct prestera_nexthop_group *nh_grp);
+static bool
+prestera_nexthop_group_util_hw_state(struct prestera_switch *sw,
+				     struct prestera_nexthop_group *nh_grp);
+
+/* TODO: move to router.h as macros */
+static bool prestera_nh_neigh_key_is_valid(struct prestera_nh_neigh_key *key)
+{
+	return memchr_inv(key, 0, sizeof(*key)) ? true : false;
+}
+
+int prestera_router_hw_init(struct prestera_switch *sw)
+{
+	int err;
+
+	err = rhashtable_init(&sw->router->nh_neigh_ht,
+			      &__prestera_nh_neigh_ht_params);
+	if (err)
+		goto err_nh_neigh_ht_init;
+
+	err = rhashtable_init(&sw->router->nexthop_group_ht,
+			      &__prestera_nexthop_group_ht_params);
+	if (err)
+		goto err_nexthop_grp_ht_init;
+
+	err = rhashtable_init(&sw->router->fib_ht,
+			      &__prestera_fib_ht_params);
+	if (err)
+		goto err_fib_ht_init;
+
+	INIT_LIST_HEAD(&sw->router->vr_list);
+	INIT_LIST_HEAD(&sw->router->rif_entry_list);
+
+	return 0;
+
+err_fib_ht_init:
+	rhashtable_destroy(&sw->router->nexthop_group_ht);
+err_nexthop_grp_ht_init:
+	rhashtable_destroy(&sw->router->nh_neigh_ht);
+err_nh_neigh_ht_init:
+	return err;
+}
+
+void prestera_router_hw_fini(struct prestera_switch *sw)
+{
+	/* Ensure there is no objects */
+	prestera_fib_node_destroy_ht(sw);
+	prestera_rif_entry_destroy_ht(sw);
+	/* Check if there can be nh_mangle ? */
+
+	rhashtable_destroy(&sw->router->nexthop_group_ht);
+	rhashtable_destroy(&sw->router->nh_neigh_ht);
+	rhashtable_destroy(&sw->router->fib_ht);
+
+	/* Sanity */
+	WARN_ON(!list_empty(&sw->router->rif_entry_list));
+	WARN_ON(!list_empty(&sw->router->vr_list));
+}
+
+static struct prestera_vr *__prestera_vr_find(struct prestera_switch *sw,
+					      u32 tb_id)
+{
+	struct prestera_vr *vr;
+
+	list_for_each_entry(vr, &sw->router->vr_list, router_node) {
+		if (vr->tb_id == tb_id)
+			return vr;
+	}
+
+	return NULL;
+}
+
+static struct prestera_vr *__prestera_vr_create(struct prestera_switch *sw,
+						u32 tb_id,
+						struct netlink_ext_ack *extack)
+{
+	struct prestera_vr *vr;
+	u16 hw_vr_id;
+	int err;
+
+	err = prestera_hw_vr_create(sw, &hw_vr_id);
+	if (err)
+		return ERR_PTR(-ENOMEM);
+
+	vr = kzalloc(sizeof(*vr), GFP_KERNEL);
+	if (!vr) {
+		err = -ENOMEM;
+		goto err_alloc_vr;
+	}
+
+	vr->tb_id = tb_id;
+	vr->hw_vr_id = hw_vr_id;
+
+	list_add(&vr->router_node, &sw->router->vr_list);
+
+	return vr;
+
+err_alloc_vr:
+	prestera_hw_vr_delete(sw, hw_vr_id);
+	kfree(vr);
+	return ERR_PTR(err);
+}
+
+static void __prestera_vr_destroy(struct prestera_switch *sw,
+				  struct prestera_vr *vr)
+{
+	prestera_hw_vr_delete(sw, vr->hw_vr_id);
+	list_del(&vr->router_node);
+	kfree(vr);
+}
+
+static struct prestera_vr *prestera_vr_get(struct prestera_switch *sw, u32 tb_id,
+					   struct netlink_ext_ack *extack)
+{
+	struct prestera_vr *vr;
+
+	vr = __prestera_vr_find(sw, tb_id);
+	if (!vr)
+		vr = __prestera_vr_create(sw, tb_id, extack);
+	if (IS_ERR(vr))
+		return ERR_CAST(vr);
+
+	return vr;
+}
+
+static void prestera_vr_put(struct prestera_switch *sw, struct prestera_vr *vr)
+{
+	if (!vr->ref_cnt)
+		__prestera_vr_destroy(sw, vr);
+}
+
+/* TODO: use router_hw_abort. Make this static */
+void prestera_vr_util_hw_abort(struct prestera_switch *sw)
+{
+	struct prestera_vr *vr, *vr_tmp;
+
+	list_for_each_entry_safe(vr, vr_tmp,
+				 &sw->router->vr_list, router_node)
+		prestera_hw_vr_abort(sw, vr->hw_vr_id);
+}
+
+/* make good things. iface is overhead struct... crutch
+ * TODO May be it must be union + vr_id should be removed
+ */
+static int
+__prestera_rif_entry_key_copy(const struct prestera_rif_entry_key *in,
+			      struct prestera_rif_entry_key *out)
+{
+	memset(out, 0, sizeof(*out));
+	out->iface.type = in->iface.type;
+
+	switch (out->iface.type) {
+	case PRESTERA_IF_PORT_E:
+		out->iface.dev_port.hw_dev_num = in->iface.dev_port.hw_dev_num;
+		out->iface.dev_port.port_num = in->iface.dev_port.port_num;
+		break;
+	case PRESTERA_IF_LAG_E:
+		out->iface.lag_id = in->iface.lag_id;
+		break;
+	case PRESTERA_IF_VID_E:
+		out->iface.vlan_id = in->iface.vlan_id;
+		break;
+	default:
+		pr_err("Unsupported iface type");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int __prestera_rif_entry_macvlan_add(const struct prestera_switch *sw,
+					    struct prestera_rif_entry *e,
+					    const char *addr)
+{
+	int err;
+	struct prestera_rif_macvlan_list_node *n;
+
+	n = kzalloc(sizeof(*n), GFP_KERNEL);
+	if (!n) {
+		err = -ENOMEM;
+		goto err_kzalloc;
+	}
+
+	/* vr_id should be unused for this call. If we want to do something
+	 * with port (not vlan) - use port_rif_id to vid mapping on Agent side,
+	 * or use rif vid, received from Agent... Or we need not to add initial
+	 * mac address on rif creation. Why rif init MAC is deleted by index,
+	 * but macvlan deleted by MAC ?
+	 * Now it is inconsistent.
+	 */
+	err = prestera_hw_macvlan_add(sw, e->vr->hw_vr_id, addr,
+				      e->key.iface.vlan_id);
+	if (err)
+		goto err_hw;
+
+	memcpy(n->addr, addr, sizeof(n->addr));
+	list_add(&n->head, &e->macvlan_list);
+
+	return 0;
+
+err_hw:
+	kfree(n);
+err_kzalloc:
+	return err;
+}
+
+static void
+__prestera_rif_entry_macvlan_del(const struct prestera_switch *sw,
+				 struct prestera_rif_entry *e,
+				 struct prestera_rif_macvlan_list_node *n)
+{
+	int err;
+
+	err = prestera_hw_macvlan_del(sw, e->vr->hw_vr_id, n->addr,
+				      e->key.iface.vlan_id);
+	if (err)
+		pr_err("%s:%d failed to delete macvlan from hw err = %d",
+		       __func__, __LINE__, err);
+
+	list_del(&n->head);
+	kfree(n);
+}
+
+static void __prestera_rif_entry_macvlan_flush(const struct prestera_switch *sw,
+					       struct prestera_rif_entry *e)
+{
+	struct prestera_rif_macvlan_list_node *n, *tmp;
+
+	list_for_each_entry_safe(n, tmp, &e->macvlan_list, head)
+		__prestera_rif_entry_macvlan_del(sw, e, n);
+}
+
+int prestera_rif_entry_set_macvlan(const struct prestera_switch *sw,
+				   struct prestera_rif_entry *e,
+				   bool enable, const char *addr)
+{
+	struct prestera_rif_macvlan_list_node *n, *tmp;
+
+	list_for_each_entry_safe(n, tmp, &e->macvlan_list, head) {
+		if (!memcmp(n->addr, addr, sizeof(n->addr))) {
+			if (!enable)
+				__prestera_rif_entry_macvlan_del(sw, e, n);
+
+			return 0;
+		}
+	}
+
+	if (enable)
+		return __prestera_rif_entry_macvlan_add(sw, e, addr);
+
+	return 0;
+}
+
+struct prestera_rif_entry *
+prestera_rif_entry_find(const struct prestera_switch *sw,
+			const struct prestera_rif_entry_key *k)
+{
+	struct prestera_rif_entry *rif_entry;
+	struct prestera_rif_entry_key lk; /* lookup key */
+
+	if (__prestera_rif_entry_key_copy(k, &lk))
+		return NULL;
+
+	list_for_each_entry(rif_entry, &sw->router->rif_entry_list,
+			    router_node) {
+		if (!memcmp(k, &rif_entry->key, sizeof(*k)))
+			return rif_entry;
+	}
+
+	return NULL;
+}
+
+void prestera_rif_entry_destroy(struct prestera_switch *sw,
+				struct prestera_rif_entry *e)
+{
+	struct prestera_iface iface;
+
+	list_del(&e->router_node);
+
+	__prestera_rif_entry_macvlan_flush(sw, e);
+
+	memcpy(&iface, &e->key.iface, sizeof(iface));
+	iface.vr_id = e->vr->hw_vr_id;
+	prestera_hw_rif_delete(sw, e->hw_id, &iface);
+
+	e->vr->ref_cnt--;
+	prestera_vr_put(sw, e->vr);
+	kfree(e);
+}
+
+void prestera_rif_entry_destroy_ht(struct prestera_switch *sw)
+{
+	struct prestera_rif_entry *e, *tmp;
+
+	list_for_each_entry_safe(e, tmp, &sw->router->rif_entry_list,
+				 router_node) {
+		prestera_rif_entry_destroy(sw, e);
+	}
+}
+
+struct prestera_rif_entry *
+prestera_rif_entry_create(struct prestera_switch *sw,
+			  struct prestera_rif_entry_key *k,
+			  u32 tb_id, unsigned char *addr)
+{
+	int err;
+	struct prestera_rif_entry *e;
+	struct prestera_iface iface;
+
+	e = kzalloc(sizeof(*e), GFP_KERNEL);
+	if (!e)
+		goto err_kzalloc;
+
+	if (__prestera_rif_entry_key_copy(k, &e->key))
+		goto err_key_copy;
+
+	e->vr = prestera_vr_get(sw, tb_id, NULL);
+	if (IS_ERR(e->vr))
+		goto err_vr_get;
+
+	e->vr->ref_cnt++;
+	memcpy(&e->addr, addr, sizeof(e->addr));
+
+	/* HW */
+	memcpy(&iface, &e->key.iface, sizeof(iface));
+	iface.vr_id = e->vr->hw_vr_id;
+	err = prestera_hw_rif_create(sw, &iface, e->addr, &e->hw_id);
+	if (err)
+		goto err_hw_create;
+
+	INIT_LIST_HEAD(&e->macvlan_list);
+
+	list_add(&e->router_node, &sw->router->rif_entry_list);
+
+	return e;
+
+err_hw_create:
+	e->vr->ref_cnt--;
+	prestera_vr_put(sw, e->vr);
+err_vr_get:
+err_key_copy:
+	kfree(e);
+err_kzalloc:
+	return NULL;
+}
+
+static void __prestera_nh_neigh_destroy(struct prestera_switch *sw,
+					struct prestera_nh_neigh *neigh)
+{
+	rhashtable_remove_fast(&sw->router->nh_neigh_ht,
+			       &neigh->ht_node,
+			       __prestera_nh_neigh_ht_params);
+	kfree(neigh);
+}
+
+static struct prestera_nh_neigh *
+__prestera_nh_neigh_create(struct prestera_switch *sw,
+			   struct prestera_nh_neigh_key *key)
+{
+	struct prestera_nh_neigh *neigh;
+	int err;
+
+	neigh = kzalloc(sizeof(*neigh), GFP_KERNEL);
+	if (!neigh)
+		goto err_kzalloc;
+
+	memcpy(&neigh->key, key, sizeof(*key));
+	neigh->info.connected = false;
+	INIT_LIST_HEAD(&neigh->nexthop_group_list);
+	INIT_LIST_HEAD(&neigh->nh_mangle_entry_list);
+	err = rhashtable_insert_fast(&sw->router->nh_neigh_ht,
+				     &neigh->ht_node,
+				     __prestera_nh_neigh_ht_params);
+	if (err)
+		goto err_rhashtable_insert;
+
+	return neigh;
+
+err_rhashtable_insert:
+	kfree(neigh);
+err_kzalloc:
+	return NULL;
+}
+
+struct prestera_nh_neigh *
+prestera_nh_neigh_find(struct prestera_switch *sw,
+		       struct prestera_nh_neigh_key *key)
+{
+	struct prestera_nh_neigh *nh_neigh;
+
+	nh_neigh = rhashtable_lookup_fast(&sw->router->nh_neigh_ht,
+					  key, __prestera_nh_neigh_ht_params);
+	return IS_ERR(nh_neigh) ? NULL : nh_neigh;
+}
+
+struct prestera_nh_neigh *
+prestera_nh_neigh_get(struct prestera_switch *sw,
+		      struct prestera_nh_neigh_key *key)
+{
+	struct prestera_nh_neigh *neigh;
+
+	neigh = prestera_nh_neigh_find(sw, key);
+	if (!neigh)
+		return __prestera_nh_neigh_create(sw, key);
+
+	return neigh;
+}
+
+void prestera_nh_neigh_put(struct prestera_switch *sw,
+			   struct prestera_nh_neigh *neigh)
+{
+	if (list_empty(&neigh->nexthop_group_list) &&
+	    list_empty(&neigh->nh_mangle_entry_list))
+		__prestera_nh_neigh_destroy(sw, neigh);
+}
+
+/* Updates new prestera_neigh_info */
+int prestera_nh_neigh_set(struct prestera_switch *sw,
+			  struct prestera_nh_neigh *neigh)
+{
+	struct prestera_nh_neigh_head *nh_head;
+	struct prestera_nexthop_group *nh_grp;
+	struct prestera_nh_mangle_entry *nm;
+	int err;
+
+	list_for_each_entry(nh_head, &neigh->nexthop_group_list, head) {
+		nh_grp = nh_head->this;
+		err = prestera_nexthop_group_set(sw, nh_grp);
+		if (err)
+			return err;
+	}
+
+	list_for_each_entry(nm, &neigh->nh_mangle_entry_list, nh_neigh_head) {
+		err = prestera_nh_mangle_entry_set(sw, nm);
+		if (err)
+			return err;
+	}
+
+	return 0;
+}
+
+bool prestera_nh_neigh_util_hw_state(struct prestera_switch *sw,
+				     struct prestera_nh_neigh *nh_neigh)
+{
+	bool state;
+	struct prestera_nh_neigh_head *nh_head, *tmp;
+	struct prestera_nh_mangle_entry  *nm, *nm_tmp;
+
+	state = false;
+	list_for_each_entry_safe(nh_head, tmp,
+				 &nh_neigh->nexthop_group_list, head) {
+		state = prestera_nexthop_group_util_hw_state(sw, nh_head->this);
+		if (state)
+			goto out;
+	}
+	list_for_each_entry_safe(nm, nm_tmp, &nh_neigh->nh_mangle_entry_list,
+				 nh_neigh_head) {
+		state = prestera_nh_mangle_entry_util_hw_state(sw, nm);
+		if (state)
+			goto out;
+	}
+
+out:
+	return state;
+}
+
+static struct prestera_nexthop_group *
+__prestera_nexthop_group_create(struct prestera_switch *sw,
+				struct prestera_nexthop_group_key *key)
+{
+	struct prestera_nexthop_group *nh_grp;
+	struct prestera_nh_neigh *nh_neigh;
+	int nh_cnt, err, gid;
+
+	nh_grp = kzalloc(sizeof(*nh_grp), GFP_KERNEL);
+	if (!nh_grp)
+		goto err_kzalloc;
+
+	memcpy(&nh_grp->key, key, sizeof(*key));
+	for (nh_cnt = 0; nh_cnt < PRESTERA_NHGR_SIZE_MAX; nh_cnt++) {
+		if (!prestera_nh_neigh_key_is_valid(&nh_grp->key.neigh[nh_cnt]))
+			break;
+
+		nh_neigh = prestera_nh_neigh_get(sw,
+						 &nh_grp->key.neigh[nh_cnt]);
+		if (!nh_neigh)
+			goto err_nh_neigh_get;
+
+		nh_grp->nh_neigh_head[nh_cnt].neigh = nh_neigh;
+		nh_grp->nh_neigh_head[nh_cnt].this = nh_grp;
+		list_add(&nh_grp->nh_neigh_head[nh_cnt].head,
+			 &nh_neigh->nexthop_group_list);
+	}
+
+	err = prestera_nh_group_create(sw, nh_cnt, &nh_grp->grp_id);
+	if (err)
+		goto err_nh_group_create;
+
+	err = prestera_nexthop_group_set(sw, nh_grp);
+	if (err)
+		goto err_nexthop_group_set;
+
+	err = rhashtable_insert_fast(&sw->router->nexthop_group_ht,
+				     &nh_grp->ht_node,
+				     __prestera_nexthop_group_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	/* reset cache for created group */
+	gid = nh_grp->grp_id;
+	sw->router->nhgrp_hw_state_cache[gid / 8] &= ~BIT(gid % 8);
+
+	return nh_grp;
+
+err_ht_insert:
+err_nexthop_group_set:
+	prestera_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
+err_nh_group_create:
+err_nh_neigh_get:
+	for (nh_cnt--; nh_cnt >= 0; nh_cnt--) {
+		list_del(&nh_grp->nh_neigh_head[nh_cnt].head);
+		prestera_nh_neigh_put(sw, nh_grp->nh_neigh_head[nh_cnt].neigh);
+	}
+
+	kfree(nh_grp);
+err_kzalloc:
+	return NULL;
+}
+
+static void
+__prestera_nexthop_group_destroy(struct prestera_switch *sw,
+				 struct prestera_nexthop_group *nh_grp)
+{
+	struct prestera_nh_neigh *nh_neigh;
+	int nh_cnt;
+
+	rhashtable_remove_fast(&sw->router->nexthop_group_ht,
+			       &nh_grp->ht_node,
+			       __prestera_nexthop_group_ht_params);
+
+	for (nh_cnt = 0; nh_cnt < PRESTERA_NHGR_SIZE_MAX; nh_cnt++) {
+		nh_neigh = nh_grp->nh_neigh_head[nh_cnt].neigh;
+		if (!nh_neigh)
+			break;
+
+		list_del(&nh_grp->nh_neigh_head[nh_cnt].head);
+		prestera_nh_neigh_put(sw, nh_neigh);
+	}
+
+	prestera_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
+	kfree(nh_grp);
+}
+
+static struct prestera_nexthop_group *
+prestera_nexthop_group_find(struct prestera_switch *sw,
+			    struct prestera_nexthop_group_key *key)
+{
+	struct prestera_nexthop_group *nh_grp;
+
+	nh_grp = rhashtable_lookup_fast(&sw->router->nexthop_group_ht,
+					key, __prestera_nexthop_group_ht_params);
+	return IS_ERR(nh_grp) ? NULL : nh_grp;
+}
+
+static struct prestera_nexthop_group *
+prestera_nexthop_group_get(struct prestera_switch *sw,
+			   struct prestera_nexthop_group_key *key)
+{
+	struct prestera_nexthop_group *nh_grp;
+
+	nh_grp = prestera_nexthop_group_find(sw, key);
+	if (!nh_grp)
+		return __prestera_nexthop_group_create(sw, key);
+
+	return nh_grp;
+}
+
+static void prestera_nexthop_group_put(struct prestera_switch *sw,
+				       struct prestera_nexthop_group *nh_grp)
+{
+	if (!nh_grp->ref_cnt)
+		__prestera_nexthop_group_destroy(sw, nh_grp);
+}
+
+/* Updates with new nh_neigh's info */
+static int prestera_nexthop_group_set(struct prestera_switch *sw,
+				      struct prestera_nexthop_group *nh_grp)
+{
+	struct prestera_neigh_info info[PRESTERA_NHGR_SIZE_MAX];
+	struct prestera_nh_neigh *neigh;
+	int nh_cnt;
+
+	memset(&info[0], 0, sizeof(info));
+	for (nh_cnt = 0; nh_cnt < PRESTERA_NHGR_SIZE_MAX; nh_cnt++) {
+		neigh = nh_grp->nh_neigh_head[nh_cnt].neigh;
+		if (!neigh)
+			break;
+
+		memcpy(&info[nh_cnt], &neigh->info, sizeof(neigh->info));
+	}
+
+	return prestera_nh_entries_set(sw, nh_cnt, &info[0], nh_grp->grp_id);
+}
+
+static bool
+prestera_nexthop_group_util_hw_state(struct prestera_switch *sw,
+				     struct prestera_nexthop_group *nh_grp)
+{
+	int err;
+	u32 buf_size = sw->size_tbl_router_nexthop / 8 + 1;
+	u32 gid = nh_grp->grp_id;
+	u8 *cache = sw->router->nhgrp_hw_state_cache;
+
+	/* Antijitter
+	 * Prevent situation, when we read state of nh_grp twice in short time,
+	 * and state bit is still cleared on second call. So just stuck active
+	 * state for PRESTERA_NH_ACTIVE_JIFFER_FILTER, after last occurred.
+	 */
+	if (!time_before(jiffies, sw->router->nhgrp_hw_cache_kick +
+			msecs_to_jiffies(PRESTERA_NH_ACTIVE_JIFFER_FILTER))) {
+		err = prestera_nhgrp_blk_get(sw, cache, buf_size);
+		if (err) {
+			MVSW_LOG_ERROR("Failed to get hw state nh_grp's");
+			return false;
+		}
+
+		sw->router->nhgrp_hw_cache_kick = jiffies;
+	}
+
+	if (cache[gid / 8] & BIT(gid % 8))
+		return true;
+
+	return false;
+}
+
+/* TODO: Move fibs to another file (hw_match.c?) */
+struct prestera_fib_node *
+prestera_fib_node_find(struct prestera_switch *sw, struct prestera_fib_key *key)
+{
+	struct prestera_fib_node *fib_node;
+
+	fib_node = rhashtable_lookup_fast(&sw->router->fib_ht, key,
+					  __prestera_fib_ht_params);
+	return IS_ERR(fib_node) ? NULL : fib_node;
+}
+
+static void __prestera_fib_node_destruct(struct prestera_switch *sw,
+					 struct prestera_fib_node *fib_node)
+{
+	struct prestera_vr *vr;
+
+	vr = fib_node->info.vr;
+	prestera_lpm_del(sw, vr->hw_vr_id, &fib_node->key.addr,
+			 fib_node->key.prefix_len);
+	switch (fib_node->info.type) {
+	case PRESTERA_FIB_TYPE_UC_NH:
+		fib_node->info.nh_grp->ref_cnt--;
+		prestera_nexthop_group_put(sw, fib_node->info.nh_grp);
+		break;
+	case PRESTERA_FIB_TYPE_TRAP:
+		break;
+	case PRESTERA_FIB_TYPE_DROP:
+		break;
+	default:
+	      MVSW_LOG_ERROR("Unknown fib_node->info.type = %d",
+			     fib_node->info.type);
+	}
+
+	vr->ref_cnt--;
+	prestera_vr_put(sw, vr);
+}
+
+void prestera_fib_node_destroy(struct prestera_switch *sw,
+			       struct prestera_fib_node *fib_node)
+{
+	__prestera_fib_node_destruct(sw, fib_node);
+	rhashtable_remove_fast(&sw->router->fib_ht, &fib_node->ht_node,
+			       __prestera_fib_ht_params);
+	kfree(fib_node);
+}
+
+void prestera_fib_node_destroy_ht(struct prestera_switch *sw)
+{
+	struct prestera_fib_node *node;
+	struct rhashtable_iter iter;
+
+	while (1) {
+		rhashtable_walk_enter(&sw->router->fib_ht, &iter);
+		rhashtable_walk_start(&iter);
+		node = rhashtable_walk_next(&iter);
+		rhashtable_walk_stop(&iter);
+		rhashtable_walk_exit(&iter);
+
+		if (!node)
+			break;
+		else if (IS_ERR(node))
+			continue;
+		else if (node)
+			prestera_fib_node_destroy(sw, node);
+	}
+}
+
+/* nh_grp_key valid only if fib_type == MVSW_PR_FIB_TYPE_UC_NH */
+struct prestera_fib_node *
+prestera_fib_node_create(struct prestera_switch *sw,
+			 struct prestera_fib_key *key,
+			 enum prestera_fib_type fib_type,
+			 struct prestera_nexthop_group_key *nh_grp_key)
+{
+	struct prestera_fib_node *fib_node;
+	u32 grp_id;
+	struct prestera_vr *vr;
+	int err;
+
+	fib_node = kzalloc(sizeof(*fib_node), GFP_KERNEL);
+	if (!fib_node)
+		goto err_kzalloc;
+
+	memcpy(&fib_node->key, key, sizeof(*key));
+	fib_node->info.type = fib_type;
+
+	vr = prestera_vr_get(sw, key->tb_id, NULL);
+	if (IS_ERR(vr))
+		goto err_vr_get;
+
+	fib_node->info.vr = vr;
+	vr->ref_cnt++;
+
+	switch (fib_type) {
+	case PRESTERA_FIB_TYPE_TRAP:
+		grp_id = PRESTERA_NHGR_UNUSED;
+		break;
+	case PRESTERA_FIB_TYPE_DROP:
+		grp_id = PRESTERA_NHGR_DROP;
+		break;
+	case PRESTERA_FIB_TYPE_UC_NH:
+		fib_node->info.nh_grp = prestera_nexthop_group_get(sw,
+								   nh_grp_key);
+		if (!fib_node->info.nh_grp)
+			goto err_nh_grp_get;
+
+		fib_node->info.nh_grp->ref_cnt++;
+		grp_id = fib_node->info.nh_grp->grp_id;
+		break;
+	default:
+		MVSW_LOG_ERROR("Unsupported fib_type %d", fib_type);
+		goto err_nh_grp_get;
+	}
+
+	err = prestera_lpm_add(sw, vr->hw_vr_id, &key->addr,
+			       key->prefix_len, grp_id);
+	if (err)
+		goto err_lpm_add;
+
+	err = rhashtable_insert_fast(&sw->router->fib_ht, &fib_node->ht_node,
+				     __prestera_fib_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	return fib_node;
+
+err_ht_insert:
+	prestera_lpm_del(sw, vr->hw_vr_id, &key->addr, key->prefix_len);
+err_lpm_add:
+	if (fib_type == PRESTERA_FIB_TYPE_UC_NH) {
+		fib_node->info.nh_grp->ref_cnt--;
+		prestera_nexthop_group_put(sw, fib_node->info.nh_grp);
+	}
+err_nh_grp_get:
+	vr->ref_cnt--;
+	prestera_vr_put(sw, vr);
+err_vr_get:
+	kfree(fib_node);
+err_kzalloc:
+	return NULL;
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_router_hw.h b/drivers/net/ethernet/marvell/prestera/prestera_router_hw.h
new file mode 100644
index 000000000000..b3acc58e729b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_router_hw.h
@@ -0,0 +1,120 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _PRESTERA_ROUTER_HW_H_
+#define _PRESTERA_ROUTER_HW_H_
+
+/* TODO: move structures, that not used from external to .c file */
+
+struct prestera_vr {
+	u16 hw_vr_id;			/* virtual router ID */
+	u32 tb_id;			/* key (kernel fib table id) */
+	struct list_head router_node;
+	unsigned int ref_cnt;
+};
+
+struct prestera_rif_macvlan_list_node {
+	struct list_head head;
+	unsigned char addr[ETH_ALEN];
+};
+
+/* Add port to vlan + FDB ... or only FDB for vlan */
+struct prestera_rif_entry {
+	struct prestera_rif_entry_key {
+		struct prestera_iface iface;
+	} key;
+	struct prestera_vr *vr;
+	unsigned char addr[ETH_ALEN];
+	struct list_head macvlan_list;
+	u16 hw_id; /* rif_id */
+	struct list_head router_node; /* ht */
+};
+
+struct prestera_nexthop_group {
+	struct prestera_nexthop_group_key key;
+	/* Store intermediate object here.
+	 * This prevent overhead kzalloc call.
+	 */
+	/* nh_neigh is used only to notify nexthop_group */
+	struct prestera_nh_neigh_head {
+		struct prestera_nexthop_group *this;
+		struct list_head head;
+		/* ptr to neigh is not necessary.
+		 * It used to prevent lookup of nh_neigh by key (n) on destroy
+		 */
+		struct prestera_nh_neigh *neigh;
+	} nh_neigh_head[PRESTERA_NHGR_SIZE_MAX];
+	u32 grp_id; /* hw */
+	struct rhash_head ht_node; /* node of prestera_vr */
+	unsigned int ref_cnt;
+};
+
+struct prestera_fib_key {
+	struct prestera_ip_addr addr;
+	u32 prefix_len;
+	u32 tb_id;
+};
+
+struct prestera_fib_info {
+	struct prestera_vr *vr;
+	struct list_head vr_node;
+	enum prestera_fib_type {
+		PRESTERA_FIB_TYPE_INVALID = 0,
+		/* must be pointer to nh_grp id */
+		PRESTERA_FIB_TYPE_UC_NH,
+		/* It can be connected route
+		 * and will be overlapped with neighbours
+		 */
+		PRESTERA_FIB_TYPE_TRAP,
+		PRESTERA_FIB_TYPE_DROP
+	} type;
+	/* Valid only if type = UC_NH*/
+	struct prestera_nexthop_group *nh_grp;
+};
+
+struct prestera_fib_node {
+	struct rhash_head ht_node; /* node of prestera_vr */
+	struct prestera_fib_key key;
+	struct prestera_fib_info info; /* action related info */
+};
+
+int prestera_rif_entry_set_macvlan(const struct prestera_switch *sw,
+				   struct prestera_rif_entry *e,
+				   bool enable, const char *addr);
+struct prestera_rif_entry *
+prestera_rif_entry_find(const struct prestera_switch *sw,
+			const struct prestera_rif_entry_key *k);
+void prestera_rif_entry_destroy(struct prestera_switch *sw,
+				struct prestera_rif_entry *e);
+void prestera_rif_entry_destroy_ht(struct prestera_switch *sw);
+struct prestera_rif_entry *
+prestera_rif_entry_create(struct prestera_switch *sw,
+			  struct prestera_rif_entry_key *k,
+			  u32 tb_id, unsigned char *addr);
+void prestera_vr_util_hw_abort(struct prestera_switch *sw);
+int prestera_router_hw_init(struct prestera_switch *sw);
+void prestera_router_hw_fini(struct prestera_switch *sw);
+struct prestera_nh_neigh *
+prestera_nh_neigh_find(struct prestera_switch *sw,
+		       struct prestera_nh_neigh_key *key);
+struct prestera_nh_neigh *
+prestera_nh_neigh_get(struct prestera_switch *sw,
+		      struct prestera_nh_neigh_key *key);
+void prestera_nh_neigh_put(struct prestera_switch *sw,
+			   struct prestera_nh_neigh *neigh);
+int prestera_nh_neigh_set(struct prestera_switch *sw,
+			  struct prestera_nh_neigh *neigh);
+bool prestera_nh_neigh_util_hw_state(struct prestera_switch *sw,
+				     struct prestera_nh_neigh *nh_neigh);
+struct prestera_fib_node *
+prestera_fib_node_find(struct prestera_switch *sw, struct prestera_fib_key *key);
+void prestera_fib_node_destroy(struct prestera_switch *sw,
+			       struct prestera_fib_node *fib_node);
+void prestera_fib_node_destroy_ht(struct prestera_switch *sw);
+struct prestera_fib_node *
+prestera_fib_node_create(struct prestera_switch *sw,
+			 struct prestera_fib_key *key,
+			 enum prestera_fib_type fib_type,
+			 struct prestera_nexthop_group_key *nh_grp_key);
+
+#endif /* _PRESTERA_ROUTER_HW_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
index 73d2eba5262f..e91ec9a870ec 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
@@ -1,355 +1,405 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
-#include <linux/bitfield.h>
-#include <linux/dmapool.h>
-#include <linux/etherdevice.h>
-#include <linux/if_vlan.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
 #include <linux/of_address.h>
 #include <linux/of_device.h>
-#include <linux/of.h>
-#include <linux/platform_device.h>
+#include <linux/dmapool.h>
+#include <linux/if_vlan.h>
+#include <net/ip.h>
 
-#include "prestera_dsa.h"
 #include "prestera.h"
 #include "prestera_hw.h"
+#include "prestera_dsa.h"
 #include "prestera_rxtx.h"
 #include "prestera_devlink.h"
 
-#define PRESTERA_SDMA_WAIT_MUL		10
+#define MVSW_DSA_TAG_ARP_BROADCAST 5
+#define MVSW_DSA_TAG_IPV4_BROADCAST 19
+#define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC 16
+#define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_1 29
+#define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_2 30
+#define MVSW_DSA_TAG_UDP_BROADCAST 33
+#define MVSW_DSA_TAG_ARP_BROADCAST_TO_ME 179
 
-struct prestera_sdma_desc {
+struct mvsw_sdma_desc {
 	__le32 word1;
 	__le32 word2;
 	__le32 buff;
 	__le32 next;
 } __packed __aligned(16);
 
-#define PRESTERA_SDMA_BUFF_SIZE_MAX	1544
+#define SDMA_BUFF_SIZE_MAX	1544
 
-#define PRESTERA_SDMA_RX_DESC_PKT_LEN(desc) \
-	((le32_to_cpu((desc)->word2) >> 16) & GENMASK(13, 0))
+#define SDMA_RX_DESC_PKT_LEN(desc) \
+	((le32_to_cpu((desc)->word2) >> 16) & 0x3FFF)
 
-#define PRESTERA_SDMA_RX_DESC_OWNER(desc) \
+#define SDMA_RX_DESC_OWNER(desc) \
 	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
 
-#define PRESTERA_SDMA_RX_DESC_IS_RCVD(desc) \
-	(PRESTERA_SDMA_RX_DESC_OWNER(desc) == PRESTERA_SDMA_RX_DESC_CPU_OWN)
-
-#define PRESTERA_SDMA_RX_DESC_CPU_OWN	0
-#define PRESTERA_SDMA_RX_DESC_DMA_OWN	1
+#define SDMA_RX_DESC_CPU_OWN	0
+#define SDMA_RX_DESC_DMA_OWN	1
 
-#define PRESTERA_SDMA_RX_QUEUE_NUM	8
+#define SDMA_RX_QUEUE_NUM	8
 
-#define PRESTERA_SDMA_RX_DESC_PER_Q	1000
+#define SDMA_RX_DESC_PER_Q	1000
 
-#define PRESTERA_SDMA_TX_DESC_PER_Q	1000
-#define PRESTERA_SDMA_TX_MAX_BURST	64
+#define SDMA_TX_DESC_PER_Q	1000
+#define SDMA_TX_MAX_BURST	32
 
-#define PRESTERA_SDMA_TX_DESC_OWNER(desc) \
+#define SDMA_TX_DESC_OWNER(desc) \
 	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
 
-#define PRESTERA_SDMA_TX_DESC_CPU_OWN	0
-#define PRESTERA_SDMA_TX_DESC_DMA_OWN	1U
+#define SDMA_TX_DESC_CPU_OWN	0
+#define SDMA_TX_DESC_DMA_OWN	1
 
-#define PRESTERA_SDMA_TX_DESC_IS_SENT(desc) \
-	(PRESTERA_SDMA_TX_DESC_OWNER(desc) == PRESTERA_SDMA_TX_DESC_CPU_OWN)
+#define SDMA_TX_DESC_IS_SENT(desc) \
+	(SDMA_TX_DESC_OWNER(desc) == SDMA_TX_DESC_CPU_OWN)
 
-#define PRESTERA_SDMA_TX_DESC_LAST	BIT(20)
-#define PRESTERA_SDMA_TX_DESC_FIRST	BIT(21)
-#define PRESTERA_SDMA_TX_DESC_CALC_CRC	BIT(12)
+#define SDMA_TX_DESC_LAST	BIT(20)
+#define SDMA_TX_DESC_FIRST	BIT(21)
+#define SDMA_TX_DESC_SINGLE	(SDMA_TX_DESC_FIRST | SDMA_TX_DESC_LAST)
+#define SDMA_TX_DESC_CALC_CRC	BIT(12)
 
-#define PRESTERA_SDMA_TX_DESC_SINGLE	\
-	(PRESTERA_SDMA_TX_DESC_FIRST | PRESTERA_SDMA_TX_DESC_LAST)
+#define mvsw_reg_write(sw, reg, val) \
+	writel(val, (sw)->dev->pp_regs + (reg))
+#define mvsw_reg_read(sw, reg) \
+	readl((sw)->dev->pp_regs + (reg))
 
-#define PRESTERA_SDMA_TX_DESC_INIT	\
-	(PRESTERA_SDMA_TX_DESC_SINGLE | PRESTERA_SDMA_TX_DESC_CALC_CRC)
+#define SDMA_RX_INTR_MASK_REG		0x2814
+#define SDMA_RX_QUEUE_STATUS_REG	0x2680
+#define SDMA_RX_QUEUE_DESC_REG(n)	(0x260C + (n) * 16)
 
-#define PRESTERA_SDMA_RX_INTR_MASK_REG		0x2814
-#define PRESTERA_SDMA_RX_QUEUE_STATUS_REG	0x2680
-#define PRESTERA_SDMA_RX_QUEUE_DESC_REG(n)	(0x260C + (n) * 16)
+#define SDMA_TX_QUEUE_DESC_REG		0x26C0
+#define SDMA_TX_QUEUE_START_REG		0x2868
 
-#define PRESTERA_SDMA_TX_QUEUE_DESC_REG		0x26C0
-#define PRESTERA_SDMA_TX_QUEUE_START_REG	0x2868
-
-struct prestera_sdma_buf {
-	struct prestera_sdma_desc *desc;
+struct mvsw_sdma_buf {
+	struct mvsw_sdma_desc *desc;
 	dma_addr_t desc_dma;
 	struct sk_buff *skb;
 	dma_addr_t buf_dma;
 	bool is_used;
 };
 
-struct prestera_rx_ring {
-	struct prestera_sdma_buf *bufs;
+struct mvsw_sdma_rx_ring {
+	struct mvsw_sdma_buf *bufs;
 	int next_rx;
+	int weight;
+	int recvd;
 };
 
-struct prestera_tx_ring {
-	struct prestera_sdma_buf *bufs;
+struct mvsw_sdma_tx_ring {
+	struct mvsw_sdma_buf *bufs;
 	int next_tx;
 	int max_burst;
 	int burst;
 };
 
-struct prestera_sdma {
-	struct prestera_rx_ring rx_ring[PRESTERA_SDMA_RX_QUEUE_NUM];
-	struct prestera_tx_ring tx_ring;
-	struct prestera_switch *sw;
+struct mvsw_pr_rxtx_sdma {
+	struct mvsw_sdma_rx_ring rx_ring[SDMA_RX_QUEUE_NUM];
+	struct mvsw_sdma_tx_ring tx_ring;
+	const struct prestera_switch *sw;
 	struct dma_pool *desc_pool;
 	struct work_struct tx_work;
 	struct napi_struct rx_napi;
+	int next_rxq;
 	struct net_device napi_dev;
-	u32 map_addr;
-	u64 dma_mask;
 	/* protect SDMA with concurrrent access from multiple CPUs */
 	spinlock_t tx_lock;
+	u32 map_addr;
+	u64 dma_mask;
+	gfp_t dma_flags;
 };
 
 struct prestera_rxtx {
-	struct prestera_sdma sdma;
+	struct mvsw_pr_rxtx_sdma sdma;
+};
+
+static int prestera_rx_weight_map[SDMA_RX_QUEUE_NUM] = {
+	1, 2, 2, 2, 2, 4, 4, 8
 };
 
-static int prestera_sdma_buf_init(struct prestera_sdma *sdma,
-				  struct prestera_sdma_buf *buf)
+static u64 *cpu_code_stats;
+
+static int mvsw_sdma_buf_desc_alloc(struct mvsw_pr_rxtx_sdma *sdma,
+				    struct mvsw_sdma_buf *buf)
 {
-	struct prestera_sdma_desc *desc;
+	struct device *dma_dev = sdma->sw->dev->dev;
+	struct mvsw_sdma_desc *desc;
 	dma_addr_t dma;
 
-	desc = dma_pool_alloc(sdma->desc_pool, GFP_DMA | GFP_KERNEL, &dma);
+	desc = dma_pool_alloc(sdma->desc_pool, sdma->dma_flags | GFP_KERNEL, &dma);
 	if (!desc)
 		return -ENOMEM;
 
-	buf->buf_dma = DMA_MAPPING_ERROR;
+	if (dma + sizeof(struct mvsw_sdma_desc) > sdma->dma_mask) {
+		dev_err(dma_dev, "failed to alloc desc\n");
+		dma_pool_free(sdma->desc_pool, desc, dma);
+		return -ENOMEM;
+	}
+
 	buf->desc_dma = dma;
 	buf->desc = desc;
-	buf->skb = NULL;
 
 	return 0;
 }
 
-static u32 prestera_sdma_map(struct prestera_sdma *sdma, dma_addr_t pa)
+static u32 mvsw_sdma_addr_phy(struct mvsw_pr_rxtx_sdma *sdma, dma_addr_t pa)
 {
 	return sdma->map_addr + pa;
 }
 
-static void prestera_sdma_rx_desc_init(struct prestera_sdma *sdma,
-				       struct prestera_sdma_desc *desc,
-				       dma_addr_t buf)
+static void mvsw_sdma_rx_desc_set_len(struct mvsw_sdma_desc *desc, size_t val)
 {
 	u32 word = le32_to_cpu(desc->word2);
 
-	u32p_replace_bits(&word, PRESTERA_SDMA_BUFF_SIZE_MAX, GENMASK(15, 0));
+	word = (word & ~GENMASK(15, 0)) | val;
 	desc->word2 = cpu_to_le32(word);
+}
 
-	desc->buff = cpu_to_le32(prestera_sdma_map(sdma, buf));
-
+static void mvsw_sdma_rx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_desc *desc,
+				   dma_addr_t buf)
+{
+	mvsw_sdma_rx_desc_set_len(desc, SDMA_BUFF_SIZE_MAX);
+	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
 	/* make sure buffer is set before reset the descriptor */
 	wmb();
-
 	desc->word1 = cpu_to_le32(0xA0000000);
 }
 
-static void prestera_sdma_rx_desc_set_next(struct prestera_sdma *sdma,
-					   struct prestera_sdma_desc *desc,
-					   dma_addr_t next)
+static void mvsw_sdma_rx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
+				       struct mvsw_sdma_desc *desc,
+				       dma_addr_t next)
 {
-	desc->next = cpu_to_le32(prestera_sdma_map(sdma, next));
+	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
 }
 
-static int prestera_sdma_rx_skb_alloc(struct prestera_sdma *sdma,
-				      struct prestera_sdma_buf *buf)
+static int mvsw_sdma_rx_dma_alloc(struct mvsw_pr_rxtx_sdma *sdma,
+				  struct mvsw_sdma_buf *buf)
 {
 	struct device *dev = sdma->sw->dev->dev;
-	struct sk_buff *skb;
-	dma_addr_t dma;
 
-	skb = alloc_skb(PRESTERA_SDMA_BUFF_SIZE_MAX, GFP_DMA | GFP_ATOMIC);
-	if (!skb)
+	buf->skb = alloc_skb(SDMA_BUFF_SIZE_MAX, sdma->dma_flags | GFP_ATOMIC);
+	if (!buf->skb)
 		return -ENOMEM;
 
-	dma = dma_map_single(dev, skb->data, skb->len, DMA_FROM_DEVICE);
-	if (dma_mapping_error(dev, dma))
-		goto err_dma_map;
-
-	if (buf->skb)
-		dma_unmap_single(dev, buf->buf_dma, buf->skb->len,
-				 DMA_FROM_DEVICE);
+	buf->buf_dma = dma_map_single(dev, buf->skb->data, buf->skb->len,
+				      DMA_FROM_DEVICE);
 
-	buf->buf_dma = dma;
-	buf->skb = skb;
+	if (dma_mapping_error(dev, buf->buf_dma))
+		goto err_dma_map;
+	if (buf->buf_dma + buf->skb->len > sdma->dma_mask)
+		goto err_dma_range;
 
 	return 0;
 
+err_dma_range:
+	dma_unmap_single(dev, buf->buf_dma, buf->skb->len, DMA_FROM_DEVICE);
+	buf->buf_dma = DMA_MAPPING_ERROR;
 err_dma_map:
-	kfree_skb(skb);
+	kfree_skb(buf->skb);
+	buf->skb = NULL;
 
 	return -ENOMEM;
 }
 
-static struct sk_buff *prestera_sdma_rx_skb_get(struct prestera_sdma *sdma,
-						struct prestera_sdma_buf *buf)
+static struct sk_buff *mvsw_sdma_rx_buf_get(struct mvsw_pr_rxtx_sdma *sdma,
+					    struct mvsw_sdma_buf *buf)
 {
+	struct sk_buff *skb_orig = buf->skb;
 	dma_addr_t buf_dma = buf->buf_dma;
-	struct sk_buff *skb = buf->skb;
-	u32 len = skb->len;
+	u32 len = skb_orig->len;
 	int err;
 
-	err = prestera_sdma_rx_skb_alloc(sdma, buf);
+	err = mvsw_sdma_rx_dma_alloc(sdma, buf);
 	if (err) {
+		struct sk_buff *skb;
+
 		buf->buf_dma = buf_dma;
-		buf->skb = skb;
+		buf->skb = skb_orig;
 
-		skb = alloc_skb(skb->len, GFP_ATOMIC);
-		if (skb) {
-			skb_put(skb, len);
-			skb_copy_from_linear_data(buf->skb, skb->data, len);
-		}
+		skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_ATOMIC);
+		if (!skb)
+			return NULL;
+
+		skb_copy_from_linear_data(buf->skb, skb_put(skb, len), len);
+		return skb;
 	}
 
-	prestera_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
+	return skb_orig;
+}
 
-	return skb;
+static void mvsw_sdma_rx_set_next_queue(struct mvsw_pr_rxtx_sdma *sdma, int rxq)
+{
+	sdma->next_rxq = rxq % SDMA_RX_QUEUE_NUM;
 }
 
-static int prestera_rxtx_process_skb(struct prestera_sdma *sdma,
-				     struct sk_buff *skb)
+static int mvsw_sdma_rx_pick_next_queue(struct mvsw_pr_rxtx_sdma *sdma)
 {
+	struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[sdma->next_rxq];
+
+	if (ring->recvd >= ring->weight) {
+		mvsw_sdma_rx_set_next_queue(sdma, sdma->next_rxq + 1);
+		ring->recvd = 0;
+	}
+
+	return sdma->next_rxq;
+}
+
+static int mvsw_pr_sdma_recv_skb(struct sk_buff *skb)
+{
+	struct prestera_rxtx_stats *rxtx_stats;
 	struct prestera_port *port;
-	struct prestera_dsa dsa;
-	u32 hw_port, dev_id;
+	struct mvsw_pr_dsa dsa;
+	u32 hw_port, hw_id;
 	u8 cpu_code;
 	int err;
 
 	skb_pull(skb, ETH_HLEN);
 
-	/* ethertype field is part of the dsa header */
-	err = prestera_dsa_parse(&dsa, skb->data - ETH_TLEN);
+	/* parse/process DSA tag
+	 * ethertype field is part of the dsa header
+	 */
+	err = mvsw_pr_dsa_parse(skb->data - ETH_TLEN, &dsa);
 	if (err)
 		return err;
 
-	dev_id = dsa.hw_dev_num;
-	hw_port = dsa.port_num;
-
-	port = prestera_port_find_by_hwid(sdma->sw, dev_id, hw_port);
+	/* get switch port */
+	hw_port = dsa.dsa_info.to_cpu.iface.port_num;
+	hw_id = dsa.dsa_info.to_cpu.hw_dev_num;
+	port = prestera_port_find(hw_id, hw_port);
 	if (unlikely(!port)) {
-		dev_warn_ratelimited(prestera_dev(sdma->sw), "received pkt for non-existent port(%u, %u)\n",
-				     dev_id, hw_port);
-		return -ENOENT;
+		pr_warn_ratelimited("prestera: received pkt for non-existent port(%u, %u)\n",
+				    hw_id, hw_port);
+		return -EEXIST;
 	}
 
-	if (unlikely(!pskb_may_pull(skb, PRESTERA_DSA_HLEN)))
+	if (unlikely(!pskb_may_pull(skb, MVSW_PR_DSA_HLEN)))
 		return -EINVAL;
 
 	/* remove DSA tag and update checksum */
-	skb_pull_rcsum(skb, PRESTERA_DSA_HLEN);
+	skb_pull_rcsum(skb, MVSW_PR_DSA_HLEN);
 
-	memmove(skb->data - ETH_HLEN, skb->data - ETH_HLEN - PRESTERA_DSA_HLEN,
+	memmove(skb->data - ETH_HLEN, skb->data - ETH_HLEN - MVSW_PR_DSA_HLEN,
 		ETH_ALEN * 2);
 
 	skb_push(skb, ETH_HLEN);
 
-	skb->protocol = eth_type_trans(skb, port->dev);
+	skb->protocol = eth_type_trans(skb, port->net_dev);
 
-	if (dsa.vlan.is_tagged) {
-		u16 tci = dsa.vlan.vid & VLAN_VID_MASK;
+	if (dsa.dsa_info.to_cpu.is_tagged) {
+		u16 tci = dsa.common_params.vid & VLAN_VID_MASK;
 
-		tci |= dsa.vlan.vpt << VLAN_PRIO_SHIFT;
-		if (dsa.vlan.cfi_bit)
+		tci |= dsa.common_params.vpt << VLAN_PRIO_SHIFT;
+		if (dsa.common_params.cfi_bit)
 			tci |= VLAN_CFI_MASK;
 
 		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), tci);
 	}
 
-	cpu_code = dsa.cpu_code;
+	cpu_code = dsa.dsa_info.to_cpu.cpu_code;
+
 	prestera_devlink_trap_report(port, skb, cpu_code);
 
-	return 0;
-}
+	switch (cpu_code) {
+	case MVSW_DSA_TAG_ARP_BROADCAST:
+	case MVSW_DSA_TAG_IPV4_BROADCAST:
+	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC:
+	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_1:
+	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_2:
+	case MVSW_DSA_TAG_UDP_BROADCAST:
+	case MVSW_DSA_TAG_ARP_BROADCAST_TO_ME:
+		skb->offload_fwd_mark = 1;
+	}
+	++cpu_code_stats[cpu_code];
 
-static int prestera_sdma_next_rx_buf_idx(int buf_idx)
-{
-	return (buf_idx + 1) % PRESTERA_SDMA_RX_DESC_PER_Q;
+	rxtx_stats = this_cpu_ptr(port->rxtx_stats);
+	u64_stats_update_begin(&rxtx_stats->syncp);
+	rxtx_stats->rx_packets++;
+	rxtx_stats->rx_bytes += skb->len;
+	u64_stats_update_end(&rxtx_stats->syncp);
+
+	return 0;
 }
 
-static int prestera_sdma_rx_poll(struct napi_struct *napi, int budget)
+static int mvsw_sdma_rx_poll(struct napi_struct *napi, int budget)
 {
-	int qnum = PRESTERA_SDMA_RX_QUEUE_NUM;
+	unsigned int qmask = GENMASK(SDMA_RX_QUEUE_NUM - 1, 0);
+	struct mvsw_pr_rxtx_sdma *sdma;
 	unsigned int rxq_done_map = 0;
-	struct prestera_sdma *sdma;
 	struct list_head rx_list;
-	unsigned int qmask;
 	int pkts_done = 0;
-	int q;
-
-	qnum = PRESTERA_SDMA_RX_QUEUE_NUM;
-	qmask = GENMASK(qnum - 1, 0);
 
 	INIT_LIST_HEAD(&rx_list);
 
-	sdma = container_of(napi, struct prestera_sdma, rx_napi);
+	sdma = container_of(napi, struct mvsw_pr_rxtx_sdma, rx_napi);
 
 	while (pkts_done < budget && rxq_done_map != qmask) {
-		for (q = 0; q < qnum && pkts_done < budget; q++) {
-			struct prestera_rx_ring *ring = &sdma->rx_ring[q];
-			struct prestera_sdma_desc *desc;
-			struct prestera_sdma_buf *buf;
-			int buf_idx = ring->next_rx;
-			struct sk_buff *skb;
-
-			buf = &ring->bufs[buf_idx];
-			desc = buf->desc;
-
-			if (PRESTERA_SDMA_RX_DESC_IS_RCVD(desc)) {
-				rxq_done_map &= ~BIT(q);
-			} else {
-				rxq_done_map |= BIT(q);
-				continue;
-			}
+		struct mvsw_sdma_rx_ring *ring;
+		struct mvsw_sdma_desc *desc;
+		struct mvsw_sdma_buf *buf;
+		struct sk_buff *skb;
+		int buf_idx;
+		int rxq;
+
+		rxq = mvsw_sdma_rx_pick_next_queue(sdma);
+		ring = &sdma->rx_ring[rxq];
+
+		buf_idx = ring->next_rx;
+		buf = &ring->bufs[buf_idx];
+		desc = buf->desc;
+
+		if (SDMA_RX_DESC_OWNER(desc) != SDMA_RX_DESC_CPU_OWN) {
+			mvsw_sdma_rx_set_next_queue(sdma, rxq + 1);
+			rxq_done_map |= BIT(rxq);
+			continue;
+		} else {
+			rxq_done_map &= ~BIT(rxq);
+		}
 
-			pkts_done++;
+		ring->recvd++;
+		pkts_done++;
 
-			__skb_trim(buf->skb, PRESTERA_SDMA_RX_DESC_PKT_LEN(desc));
+		__skb_trim(buf->skb, SDMA_RX_DESC_PKT_LEN(desc));
 
-			skb = prestera_sdma_rx_skb_get(sdma, buf);
-			if (!skb)
-				goto rx_next_buf;
+		skb = mvsw_sdma_rx_buf_get(sdma, buf);
+		if (!skb)
+			goto rx_reset_buf;
 
-			if (unlikely(prestera_rxtx_process_skb(sdma, skb)))
-				goto rx_next_buf;
+		if (unlikely(mvsw_pr_sdma_recv_skb(skb)))
+			goto rx_reset_buf;
 
-			list_add_tail(&skb->list, &rx_list);
-rx_next_buf:
-			ring->next_rx = prestera_sdma_next_rx_buf_idx(buf_idx);
-		}
+		list_add_tail(&skb->list, &rx_list);
+rx_reset_buf:
+		mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
+		ring->next_rx = (buf_idx + 1) % SDMA_RX_DESC_PER_Q;
 	}
 
 	if (pkts_done < budget && napi_complete_done(napi, pkts_done))
-		prestera_write(sdma->sw, PRESTERA_SDMA_RX_INTR_MASK_REG,
-			       GENMASK(9, 2));
+		mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0xff << 2);
 
 	netif_receive_skb_list(&rx_list);
 
 	return pkts_done;
 }
 
-static void prestera_sdma_rx_fini(struct prestera_sdma *sdma)
+static void mvsw_sdma_rx_fini(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	int qnum = PRESTERA_SDMA_RX_QUEUE_NUM;
 	int q, b;
 
 	/* disable all rx queues */
-	prestera_write(sdma->sw, PRESTERA_SDMA_RX_QUEUE_STATUS_REG,
-		       GENMASK(15, 8));
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
 
-	for (q = 0; q < qnum; q++) {
-		struct prestera_rx_ring *ring = &sdma->rx_ring[q];
+	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
+		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
 
 		if (!ring->bufs)
 			break;
 
-		for (b = 0; b < PRESTERA_SDMA_RX_DESC_PER_Q; b++) {
-			struct prestera_sdma_buf *buf = &ring->bufs[b];
+		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
+			struct mvsw_sdma_buf *buf = &ring->bufs[b];
 
 			if (buf->desc_dma)
 				dma_pool_free(sdma->desc_pool, buf->desc,
@@ -367,151 +417,179 @@ static void prestera_sdma_rx_fini(struct prestera_sdma *sdma)
 	}
 }
 
-static int prestera_sdma_rx_init(struct prestera_sdma *sdma)
+static int mvsw_sdma_rx_init(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	int bnum = PRESTERA_SDMA_RX_DESC_PER_Q;
-	int qnum = PRESTERA_SDMA_RX_QUEUE_NUM;
+	int q, b;
 	int err;
-	int q;
 
 	/* disable all rx queues */
-	prestera_write(sdma->sw, PRESTERA_SDMA_RX_QUEUE_STATUS_REG,
-		       GENMASK(15, 8));
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
 
-	for (q = 0; q < qnum; q++) {
-		struct prestera_sdma_buf *head, *tail, *next, *prev;
-		struct prestera_rx_ring *ring = &sdma->rx_ring[q];
+	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
+		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
+		struct mvsw_sdma_buf *head;
 
-		ring->bufs = kmalloc_array(bnum, sizeof(*head), GFP_KERNEL);
+		ring->bufs = kmalloc_array(SDMA_RX_DESC_PER_Q, sizeof(*head),
+					   GFP_KERNEL);
 		if (!ring->bufs)
 			return -ENOMEM;
 
+		ring->weight = prestera_rx_weight_map[q];
+		ring->recvd = 0;
 		ring->next_rx = 0;
 
-		tail = &ring->bufs[bnum - 1];
 		head = &ring->bufs[0];
-		next = head;
-		prev = next;
 
-		do {
-			err = prestera_sdma_buf_init(sdma, next);
+		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
+			struct mvsw_sdma_buf *buf = &ring->bufs[b];
+
+			err = mvsw_sdma_buf_desc_alloc(sdma, buf);
 			if (err)
 				return err;
 
-			err = prestera_sdma_rx_skb_alloc(sdma, next);
+			err = mvsw_sdma_rx_dma_alloc(sdma, buf);
 			if (err)
 				return err;
 
-			prestera_sdma_rx_desc_init(sdma, next->desc,
-						   next->buf_dma);
+			mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
 
-			prestera_sdma_rx_desc_set_next(sdma, prev->desc,
-						       next->desc_dma);
+			if (b == 0)
+				continue;
 
-			prev = next;
-			next++;
-		} while (prev != tail);
+			mvsw_sdma_rx_desc_set_next(sdma, ring->bufs[b - 1].desc,
+						   buf->desc_dma);
 
-		/* join tail with head to make a circular list */
-		prestera_sdma_rx_desc_set_next(sdma, tail->desc, head->desc_dma);
+			if (b == SDMA_RX_DESC_PER_Q - 1)
+				mvsw_sdma_rx_desc_set_next(sdma, buf->desc,
+							   head->desc_dma);
+		}
 
-		prestera_write(sdma->sw, PRESTERA_SDMA_RX_QUEUE_DESC_REG(q),
-			       prestera_sdma_map(sdma, head->desc_dma));
+		mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_DESC_REG(q),
+			       mvsw_sdma_addr_phy(sdma, head->desc_dma));
 	}
 
 	/* make sure all rx descs are filled before enabling all rx queues */
 	wmb();
-
-	prestera_write(sdma->sw, PRESTERA_SDMA_RX_QUEUE_STATUS_REG,
-		       GENMASK(7, 0));
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff);
 
 	return 0;
 }
 
-static void prestera_sdma_tx_desc_init(struct prestera_sdma *sdma,
-				       struct prestera_sdma_desc *desc)
+static void mvsw_sdma_tx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_desc *desc)
 {
-	desc->word1 = cpu_to_le32(PRESTERA_SDMA_TX_DESC_INIT);
+	desc->word1 = cpu_to_le32(SDMA_TX_DESC_SINGLE | SDMA_TX_DESC_CALC_CRC);
 	desc->word2 = 0;
 }
 
-static void prestera_sdma_tx_desc_set_next(struct prestera_sdma *sdma,
-					   struct prestera_sdma_desc *desc,
-					   dma_addr_t next)
+static void mvsw_sdma_tx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
+				       struct mvsw_sdma_desc *desc,
+				       dma_addr_t next)
 {
-	desc->next = cpu_to_le32(prestera_sdma_map(sdma, next));
+	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
 }
 
-static void prestera_sdma_tx_desc_set_buf(struct prestera_sdma *sdma,
-					  struct prestera_sdma_desc *desc,
-					  dma_addr_t buf, size_t len)
+static void mvsw_sdma_tx_desc_set_buf(struct mvsw_pr_rxtx_sdma *sdma,
+				      struct mvsw_sdma_desc *desc,
+				      dma_addr_t buf, size_t len)
 {
 	u32 word = le32_to_cpu(desc->word2);
 
-	u32p_replace_bits(&word, len + ETH_FCS_LEN, GENMASK(30, 16));
+	word = (word & ~GENMASK(30, 16)) | ((len + 4) << 16);
 
-	desc->buff = cpu_to_le32(prestera_sdma_map(sdma, buf));
+	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
 	desc->word2 = cpu_to_le32(word);
 }
 
-static void prestera_sdma_tx_desc_xmit(struct prestera_sdma_desc *desc)
+static void mvsw_sdma_tx_desc_xmit(struct mvsw_sdma_desc *desc)
 {
 	u32 word = le32_to_cpu(desc->word1);
 
-	word |= PRESTERA_SDMA_TX_DESC_DMA_OWN << 31;
+	word |= (SDMA_TX_DESC_DMA_OWN << 31);
 
 	/* make sure everything is written before enable xmit */
 	wmb();
-
 	desc->word1 = cpu_to_le32(word);
 }
 
-static int prestera_sdma_tx_buf_map(struct prestera_sdma *sdma,
-				    struct prestera_sdma_buf *buf,
-				    struct sk_buff *skb)
+static int mvsw_sdma_tx_buf_map(struct mvsw_pr_rxtx_sdma *sdma,
+				struct mvsw_sdma_buf *buf,
+				struct sk_buff *skb)
 {
 	struct device *dma_dev = sdma->sw->dev->dev;
+	struct sk_buff *new_skb;
+	size_t len = skb->len;
 	dma_addr_t dma;
 
-	dma = dma_map_single(dma_dev, skb->data, skb->len, DMA_TO_DEVICE);
+	dma = dma_map_single(dma_dev, skb->data, len, DMA_TO_DEVICE);
+	if (!dma_mapping_error(dma_dev, dma) && dma + len <= sdma->dma_mask) {
+		buf->buf_dma = dma;
+		buf->skb = skb;
+		return 0;
+	}
+
+	if (!dma_mapping_error(dma_dev, dma))
+		dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
+
+	new_skb = alloc_skb(len, GFP_ATOMIC | sdma->dma_flags);
+	if (!new_skb)
+		goto err_alloc_skb;
+
+	dma = dma_map_single(dma_dev, new_skb->data, len, DMA_TO_DEVICE);
 	if (dma_mapping_error(dma_dev, dma))
-		return -ENOMEM;
+		goto err_dma_map;
+	if (dma + len > sdma->dma_mask)
+		goto err_dma_range;
+
+	skb_copy_from_linear_data(skb, skb_put(new_skb, len), len);
 
+	dev_consume_skb_any(skb);
+
+	buf->skb = new_skb;
 	buf->buf_dma = dma;
-	buf->skb = skb;
 
 	return 0;
+
+err_dma_range:
+	dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
+err_dma_map:
+	dev_kfree_skb(new_skb);
+err_alloc_skb:
+	dev_kfree_skb(skb);
+
+	return -ENOMEM;
 }
 
-static void prestera_sdma_tx_buf_unmap(struct prestera_sdma *sdma,
-				       struct prestera_sdma_buf *buf)
+static void mvsw_sdma_tx_buf_unmap(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_buf *buf)
 {
 	struct device *dma_dev = sdma->sw->dev->dev;
 
 	dma_unmap_single(dma_dev, buf->buf_dma, buf->skb->len, DMA_TO_DEVICE);
 }
 
-static void prestera_sdma_tx_recycle_work_fn(struct work_struct *work)
+static void mvsw_sdma_tx_recycle_work_fn(struct work_struct *work)
 {
-	int bnum = PRESTERA_SDMA_TX_DESC_PER_Q;
-	struct prestera_tx_ring *tx_ring;
-	struct prestera_sdma *sdma;
+	struct mvsw_sdma_tx_ring *tx_ring;
+	struct mvsw_pr_rxtx_sdma *sdma;
+	struct device *dma_dev;
 	int b;
 
-	sdma = container_of(work, struct prestera_sdma, tx_work);
+	sdma = container_of(work, struct mvsw_pr_rxtx_sdma, tx_work);
 
+	dma_dev = sdma->sw->dev->dev;
 	tx_ring = &sdma->tx_ring;
 
-	for (b = 0; b < bnum; b++) {
-		struct prestera_sdma_buf *buf = &tx_ring->bufs[b];
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
 
 		if (!buf->is_used)
 			continue;
 
-		if (!PRESTERA_SDMA_TX_DESC_IS_SENT(buf->desc))
+		if (!SDMA_TX_DESC_IS_SENT(buf->desc))
 			continue;
 
-		prestera_sdma_tx_buf_unmap(sdma, buf);
+		mvsw_sdma_tx_buf_unmap(sdma, buf);
 		dev_consume_skb_any(buf->skb);
 		buf->skb = NULL;
 
@@ -522,61 +600,62 @@ static void prestera_sdma_tx_recycle_work_fn(struct work_struct *work)
 	}
 }
 
-static int prestera_sdma_tx_init(struct prestera_sdma *sdma)
+static int mvsw_sdma_tx_init(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	struct prestera_sdma_buf *head, *tail, *next, *prev;
-	struct prestera_tx_ring *tx_ring = &sdma->tx_ring;
-	int bnum = PRESTERA_SDMA_TX_DESC_PER_Q;
+	struct mvsw_sdma_tx_ring *tx_ring = &sdma->tx_ring;
+	struct mvsw_sdma_buf *head;
 	int err;
+	int b;
 
-	INIT_WORK(&sdma->tx_work, prestera_sdma_tx_recycle_work_fn);
 	spin_lock_init(&sdma->tx_lock);
 
-	tx_ring->bufs = kmalloc_array(bnum, sizeof(*head), GFP_KERNEL);
+	INIT_WORK(&sdma->tx_work, mvsw_sdma_tx_recycle_work_fn);
+
+	tx_ring->bufs = kmalloc_array(SDMA_TX_DESC_PER_Q, sizeof(*head),
+				      GFP_KERNEL);
 	if (!tx_ring->bufs)
 		return -ENOMEM;
 
-	tail = &tx_ring->bufs[bnum - 1];
 	head = &tx_ring->bufs[0];
-	next = head;
-	prev = next;
 
-	tx_ring->max_burst = PRESTERA_SDMA_TX_MAX_BURST;
+	tx_ring->max_burst = SDMA_TX_MAX_BURST;
 	tx_ring->burst = tx_ring->max_burst;
 	tx_ring->next_tx = 0;
 
-	do {
-		err = prestera_sdma_buf_init(sdma, next);
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
+
+		err = mvsw_sdma_buf_desc_alloc(sdma, buf);
 		if (err)
 			return err;
 
-		next->is_used = false;
+		mvsw_sdma_tx_desc_init(sdma, buf->desc);
 
-		prestera_sdma_tx_desc_init(sdma, next->desc);
+		buf->is_used = false;
+		buf->skb = NULL;
 
-		prestera_sdma_tx_desc_set_next(sdma, prev->desc,
-					       next->desc_dma);
+		if (b == 0)
+			continue;
 
-		prev = next;
-		next++;
-	} while (prev != tail);
+		mvsw_sdma_tx_desc_set_next(sdma, tx_ring->bufs[b - 1].desc,
+					   buf->desc_dma);
 
-	/* join tail with head to make a circular list */
-	prestera_sdma_tx_desc_set_next(sdma, tail->desc, head->desc_dma);
+		if (b == SDMA_TX_DESC_PER_Q - 1)
+			mvsw_sdma_tx_desc_set_next(sdma, buf->desc,
+						   head->desc_dma);
+	}
 
 	/* make sure descriptors are written */
 	wmb();
-
-	prestera_write(sdma->sw, PRESTERA_SDMA_TX_QUEUE_DESC_REG,
-		       prestera_sdma_map(sdma, head->desc_dma));
+	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_DESC_REG,
+		       mvsw_sdma_addr_phy(sdma, head->desc_dma));
 
 	return 0;
 }
 
-static void prestera_sdma_tx_fini(struct prestera_sdma *sdma)
+static void mvsw_sdma_tx_fini(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	struct prestera_tx_ring *ring = &sdma->tx_ring;
-	int bnum = PRESTERA_SDMA_TX_DESC_PER_Q;
+	struct mvsw_sdma_tx_ring *ring = &sdma->tx_ring;
 	int b;
 
 	cancel_work_sync(&sdma->tx_work);
@@ -584,8 +663,8 @@ static void prestera_sdma_tx_fini(struct prestera_sdma *sdma)
 	if (!ring->bufs)
 		return;
 
-	for (b = 0; b < bnum; b++) {
-		struct prestera_sdma_buf *buf = &ring->bufs[b];
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &ring->bufs[b];
 
 		if (buf->desc)
 			dma_pool_free(sdma->desc_pool, buf->desc,
@@ -601,125 +680,136 @@ static void prestera_sdma_tx_fini(struct prestera_sdma *sdma)
 	}
 }
 
-static void prestera_rxtx_handle_event(struct prestera_switch *sw,
-				       struct prestera_event *evt,
-				       void *arg)
+static void mvsw_rxtx_handle_event(struct prestera_switch *sw,
+				   struct prestera_event *evt, void *arg)
 {
-	struct prestera_sdma *sdma = arg;
+	struct mvsw_pr_rxtx_sdma *sdma = arg;
 
 	if (evt->id != PRESTERA_RXTX_EVENT_RCV_PKT)
 		return;
 
-	prestera_write(sdma->sw, PRESTERA_SDMA_RX_INTR_MASK_REG, 0);
+	mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0);
 	napi_schedule(&sdma->rx_napi);
 }
 
-static int prestera_sdma_switch_init(struct prestera_switch *sw)
+int prestera_rxtx_switch_init(struct prestera_switch *sw)
 {
-	struct prestera_sdma *sdma = &sw->rxtx->sdma;
-	struct device *dev = sw->dev->dev;
-	struct prestera_rxtx_params p;
+	struct mvsw_pr_rxtx_sdma *sdma;
 	int err;
 
-	p.use_sdma = true;
+	cpu_code_stats = kzalloc(sizeof(u64) *
+				 MVSW_PR_RXTX_CPU_CODE_MAX_NUM, GFP_KERNEL);
+	if (!cpu_code_stats)
+		return -ENOMEM;
 
-	err = prestera_hw_rxtx_init(sw, &p);
+	sw->rxtx = kzalloc(sizeof(*sw->rxtx), GFP_KERNEL);
+	if (!sw->rxtx) {
+		err = -ENOMEM;
+		goto err_rxtx_alloc;
+	}
+
+	sdma = &sw->rxtx->sdma;
+
+	err = prestera_hw_rxtx_init(sw, true, &sdma->map_addr);
 	if (err) {
-		dev_err(dev, "failed to init rxtx by hw\n");
-		return err;
+		dev_err(sw->dev->dev, "failed to init rxtx by hw\n");
+		goto err_hw_rxtx_init;
 	}
 
-	sdma->dma_mask = dma_get_mask(dev);
-	sdma->map_addr = p.map_addr;
+	sdma->dma_flags = sw->dev->dma_flags;
+	sdma->dma_mask = dma_get_mask(sw->dev->dev);
 	sdma->sw = sw;
 
-	sdma->desc_pool = dma_pool_create("desc_pool", dev,
-					  sizeof(struct prestera_sdma_desc),
-					  16, 0);
-	if (!sdma->desc_pool)
-		return -ENOMEM;
+	sdma->desc_pool = dma_pool_create("desc_pool", sdma->sw->dev->dev,
+					  sizeof(struct mvsw_sdma_desc), 16, 0);
+	if (!sdma->desc_pool) {
+		err = -ENOMEM;
+		goto err_dma_pool;
+	}
 
-	err = prestera_sdma_rx_init(sdma);
+	err = mvsw_sdma_rx_init(sdma);
 	if (err) {
-		dev_err(dev, "failed to init rx ring\n");
+		dev_err(sw->dev->dev, "failed to init rx ring\n");
 		goto err_rx_init;
 	}
 
-	err = prestera_sdma_tx_init(sdma);
+	err = mvsw_sdma_tx_init(sdma);
 	if (err) {
-		dev_err(dev, "failed to init tx ring\n");
+		dev_err(sw->dev->dev, "failed to init tx ring\n");
 		goto err_tx_init;
 	}
 
 	err = prestera_hw_event_handler_register(sw, PRESTERA_EVENT_TYPE_RXTX,
-						 prestera_rxtx_handle_event,
-						 sdma);
+						 mvsw_rxtx_handle_event, sdma);
 	if (err)
 		goto err_evt_register;
 
 	init_dummy_netdev(&sdma->napi_dev);
 
-	netif_napi_add(&sdma->napi_dev, &sdma->rx_napi, prestera_sdma_rx_poll, 64);
+	netif_napi_add(&sdma->napi_dev, &sdma->rx_napi, mvsw_sdma_rx_poll, 64);
 	napi_enable(&sdma->rx_napi);
 
 	return 0;
 
 err_evt_register:
 err_tx_init:
-	prestera_sdma_tx_fini(sdma);
+	mvsw_sdma_tx_fini(sdma);
 err_rx_init:
-	prestera_sdma_rx_fini(sdma);
+	mvsw_sdma_rx_fini(sdma);
 
 	dma_pool_destroy(sdma->desc_pool);
+err_dma_pool:
+err_hw_rxtx_init:
+	kfree(sw->rxtx);
+err_rxtx_alloc:
+	kfree(cpu_code_stats);
 	return err;
 }
 
-static void prestera_sdma_switch_fini(struct prestera_switch *sw)
+void prestera_rxtx_switch_fini(struct prestera_switch *sw)
 {
-	struct prestera_sdma *sdma = &sw->rxtx->sdma;
+	struct mvsw_pr_rxtx_sdma *sdma = &sw->rxtx->sdma;
 
+	prestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_RXTX);
 	napi_disable(&sdma->rx_napi);
 	netif_napi_del(&sdma->rx_napi);
-	prestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_RXTX,
-					     prestera_rxtx_handle_event);
-	prestera_sdma_tx_fini(sdma);
-	prestera_sdma_rx_fini(sdma);
+	mvsw_sdma_rx_fini(sdma);
+	mvsw_sdma_tx_fini(sdma);
 	dma_pool_destroy(sdma->desc_pool);
+	kfree(sw->rxtx);
+	sw->rxtx = NULL;
+	kfree(cpu_code_stats);
 }
 
-static bool prestera_sdma_is_ready(struct prestera_sdma *sdma)
-{
-	return !(prestera_read(sdma->sw, PRESTERA_SDMA_TX_QUEUE_START_REG) & 1);
-}
-
-static int prestera_sdma_tx_wait(struct prestera_sdma *sdma,
-				 struct prestera_tx_ring *tx_ring)
+static int mvsw_sdma_wait_tx(struct mvsw_pr_rxtx_sdma *sdma,
+			     struct mvsw_sdma_tx_ring *tx_ring)
 {
-	int tx_wait_num = PRESTERA_SDMA_WAIT_MUL * tx_ring->max_burst;
+	int tx_retry_num = 10 * tx_ring->max_burst;
 
-	do {
-		if (prestera_sdma_is_ready(sdma))
+	while (--tx_retry_num) {
+		if (!(mvsw_reg_read(sdma->sw, SDMA_TX_QUEUE_START_REG) & 1))
 			return 0;
 
-		udelay(1);
-	} while (--tx_wait_num);
+		udelay(5);
+	}
 
 	return -EBUSY;
 }
 
-static void prestera_sdma_tx_start(struct prestera_sdma *sdma)
+static void mvsw_sdma_start_tx(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	prestera_write(sdma->sw, PRESTERA_SDMA_TX_QUEUE_START_REG, 1);
+	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_START_REG, 1);
 	schedule_work(&sdma->tx_work);
 }
 
-static netdev_tx_t prestera_sdma_xmit(struct prestera_sdma *sdma,
-				      struct sk_buff *skb)
+static int mvsw_pr_rxtx_sdma_xmit(struct prestera_rxtx *rxtx,
+				  struct sk_buff *skb)
 {
+	struct mvsw_pr_rxtx_sdma *sdma = &rxtx->sdma;
 	struct device *dma_dev = sdma->sw->dev->dev;
+	struct mvsw_sdma_tx_ring *tx_ring;
 	struct net_device *dev = skb->dev;
-	struct prestera_tx_ring *tx_ring;
-	struct prestera_sdma_buf *buf;
+	struct mvsw_sdma_buf *buf;
 	int err;
 
 	spin_lock(&sdma->tx_lock);
@@ -729,97 +819,117 @@ static netdev_tx_t prestera_sdma_xmit(struct prestera_sdma *sdma,
 	buf = &tx_ring->bufs[tx_ring->next_tx];
 	if (buf->is_used) {
 		schedule_work(&sdma->tx_work);
+		err = -EBUSY;
 		goto drop_skb;
 	}
 
-	if (unlikely(eth_skb_pad(skb)))
-		goto drop_skb_nofree;
+	if (unlikely(skb_put_padto(skb, ETH_ZLEN))) {
+		err = -ENOMEM;
+		goto drop_skb;
+	}
 
-	err = prestera_sdma_tx_buf_map(sdma, buf, skb);
+	err = mvsw_sdma_tx_buf_map(sdma, buf, skb);
 	if (err)
 		goto drop_skb;
 
-	prestera_sdma_tx_desc_set_buf(sdma, buf->desc, buf->buf_dma, skb->len);
+	mvsw_sdma_tx_desc_set_buf(sdma, buf->desc, buf->buf_dma, skb->len);
 
 	dma_sync_single_for_device(dma_dev, buf->buf_dma, skb->len,
 				   DMA_TO_DEVICE);
 
-	if (tx_ring->burst) {
-		tx_ring->burst--;
-	} else {
+	if (!tx_ring->burst--) {
 		tx_ring->burst = tx_ring->max_burst;
 
-		err = prestera_sdma_tx_wait(sdma, tx_ring);
+		err = mvsw_sdma_wait_tx(sdma, tx_ring);
 		if (err)
 			goto drop_skb_unmap;
 	}
 
-	tx_ring->next_tx = (tx_ring->next_tx + 1) % PRESTERA_SDMA_TX_DESC_PER_Q;
-	prestera_sdma_tx_desc_xmit(buf->desc);
+	tx_ring->next_tx = (tx_ring->next_tx + 1) % SDMA_TX_DESC_PER_Q;
+	mvsw_sdma_tx_desc_xmit(buf->desc);
 	buf->is_used = true;
 
-	prestera_sdma_tx_start(sdma);
+	mvsw_sdma_start_tx(sdma);
 
 	goto tx_done;
 
 drop_skb_unmap:
-	prestera_sdma_tx_buf_unmap(sdma, buf);
+	mvsw_sdma_tx_buf_unmap(sdma, buf);
 drop_skb:
-	dev_consume_skb_any(skb);
-drop_skb_nofree:
 	dev->stats.tx_dropped++;
 tx_done:
 	spin_unlock(&sdma->tx_lock);
-	return NETDEV_TX_OK;
-}
-
-int prestera_rxtx_switch_init(struct prestera_switch *sw)
-{
-	struct prestera_rxtx *rxtx;
-
-	rxtx = kzalloc(sizeof(*rxtx), GFP_KERNEL);
-	if (!rxtx)
-		return -ENOMEM;
-
-	sw->rxtx = rxtx;
-
-	return prestera_sdma_switch_init(sw);
-}
-
-void prestera_rxtx_switch_fini(struct prestera_switch *sw)
-{
-	prestera_sdma_switch_fini(sw);
-	kfree(sw->rxtx);
+	return err;
 }
 
-int prestera_rxtx_port_init(struct prestera_port *port)
+netdev_tx_t prestera_rxtx_xmit(struct sk_buff *skb, struct prestera_port *port)
 {
-	int err;
-
-	err = prestera_hw_rxtx_port_init(port);
-	if (err)
-		return err;
+	size_t dsa_resize_len = MVSW_PR_DSA_HLEN;
+	struct prestera_rxtx_stats *rxtx_stats;
+	struct mvsw_pr_dsa_from_cpu *from_cpu;
+	struct mvsw_pr_dsa dsa;
+	u64 skb_len = skb->len;
+
+	if (unlikely(!port->sw || !port->sw->rxtx))
+		goto tx_drop;
+
+	/* common DSA tag fill-up */
+	memset(&dsa, 0, sizeof(dsa));
+	dsa.dsa_cmd = MVSW_NET_DSA_CMD_FROM_CPU_E;
+
+	from_cpu = &dsa.dsa_info.from_cpu;
+	from_cpu->egr_filter_en = false;
+	from_cpu->egr_filter_registered = false;
+	from_cpu->dst_eport = port->hw_id;
+
+	from_cpu->dst_iface.dev_port.port_num = port->hw_id;
+	from_cpu->dst_iface.dev_port.hw_dev_num = port->dev_id;
+	from_cpu->dst_iface.type = PRESTERA_IF_PORT_E;
+
+	/* epmorary removing due to issue with vlan sub interface
+	 * on 1.Q bridge
+	 */
+	/* If (skb->protocol == htons(ETH_P_8021Q)) { */
+		/* 802.1q packet tag size is 4 bytes, so DSA len would
+		 * need only allocation of MVSW_PR_DSA_HLEN - size of
+		 * 802.1q tag
+		 */
+		/*dsa.common_params.vpt = skb_vlan_tag_get_prio(skb);
+		 * dsa.common_params.cfi_bit = skb_vlan_tag_get_cfi(skb);
+		 * dsa.common_params.vid = skb_vlan_tag_get_id(skb);
+		 * dsa_resize_len -= VLAN_HLEN;
+		 */
+	/* } */
+
+	if (skb_cow_head(skb, dsa_resize_len) < 0)
+		goto tx_drop_stats_inc;
+
+	/* expects skb->data at mac header */
+	skb_push(skb, dsa_resize_len);
+	memmove(skb->data, skb->data + dsa_resize_len, 2 * ETH_ALEN);
+
+	if (mvsw_pr_dsa_build(&dsa, skb->data + 2 * ETH_ALEN) != 0)
+		goto tx_drop_stats_inc;
+
+	if (mvsw_pr_rxtx_sdma_xmit(port->sw->rxtx, skb))
+		goto tx_drop_stats_inc;
+
+	rxtx_stats = this_cpu_ptr(port->rxtx_stats);
+	u64_stats_update_begin(&rxtx_stats->syncp);
+	rxtx_stats->tx_packets++;
+	rxtx_stats->tx_bytes += skb_len;
+	u64_stats_update_end(&rxtx_stats->syncp);
 
-	port->dev->needed_headroom = PRESTERA_DSA_HLEN;
+	return NETDEV_TX_OK;
 
-	return 0;
+tx_drop_stats_inc:
+	this_cpu_inc(port->rxtx_stats->tx_dropped);
+tx_drop:
+	dev_kfree_skb_any(skb);
+	return NET_XMIT_DROP;
 }
 
-netdev_tx_t prestera_rxtx_xmit(struct prestera_port *port, struct sk_buff *skb)
+u64 mvsw_pr_rxtx_get_cpu_code_stats(u8 cpu_code)
 {
-	struct prestera_dsa dsa;
-
-	dsa.hw_dev_num = port->dev_id;
-	dsa.port_num = port->hw_id;
-
-	if (skb_cow_head(skb, PRESTERA_DSA_HLEN) < 0)
-		return NET_XMIT_DROP;
-
-	skb_push(skb, PRESTERA_DSA_HLEN);
-	memmove(skb->data, skb->data + PRESTERA_DSA_HLEN, 2 * ETH_ALEN);
-
-	if (prestera_dsa_build(&dsa, skb->data + 2 * ETH_ALEN) != 0)
-		return NET_XMIT_DROP;
-
-	return prestera_sdma_xmit(&port->sw->rxtx->sdma, skb);
+	return cpu_code_stats[cpu_code];
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
index 882a1225c323..3bf15165d035 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
@@ -1,19 +1,20 @@
 /* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved. */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
-#ifndef _PRESTERA_RXTX_H_
-#define _PRESTERA_RXTX_H_
+#ifndef _MVSW_PRESTERA_RXTX_H_
+#define _MVSW_PRESTERA_RXTX_H_
 
 #include <linux/netdevice.h>
 
+#define MVSW_PR_RXTX_CPU_CODE_MAX_NUM	256
+
 struct prestera_switch;
-struct prestera_port;
 
 int prestera_rxtx_switch_init(struct prestera_switch *sw);
 void prestera_rxtx_switch_fini(struct prestera_switch *sw);
 
-int prestera_rxtx_port_init(struct prestera_port *port);
+netdev_tx_t prestera_rxtx_xmit(struct sk_buff *skb, struct prestera_port *port);
 
-netdev_tx_t prestera_rxtx_xmit(struct prestera_port *port, struct sk_buff *skb);
+u64 mvsw_pr_rxtx_get_cpu_code_stats(u8 cpu_code);
 
-#endif /* _PRESTERA_RXTX_H_ */
+#endif /* _MVSW_PRESTERA_RXTX_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_shm.c b/drivers/net/ethernet/marvell/prestera/prestera_shm.c
new file mode 100644
index 000000000000..20d959f85410
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_shm.c
@@ -0,0 +1,617 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/device.h>
+#include <linux/mm.h>
+#include <linux/mmzone.h>
+#include <linux/cdev.h>
+#include <linux/platform_device.h>
+#include <linux/kfifo.h>
+#include <linux/if_arp.h>
+#include <linux/mmu_context.h>
+
+#include "prestera.h"
+#include "prestera_fw.h"
+#include "prestera_shm.h"
+
+#define PRESTERA_SW_SHM_DEV_NAME "prestera_shm"
+#define PRESTERA_SHM_FIFO_SZ 128
+
+#define SIM_SDMA_RX_QUEUE_DESC_REG(n)	(0x260C + (n) * 16)
+#define SIM_SDMA_TX_QUEUE_DESC_REG	0x26C0
+#define SIM_REG(x) ((phys_addr_t *)((char *)shm_dev->fw.dev.pp_regs + (x)))
+#define SIM_REG_DEREF(x) (*(SIM_REG(x)))
+
+struct prestera_shm_msg {
+	int command;
+	long arg;
+};
+
+struct prestera_shm_dev {
+	struct device *dev_ptr;
+	atomic_t pending_intr_cntr;
+	wait_queue_head_t shm_queue;
+	struct task_struct *shm_kthread;
+	struct page *alloc_pages;
+	phys_addr_t addr_phys;
+	size_t size;
+	struct prestera_fw fw;
+	void __iomem *shm_mmap_memory;
+	dev_t shm_cdev_ids;
+	struct cdev shm_cdev;
+	struct class *shm_class;
+	struct task_struct *sim_kthread;
+	struct net_device *net_dev;
+	int initialized;
+};
+
+/*  Needed so devlink_nl_put_handle() won't crash trying to write NL attributes for bus name: */
+static struct bus_type prestera_shm_bus_type = {
+	.name		= "prestera_shm_bus",
+};
+
+/* Interface netdev name for simulation mode. When specified, enables simulation mode */
+static char *sim_devname;
+
+static netdev_tx_t prestera_shm_sim_netdev_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	int i = 0;
+	phys_addr_t pa;
+	unsigned int *ulptr;
+	unsigned char *dst_buf;
+	struct prestera_shm_dev **pp_dev;
+	struct prestera_shm_dev *shm_dev;
+
+	pp_dev = (struct prestera_shm_dev **)netdev_priv(dev);
+	shm_dev = *pp_dev;
+
+	pa = SIM_REG_DEREF(SIM_SDMA_RX_QUEUE_DESC_REG(0));
+	if (!pa) {
+		/*
+		 * We can either return NETDEV_TX_BUSY which will cause
+		 * constant requeueing and ksoftirqd running constantly
+		 * at 100% CPU (which causes appDemo initialization to fail)
+		 * or just free the SKB and return OK.
+		 */
+		dev_kfree_skb(skb);
+		dev->stats.tx_errors++;
+		return NETDEV_TX_OK;
+	}
+
+	ulptr = phys_to_virt(pa);
+
+	for (i = 0; ((i < 1000) && (ulptr[3])); i++) {
+		if (*ulptr & 0x80000000) {
+			/* found a ready buffer descriptor */
+			dst_buf = phys_to_virt(ulptr[2]);
+			skb_copy_bits(skb, 0, dst_buf, skb->len);
+			ulptr[1] = skb->len << 16;
+			*ulptr = 0x0C000000;
+			dev->stats.tx_packets++;
+			dev->stats.tx_bytes += skb->len;
+			dev_kfree_skb(skb);
+
+			return NETDEV_TX_OK;
+		}
+		pa = ulptr[3];
+		if (!pa)
+			break;
+		ulptr = phys_to_virt(pa);
+	}
+	dev->stats.tx_errors++;
+	return NETDEV_TX_BUSY;
+}
+
+static int prestera_shm_sim_set_mac_addr(struct net_device *dev, void *addr)
+{
+	eth_commit_mac_addr_change(dev, addr);
+	return 0;
+}
+
+static const struct net_device_ops shm_sim_netdev_ops = {
+	.ndo_start_xmit         = prestera_shm_sim_netdev_xmit,
+	.ndo_set_mac_address	= prestera_shm_sim_set_mac_addr,
+};
+
+static int prestera_shm_sim_sdma(void *data)
+{
+	int i = 0;
+	phys_addr_t pa;
+	unsigned int len;
+	unsigned int *ulptr;
+	unsigned char *dst_buf;
+	struct sk_buff *new_skb;
+	struct prestera_shm_dev *shm_dev = (struct prestera_shm_dev *)data;
+
+	while (!kthread_should_stop()) {
+		/* Simulate SDMA TX path */
+		pa = SIM_REG_DEREF(SIM_SDMA_TX_QUEUE_DESC_REG);
+		if (!pa) {
+			msleep(20);
+			continue;
+		}
+
+		ulptr = phys_to_virt(pa);
+
+		for (i = 0; ((i < 1000) && (ulptr[3])); i++) {
+			if (*ulptr & 0x80000000) {
+			/* found a ready to send buffer descriptor */
+				dst_buf = phys_to_virt(ulptr[2]);
+				len = ulptr[1] >> 16;
+				new_skb = alloc_skb(len, GFP_KERNEL);
+				skb_copy_to_linear_data(new_skb, dst_buf, len);
+				shm_dev->net_dev->stats.rx_packets++;
+				shm_dev->net_dev->stats.rx_bytes += len;
+
+				if (netif_receive_skb(new_skb) != NET_RX_SUCCESS)
+					dev_kfree_skb(new_skb);
+
+				*ulptr = 0x0300000;
+			}
+
+			pa = ulptr[3];
+			if (!pa)
+				break;
+
+			ulptr = phys_to_virt(pa);
+		}
+		msleep(20);
+	}
+
+	return 0;
+}
+
+/* mmap() handler -
+ * allocates kernel contiguous physical memory and map it to user-space
+ * for shared memory IPC interface to user-space
+ */
+
+static int prestera_shm_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	struct prestera_shm_dev *dev = filp->private_data;
+	void *vaddr;
+
+	dev->size = MAX_ORDER_NR_PAGES * PAGE_SIZE;
+
+	pr_err("%s: Entry. Size=%lu. VMA_size = %lu\n", __func__, dev->size,
+	       vma->vm_end - vma->vm_start);
+
+	dev->alloc_pages = alloc_pages(GFP_DMA, MAX_ORDER - 1);
+
+	if (!dev->alloc_pages/*dev->shm_mmap_memory*/) {
+		pr_err("%s: Failed allocating %lu bytes of memory.\n", __func__, dev->size);
+		return -ENOMEM;
+	}
+
+	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
+
+	dev->addr_phys = (page_to_pfn(dev->alloc_pages) << PAGE_SHIFT);
+
+	vaddr = page_address(dev->alloc_pages);
+	dev->shm_mmap_memory = vaddr;
+	if (!dev->shm_mmap_memory) {
+		pr_err("%s: Failed remap kernel vaddr, %lu bytes.\n", __func__, dev->size);
+		return -ENOMEM;
+	}
+
+	/* In lieu of physical registers */
+	dev->fw.hw_regs = (u8 __iomem *)dev->shm_mmap_memory;
+	dev->fw.mem_addr = (u8 __iomem *)dev->shm_mmap_memory;
+	pr_info("%s: memptr %p hw_regs %p mem_addr %p\n", __func__,
+		dev->shm_mmap_memory, dev->fw.hw_regs,
+		dev->fw.mem_addr);
+
+	if (remap_pfn_range(vma, vma->vm_start,
+			    dev->addr_phys >> PAGE_SHIFT,
+			    vma->vm_end - vma->vm_start, vma->vm_page_prot) < 0) {
+		pr_err("%s: failed remapping virt %lx phys %llx len %lu\n",
+		       __func__, vma->vm_start, dev->addr_phys,
+		       vma->vm_end - vma->vm_start);
+		__free_pages(dev->alloc_pages, MAX_ORDER_NR_PAGES);
+		return -EAGAIN;
+	}
+
+	pr_info("%s: remapped virt %lx phys %llx len %lu\n",
+		__func__, vma->vm_start, dev->addr_phys,
+		vma->vm_end - vma->vm_start);
+
+	return 0;
+}
+
+static int prestera_shm_open(struct inode *inode, struct file *filp)
+{
+	struct prestera_shm_dev *dev;
+
+	dev = container_of(inode->i_cdev, struct prestera_shm_dev, shm_cdev);
+
+	if (!dev->initialized)
+		return -ENODEV;
+
+	filp->private_data = dev;
+
+	return 0;
+}
+
+static int prestera_shm_release(struct inode *inode, struct file *filp)
+{
+	struct prestera_shm_dev *dev = filp->private_data;
+
+	__free_pages(dev->alloc_pages, MAX_ORDER - 1);
+	dev->alloc_pages = NULL;
+
+	dev->shm_mmap_memory = NULL;
+	filp->private_data = NULL;
+
+	return 0;
+}
+
+static void prestera_shm_handle_interrupt(struct prestera_shm_dev *dev)
+{
+	if (prestera_fw_read(&dev->fw, PRESTERA_RX_STATUS_REG)) {
+		prestera_fw_write(&dev->fw, PRESTERA_RX_STATUS_REG, 0);
+
+		if (likely(dev->fw.dev.recv_pkt))
+			dev->fw.dev.recv_pkt(&dev->fw.dev);
+	}
+}
+
+static int prestera_shm_kthread(void *data)
+{
+	struct prestera_shm_dev *dev = (struct prestera_shm_dev *)data;
+
+	sched_set_fifo(current);
+	while (!kthread_should_stop()) {
+		wait_event_interruptible(dev->shm_queue,
+					 ((kthread_should_stop()) ||
+					 (atomic_read(&dev->pending_intr_cntr) > 0)));
+
+		if (kthread_should_stop()) {
+			pr_err("%s: stopping...\n", __func__);
+			break;
+		}
+
+		while (atomic_fetch_dec(&dev->pending_intr_cntr))
+			prestera_fw_handle_event(&dev->fw);
+	}
+	return 0;
+}
+
+static int prestera_shm_ioctl_handle_one(struct prestera_shm_dev *dev,
+					 struct prestera_shm_msg *msg)
+{
+	int err;
+	struct prestera_fw_rev *rev = &dev->fw.dev.fw_rev;
+
+	switch (msg->command) {
+	case PRESTERA_SHM_INTERRUPT:
+		prestera_shm_handle_interrupt(dev);
+		atomic_inc(&dev->pending_intr_cntr);
+		wake_up(&dev->shm_queue);
+		return 0;
+
+	case PRESTERA_SHM_INIT:
+
+		if (!dev->shm_mmap_memory) {
+			dev_err(dev->dev_ptr, "%s: userspace must call mmap() for this driver before calling ioctl() with PRESTERA_SHM_INIT!",
+				__func__);
+			return -ENXIO;
+		}
+
+		err = prestera_fw_init(&dev->fw);
+		if (err)
+			return err;
+
+		prestera_fw_rev_parse_int(msg->arg, rev);
+		if (prestera_fw_rev_check(&dev->fw))
+			return -EINVAL;
+
+		pr_info("Before Registering prestera device\n");
+		err = prestera_device_register(&dev->fw.dev);
+		pr_info("Registered prestera device (return code %d).\n", err);
+		return err;
+	}
+
+	return -EINVAL;
+}
+
+/* Handle simulation of PCIe interrupt and firmware version number update
+ */
+static long prestera_shm_ioctl(struct file *filp, unsigned int command,
+			       unsigned long arg)
+{
+	struct prestera_shm_dev *dev = filp->private_data;
+	struct prestera_shm_msg msg;
+
+	msg.command = command;
+	msg.arg = arg;
+
+	return prestera_shm_ioctl_handle_one(dev, &msg);
+}
+
+static const struct file_operations shm_file_operations = {
+	.owner =	  THIS_MODULE,
+	.unlocked_ioctl = prestera_shm_ioctl,
+	.mmap =           prestera_shm_mmap,
+	.open =		  prestera_shm_open,
+	.release =	  prestera_shm_release,
+};
+
+/* Module device specific information initialization function -
+ * Allocates character device for ioctl() and mmap() functionalities
+ */
+
+static int prestera_shm_dev_init(struct prestera_shm_dev *dev,
+				 struct platform_device *pdev)
+{
+	int ret;
+	struct resource *resource = NULL;
+	void __iomem *base;
+	struct prestera_shm_dev **pp_dev;
+	unsigned char addr[ETH_ALEN];
+
+	atomic_set(&dev->pending_intr_cntr, 0);
+	init_waitqueue_head(&dev->shm_queue);
+	dev->shm_kthread = kthread_run(prestera_shm_kthread, (void *)dev,
+				       "prestera_shm_kthread");
+	if (!dev->shm_kthread)
+		return -ENOMEM;
+
+	ret = alloc_chrdev_region(&dev->shm_cdev_ids, 0, 1, PRESTERA_SHM_DEVNAME);
+	if (ret)
+		goto err_chrdev_region;
+
+	cdev_init(&dev->shm_cdev, &shm_file_operations);
+
+	ret = cdev_add(&dev->shm_cdev, dev->shm_cdev_ids, 1);
+	if (ret)
+		goto err_cdev_add;
+
+	dev->shm_class = class_create(THIS_MODULE, PRESTERA_SHM_DEVNAME);
+	if (IS_ERR(dev->shm_class)) {
+		ret = PTR_ERR(dev->shm_class);
+		goto err_class_create;
+	}
+
+	dev->dev_ptr = device_create(dev->shm_class, NULL, dev->shm_cdev_ids,
+				     NULL, PRESTERA_SHM_DEVNAME);
+
+	dev->dev_ptr->bus = &prestera_shm_bus_type;
+	if (IS_ERR(dev->dev_ptr)) {
+		ret = PTR_ERR(dev->dev_ptr);
+		goto err_dev_create;
+	}
+
+	if (!dev->dev_ptr->dma_mask) {
+		pr_info("%s: Fixing dma_mask...\n", __func__);
+		dev->dev_ptr->dma_mask = &dev->dev_ptr->coherent_dma_mask;
+	}
+
+	/*
+	 * AC5X DDR starts at physical address 0x2_0000_0000,
+	 * and can end at 0xff_ffff_ffff so we need a 40 bit
+	 * mask for it ...
+	 */
+	ret = dma_set_mask_and_coherent(dev->dev_ptr, DMA_BIT_MASK(40));
+	if (ret) {
+		dev_err(dev->dev_ptr, "fail to set DMA mask, return code is: %d\n", ret);
+		goto err_dma_mask;
+	}
+	dev->dev_ptr->bus_dma_limit = DMA_BIT_MASK(40);
+	pr_info("%s: coherent_dma_mask %llx bus_dma_limit %llx\n", __func__,
+		dev->dev_ptr->coherent_dma_mask, dev->dev_ptr->bus_dma_limit);
+#if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE) || \
+	defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \
+	defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)
+	dev->dev_ptr->dma_coherent = true;
+#endif
+	if (!sim_devname) {
+		dev->fw.dev.dma_flags = GFP_DMA;
+		resource = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+		if (!resource || resource_size(resource) < PAGE_SIZE) {
+			dev_err(dev->dev_ptr, "Failed getting valid IO resource from device tree!\n");
+			goto err_dma_mask;
+		}
+
+		base = devm_ioremap_resource(dev->dev_ptr, resource);
+		if (IS_ERR(base))
+			goto err_dma_mask;
+
+	} else {
+		/* X86 does not really support GFP_DMA.
+		 *  It translates into ISA lower 16MB in memory.
+		 */
+		dev->fw.dev.dma_flags = 0;
+
+		/* Simulate MG SDMA area in software */
+		base = kzalloc(0x10000, GFP_KERNEL);
+		if (!base)
+			goto err_dma_mask;
+
+		dev->sim_kthread = kthread_run(prestera_shm_sim_sdma, dev, "sim_mg_sdma");
+
+		if (!dev->sim_kthread) {
+			kfree(base);
+			goto err_dma_mask;
+		}
+
+		dev->net_dev = alloc_etherdev(sizeof(void *));
+
+		if (!dev->net_dev) {
+			kthread_stop(dev->sim_kthread);
+			kfree(base);
+			goto err_dma_mask;
+		}
+
+		pp_dev = (struct prestera_shm_dev **)netdev_priv(dev->net_dev);
+		*pp_dev = dev;
+		dev->net_dev->netdev_ops = &shm_sim_netdev_ops;
+		SET_NETDEV_DEV(dev->net_dev, dev->dev_ptr);
+
+		dev->net_dev->mtu = 1536;
+		dev->net_dev->min_mtu = 64;
+		dev->net_dev->max_mtu = 1536;
+		dev->net_dev->type = ARPHRD_ETHER;
+		dev->net_dev->addr_len = ETH_ALEN;
+
+		strcpy(dev->net_dev->name, "sim%d");
+		get_random_bytes(addr + 1, ETH_ALEN - 1);
+		addr[0] = 0x0;
+		memcpy(dev->net_dev->dev_addr, addr, ETH_ALEN);
+
+		ret = register_netdev(dev->net_dev);
+
+		if (ret) {
+			pr_err("%s: failed registering network device %s with error number %d\n",
+			       __func__, dev->net_dev->name, ret);
+		} else {
+			netif_carrier_on(dev->net_dev);
+			pr_info("%s: ifindex %d ns %p netdev %p\n",
+				__func__, dev->net_dev->ifindex,
+				dev_net(dev->net_dev),
+				__dev_get_by_index(dev_net(dev->net_dev),
+						   dev->net_dev->ifindex));
+		}
+	}
+
+	dev->fw.dev.dev = dev->dev_ptr;
+	dev->fw.dev.send_req = prestera_fw_send_req;
+
+	dev->fw.dev.pp_regs = base;
+	if (resource)
+		pr_info("%s: remmap %llx..%llx to %p...\n",
+			__func__, resource->start, resource->end,
+			dev->fw.dev.pp_regs);
+	dev->fw.dev.running = true;
+
+	pr_info("prestera_shm: Initialized Marvell Prestera shared memory device\n");
+	dev->initialized = true;
+	return ret;
+
+err_dma_mask:
+	device_destroy(dev->shm_class, dev->shm_cdev_ids);
+err_dev_create:
+	class_destroy(dev->shm_class);
+err_class_create:
+	cdev_del(&dev->shm_cdev);
+err_cdev_add:
+	unregister_chrdev_region(dev->shm_cdev_ids, 1);
+err_chrdev_region:
+	kthread_stop(dev->shm_kthread);
+	return ret;
+}
+
+static int prestera_shm_probe(struct platform_device *pdev)
+{
+	struct prestera_shm_dev *dev;
+	int ret;
+
+	pr_info("prestera_shm: Probing Marvell Prestera shared memory driver...\n");
+	dev = devm_kzalloc(&pdev->dev, sizeof(*dev), GFP_KERNEL);
+	if (!dev)
+		return -ENOMEM;
+
+	ret = prestera_shm_dev_init(dev, pdev);
+
+	if (ret < 0)
+		return ret;
+
+	platform_set_drvdata(pdev, dev);
+
+	pr_info("prestera_shm: Probed Marvell Prestera shared memory driver\n");
+	return 0;
+}
+
+static void prestera_shm_dev_deinit(struct prestera_shm_dev *dev)
+{
+	kthread_stop(dev->shm_kthread);
+	dev->fw.dev.running = false;
+	prestera_device_unregister(&dev->fw.dev);
+	prestera_fw_uninit(&dev->fw);
+	cancel_delayed_work_sync(&dev->fw.dev.keepalive_wdog_work);
+
+	if (sim_devname) {
+		kthread_stop(dev->sim_kthread);
+		unregister_netdev(dev->net_dev);
+	}
+	dev->dev_ptr->bus = NULL;
+	if (dev->alloc_pages)
+		__free_pages(dev->alloc_pages, MAX_ORDER - 1);
+
+	device_destroy(dev->shm_class, dev->shm_cdev_ids);
+	class_destroy(dev->shm_class);
+
+	cdev_del(&dev->shm_cdev);
+	unregister_chrdev_region(dev->shm_cdev_ids, 1);
+	if (sim_devname)
+		kfree(dev->fw.dev.pp_regs);
+	pr_info("%s: Unregistered Marvell Prestera shared memory driver\n", __func__);
+}
+
+static int prestera_shm_remove(struct platform_device *pdev)
+{
+	struct prestera_shm_dev *dev = platform_get_drvdata(pdev);
+
+	pr_info("%s: Unregistering Marvell Prestera shared memory driver.\n", __func__);
+	prestera_shm_dev_deinit(dev);
+	return 0;
+}
+
+static const struct of_device_id prestera_shm_of_match[] = {
+	{ .compatible = "marvell,prestera", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, prestera_shm_of_match);
+
+static struct platform_driver prestera_shm_driver = {
+	.driver		= {
+		.name	= PRESTERA_SW_SHM_DEV_NAME,
+		.owner	= THIS_MODULE,
+		.of_match_table = prestera_shm_of_match,
+	},
+	.probe		= prestera_shm_probe,
+	.remove		= prestera_shm_remove,
+};
+
+#ifdef CONFIG_X86_64
+struct platform_device *g_pdev;
+
+static int __init prestera_shm_init(void)
+{
+	int ret;
+
+	pr_info("Entry: %s\n", __func__);
+
+	g_pdev = platform_device_alloc("prestera_shm", -1);
+
+	if (!g_pdev)
+		return -ENOMEM;
+
+	return prestera_shm_probe(g_pdev);
+}
+
+/*
+ * Exit function of our module.
+ */
+static void __exit prestera_shm_exit(void)
+{
+	pr_info("Exit: %s\n", __func__);
+
+	prestera_shm_remove(g_pdev);
+	platform_device_unregister(g_pdev);
+}
+
+module_init(prestera_shm_init);
+module_exit(prestera_shm_exit);
+#else
+
+module_platform_driver(prestera_shm_driver);
+
+#endif
+
+MODULE_AUTHOR("Marvell Semi.");
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Marvell Prestera switch shared memory interface");
+module_param(sim_devname, charp, 0444);
+MODULE_PARM_DESC(sim_devname, "Interface name for simulation mode. When specified, enables simulation mode.");
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_shm.h b/drivers/net/ethernet/marvell/prestera/prestera_shm.h
new file mode 100644
index 000000000000..a2949953e817
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_shm.h
@@ -0,0 +1,15 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#ifndef PRESTERA_SHM_H_
+#define PRESTERA_SHM_H_
+
+#define PRESTERA_SHM_INTERRUPT_IOC_MAGIC	's'
+#define PRESTERA_SHM_INIT_IOC_MAGIC	'i'
+#define PRESTERA_SHM_BARRIER_IOC_MAGIC	'b'
+
+#define PRESTERA_SHM_INTERRUPT	_IOW(PRESTERA_SHM_INTERRUPT_IOC_MAGIC, 0, __u32)
+#define PRESTERA_SHM_INIT _IOW(PRESTERA_SHM_INIT_IOC_MAGIC, 0, __u32)
+#define PRESTERA_SHM_DEVNAME "prestera_shm"
+
+#endif
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c
new file mode 100644
index 000000000000..3ddfd8643092
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c
@@ -0,0 +1,189 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include "prestera_storm_control.h"
+#include "prestera_hw.h"
+
+#define SYSFS_ATTR_MODE		0644
+
+static ssize_t storm_control_attr_store(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size);
+static ssize_t storm_control_attr_show(struct device *dev,
+				       struct device_attribute *attr,
+				       char *buf);
+
+struct strom_control_attributes {
+	u32 bc_kbyte_per_sec_rate;
+	u32 unknown_uc_kbyte_per_sec_rate;
+	u32 unreg_mc_kbyte_per_sec_rate;
+};
+
+struct prestera_storm_control {
+	struct prestera_switch *sw;
+	struct strom_control_attributes *attribute_values;
+};
+
+static DEVICE_ATTR(broadcast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static DEVICE_ATTR(unknown_unicast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static DEVICE_ATTR(unregistered_multicast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static struct attribute *prestera_sw_dev_attrs[] = {
+	&dev_attr_broadcast_kbyte_per_sec_rate.attr,
+	&dev_attr_unknown_unicast_kbyte_per_sec_rate.attr,
+	&dev_attr_unregistered_multicast_kbyte_per_sec_rate.attr,
+	NULL
+};
+
+static struct attribute_group prestera_sw_dev_attr_group = {
+	.name = "storm_control", /* we want them in subdirectory */
+	.attrs = prestera_sw_dev_attrs,
+};
+
+static ssize_t storm_control_attr_store(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size)
+{
+	struct prestera_port *port = dev_to_prestera_port(dev);
+	struct strom_control_attributes *sc_attr;
+	struct prestera_storm_control *sc;
+	u32 *attr_to_change = NULL;
+	u32 kbyte_per_sec_rate;
+	ssize_t ret = -EINVAL;
+	u32 storm_type;
+
+	if (!port)
+		return -EINVAL;
+
+	sc = port->sw->storm_control;
+	sc_attr = &sc->attribute_values[port->fp_id];
+
+	ret = kstrtou32(buf, 10, &kbyte_per_sec_rate);
+	if (ret)
+		return ret;
+
+	if (!strcmp(attr->attr.name, "broadcast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->bc_kbyte_per_sec_rate;
+		storm_type = PRESTERA_PORT_STORM_CTL_TYPE_BC;
+	}
+
+	if (!strcmp(attr->attr.name, "unknown_unicast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->unknown_uc_kbyte_per_sec_rate;
+		storm_type = PRESTERA_PORT_STORM_CTL_TYPE_UC_UNK;
+	}
+
+	if (!strcmp(attr->attr.name,
+		    "unregistered_multicast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->unreg_mc_kbyte_per_sec_rate;
+		storm_type = PRESTERA_PORT_STORM_CTL_TYPE_MC;
+	}
+
+	if (!attr_to_change)
+		return -EINVAL;
+
+	if (kbyte_per_sec_rate != *attr_to_change)
+		ret = prestera_hw_port_storm_control_cfg_set(port, storm_type,
+							     kbyte_per_sec_rate);
+	else
+		return size;
+
+	if (ret)
+		return ret;
+
+	*attr_to_change = kbyte_per_sec_rate;
+
+	return size;
+}
+
+static ssize_t storm_control_attr_show(struct device *dev,
+				       struct device_attribute *attr,
+				       char *buf)
+{
+	struct prestera_port *port = dev_to_prestera_port(dev);
+	struct strom_control_attributes *sc_attr;
+	struct prestera_storm_control *sc;
+
+	if (!port)
+		return -EINVAL;
+
+	sc = port->sw->storm_control;
+
+	sc_attr = &sc->attribute_values[port->fp_id];
+
+	if (!strcmp(attr->attr.name, "broadcast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n", sc_attr->bc_kbyte_per_sec_rate);
+
+	if (!strcmp(attr->attr.name, "unknown_unicast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n",
+			       sc_attr->unknown_uc_kbyte_per_sec_rate);
+
+	if (!strcmp(attr->attr.name,
+		    "unregistered_multicast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n",
+			       sc_attr->unreg_mc_kbyte_per_sec_rate);
+
+	return -EINVAL;
+}
+
+int prestera_storm_control_init(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc;
+	struct prestera_port *port;
+	int err;
+
+	sc = kzalloc(sizeof(*sc), GFP_KERNEL);
+	if (!sc)
+		return -ENOMEM;
+
+	sc->attribute_values = kcalloc(sw->port_count,
+				       sizeof(*sc->attribute_values),
+				       GFP_KERNEL);
+	if (!sc->attribute_values) {
+		err = -ENOMEM;
+		goto err_values_alloca;
+	}
+
+	list_for_each_entry(port, &sw->port_list, list) {
+		err = sysfs_create_group(&port->net_dev->dev.kobj,
+					 &prestera_sw_dev_attr_group);
+		if (err) {
+			pr_err("Failed to create sysfs group for %s\n",
+			       dev_name(&port->net_dev->dev));
+			goto err_group_create;
+		}
+	}
+
+	sc->sw = sw;
+	sw->storm_control = sc;
+
+	return 0;
+
+err_group_create:
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list) {
+		sysfs_remove_group(&port->net_dev->dev.kobj,
+				   &prestera_sw_dev_attr_group);
+	}
+	kfree(sc->attribute_values);
+err_values_alloca:
+	kfree(sc);
+	return err;
+}
+
+void prestera_storm_control_fini(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc = sw->storm_control;
+	struct prestera_port *port;
+
+	list_for_each_entry(port, &sw->port_list, list)
+		sysfs_remove_group(&port->net_dev->dev.kobj,
+				   &prestera_sw_dev_attr_group);
+
+	kfree(sc->attribute_values);
+	kfree(sc);
+}
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h
new file mode 100644
index 000000000000..c1e7c53c1fc2
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h
@@ -0,0 +1,12 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _MVSW_PRESTERA_STORM_CONTROL_H_
+#define _MVSW_PRESTERA_STORM_CONTROL_H_
+
+#include "prestera.h"
+
+int prestera_storm_control_init(struct prestera_switch *sw);
+void prestera_storm_control_fini(struct prestera_switch *sw);
+
+#endif /* _MVSW_PRESTERA_STORM_CONTROL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c b/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
index b4599fe4ca8d..7ac8bbac5046 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
@@ -1,108 +1,219 @@
-// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved */
-
-#include <linux/if_bridge.h>
-#include <linux/if_vlan.h>
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+ *
+ * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
+ *
+ */
 #include <linux/kernel.h>
 #include <linux/module.h>
+#include <linux/if_vlan.h>
+#include <linux/if_bridge.h>
 #include <linux/notifier.h>
-#include <net/netevent.h>
 #include <net/switchdev.h>
+#include <net/netevent.h>
+#include <net/vxlan.h>
 
 #include "prestera.h"
-#include "prestera_hw.h"
 #include "prestera_switchdev.h"
+#include "prestera_hw.h"
 
 #define PRESTERA_VID_ALL (0xffff)
-
-#define PRESTERA_DEFAULT_AGEING_TIME_MS 300000
-#define PRESTERA_MAX_AGEING_TIME_MS 1000000000
-#define PRESTERA_MIN_AGEING_TIME_MS 32000
-
-struct prestera_fdb_event_work {
-	struct work_struct work;
-	struct switchdev_notifier_fdb_info fdb_info;
-	struct net_device *dev;
-	unsigned long event;
-};
+#define PRESTERA_DEFAULT_ISOLATION_SRCID 1 /* source_id */
 
 struct prestera_switchdev {
-	struct prestera_switch *sw;
+	struct notifier_block swdev_n;
+	struct notifier_block swdev_blocking_n;
+
+	u32 ageing_time;
 	struct list_head bridge_list;
 	bool bridge_8021q_exists;
-	struct notifier_block swdev_nb_blk;
-	struct notifier_block swdev_nb;
+};
+
+struct prestera_br_mdb_port {
+	struct prestera_bridge_port *br_port;
+	struct list_head br_mdb_port_node;
+};
+
+/* Software representation of MDB table. */
+struct prestera_br_mdb_entry {
+	struct prestera_bridge *bridge;
+	struct prestera_mdb_entry *mdb;
+	struct list_head br_mdb_port_list;
+	struct list_head br_mdb_entry_node;
+	bool enabled;
 };
 
 struct prestera_bridge {
-	struct list_head head;
 	struct net_device *dev;
-	struct prestera_switchdev *swdev;
+	struct list_head bridge_node;
 	struct list_head port_list;
-	bool vlan_enabled;
+	struct list_head br_mdb_entry_list;
+	bool mrouter_exist;
 	u16 bridge_id;
+	/* This can be extended to list of isolation groups */
+	u32 isolation_srcid; /* source_id */
+	u8 vlan_enabled:1, multicast_enabled:1, mrouter:1;
 };
 
 struct prestera_bridge_port {
-	struct list_head head;
 	struct net_device *dev;
 	struct prestera_bridge *bridge;
+	struct list_head bridge_node;
 	struct list_head vlan_list;
-	refcount_t ref_count;
-	unsigned long flags;
+	struct list_head br_mdb_port_list;
+	unsigned int ref_count;
 	u8 stp_state;
+	bool mrouter;
+	unsigned long flags;
 };
 
 struct prestera_bridge_vlan {
-	struct list_head head;
+	struct list_head bridge_port_node;
 	struct list_head port_vlan_list;
 	u16 vid;
 };
 
-struct prestera_port_vlan {
-	struct list_head br_vlan_head;
-	struct list_head port_head;
-	struct prestera_port *port;
-	struct prestera_bridge_port *br_port;
-	u16 vid;
+struct prestera_swdev_work {
+	struct work_struct work;
+	struct switchdev_notifier_fdb_info fdb_info;
+	struct net_device *dev;
+	unsigned long event;
 };
 
-static struct workqueue_struct *swdev_wq;
+static struct workqueue_struct *swdev_owq;
 
-static void prestera_bridge_port_put(struct prestera_bridge_port *br_port);
+static struct prestera_bridge_port *
+prestera_bridge_port_get(struct prestera_switch *sw,
+			 struct net_device *brport_dev);
 
-static int prestera_port_vid_stp_set(struct prestera_port *port, u16 vid,
-				     u8 state);
+static void prestera_bridge_port_put(struct prestera_switch *sw,
+				     struct prestera_bridge_port *br_port);
 
-static struct prestera_bridge_vlan *
-prestera_bridge_vlan_create(struct prestera_bridge_port *br_port, u16 vid)
+static int
+prestera_mdb_port_addr_obj_add(const struct switchdev_obj_port_mdb *mdb,
+			       struct switchdev_trans *trans);
+static int
+prestera_mdb_port_addr_obj_del(struct prestera_port *port,
+			       const struct switchdev_obj_port_mdb *mdb);
+
+static void
+prestera_mdb_flush_bridge_port(struct prestera_bridge_port *br_port);
+static int
+prestera_mdb_port_add(struct prestera_mdb_entry *br_mdb,
+		      struct net_device *orig_dev,
+		      const unsigned char addr[ETH_ALEN], u16 vid);
+
+static void
+prestera_br_mdb_entry_put(struct prestera_br_mdb_entry *br_mdb_entry);
+static int prestera_br_mdb_mc_enable_sync(struct prestera_bridge *br_dev);
+static int prestera_br_mdb_sync(struct prestera_bridge *br_dev);
+static int prestera_br_mdb_port_add(struct prestera_br_mdb_entry *br_mdb,
+				    struct prestera_bridge_port *br_port);
+static void
+prestera_mdb_port_del(struct prestera_mdb_entry *mdb,
+		      struct net_device *orig_dev);
+
+static struct prestera_bridge *
+prestera_bridge_find(const struct prestera_switch *sw,
+		     const struct net_device *br_dev)
 {
-	struct prestera_bridge_vlan *br_vlan;
+	struct prestera_bridge *bridge;
 
-	br_vlan = kzalloc(sizeof(*br_vlan), GFP_KERNEL);
-	if (!br_vlan)
+	list_for_each_entry(bridge, &sw->swdev->bridge_list,
+			    bridge_node)
+		if (bridge->dev == br_dev)
+			return bridge;
+
+	return NULL;
+}
+
+bool prestera_bridge_is_offloaded(const struct prestera_switch *sw,
+				  const struct net_device *br_dev)
+{
+	return !!prestera_bridge_find(sw, br_dev);
+}
+
+static struct prestera_bridge_port *
+__prestera_bridge_port_find(const struct prestera_bridge *bridge,
+			    const struct net_device *brport_dev)
+{
+	struct prestera_bridge_port *br_port;
+
+	list_for_each_entry(br_port, &bridge->port_list,
+			    bridge_node) {
+		if (br_port->dev == brport_dev)
+			return br_port;
+	}
+
+	return NULL;
+}
+
+static struct prestera_bridge_port *
+prestera_bridge_port_find(struct prestera_switch *sw,
+			  struct net_device *brport_dev)
+{
+	struct net_device *br_dev = netdev_master_upper_dev_get(brport_dev);
+	struct prestera_bridge *bridge;
+
+	if (!br_dev)
 		return NULL;
 
-	INIT_LIST_HEAD(&br_vlan->port_vlan_list);
-	br_vlan->vid = vid;
-	list_add(&br_vlan->head, &br_port->vlan_list);
+	bridge = prestera_bridge_find(sw, br_dev);
+	if (!bridge)
+		return NULL;
 
-	return br_vlan;
+	return __prestera_bridge_port_find(bridge, brport_dev);
+}
+
+static void
+prestera_br_port_flags_reset(struct prestera_bridge_port *br_port,
+			     struct prestera_port *port)
+{
+	prestera_port_uc_flood_set(port, false);
+	prestera_port_mc_flood_set(port, false);
+	prestera_port_learning_set(port, false);
+	prestera_port_isolation_grp_set(port, PRESTERA_PORT_SRCID_ZERO);
 }
 
-static void prestera_bridge_vlan_destroy(struct prestera_bridge_vlan *br_vlan)
+static int prestera_br_port_flags_set(struct prestera_bridge_port *br_port,
+				      struct prestera_port *port)
 {
-	list_del(&br_vlan->head);
-	WARN_ON(!list_empty(&br_vlan->port_vlan_list));
-	kfree(br_vlan);
+	struct prestera_bridge *br_dev;
+	u32 iso_srcid;
+	int err;
+
+	br_dev = br_port->bridge;
+
+	err = prestera_port_uc_flood_set(port, br_port->flags & BR_FLOOD);
+	if (err)
+		goto err_out;
+
+	err = prestera_br_mdb_mc_enable_sync(br_port->bridge);
+	if (err)
+		goto err_out;
+
+	err = prestera_port_learning_set(port, br_port->flags & BR_LEARNING);
+	if (err)
+		goto err_out;
+
+	iso_srcid = br_port->flags & BR_ISOLATED ?
+			br_dev->isolation_srcid : PRESTERA_PORT_SRCID_ZERO;
+	err = prestera_port_isolation_grp_set(port, iso_srcid);
+	if (err)
+		goto err_out;
+
+	return 0;
+
+err_out:
+	prestera_br_port_flags_reset(br_port, port);
+	return err;
 }
 
 static struct prestera_bridge_vlan *
-prestera_bridge_vlan_by_vid(struct prestera_bridge_port *br_port, u16 vid)
+prestera_bridge_vlan_find(const struct prestera_bridge_port *br_port, u16 vid)
 {
 	struct prestera_bridge_vlan *br_vlan;
 
-	list_for_each_entry(br_vlan, &br_port->vlan_list, head) {
+	list_for_each_entry(br_vlan, &br_port->vlan_list, bridge_port_node) {
 		if (br_vlan->vid == vid)
 			return br_vlan;
 	}
@@ -110,641 +221,821 @@ prestera_bridge_vlan_by_vid(struct prestera_bridge_port *br_port, u16 vid)
 	return NULL;
 }
 
-static int prestera_bridge_vlan_port_count(struct prestera_bridge *bridge,
-					   u16 vid)
+u16 prestera_vlan_dev_vlan_id(struct prestera_switch *sw,
+			      struct net_device *dev)
+{
+	struct prestera_bridge *bridge_dev;
+
+	bridge_dev = prestera_bridge_find(sw, dev);
+
+	return bridge_dev ? bridge_dev->bridge_id : 0;
+}
+
+static struct prestera_bridge_vlan *
+prestera_bridge_vlan_create(struct prestera_bridge_port *br_port, u16 vid)
 {
-	struct prestera_bridge_port *br_port;
 	struct prestera_bridge_vlan *br_vlan;
-	int count = 0;
 
-	list_for_each_entry(br_port, &bridge->port_list, head) {
-		list_for_each_entry(br_vlan, &br_port->vlan_list, head) {
-			if (br_vlan->vid == vid) {
-				count += 1;
-				break;
-			}
-		}
-	}
+	br_vlan = kzalloc(sizeof(*br_vlan), GFP_KERNEL);
+	if (!br_vlan)
+		return NULL;
 
-	return count;
+	INIT_LIST_HEAD(&br_vlan->port_vlan_list);
+	br_vlan->vid = vid;
+	list_add(&br_vlan->bridge_port_node, &br_port->vlan_list);
+
+	return br_vlan;
 }
 
-static void prestera_bridge_vlan_put(struct prestera_bridge_vlan *br_vlan)
+static void
+prestera_bridge_vlan_destroy(struct prestera_bridge_vlan *br_vlan)
 {
-	if (list_empty(&br_vlan->port_vlan_list))
-		prestera_bridge_vlan_destroy(br_vlan);
+	list_del(&br_vlan->bridge_port_node);
+	WARN_ON(!list_empty(&br_vlan->port_vlan_list));
+	kfree(br_vlan);
 }
 
-static struct prestera_port_vlan *
-prestera_port_vlan_by_vid(struct prestera_port *port, u16 vid)
+static struct prestera_bridge_vlan *
+prestera_bridge_vlan_get(struct prestera_bridge_port *br_port, u16 vid)
 {
-	struct prestera_port_vlan *port_vlan;
+	struct prestera_bridge_vlan *br_vlan;
 
-	list_for_each_entry(port_vlan, &port->vlans_list, port_head) {
-		if (port_vlan->vid == vid)
-			return port_vlan;
-	}
+	br_vlan = prestera_bridge_vlan_find(br_port, vid);
+	if (br_vlan)
+		return br_vlan;
 
-	return NULL;
+	return prestera_bridge_vlan_create(br_port, vid);
 }
 
-static struct prestera_port_vlan *
-prestera_port_vlan_create(struct prestera_port *port, u16 vid, bool untagged)
+static void prestera_bridge_vlan_put(struct prestera_bridge_vlan *br_vlan)
 {
-	struct prestera_port_vlan *port_vlan;
+	if (list_empty(&br_vlan->port_vlan_list))
+		prestera_bridge_vlan_destroy(br_vlan);
+}
+
+static int
+prestera_port_vlan_bridge_join(struct prestera_port_vlan *port_vlan,
+			       struct prestera_bridge_port *br_port,
+			       struct netlink_ext_ack *extack)
+{
+	struct prestera_port *port = port_vlan->port;
+	struct prestera_bridge_vlan *br_vlan;
+	u16 vid = port_vlan->vid;
 	int err;
 
-	port_vlan = prestera_port_vlan_by_vid(port, vid);
-	if (port_vlan)
-		return ERR_PTR(-EEXIST);
+	if (port_vlan->bridge_port)
+		return 0;
 
-	err = prestera_hw_vlan_port_set(port, vid, true, untagged);
+	err = prestera_br_port_flags_set(br_port, port);
 	if (err)
-		return ERR_PTR(err);
+		goto err_flags2port_set;
 
-	port_vlan = kzalloc(sizeof(*port_vlan), GFP_KERNEL);
-	if (!port_vlan) {
+	err = prestera_port_vid_stp_set(port, vid, br_port->stp_state);
+	if (err)
+		goto err_port_vid_stp_set;
+
+	br_vlan = prestera_bridge_vlan_get(br_port, vid);
+	if (!br_vlan) {
 		err = -ENOMEM;
-		goto err_port_vlan_alloc;
+		goto err_bridge_vlan_get;
 	}
 
-	port_vlan->port = port;
-	port_vlan->vid = vid;
+	list_add(&port_vlan->bridge_vlan_node, &br_vlan->port_vlan_list);
 
-	list_add(&port_vlan->port_head, &port->vlans_list);
+	prestera_bridge_port_get(port->sw, br_port->dev);
+	port_vlan->bridge_port = br_port;
 
-	return port_vlan;
+	return 0;
 
-err_port_vlan_alloc:
-	prestera_hw_vlan_port_set(port, vid, false, false);
-	return ERR_PTR(err);
+err_bridge_vlan_get:
+	prestera_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
+err_port_vid_stp_set:
+	prestera_br_port_flags_reset(br_port, port);
+err_flags2port_set:
+	return err;
 }
 
-static int prestera_fdb_add(struct prestera_port *port,
-			    const unsigned char *mac, u16 vid, bool dynamic)
+static int
+prestera_bridge_vlan_port_count_get(struct prestera_bridge *bridge,
+				    u16 vid)
 {
-	if (prestera_port_is_lag_member(port))
-		return prestera_hw_lag_fdb_add(port->sw, prestera_port_lag_id(port),
-					      mac, vid, dynamic);
+	int count = 0;
+	struct prestera_bridge_port *br_port;
+	struct prestera_bridge_vlan *br_vlan;
+
+	list_for_each_entry(br_port, &bridge->port_list, bridge_node) {
+		list_for_each_entry(br_vlan, &br_port->vlan_list,
+				    bridge_port_node) {
+			if (br_vlan->vid == vid) {
+				count += 1;
+				break;
+			}
+		}
+	}
 
-	return prestera_hw_fdb_add(port, mac, vid, dynamic);
+	return count;
 }
 
-static int prestera_fdb_del(struct prestera_port *port,
-			    const unsigned char *mac, u16 vid)
+static int prestera_fdb_flush_vlan(struct prestera_switch *sw, u16 vid,
+				   enum prestera_fdb_flush_mode mode)
 {
-	if (prestera_port_is_lag_member(port))
-		return prestera_hw_lag_fdb_del(port->sw, prestera_port_lag_id(port),
-					      mac, vid);
-	else
-		return prestera_hw_fdb_del(port, mac, vid);
+	return prestera_hw_fdb_flush_vlan(sw, vid, mode);
 }
 
 static int prestera_fdb_flush_port_vlan(struct prestera_port *port, u16 vid,
-					u32 mode)
+					enum prestera_fdb_flush_mode mode)
 {
 	if (prestera_port_is_lag_member(port))
-		return prestera_hw_fdb_flush_lag_vlan(port->sw, prestera_port_lag_id(port),
+		return prestera_hw_fdb_flush_lag_vlan(port->sw, port->lag_id,
 						      vid, mode);
 	else
 		return prestera_hw_fdb_flush_port_vlan(port, vid, mode);
 }
 
-static int prestera_fdb_flush_port(struct prestera_port *port, u32 mode)
+static int prestera_fdb_flush_port(struct prestera_port *port,
+				   enum prestera_fdb_flush_mode mode)
 {
 	if (prestera_port_is_lag_member(port))
-		return prestera_hw_fdb_flush_lag(port->sw, prestera_port_lag_id(port),
-						 mode);
+		return prestera_hw_fdb_flush_lag(port->sw, port->lag_id, mode);
 	else
 		return prestera_hw_fdb_flush_port(port, mode);
 }
 
-static void
+int prestera_bridge_port_down(struct prestera_port *port)
+{
+	return prestera_fdb_flush_port(port, PRESTERA_FDB_FLUSH_MODE_DYNAMIC);
+}
+
+void
 prestera_port_vlan_bridge_leave(struct prestera_port_vlan *port_vlan)
 {
-	u32 fdb_flush_mode = PRESTERA_FDB_FLUSH_MODE_DYNAMIC;
 	struct prestera_port *port = port_vlan->port;
+	u32 mode = PRESTERA_FDB_FLUSH_MODE_DYNAMIC;
 	struct prestera_bridge_vlan *br_vlan;
 	struct prestera_bridge_port *br_port;
-	bool last_port, last_vlan;
 	u16 vid = port_vlan->vid;
+	bool last_port, last_vlan;
 	int port_count;
 
-	br_port = port_vlan->br_port;
-	port_count = prestera_bridge_vlan_port_count(br_port->bridge, vid);
-	br_vlan = prestera_bridge_vlan_by_vid(br_port, vid);
-
+	br_port = port_vlan->bridge_port;
 	last_vlan = list_is_singular(&br_port->vlan_list);
+	port_count = prestera_bridge_vlan_port_count_get(br_port->bridge, vid);
+	br_vlan = prestera_bridge_vlan_find(br_port, vid);
 	last_port = port_count == 1;
-
 	if (last_vlan)
-		prestera_fdb_flush_port(port, fdb_flush_mode);
+		prestera_fdb_flush_port(port, mode);
 	else if (last_port)
-		prestera_hw_fdb_flush_vlan(port->sw, vid, fdb_flush_mode);
+		prestera_fdb_flush_vlan(port->sw, vid, mode);
 	else
-		prestera_fdb_flush_port_vlan(port, vid, fdb_flush_mode);
-
-	list_del(&port_vlan->br_vlan_head);
-	prestera_bridge_vlan_put(br_vlan);
-	prestera_bridge_port_put(br_port);
-	port_vlan->br_port = NULL;
-}
-
-static void prestera_port_vlan_destroy(struct prestera_port_vlan *port_vlan)
-{
-	struct prestera_port *port = port_vlan->port;
-	u16 vid = port_vlan->vid;
+		prestera_fdb_flush_port_vlan(port, vid, mode);
 
-	if (port_vlan->br_port)
-		prestera_port_vlan_bridge_leave(port_vlan);
+	prestera_mdb_flush_bridge_port(br_port);
 
-	prestera_hw_vlan_port_set(port, vid, false, false);
-	list_del(&port_vlan->port_head);
-	kfree(port_vlan);
+	list_del(&port_vlan->bridge_vlan_node);
+	prestera_bridge_vlan_put(br_vlan);
+	prestera_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
+	prestera_bridge_port_put(port->sw, br_port);
+	port_vlan->bridge_port = NULL;
 }
 
-static struct prestera_bridge *
-prestera_bridge_create(struct prestera_switchdev *swdev, struct net_device *dev)
+static int
+prestera_bridge_port_vlan_add(struct prestera_port *port,
+			      struct prestera_bridge_port *br_port,
+			      u16 vid, bool is_untagged, bool is_pvid,
+			      struct netlink_ext_ack *extack)
 {
-	bool vlan_enabled = br_vlan_enabled(dev);
-	struct prestera_bridge *bridge;
-	u16 bridge_id;
+	u16 pvid;
+	struct prestera_port_vlan *port_vlan;
+	u16 old_pvid = port->pvid;
 	int err;
 
-	if (vlan_enabled && swdev->bridge_8021q_exists) {
-		netdev_err(dev, "Only one VLAN-aware bridge is supported\n");
-		return ERR_PTR(-EINVAL);
-	}
+	if (is_pvid)
+		pvid = vid;
+	else
+		pvid = port->pvid == vid ? 0 : port->pvid;
 
-	bridge = kzalloc(sizeof(*bridge), GFP_KERNEL);
-	if (!bridge)
-		return ERR_PTR(-ENOMEM);
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
+	if (port_vlan && port_vlan->bridge_port != br_port)
+		return -EEXIST;
 
-	if (vlan_enabled) {
-		swdev->bridge_8021q_exists = true;
+	if (!port_vlan) {
+		port_vlan = prestera_port_vlan_create(port, vid, is_untagged);
+		if (IS_ERR(port_vlan))
+			return PTR_ERR(port_vlan);
 	} else {
-		err = prestera_hw_bridge_create(swdev->sw, &bridge_id);
-		if (err) {
-			kfree(bridge);
-			return ERR_PTR(err);
-		}
-
-		bridge->bridge_id = bridge_id;
+		err = prestera_port_vlan_set(port, vid, true, is_untagged);
+		if (err)
+			goto err_port_vlan_set;
 	}
 
-	bridge->vlan_enabled = vlan_enabled;
-	bridge->swdev = swdev;
-	bridge->dev = dev;
-
-	INIT_LIST_HEAD(&bridge->port_list);
-
-	list_add(&bridge->head, &swdev->bridge_list);
-
-	return bridge;
-}
+	err = prestera_port_pvid_set(port, pvid);
+	if (err)
+		goto err_port_pvid_set;
 
-static void prestera_bridge_destroy(struct prestera_bridge *bridge)
-{
-	struct prestera_switchdev *swdev = bridge->swdev;
+	err = prestera_port_vlan_bridge_join(port_vlan, br_port, extack);
+	if (err)
+		goto err_port_vlan_bridge_join;
 
-	list_del(&bridge->head);
+	return 0;
 
-	if (bridge->vlan_enabled)
-		swdev->bridge_8021q_exists = false;
-	else
-		prestera_hw_bridge_delete(swdev->sw, bridge->bridge_id);
+err_port_vlan_bridge_join:
+	prestera_port_pvid_set(port, old_pvid);
+err_port_pvid_set:
+	prestera_port_vlan_set(port, vid, false, false);
+err_port_vlan_set:
+	prestera_port_vlan_destroy(port_vlan);
 
-	WARN_ON(!list_empty(&bridge->port_list));
-	kfree(bridge);
+	return err;
 }
 
-static void prestera_bridge_put(struct prestera_bridge *bridge)
-{
-	if (list_empty(&bridge->port_list))
-		prestera_bridge_destroy(bridge);
-}
-
-static
-struct prestera_bridge *prestera_bridge_by_dev(struct prestera_switchdev *swdev,
-					       const struct net_device *dev)
+static int prestera_port_vlans_add(struct prestera_port *port,
+				   const struct switchdev_obj_port_vlan *vlan,
+				   struct switchdev_trans *trans,
+				   struct netlink_ext_ack *extack)
 {
+	bool flag_untagged = vlan->flags & BRIDGE_VLAN_INFO_UNTAGGED;
+	bool flag_pvid = vlan->flags & BRIDGE_VLAN_INFO_PVID;
+	struct net_device *orig_dev = vlan->obj.orig_dev;
+	struct prestera_bridge_port *br_port;
 	struct prestera_bridge *bridge;
+	struct prestera_switch *sw = port->sw;
+	u16 vid;
 
-	list_for_each_entry(bridge, &swdev->bridge_list, head)
-		if (bridge->dev == dev)
-			return bridge;
+	if (netif_is_bridge_master(orig_dev))
+		return 0;
 
-	return NULL;
-}
+	if (switchdev_trans_ph_commit(trans))
+		return 0;
 
-static struct prestera_bridge_port *
-__prestera_bridge_port_by_dev(struct prestera_bridge *bridge,
-			      struct net_device *dev)
-{
-	struct prestera_bridge_port *br_port;
+	br_port = prestera_bridge_port_find(sw, orig_dev);
+	if (WARN_ON(!br_port))
+		return -EINVAL;
 
-	list_for_each_entry(br_port, &bridge->port_list, head) {
-		if (br_port->dev == dev)
-			return br_port;
-	}
+	bridge = br_port->bridge;
+	if (!bridge->vlan_enabled)
+		return 0;
 
-	return NULL;
-}
+	for (vid = vlan->vid_begin; vid <= vlan->vid_end; vid++) {
+		int err;
 
-static int prestera_match_upper_bridge_dev(struct net_device *dev,
-					   struct netdev_nested_priv *priv)
-{
-	if (netif_is_bridge_master(dev))
-		priv->data = dev;
+		err = prestera_bridge_port_vlan_add(port, br_port,
+						    vid, flag_untagged,
+						    flag_pvid, extack);
+		if (err)
+			return err;
+	}
+
+	if (list_is_singular(&bridge->port_list))
+		prestera_rif_enable(port->sw, bridge->dev, true);
 
 	return 0;
 }
 
-static struct net_device *prestera_get_upper_bridge_dev(struct net_device *dev)
+static int prestera_port_obj_add(struct net_device *dev,
+				 const struct switchdev_obj *obj,
+				 struct switchdev_trans *trans,
+				 struct netlink_ext_ack *extack)
 {
-	struct netdev_nested_priv priv = { };
+	struct prestera_port *port = netdev_priv(dev);
+	const struct switchdev_obj_port_vlan *vlan;
+	const struct switchdev_obj_port_mdb *mdb;
+	int err = 0;
+
+	switch (obj->id) {
+	case SWITCHDEV_OBJ_ID_PORT_VLAN:
+		vlan = SWITCHDEV_OBJ_PORT_VLAN(obj);
+		err = prestera_port_vlans_add(port, vlan, trans, extack);
+		break;
+	case SWITCHDEV_OBJ_ID_PORT_MDB:
+		mdb = SWITCHDEV_OBJ_PORT_MDB(obj);
+		err = prestera_mdb_port_addr_obj_add(mdb, trans);
+		break;
+	case SWITCHDEV_OBJ_ID_HOST_MDB:
+		fallthrough;
+	default:
+		err = -EOPNOTSUPP;
+	}
 
-	netdev_walk_all_upper_dev_rcu(dev, prestera_match_upper_bridge_dev,
-				      &priv);
-	return priv.data;
+	return err;
 }
 
-static struct prestera_bridge_port *
-prestera_bridge_port_by_dev(struct prestera_switchdev *swdev,
-			    struct net_device *dev)
+static void
+prestera_bridge_port_vlan_del(struct prestera_port *port,
+			      struct prestera_bridge_port *br_port, u16 vid)
 {
-	struct net_device *br_dev = prestera_get_upper_bridge_dev(dev);
-	struct prestera_bridge *bridge;
-
-	if (!br_dev)
-		return NULL;
+	u16 pvid = port->pvid == vid ? 0 : port->pvid;
+	struct prestera_port_vlan *port_vlan;
 
-	bridge = prestera_bridge_by_dev(swdev, br_dev);
-	if (!bridge)
-		return NULL;
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
+	if (WARN_ON(!port_vlan))
+		return;
 
-	return __prestera_bridge_port_by_dev(bridge, dev);
+	prestera_port_vlan_bridge_leave(port_vlan);
+	prestera_port_pvid_set(port, pvid);
+	prestera_port_vlan_destroy(port_vlan);
 }
 
-static struct prestera_bridge_port *
-prestera_bridge_port_create(struct prestera_bridge *bridge,
-			    struct net_device *dev)
+static int prestera_port_vlans_del(struct prestera_port *port,
+				   const struct switchdev_obj_port_vlan *vlan)
 {
+	struct prestera_switch *sw = port->sw;
+	struct net_device *orig_dev = vlan->obj.orig_dev;
 	struct prestera_bridge_port *br_port;
+	u16 vid;
 
-	br_port = kzalloc(sizeof(*br_port), GFP_KERNEL);
-	if (!br_port)
-		return NULL;
+	if (netif_is_bridge_master(orig_dev))
+		return -EOPNOTSUPP;
 
-	br_port->flags = BR_LEARNING | BR_FLOOD | BR_LEARNING_SYNC |
-				BR_MCAST_FLOOD;
-	br_port->stp_state = BR_STATE_DISABLED;
-	refcount_set(&br_port->ref_count, 1);
-	br_port->bridge = bridge;
-	br_port->dev = dev;
+	br_port = prestera_bridge_port_find(sw, orig_dev);
+	if (WARN_ON(!br_port))
+		return -EINVAL;
 
-	INIT_LIST_HEAD(&br_port->vlan_list);
-	list_add(&br_port->head, &bridge->port_list);
+	if (!br_port->bridge->vlan_enabled)
+		return 0;
 
-	return br_port;
-}
+	for (vid = vlan->vid_begin; vid <= vlan->vid_end; vid++)
+		prestera_bridge_port_vlan_del(port, br_port, vid);
 
-static void
-prestera_bridge_port_destroy(struct prestera_bridge_port *br_port)
-{
-	list_del(&br_port->head);
-	WARN_ON(!list_empty(&br_port->vlan_list));
-	kfree(br_port);
+	return 0;
 }
 
-static void prestera_bridge_port_get(struct prestera_bridge_port *br_port)
+static int prestera_port_obj_del(struct net_device *dev,
+				 const struct switchdev_obj *obj)
 {
-	refcount_inc(&br_port->ref_count);
+	struct prestera_port *port = netdev_priv(dev);
+	const struct switchdev_obj_port_mdb *mdb;
+	int err = 0;
+
+	switch (obj->id) {
+	case SWITCHDEV_OBJ_ID_PORT_VLAN:
+		err = prestera_port_vlans_del(port,
+					      SWITCHDEV_OBJ_PORT_VLAN(obj));
+		break;
+	case SWITCHDEV_OBJ_ID_PORT_MDB:
+		mdb = SWITCHDEV_OBJ_PORT_MDB(obj);
+		err = prestera_mdb_port_addr_obj_del(port, mdb);
+		break;
+	default:
+		err = -EOPNOTSUPP;
+		break;
+	}
+
+	return err;
 }
 
-static void prestera_bridge_port_put(struct prestera_bridge_port *br_port)
+static int prestera_port_attr_br_vlan_set(struct prestera_port *port,
+					  struct switchdev_trans *trans,
+					  struct net_device *orig_dev,
+					  bool vlan_enabled)
 {
-	struct prestera_bridge *bridge = br_port->bridge;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_bridge *bridge;
 
-	if (refcount_dec_and_test(&br_port->ref_count)) {
-		prestera_bridge_port_destroy(br_port);
-		prestera_bridge_put(bridge);
-	}
+	if (!switchdev_trans_ph_prepare(trans))
+		return 0;
+
+	bridge = prestera_bridge_find(sw, orig_dev);
+	if (WARN_ON(!bridge))
+		return -EINVAL;
+
+	if (bridge->vlan_enabled == vlan_enabled)
+		return 0;
+
+	netdev_err(bridge->dev,
+		   "VLAN filtering can't be changed for existing bridge\n");
+	return -EINVAL;
 }
 
-static struct prestera_bridge_port *
-prestera_bridge_port_add(struct prestera_bridge *bridge, struct net_device *dev)
+static int prestera_port_attr_br_flags_set(struct prestera_port *port,
+					   struct switchdev_trans *trans,
+					   struct net_device *orig_dev,
+					   unsigned long flags)
 {
 	struct prestera_bridge_port *br_port;
 
-	br_port = __prestera_bridge_port_by_dev(bridge, dev);
-	if (br_port) {
-		prestera_bridge_port_get(br_port);
-		return br_port;
-	}
+	if (switchdev_trans_ph_prepare(trans))
+		return 0;
 
-	br_port = prestera_bridge_port_create(bridge, dev);
+	br_port = prestera_bridge_port_find(port->sw, orig_dev);
 	if (!br_port)
-		return ERR_PTR(-ENOMEM);
+		return 0;
 
-	return br_port;
+	memcpy(&br_port->flags, &flags, sizeof(flags));
+	return prestera_br_port_flags_set(br_port, port);
 }
 
-static int
-prestera_bridge_1d_port_join(struct prestera_bridge_port *br_port)
+static int prestera_switch_ageing_set(struct prestera_switch *sw,
+				      u32 ageing_time)
 {
-	struct prestera_port *port = netdev_priv(br_port->dev);
-	struct prestera_bridge *bridge = br_port->bridge;
-	int err;
+	return prestera_hw_switch_ageing_set(sw, ageing_time / 1000);
+}
 
-	err = prestera_hw_bridge_port_add(port, bridge->bridge_id);
-	if (err)
-		return err;
+static int prestera_port_attr_br_ageing_set(struct prestera_port *port,
+					    struct switchdev_trans *trans,
+					    unsigned long ageing_clock_t)
+{
+	int err;
+	struct prestera_switch *sw = port->sw;
+	unsigned long ageing_jiffies = clock_t_to_jiffies(ageing_clock_t);
+	u32 ageing_time = jiffies_to_msecs(ageing_jiffies);
+
+	if (switchdev_trans_ph_prepare(trans)) {
+		if (ageing_time < PRESTERA_MIN_AGEING_TIME ||
+		    ageing_time > PRESTERA_MAX_AGEING_TIME)
+			return -ERANGE;
+		else
+			return 0;
+	}
 
-	err = prestera_hw_port_flood_set(port, BR_FLOOD | BR_MCAST_FLOOD,
-					 br_port->flags);
-	if (err)
-		goto err_port_flood_set;
+	err = prestera_switch_ageing_set(sw, ageing_time);
+	if (!err)
+		sw->swdev->ageing_time = ageing_time;
 
-	err = prestera_hw_port_learning_set(port, br_port->flags & BR_LEARNING);
-	if (err)
-		goto err_port_learning_set;
+	return err;
+}
 
-	return 0;
+static int
+prestera_port_bridge_vlan_stp_set(struct prestera_port *port,
+				  struct prestera_bridge_vlan *br_vlan,
+				  u8 state)
+{
+	struct prestera_port_vlan *port_vlan;
 
-err_port_learning_set:
-err_port_flood_set:
-	prestera_hw_bridge_port_delete(port, bridge->bridge_id);
+	list_for_each_entry(port_vlan, &br_vlan->port_vlan_list,
+			    bridge_vlan_node) {
+		if (port_vlan->port != port)
+			continue;
+		return prestera_port_vid_stp_set(port, br_vlan->vid, state);
+	}
 
-	return err;
+	return 0;
 }
 
-int prestera_bridge_port_join(struct net_device *br_dev,
-			      struct prestera_port *port,
-			      struct netlink_ext_ack *extack)
+static int prestera_port_attr_stp_state_set(struct prestera_port *port,
+					    struct switchdev_trans *trans,
+					    struct net_device *orig_dev,
+					    u8 state)
 {
-	struct prestera_switchdev *swdev = port->sw->swdev;
 	struct prestera_bridge_port *br_port;
-	struct prestera_bridge *bridge;
+	struct prestera_bridge_vlan *br_vlan;
 	int err;
+	u16 vid;
 
-	bridge = prestera_bridge_by_dev(swdev, br_dev);
-	if (!bridge) {
-		bridge = prestera_bridge_create(swdev, br_dev);
-		if (IS_ERR(bridge))
-			return PTR_ERR(bridge);
-	}
+	if (switchdev_trans_ph_prepare(trans))
+		return 0;
 
-	br_port = prestera_bridge_port_add(bridge, port->dev);
-	if (IS_ERR(br_port)) {
-		prestera_bridge_put(bridge);
-		return PTR_ERR(br_port);
+	br_port = prestera_bridge_port_find(port->sw, orig_dev);
+	if (!br_port)
+		return 0;
+
+	if (!br_port->bridge->vlan_enabled) {
+		vid = br_port->bridge->bridge_id;
+		err = prestera_port_vid_stp_set(port, vid, state);
+		if (err)
+			goto err_port_bridge_stp_set;
+	} else {
+		list_for_each_entry(br_vlan, &br_port->vlan_list,
+				    bridge_port_node) {
+			err = prestera_port_bridge_vlan_stp_set(port, br_vlan,
+								state);
+			if (err)
+				goto err_port_bridge_vlan_stp_set;
+		}
 	}
 
-	err = switchdev_bridge_port_offload(br_port->dev, port->dev, NULL,
-					    NULL, NULL, false, extack);
-	if (err)
-		goto err_switchdev_offload;
+	br_port->stp_state = state;
 
-	if (bridge->vlan_enabled)
-		return 0;
+	return 0;
 
-	err = prestera_bridge_1d_port_join(br_port);
-	if (err)
-		goto err_port_join;
+err_port_bridge_vlan_stp_set:
+	list_for_each_entry_continue_reverse(br_vlan, &br_port->vlan_list,
+					     bridge_port_node)
+		prestera_port_bridge_vlan_stp_set(port, br_vlan,
+						  br_port->stp_state);
+	return err;
 
-	return 0;
+err_port_bridge_stp_set:
+	prestera_port_vid_stp_set(port, vid, br_port->stp_state);
 
-err_port_join:
-	switchdev_bridge_port_unoffload(br_port->dev, NULL, NULL, NULL);
-err_switchdev_offload:
-	prestera_bridge_port_put(br_port);
 	return err;
 }
 
-static void prestera_bridge_1q_port_leave(struct prestera_bridge_port *br_port)
+static int
+prestera_br_port_lag_mdb_mc_enable_sync(struct prestera_bridge_port *br_port,
+					bool enabled)
 {
-	struct prestera_port *port = netdev_priv(br_port->dev);
+	struct prestera_port *pr_port;
+	struct prestera_switch *sw;
+	u16 lag_id;
+	int err;
 
-	prestera_hw_fdb_flush_port(port, PRESTERA_FDB_FLUSH_MODE_ALL);
-	prestera_port_pvid_set(port, PRESTERA_DEFAULT_VID);
-}
+	pr_port = prestera_port_dev_lower_find(br_port->dev);
+	if (!pr_port)
+		return 0;
 
-static void prestera_bridge_1d_port_leave(struct prestera_bridge_port *br_port)
-{
-	struct prestera_port *port = netdev_priv(br_port->dev);
+	sw = pr_port->sw;
+	err = prestera_lag_id_find(sw, br_port->dev, &lag_id);
+	if (err)
+		return err;
 
-	prestera_hw_fdb_flush_port(port, PRESTERA_FDB_FLUSH_MODE_ALL);
-	prestera_hw_bridge_port_delete(port, br_port->bridge->bridge_id);
+	list_for_each_entry(pr_port, &sw->port_list, list) {
+		if (pr_port->lag_id == lag_id) {
+			err = prestera_port_mc_flood_set(pr_port, enabled);
+			if (err)
+				return err;
+		}
+	}
+
+	return 0;
 }
 
-static int prestera_port_vid_stp_set(struct prestera_port *port, u16 vid,
-				     u8 state)
+static int prestera_br_mdb_mc_enable_sync(struct prestera_bridge *br_dev)
 {
-	u8 hw_state = state;
+	struct prestera_bridge_port *br_port;
+	struct prestera_port *port;
+	bool enabled;
+	int err;
 
-	switch (state) {
-	case BR_STATE_DISABLED:
-		hw_state = PRESTERA_STP_DISABLED;
-		break;
+	/*
+	 * if mrouter exists:
+	 *  - make sure every mrouter receives unreg mcast traffic;
+	 * if mrouter doesn't exists:
+	 *  - make sure every port receives unreg mcast traffic;
+	 */
+	list_for_each_entry(br_port, &br_dev->port_list,
+			    bridge_node) {
+		if (br_dev->multicast_enabled && br_dev->mrouter_exist)
+			enabled = br_port->mrouter;
+		else
+			enabled = br_port->flags & BR_MCAST_FLOOD;
+
+		if (netif_is_lag_master(br_port->dev)) {
+			err = prestera_br_port_lag_mdb_mc_enable_sync(br_port,
+								      enabled);
+			if (err)
+				return err;
+			continue;
+		}
 
-	case BR_STATE_BLOCKING:
-	case BR_STATE_LISTENING:
-		hw_state = PRESTERA_STP_BLOCK_LISTEN;
-		break;
+		port = prestera_port_dev_lower_find(br_port->dev);
+		if (!port)
+			continue;
 
-	case BR_STATE_LEARNING:
-		hw_state = PRESTERA_STP_LEARN;
-		break;
+		err = prestera_port_mc_flood_set(port, enabled);
+		if (err)
+			return err;
+	}
 
-	case BR_STATE_FORWARDING:
-		hw_state = PRESTERA_STP_FORWARD;
-		break;
+	return 0;
+}
 
-	default:
-		return -EINVAL;
-	}
+static bool
+prestera_br_mdb_port_is_member(struct prestera_br_mdb_entry *br_mdb,
+			       struct net_device *orig_dev)
+{
+	struct prestera_br_mdb_port *tmp_port;
+
+	list_for_each_entry(tmp_port, &br_mdb->br_mdb_port_list,
+			    br_mdb_port_node)
+		if (tmp_port->br_port->dev == orig_dev)
+			return true;
 
-	return prestera_hw_vlan_port_stp_set(port, vid, hw_state);
+	return false;
 }
 
-void prestera_bridge_port_leave(struct net_device *br_dev,
-				struct prestera_port *port)
+/* Sync bridge mdb (software table) with HW table (if MC is enabled). */
+static int prestera_br_mdb_sync(struct prestera_bridge *br_dev)
 {
-	struct prestera_switchdev *swdev = port->sw->swdev;
+	struct prestera_br_mdb_port *br_mdb_port;
 	struct prestera_bridge_port *br_port;
-	struct prestera_bridge *bridge;
-
-	bridge = prestera_bridge_by_dev(swdev, br_dev);
-	if (!bridge)
-		return;
+	struct prestera_br_mdb_entry *br_mdb;
+	struct prestera_mdb_entry *mdb;
+	struct prestera_port *pr_port;
+	int err = 0;
 
-	br_port = __prestera_bridge_port_by_dev(bridge, port->dev);
-	if (!br_port)
-		return;
+	if (!br_dev->multicast_enabled)
+		return 0;
 
-	bridge = br_port->bridge;
+	list_for_each_entry(br_mdb, &br_dev->br_mdb_entry_list,
+			    br_mdb_entry_node) {
+		mdb = br_mdb->mdb;
+		/*
+		 * Make sure every port that explicitly been added to the mdb
+		 * joins the specified group.
+		 */
+		list_for_each_entry(br_mdb_port, &br_mdb->br_mdb_port_list,
+				    br_mdb_port_node) {
+			br_port = br_mdb_port->br_port;
+			pr_port = prestera_port_dev_lower_find(br_port->dev);
+
+			/*
+			 * Match only mdb and br_mdb ports that belong to the
+			 * same broadcast domain.
+			 */
+			if (br_dev->vlan_enabled &&
+			    !prestera_port_vlan_find_by_vid(pr_port,
+							    mdb->vid))
+				continue;
+
+			/*
+			 * If port is not in MDB or there's no Mrouter
+			 * clear HW mdb.
+			 */
+			if (prestera_br_mdb_port_is_member(br_mdb,
+							   br_mdb_port->br_port->dev) &&
+							   br_dev->mrouter_exist)
+				err = prestera_mdb_port_add(mdb, br_port->dev,
+							    mdb->addr,
+							    mdb->vid);
+			else
+				prestera_mdb_port_del(mdb, br_port->dev);
 
-	if (bridge->vlan_enabled)
-		prestera_bridge_1q_port_leave(br_port);
-	else
-		prestera_bridge_1d_port_leave(br_port);
+			if (err)
+				return err;
+		}
 
-	switchdev_bridge_port_unoffload(br_port->dev, NULL, NULL, NULL);
+		/*
+		 * Make sure that every mrouter port joins every MC group int
+		 * broadcast domain. If it's not an mrouter - it should leave
+		 */
+		list_for_each_entry(br_port, &br_dev->port_list, bridge_node) {
+			pr_port = prestera_port_dev_lower_find(br_port->dev);
+
+			/*
+			 * Make sure mrouter woudln't receive traffci from
+			 * another broadcast domain (e.g. from a vlan, which
+			 * mrouter port is not a member of).
+			 */
+			if (br_dev->vlan_enabled &&
+			    !prestera_port_vlan_find_by_vid(pr_port,
+							    mdb->vid))
+				continue;
+
+			if (br_port->mrouter) {
+				err = prestera_mdb_port_add(mdb, br_port->dev,
+							    mdb->addr,
+							    mdb->vid);
+				if (err)
+					return err;
+			} else if (!br_port->mrouter &&
+				   !prestera_br_mdb_port_is_member
+				   (br_mdb, br_port->dev)) {
+				prestera_mdb_port_del(mdb, br_port->dev);
+			}
+		}
+	}
 
-	prestera_hw_port_learning_set(port, false);
-	prestera_hw_port_flood_set(port, BR_FLOOD | BR_MCAST_FLOOD, 0);
-	prestera_port_vid_stp_set(port, PRESTERA_VID_ALL, BR_STATE_FORWARDING);
-	prestera_bridge_port_put(br_port);
+	return 0;
 }
 
-static int prestera_port_attr_br_flags_set(struct prestera_port *port,
-					   struct net_device *dev,
-					   struct switchdev_brport_flags flags)
+static int
+prestera_mdb_enable_set(struct prestera_br_mdb_entry *br_mdb, bool enable)
 {
-	struct prestera_bridge_port *br_port;
 	int err;
 
-	br_port = prestera_bridge_port_by_dev(port->sw->swdev, dev);
-	if (!br_port)
-		return 0;
-
-	err = prestera_hw_port_flood_set(port, flags.mask, flags.val);
-	if (err)
-		return err;
+	if (enable != br_mdb->enabled) {
+		if (enable)
+			err = prestera_hw_mdb_create(br_mdb->mdb);
+		else
+			err = prestera_hw_mdb_destroy(br_mdb->mdb);
 
-	if (flags.mask & BR_LEARNING) {
-		err = prestera_hw_port_learning_set(port,
-						    flags.val & BR_LEARNING);
 		if (err)
 			return err;
-	}
 
-	memcpy(&br_port->flags, &flags.val, sizeof(flags.val));
+		br_mdb->enabled = enable;
+	}
 
 	return 0;
 }
 
-static int prestera_port_attr_br_ageing_set(struct prestera_port *port,
-					    unsigned long ageing_clock_t)
+static int
+prestera_br_mdb_enable_set(struct prestera_bridge *br_dev, bool enable)
 {
-	unsigned long ageing_jiffies = clock_t_to_jiffies(ageing_clock_t);
-	u32 ageing_time_ms = jiffies_to_msecs(ageing_jiffies);
-	struct prestera_switch *sw = port->sw;
+	struct prestera_br_mdb_entry *br_mdb;
+	int err;
 
-	if (ageing_time_ms < PRESTERA_MIN_AGEING_TIME_MS ||
-	    ageing_time_ms > PRESTERA_MAX_AGEING_TIME_MS)
-		return -ERANGE;
+	list_for_each_entry(br_mdb, &br_dev->br_mdb_entry_list,
+			    br_mdb_entry_node)
+		if (prestera_mdb_enable_set(br_mdb, enable))
+			return err;
 
-	return prestera_hw_switch_ageing_set(sw, ageing_time_ms);
+	return 0;
 }
 
-static int prestera_port_attr_br_vlan_set(struct prestera_port *port,
-					  struct net_device *dev,
-					  bool vlan_enabled)
+static int prestera_port_attr_br_mc_disabled_set(struct prestera_port *port,
+						 struct switchdev_trans *trans,
+						 struct net_device *orig_dev,
+						 bool mc_disabled)
 {
 	struct prestera_switch *sw = port->sw;
-	struct prestera_bridge *bridge;
+	struct prestera_bridge *br_dev;
 
-	bridge = prestera_bridge_by_dev(sw->swdev, dev);
-	if (WARN_ON(!bridge))
-		return -EINVAL;
+	if (!switchdev_trans_ph_prepare(trans))
+		return 0;
 
-	if (bridge->vlan_enabled == vlan_enabled)
+	br_dev = prestera_bridge_find(sw, orig_dev);
+	if (!br_dev)
 		return 0;
 
-	netdev_err(bridge->dev, "VLAN filtering can't be changed for existing bridge\n");
+	br_dev->multicast_enabled = !mc_disabled;
 
-	return -EINVAL;
+	/* There's no point in enabling mdb back if router is missing. */
+	WARN_ON(prestera_br_mdb_enable_set(br_dev, br_dev->multicast_enabled &&
+					   br_dev->mrouter_exist));
+
+	WARN_ON(prestera_br_mdb_sync(br_dev));
+
+	WARN_ON(prestera_br_mdb_mc_enable_sync(br_dev));
+
+	return 0;
 }
 
-static int prestera_port_bridge_vlan_stp_set(struct prestera_port *port,
-					     struct prestera_bridge_vlan *br_vlan,
-					     u8 state)
+static bool
+prestera_bridge_mdb_mc_mrouter_exists(struct prestera_bridge *br_dev)
 {
-	struct prestera_port_vlan *port_vlan;
-
-	list_for_each_entry(port_vlan, &br_vlan->port_vlan_list, br_vlan_head) {
-		if (port_vlan->port != port)
-			continue;
+	struct prestera_bridge_port *br_port;
 
-		return prestera_port_vid_stp_set(port, br_vlan->vid, state);
-	}
+	list_for_each_entry(br_port, &br_dev->port_list, bridge_node)
+		if (br_port->mrouter)
+			return true;
 
-	return 0;
+	return false;
 }
 
-static int prestera_port_attr_stp_state_set(struct prestera_port *port,
-					    struct net_device *dev,
-					    u8 state)
+static int
+prestera_port_attr_mrouter_set(struct prestera_port *port,
+			       struct net_device *orig_dev,
+			       bool is_port_mrouter)
 {
 	struct prestera_bridge_port *br_port;
-	struct prestera_bridge_vlan *br_vlan;
-	int err;
-	u16 vid;
+	struct prestera_bridge *br_dev;
 
-	br_port = prestera_bridge_port_by_dev(port->sw->swdev, dev);
+	br_port = prestera_bridge_port_find(port->sw, orig_dev);
 	if (!br_port)
 		return 0;
 
-	if (!br_port->bridge->vlan_enabled) {
-		vid = br_port->bridge->bridge_id;
-		err = prestera_port_vid_stp_set(port, vid, state);
-		if (err)
-			goto err_port_stp_set;
-	} else {
-		list_for_each_entry(br_vlan, &br_port->vlan_list, head) {
-			err = prestera_port_bridge_vlan_stp_set(port, br_vlan,
-								state);
-			if (err)
-				goto err_port_vlan_stp_set;
-		}
-	}
+	br_dev = br_port->bridge;
+	br_port->mrouter = is_port_mrouter;
 
-	br_port->stp_state = state;
+	br_dev->mrouter_exist = prestera_bridge_mdb_mc_mrouter_exists(br_dev);
 
-	return 0;
+	/*
+	 * Enable MDB processing if both mrouter exists and mc is enabled.
+	 * In case if MC enabled, but there is no mrouter, device would flood
+	 * all multicast traffic (even if MDB table is not empty) with the use
+	 * of bridge's flood capabilities (without the use of flood_domain).
+	 */
+	WARN_ON(prestera_br_mdb_enable_set(br_dev, br_dev->multicast_enabled &&
+					   br_dev->mrouter_exist));
 
-err_port_vlan_stp_set:
-	list_for_each_entry_continue_reverse(br_vlan, &br_port->vlan_list, head)
-		prestera_port_bridge_vlan_stp_set(port, br_vlan, br_port->stp_state);
-	return err;
+	WARN_ON(prestera_br_mdb_sync(br_dev));
 
-err_port_stp_set:
-	prestera_port_vid_stp_set(port, vid, br_port->stp_state);
+	WARN_ON(prestera_br_mdb_mc_enable_sync(br_dev));
 
-	return err;
+	return 0;
 }
 
-static int prestera_port_obj_attr_set(struct net_device *dev, const void *ctx,
+static int prestera_port_obj_attr_set(struct net_device *dev,
 				      const struct switchdev_attr *attr,
-				      struct netlink_ext_ack *extack)
+				      struct switchdev_trans *trans)
 {
-	struct prestera_port *port = netdev_priv(dev);
 	int err = 0;
+	struct prestera_port *port = netdev_priv(dev);
 
 	switch (attr->id) {
 	case SWITCHDEV_ATTR_ID_PORT_STP_STATE:
-		err = prestera_port_attr_stp_state_set(port, attr->orig_dev,
+		err = prestera_port_attr_stp_state_set(port, trans,
+						       attr->orig_dev,
 						       attr->u.stp_state);
 		break;
 	case SWITCHDEV_ATTR_ID_PORT_PRE_BRIDGE_FLAGS:
-		if (attr->u.brport_flags.mask &
-		    ~(BR_LEARNING | BR_FLOOD | BR_MCAST_FLOOD))
+		if (attr->u.brport_flags &
+		    ~(BR_LEARNING | BR_FLOOD | BR_MCAST_FLOOD | BR_ISOLATED))
 			err = -EINVAL;
 		break;
 	case SWITCHDEV_ATTR_ID_PORT_BRIDGE_FLAGS:
-		err = prestera_port_attr_br_flags_set(port, attr->orig_dev,
+		err = prestera_port_attr_br_flags_set(port, trans,
+						      attr->orig_dev,
 						      attr->u.brport_flags);
 		break;
 	case SWITCHDEV_ATTR_ID_BRIDGE_AGEING_TIME:
-		err = prestera_port_attr_br_ageing_set(port,
+		err = prestera_port_attr_br_ageing_set(port, trans,
 						       attr->u.ageing_time);
 		break;
 	case SWITCHDEV_ATTR_ID_BRIDGE_VLAN_FILTERING:
-		err = prestera_port_attr_br_vlan_set(port, attr->orig_dev,
+		err = prestera_port_attr_br_vlan_set(port, trans,
+						     attr->orig_dev,
 						     attr->u.vlan_filtering);
 		break;
+	case SWITCHDEV_ATTR_ID_PORT_MROUTER:
+		err = prestera_port_attr_mrouter_set(port, attr->orig_dev,
+						     attr->u.mrouter);
+		break;
+	case SWITCHDEV_ATTR_ID_BRIDGE_MC_DISABLED:
+		err = prestera_port_attr_br_mc_disabled_set(port, trans,
+							    attr->orig_dev,
+							    attr->u.mc_disabled);
+		break;
 	default:
 		err = -EOPNOTSUPP;
 	}
@@ -756,27 +1047,56 @@ static void
 prestera_fdb_offload_notify(struct prestera_port *port,
 			    struct switchdev_notifier_fdb_info *info)
 {
-	struct switchdev_notifier_fdb_info send_info = {};
+	struct switchdev_notifier_fdb_info send_info;
+	struct net_device *net_dev = port->net_dev;
+	struct prestera_lag *lag;
 
 	send_info.addr = info->addr;
 	send_info.vid = info->vid;
 	send_info.offloaded = true;
+	if (prestera_port_is_lag_member(port)) {
+		lag = prestera_lag_get(port->sw, port->lag_id);
+		if (lag)
+			net_dev = lag->dev;
+	}
+	call_switchdev_notifiers(SWITCHDEV_FDB_OFFLOADED,
+				 net_dev, &send_info.info, NULL);
+}
 
-	call_switchdev_notifiers(SWITCHDEV_FDB_OFFLOADED, port->dev,
-				 &send_info.info, NULL);
+static int prestera_fdb_add(struct prestera_port *port,
+			    const unsigned char *mac,
+			    u16 vid, bool dynamic)
+{
+	if (prestera_port_is_lag_member(port))
+		return prestera_hw_lag_fdb_add(port->sw, port->lag_id,
+					       mac, vid, dynamic);
+	else
+		return prestera_hw_fdb_add(port, mac, vid, dynamic);
 }
 
-static int prestera_port_fdb_set(struct prestera_port *port,
-				 struct switchdev_notifier_fdb_info *fdb_info,
-				 bool adding)
+static int prestera_fdb_del(struct prestera_port *port,
+			    const unsigned char *mac, u16 vid)
+{
+	if (prestera_port_is_lag_member(port))
+		return prestera_hw_lag_fdb_del(port->sw, port->lag_id,
+					       mac, vid);
+	else
+		return prestera_hw_fdb_del(port, mac, vid);
+}
+
+static int
+prestera_port_fdb_set(struct prestera_port *port,
+		      struct switchdev_notifier_fdb_info *fdb_info,
+		      bool adding)
 {
 	struct prestera_switch *sw = port->sw;
 	struct prestera_bridge_port *br_port;
 	struct prestera_bridge *bridge;
+	struct net_device *orig_dev = fdb_info->info.dev;
 	int err;
 	u16 vid;
 
-	br_port = prestera_bridge_port_by_dev(sw->swdev, port->dev);
+	br_port = prestera_bridge_port_find(sw, orig_dev);
 	if (!br_port)
 		return -EINVAL;
 
@@ -795,45 +1115,45 @@ static int prestera_port_fdb_set(struct prestera_port *port,
 	return err;
 }
 
-static void prestera_fdb_event_work(struct work_struct *work)
+static void prestera_bridge_fdb_event_work(struct work_struct *work)
 {
+	int err = 0;
+	struct prestera_swdev_work *swdev_work =
+	    container_of(work, struct prestera_swdev_work, work);
+	struct net_device *dev = swdev_work->dev;
 	struct switchdev_notifier_fdb_info *fdb_info;
-	struct prestera_fdb_event_work *swdev_work;
 	struct prestera_port *port;
-	struct net_device *dev;
-	int err;
-
-	swdev_work = container_of(work, struct prestera_fdb_event_work, work);
-	dev = swdev_work->dev;
 
 	rtnl_lock();
+	if (netif_is_vxlan(dev))
+		goto out;
 
 	port = prestera_port_dev_lower_find(dev);
 	if (!port)
-		goto out_unlock;
+		goto out;
 
 	switch (swdev_work->event) {
 	case SWITCHDEV_FDB_ADD_TO_DEVICE:
 		fdb_info = &swdev_work->fdb_info;
-		if (!fdb_info->added_by_user || fdb_info->is_local)
+		if (!fdb_info->added_by_user)
 			break;
-
 		err = prestera_port_fdb_set(port, fdb_info, true);
 		if (err)
 			break;
-
 		prestera_fdb_offload_notify(port, fdb_info);
 		break;
-
 	case SWITCHDEV_FDB_DEL_TO_DEVICE:
 		fdb_info = &swdev_work->fdb_info;
 		prestera_port_fdb_set(port, fdb_info, false);
 		break;
+	case SWITCHDEV_FDB_ADD_TO_BRIDGE:
+	case SWITCHDEV_FDB_DEL_TO_BRIDGE:
+		prestera_k_arb_fdb_evt(port->sw, port->net_dev);
+		break;
 	}
 
-out_unlock:
+out:
 	rtnl_unlock();
-
 	kfree(swdev_work->fdb_info.addr);
 	kfree(swdev_work);
 	dev_put(dev);
@@ -842,439 +1162,730 @@ static void prestera_fdb_event_work(struct work_struct *work)
 static int prestera_switchdev_event(struct notifier_block *unused,
 				    unsigned long event, void *ptr)
 {
-	struct net_device *dev = switchdev_notifier_info_to_dev(ptr);
+	int err = 0;
+	struct net_device *net_dev = switchdev_notifier_info_to_dev(ptr);
+	struct prestera_swdev_work *swdev_work;
 	struct switchdev_notifier_fdb_info *fdb_info;
 	struct switchdev_notifier_info *info = ptr;
-	struct prestera_fdb_event_work *swdev_work;
-	struct net_device *upper;
-	int err;
+	struct net_device *upper_br;
 
 	if (event == SWITCHDEV_PORT_ATTR_SET) {
-		err = switchdev_handle_port_attr_set(dev, ptr,
+		err = switchdev_handle_port_attr_set(net_dev, ptr,
 						     prestera_netdev_check,
 						     prestera_port_obj_attr_set);
 		return notifier_from_errno(err);
 	}
 
-	if (!prestera_netdev_check(dev))
+	upper_br = netdev_master_upper_dev_get_rcu(net_dev);
+	if (!upper_br)
 		return NOTIFY_DONE;
 
-	upper = netdev_master_upper_dev_get_rcu(dev);
-	if (!upper)
-		return NOTIFY_DONE;
-
-	if (!netif_is_bridge_master(upper))
+	if (!netif_is_bridge_master(upper_br))
 		return NOTIFY_DONE;
 
 	swdev_work = kzalloc(sizeof(*swdev_work), GFP_ATOMIC);
 	if (!swdev_work)
 		return NOTIFY_BAD;
 
+	swdev_work->dev = net_dev;
 	swdev_work->event = event;
-	swdev_work->dev = dev;
 
 	switch (event) {
 	case SWITCHDEV_FDB_ADD_TO_DEVICE:
 	case SWITCHDEV_FDB_DEL_TO_DEVICE:
+	case SWITCHDEV_FDB_ADD_TO_BRIDGE:
+	case SWITCHDEV_FDB_DEL_TO_BRIDGE:
 		fdb_info = container_of(info,
 					struct switchdev_notifier_fdb_info,
 					info);
 
-		INIT_WORK(&swdev_work->work, prestera_fdb_event_work);
+		INIT_WORK(&swdev_work->work, prestera_bridge_fdb_event_work);
 		memcpy(&swdev_work->fdb_info, ptr,
 		       sizeof(swdev_work->fdb_info));
-
 		swdev_work->fdb_info.addr = kzalloc(ETH_ALEN, GFP_ATOMIC);
 		if (!swdev_work->fdb_info.addr)
-			goto out_bad;
-
+			goto out;
 		ether_addr_copy((u8 *)swdev_work->fdb_info.addr,
 				fdb_info->addr);
-		dev_hold(dev);
-		break;
+		dev_hold(net_dev);
 
+		break;
+	case SWITCHDEV_VXLAN_FDB_ADD_TO_DEVICE:
+	case SWITCHDEV_VXLAN_FDB_DEL_TO_DEVICE:
 	default:
 		kfree(swdev_work);
 		return NOTIFY_DONE;
 	}
 
-	queue_work(swdev_wq, &swdev_work->work);
-	return NOTIFY_DONE;
+	queue_work(swdev_owq, &swdev_work->work);
+	return NOTIFY_DONE;
+out:
+	kfree(swdev_work);
+	return NOTIFY_BAD;
+}
+
+static int prestera_switchdev_blocking_event(struct notifier_block *unused,
+					     unsigned long event, void *ptr)
+{
+	int err = 0;
+	struct net_device *net_dev = switchdev_notifier_info_to_dev(ptr);
+
+	switch (event) {
+	case SWITCHDEV_PORT_OBJ_ADD:
+		if (netif_is_vxlan(net_dev)) {
+			err = -EOPNOTSUPP;
+		} else {
+			err = switchdev_handle_port_obj_add
+			    (net_dev, ptr, prestera_netdev_check,
+			     prestera_port_obj_add);
+		}
+		break;
+	case SWITCHDEV_PORT_OBJ_DEL:
+		if (netif_is_vxlan(net_dev)) {
+			err = -EOPNOTSUPP;
+		} else {
+			err = switchdev_handle_port_obj_del
+			    (net_dev, ptr, prestera_netdev_check,
+			     prestera_port_obj_del);
+		}
+		break;
+	case SWITCHDEV_PORT_ATTR_SET:
+		err = switchdev_handle_port_attr_set
+		    (net_dev, ptr, prestera_netdev_check,
+		    prestera_port_obj_attr_set);
+		break;
+	default:
+		err = -EOPNOTSUPP;
+	}
+
+	return notifier_from_errno(err);
+}
+
+static struct prestera_bridge *
+prestera_bridge_create(struct prestera_switch *sw, struct net_device *br_dev)
+{
+	struct prestera_bridge *bridge;
+	bool vlan_enabled = br_vlan_enabled(br_dev);
+	u16 bridge_id;
+	int err;
+
+	if (vlan_enabled && sw->swdev->bridge_8021q_exists) {
+		netdev_err(br_dev, "Only one VLAN-aware bridge is supported\n");
+		return ERR_PTR(-EINVAL);
+	}
+
+	bridge = kzalloc(sizeof(*bridge), GFP_KERNEL);
+	if (!bridge)
+		return ERR_PTR(-ENOMEM);
+
+	if (vlan_enabled) {
+		sw->swdev->bridge_8021q_exists = true;
+	} else {
+		err = prestera_hw_bridge_create(sw, &bridge_id);
+		if (err) {
+			kfree(bridge);
+			return ERR_PTR(err);
+		}
+
+		bridge->bridge_id = bridge_id;
+	}
+
+	bridge->dev = br_dev;
+	bridge->vlan_enabled = vlan_enabled;
+	bridge->isolation_srcid = PRESTERA_DEFAULT_ISOLATION_SRCID;
+	bridge->multicast_enabled = br_multicast_enabled(br_dev);
+	bridge->mrouter = br_multicast_router(br_dev);
+	INIT_LIST_HEAD(&bridge->port_list);
+	INIT_LIST_HEAD(&bridge->br_mdb_entry_list);
+
+	list_add(&bridge->bridge_node, &sw->swdev->bridge_list);
+
+	return bridge;
+}
+
+static void
+prestera_bridge_destroy(struct prestera_switch *sw,
+			struct prestera_bridge *bridge)
+{
+	list_del(&bridge->bridge_node);
+	if (bridge->vlan_enabled)
+		sw->swdev->bridge_8021q_exists = false;
+	else
+		prestera_hw_bridge_delete(sw, bridge->bridge_id);
+
+	WARN_ON(!list_empty(&bridge->br_mdb_entry_list));
+	WARN_ON(!list_empty(&bridge->port_list));
+	kfree(bridge);
+}
+
+static struct prestera_bridge *
+prestera_bridge_get(struct prestera_switch *sw, struct net_device *br_dev)
+{
+	struct prestera_bridge *bridge;
+
+	bridge = prestera_bridge_find(sw, br_dev);
+	if (bridge)
+		return bridge;
+
+	return prestera_bridge_create(sw, br_dev);
+}
+
+static void
+prestera_bridge_put(struct prestera_switch *sw, struct prestera_bridge *bridge)
+{
+	if (list_empty(&bridge->port_list))
+		prestera_bridge_destroy(sw, bridge);
+}
+
+static struct prestera_bridge_port *
+prestera_bridge_port_create(struct prestera_bridge *bridge,
+			    struct net_device *brport_dev)
+{
+	struct prestera_bridge_port *br_port;
+	struct prestera_port *port;
+
+	br_port = kzalloc(sizeof(*br_port), GFP_KERNEL);
+	if (!br_port)
+		return NULL;
+
+	port = prestera_port_dev_lower_find(brport_dev);
+
+	br_port->dev = brport_dev;
+	br_port->bridge = bridge;
+	br_port->stp_state = BR_STATE_DISABLED;
+	br_port->flags = BR_LEARNING | BR_FLOOD | BR_LEARNING_SYNC |
+				BR_MCAST_FLOOD;
+	INIT_LIST_HEAD(&br_port->vlan_list);
+	INIT_LIST_HEAD(&br_port->br_mdb_port_list);
+
+	list_add(&br_port->bridge_node, &bridge->port_list);
+	br_port->ref_count = 1;
+
+	return br_port;
+}
+
+static void
+prestera_bridge_port_destroy(struct prestera_bridge_port *br_port)
+{
+	list_del(&br_port->bridge_node);
+	WARN_ON(!list_empty(&br_port->vlan_list));
+	WARN_ON(!list_empty(&br_port->br_mdb_port_list));
+	kfree(br_port);
+}
+
+static struct prestera_bridge_port *
+prestera_bridge_port_get(struct prestera_switch *sw, struct net_device *dev)
+{
+	struct net_device *br_dev = netdev_master_upper_dev_get(dev);
+	struct prestera_bridge *bridge;
+	struct prestera_bridge_port *br_port;
+	int err;
+
+	br_port = prestera_bridge_port_find(sw, dev);
+	if (br_port) {
+		br_port->ref_count++;
+		return br_port;
+	}
+
+	bridge = prestera_bridge_get(sw, br_dev);
+	if (IS_ERR(bridge))
+		return ERR_CAST(bridge);
+
+	br_port = prestera_bridge_port_create(bridge, dev);
+	if (!br_port) {
+		err = -ENOMEM;
+		goto err_brport_create;
+	}
+
+	return br_port;
+
+err_brport_create:
+	prestera_bridge_put(sw, bridge);
+	return ERR_PTR(err);
+}
+
+static void prestera_bridge_port_put(struct prestera_switch *sw,
+				     struct prestera_bridge_port *br_port)
+{
+	struct prestera_bridge *bridge;
+
+	if (--br_port->ref_count != 0)
+		return;
+
+	bridge = br_port->bridge;
+	prestera_bridge_port_destroy(br_port);
+	if (list_empty(&bridge->port_list)) {
+		prestera_rif_enable(sw, bridge->dev, false);
+		prestera_bridge_rifs_destroy(sw, bridge->dev);
+	}
+	prestera_bridge_put(sw, bridge);
+}
+
+static int
+prestera_bridge_8021q_port_join(struct prestera_bridge *bridge,
+				struct prestera_bridge_port *br_port,
+				struct prestera_port *port,
+				struct netlink_ext_ack *extack)
+{
+	if (is_vlan_dev(br_port->dev)) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "Can not enslave a VLAN device to a VLAN-aware bridge");
+		return -EINVAL;
+	}
 
-out_bad:
-	kfree(swdev_work);
-	return NOTIFY_BAD;
+	return 0;
 }
 
 static int
-prestera_port_vlan_bridge_join(struct prestera_port_vlan *port_vlan,
-			       struct prestera_bridge_port *br_port)
+prestera_bridge_8021d_port_join(struct prestera_bridge *bridge,
+				struct prestera_bridge_port *br_port,
+				struct prestera_port *port,
+				struct netlink_ext_ack *extack)
 {
-	struct prestera_port *port = port_vlan->port;
-	struct prestera_bridge_vlan *br_vlan;
-	u16 vid = port_vlan->vid;
 	int err;
 
-	if (port_vlan->br_port)
-		return 0;
-
-	err = prestera_hw_port_flood_set(port, BR_FLOOD | BR_MCAST_FLOOD,
-					 br_port->flags);
+	if (is_vlan_dev(br_port->dev)) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "Enslaving of a VLAN device is not supported");
+		return -ENOTSUPP;
+	}
+	err = prestera_hw_bridge_port_add(port, bridge->bridge_id);
 	if (err)
 		return err;
 
-	err = prestera_hw_port_learning_set(port, br_port->flags & BR_LEARNING);
-	if (err)
-		goto err_port_learning_set;
-
-	err = prestera_port_vid_stp_set(port, vid, br_port->stp_state);
+	err = prestera_br_port_flags_set(br_port, port);
 	if (err)
-		goto err_port_vid_stp_set;
-
-	br_vlan = prestera_bridge_vlan_by_vid(br_port, vid);
-	if (!br_vlan) {
-		br_vlan = prestera_bridge_vlan_create(br_port, vid);
-		if (!br_vlan) {
-			err = -ENOMEM;
-			goto err_bridge_vlan_get;
-		}
-	}
+		goto err_flags2port_set;
 
-	list_add(&port_vlan->br_vlan_head, &br_vlan->port_vlan_list);
+	if (list_is_singular(&bridge->port_list))
+		prestera_rif_enable(port->sw, bridge->dev, true);
 
-	prestera_bridge_port_get(br_port);
-	port_vlan->br_port = br_port;
-
-	return 0;
+	return err;
 
-err_bridge_vlan_get:
-	prestera_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
-err_port_vid_stp_set:
-	prestera_hw_port_learning_set(port, false);
-err_port_learning_set:
+err_flags2port_set:
+	prestera_hw_bridge_port_delete(port, bridge->bridge_id);
 	return err;
 }
 
-static int
-prestera_bridge_port_vlan_add(struct prestera_port *port,
-			      struct prestera_bridge_port *br_port,
-			      u16 vid, bool is_untagged, bool is_pvid,
+int prestera_port_bridge_join(struct prestera_port *port,
+			      struct net_device *brport_dev,
+			      struct net_device *br_dev,
 			      struct netlink_ext_ack *extack)
 {
-	struct prestera_port_vlan *port_vlan;
-	u16 old_pvid = port->pvid;
-	u16 pvid;
+	struct prestera_bridge *bridge;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_bridge_port *br_port;
 	int err;
 
-	if (is_pvid)
-		pvid = vid;
-	else
-		pvid = port->pvid == vid ? 0 : port->pvid;
+	br_port = prestera_bridge_port_get(sw, brport_dev);
+	if (IS_ERR(br_port))
+		return PTR_ERR(br_port);
 
-	port_vlan = prestera_port_vlan_by_vid(port, vid);
-	if (port_vlan && port_vlan->br_port != br_port)
-		return -EEXIST;
+	bridge = br_port->bridge;
 
-	if (!port_vlan) {
-		port_vlan = prestera_port_vlan_create(port, vid, is_untagged);
-		if (IS_ERR(port_vlan))
-			return PTR_ERR(port_vlan);
+	/* Enslaved port is not usable as a router interface */
+	if (prestera_rif_exists(sw, port->net_dev))
+		prestera_rif_enable(sw, port->net_dev, false);
+
+	if (bridge->vlan_enabled) {
+		err = prestera_bridge_8021q_port_join(bridge, br_port,
+						      port, extack);
 	} else {
-		err = prestera_hw_vlan_port_set(port, vid, true, is_untagged);
-		if (err)
-			goto err_port_vlan_set;
+		err = prestera_bridge_8021d_port_join(bridge, br_port,
+						      port, extack);
 	}
 
-	err = prestera_port_pvid_set(port, pvid);
-	if (err)
-		goto err_port_pvid_set;
-
-	err = prestera_port_vlan_bridge_join(port_vlan, br_port);
 	if (err)
-		goto err_port_vlan_bridge_join;
+		goto err_port_join;
 
 	return 0;
 
-err_port_vlan_bridge_join:
-	prestera_port_pvid_set(port, old_pvid);
-err_port_pvid_set:
-	prestera_hw_vlan_port_set(port, vid, false, false);
-err_port_vlan_set:
-	prestera_port_vlan_destroy(port_vlan);
-
+err_port_join:
+	prestera_bridge_port_put(sw, br_port);
 	return err;
 }
 
 static void
-prestera_bridge_port_vlan_del(struct prestera_port *port,
-			      struct prestera_bridge_port *br_port, u16 vid)
+prestera_bridge_8021d_port_leave(struct prestera_bridge *bridge,
+				 struct prestera_bridge_port *br_port,
+				 struct prestera_port *port)
 {
-	u16 pvid = port->pvid == vid ? 0 : port->pvid;
-	struct prestera_port_vlan *port_vlan;
-
-	port_vlan = prestera_port_vlan_by_vid(port, vid);
-	if (WARN_ON(!port_vlan))
-		return;
+	prestera_fdb_flush_port(port, PRESTERA_FDB_FLUSH_MODE_ALL);
+	prestera_hw_bridge_port_delete(port, bridge->bridge_id);
+}
 
-	prestera_port_vlan_bridge_leave(port_vlan);
-	prestera_port_pvid_set(port, pvid);
-	prestera_port_vlan_destroy(port_vlan);
+static void
+prestera_bridge_8021q_port_leave(struct prestera_bridge *bridge,
+				 struct prestera_bridge_port *br_port,
+				 struct prestera_port *port)
+{
+	prestera_fdb_flush_port(port, PRESTERA_FDB_FLUSH_MODE_ALL);
+	prestera_port_pvid_set(port, PRESTERA_DEFAULT_VID);
 }
 
-static int prestera_port_vlans_add(struct prestera_port *port,
-				   const struct switchdev_obj_port_vlan *vlan,
-				   struct netlink_ext_ack *extack)
+void prestera_port_bridge_leave(struct prestera_port *port,
+				struct net_device *brport_dev,
+				struct net_device *br_dev)
 {
-	bool flag_untagged = vlan->flags & BRIDGE_VLAN_INFO_UNTAGGED;
-	bool flag_pvid = vlan->flags & BRIDGE_VLAN_INFO_PVID;
-	struct net_device *orig_dev = vlan->obj.orig_dev;
-	struct prestera_bridge_port *br_port;
 	struct prestera_switch *sw = port->sw;
 	struct prestera_bridge *bridge;
+	struct prestera_bridge_port *br_port;
 
-	if (netif_is_bridge_master(orig_dev))
-		return 0;
+	bridge = prestera_bridge_find(sw, br_dev);
+	if (!bridge)
+		return;
+	br_port = __prestera_bridge_port_find(bridge, brport_dev);
+	if (!br_port)
+		return;
 
-	br_port = prestera_bridge_port_by_dev(sw->swdev, port->dev);
-	if (WARN_ON(!br_port))
-		return -EINVAL;
+	if (bridge->vlan_enabled)
+		prestera_bridge_8021q_port_leave(bridge, br_port, port);
+	else
+		prestera_bridge_8021d_port_leave(bridge, br_port, port);
 
-	bridge = br_port->bridge;
-	if (!bridge->vlan_enabled)
-		return 0;
+	prestera_mdb_flush_bridge_port(br_port);
+
+	prestera_br_port_flags_reset(br_port, port);
+	prestera_port_vid_stp_set(port, PRESTERA_VID_ALL, BR_STATE_FORWARDING);
+	prestera_bridge_port_put(sw, br_port);
+
+	/* Offload rif that was previosly disabled */
+	if (prestera_rif_exists(sw, port->net_dev))
+		prestera_rif_enable(sw, port->net_dev, true);
 
-	return prestera_bridge_port_vlan_add(port, br_port,
-					     vlan->vid, flag_untagged,
-					     flag_pvid, extack);
 }
 
-static int prestera_port_obj_add(struct net_device *dev, const void *ctx,
-				 const struct switchdev_obj *obj,
-				 struct netlink_ext_ack *extack)
+static int prestera_fdb_init(struct prestera_switch *sw)
 {
-	struct prestera_port *port = netdev_priv(dev);
-	const struct switchdev_obj_port_vlan *vlan;
+	int err;
 
-	switch (obj->id) {
-	case SWITCHDEV_OBJ_ID_PORT_VLAN:
-		vlan = SWITCHDEV_OBJ_PORT_VLAN(obj);
-		return prestera_port_vlans_add(port, vlan, extack);
-	default:
-		return -EOPNOTSUPP;
-	}
+	err = prestera_switch_ageing_set(sw, PRESTERA_DEFAULT_AGEING_TIME);
+	if (err)
+		return err;
+
+	return 0;
 }
 
-static int prestera_port_vlans_del(struct prestera_port *port,
-				   const struct switchdev_obj_port_vlan *vlan)
+static struct prestera_br_mdb_entry *
+prestera_br_mdb_entry_create(struct prestera_switch *sw,
+			     struct prestera_bridge *br_dev,
+			     const unsigned char *addr, u16 vid)
 {
-	struct net_device *orig_dev = vlan->obj.orig_dev;
-	struct prestera_bridge_port *br_port;
-	struct prestera_switch *sw = port->sw;
+	struct prestera_br_mdb_entry *br_mdb_entry;
+	struct prestera_mdb_entry *mdb_entry;
 
-	if (netif_is_bridge_master(orig_dev))
-		return -EOPNOTSUPP;
+	br_mdb_entry = kzalloc(sizeof(*br_mdb_entry), GFP_KERNEL);
+	if (!br_mdb_entry)
+		return NULL;
 
-	br_port = prestera_bridge_port_by_dev(sw->swdev, port->dev);
-	if (WARN_ON(!br_port))
-		return -EINVAL;
+	mdb_entry = prestera_mdb_entry_create(sw, addr, vid);
+	if (!mdb_entry)
+		goto err_mdb_alloc;
 
-	if (!br_port->bridge->vlan_enabled)
-		return 0;
+	br_mdb_entry->mdb = mdb_entry;
+	br_mdb_entry->bridge = br_dev;
+	br_mdb_entry->enabled = true;
+	INIT_LIST_HEAD(&br_mdb_entry->br_mdb_port_list);
 
-	prestera_bridge_port_vlan_del(port, br_port, vlan->vid);
+	list_add(&br_mdb_entry->br_mdb_entry_node, &br_dev->br_mdb_entry_list);
 
-	return 0;
+	return br_mdb_entry;
+
+err_mdb_alloc:
+	kfree(br_mdb_entry);
+	return NULL;
 }
 
-static int prestera_port_obj_del(struct net_device *dev, const void *ctx,
-				 const struct switchdev_obj *obj)
+static struct prestera_br_mdb_entry *
+prestera_br_mdb_entry_find(struct prestera_bridge *br_dev,
+			   const unsigned char *addr, u16 vid)
 {
-	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_br_mdb_entry *br_mdb;
 
-	switch (obj->id) {
-	case SWITCHDEV_OBJ_ID_PORT_VLAN:
-		return prestera_port_vlans_del(port, SWITCHDEV_OBJ_PORT_VLAN(obj));
-	default:
-		return -EOPNOTSUPP;
-	}
+	list_for_each_entry(br_mdb, &br_dev->br_mdb_entry_list,
+			    br_mdb_entry_node)
+		if (ether_addr_equal(&br_mdb->mdb->addr[0], addr) &&
+		    vid == br_mdb->mdb->vid)
+			return br_mdb;
+
+	return NULL;
 }
 
-static int prestera_switchdev_blk_event(struct notifier_block *unused,
-					unsigned long event, void *ptr)
+static struct prestera_br_mdb_entry *
+prestera_br_mdb_entry_get(struct prestera_switch *sw,
+			  struct prestera_bridge *br_dev,
+			  const unsigned char *addr, u16 vid)
 {
-	struct net_device *dev = switchdev_notifier_info_to_dev(ptr);
-	int err;
+	struct prestera_br_mdb_entry *br_mdb;
 
-	switch (event) {
-	case SWITCHDEV_PORT_OBJ_ADD:
-		err = switchdev_handle_port_obj_add(dev, ptr,
-						    prestera_netdev_check,
-						    prestera_port_obj_add);
-		break;
-	case SWITCHDEV_PORT_OBJ_DEL:
-		err = switchdev_handle_port_obj_del(dev, ptr,
-						    prestera_netdev_check,
-						    prestera_port_obj_del);
-		break;
-	case SWITCHDEV_PORT_ATTR_SET:
-		err = switchdev_handle_port_attr_set(dev, ptr,
-						     prestera_netdev_check,
-						     prestera_port_obj_attr_set);
-		break;
-	default:
-		return NOTIFY_DONE;
-	}
+	br_mdb = prestera_br_mdb_entry_find(br_dev, addr, vid);
+	if (br_mdb)
+		return br_mdb;
 
-	return notifier_from_errno(err);
+	return prestera_br_mdb_entry_create(sw, br_dev, addr, vid);
 }
 
-static void prestera_fdb_event(struct prestera_switch *sw,
-			       struct prestera_event *evt, void *arg)
+static void
+prestera_br_mdb_entry_put(struct prestera_br_mdb_entry *br_mdb)
 {
-	struct switchdev_notifier_fdb_info info = {};
-	struct net_device *dev = NULL;
-	struct prestera_port *port;
-	struct prestera_lag *lag;
+	struct prestera_bridge_port *br_port;
 
-	switch (evt->fdb_evt.type) {
-	case PRESTERA_FDB_ENTRY_TYPE_REG_PORT:
-		port = prestera_find_port(sw, evt->fdb_evt.dest.port_id);
-		if (port)
-			dev = port->dev;
-		break;
-	case PRESTERA_FDB_ENTRY_TYPE_LAG:
-		lag = prestera_lag_by_id(sw, evt->fdb_evt.dest.lag_id);
-		if (lag)
-			dev = lag->dev;
-		break;
-	default:
-		return;
+	if (list_empty(&br_mdb->br_mdb_port_list)) {
+		list_for_each_entry(br_port, &br_mdb->bridge->port_list,
+				    bridge_node)
+			prestera_mdb_port_del(br_mdb->mdb, br_port->dev);
+
+		prestera_mdb_entry_destroy(br_mdb->mdb);
+		list_del(&br_mdb->br_mdb_entry_node);
+		kfree(br_mdb);
 	}
+}
 
-	if (!dev)
-		return;
+static int prestera_br_mdb_port_add(struct prestera_br_mdb_entry *br_mdb,
+				    struct prestera_bridge_port *br_port)
+{
+	struct prestera_br_mdb_port *br_mdb_port;
 
-	info.addr = evt->fdb_evt.data.mac;
-	info.vid = evt->fdb_evt.vid;
-	info.offloaded = true;
+	br_mdb_port = kzalloc(sizeof(*br_mdb_port), GFP_KERNEL);
+	if (!br_mdb_port)
+		return -ENOMEM;
 
-	rtnl_lock();
+	br_mdb_port->br_port = br_port;
+	list_add(&br_mdb_port->br_mdb_port_node,
+		 &br_mdb->br_mdb_port_list);
 
-	switch (evt->id) {
-	case PRESTERA_FDB_EVENT_LEARNED:
-		call_switchdev_notifiers(SWITCHDEV_FDB_ADD_TO_BRIDGE,
-					 dev, &info.info, NULL);
-		break;
-	case PRESTERA_FDB_EVENT_AGED:
-		call_switchdev_notifiers(SWITCHDEV_FDB_DEL_TO_BRIDGE,
-					 dev, &info.info, NULL);
-		break;
-	}
+	return 0;
+}
 
-	rtnl_unlock();
+static void
+prestera_br_mdb_port_del(struct prestera_br_mdb_entry *br_mdb,
+			 struct prestera_bridge_port *br_port)
+{
+	struct prestera_br_mdb_port *br_mdb_port, *tmp;
+
+	list_for_each_entry_safe(br_mdb_port, tmp, &br_mdb->br_mdb_port_list,
+				 br_mdb_port_node) {
+		if (br_mdb_port->br_port == br_port) {
+			list_del(&br_mdb_port->br_mdb_port_node);
+			kfree(br_mdb_port);
+		}
+	}
 }
 
-static int prestera_fdb_init(struct prestera_switch *sw)
+static int
+prestera_mdb_port_add(struct prestera_mdb_entry *mdb,
+		      struct net_device *orig_dev,
+		      const unsigned char addr[ETH_ALEN], u16 vid)
 {
+	struct prestera_flood_domain *flood_domain = mdb->flood_domain;
 	int err;
 
-	err = prestera_hw_event_handler_register(sw, PRESTERA_EVENT_TYPE_FDB,
-						 prestera_fdb_event, NULL);
-	if (err)
-		return err;
-
-	err = prestera_hw_switch_ageing_set(sw, PRESTERA_DEFAULT_AGEING_TIME_MS);
-	if (err)
-		goto err_ageing_set;
+	if (!prestera_flood_domain_port_find(flood_domain,
+					     orig_dev, vid)) {
+		err = prestera_flood_domain_port_create(flood_domain, orig_dev,
+							vid);
+		if (err)
+			return err;
+	}
 
 	return 0;
+}
 
-err_ageing_set:
-	prestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_FDB,
-					     prestera_fdb_event);
-	return err;
+static void
+prestera_mdb_port_del(struct prestera_mdb_entry *mdb,
+		      struct net_device *orig_dev)
+{
+	struct prestera_flood_domain *fl_domain = mdb->flood_domain;
+	struct prestera_flood_domain_port *flood_domain_port;
+
+	flood_domain_port = prestera_flood_domain_port_find(fl_domain,
+							    orig_dev,
+							    mdb->vid);
+	if (flood_domain_port)
+		prestera_flood_domain_port_destroy(flood_domain_port);
 }
 
-static void prestera_fdb_fini(struct prestera_switch *sw)
+static void
+prestera_mdb_flush_bridge_port(struct prestera_bridge_port *br_port)
 {
-	prestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_FDB,
-					     prestera_fdb_event);
+	struct prestera_br_mdb_port *br_mdb_port, *tmp_port;
+	struct prestera_br_mdb_entry *br_mdb, *br_mdb_tmp;
+	struct prestera_bridge *br_dev = br_port->bridge;
+	struct prestera_mdb_entry *mdb;
+
+	list_for_each_entry_safe(br_mdb, br_mdb_tmp, &br_dev->br_mdb_entry_list,
+				 br_mdb_entry_node) {
+		mdb = br_mdb->mdb;
+
+		list_for_each_entry_safe(br_mdb_port, tmp_port,
+					 &br_mdb->br_mdb_port_list,
+					 br_mdb_port_node) {
+			prestera_mdb_port_del(br_mdb->mdb,
+					      br_mdb_port->br_port->dev);
+			prestera_br_mdb_port_del(br_mdb,  br_mdb_port->br_port);
+			prestera_br_mdb_entry_put(br_mdb);
+		}
+	}
 }
 
-static int prestera_switchdev_handler_init(struct prestera_switchdev *swdev)
+static int
+prestera_mdb_port_addr_obj_add(const struct switchdev_obj_port_mdb *mdb,
+			       struct switchdev_trans *trans)
 {
+	struct prestera_br_mdb_entry *br_mdb;
+	struct prestera_bridge_port *br_port;
+	struct prestera_bridge *br_dev;
+	struct prestera_switch *sw;
+	struct prestera_port *port;
 	int err;
 
-	swdev->swdev_nb.notifier_call = prestera_switchdev_event;
-	err = register_switchdev_notifier(&swdev->swdev_nb);
-	if (err)
-		goto err_register_swdev_notifier;
+	if (switchdev_trans_ph_commit(trans))
+		return 0;
+
+	sw = prestera_switch_get(mdb->obj.orig_dev);
+	port = prestera_port_dev_lower_find(mdb->obj.orig_dev);
+
+	br_port = prestera_bridge_port_find(sw, mdb->obj.orig_dev);
+	if (!br_port)
+		return 0;
+
+	br_dev = br_port->bridge;
+
+	if (mdb->vid && !prestera_port_vlan_find_by_vid(port, mdb->vid))
+		return 0;
+
+	if (mdb->vid)
+		br_mdb = prestera_br_mdb_entry_get(sw, br_dev, &mdb->addr[0],
+						   mdb->vid);
+	else
+		br_mdb = prestera_br_mdb_entry_get(sw, br_dev, &mdb->addr[0],
+						   br_dev->bridge_id);
+
+	if (!br_mdb)
+		return -ENOMEM;
+
+	/*
+	 * Make sure newly allocated MDB entry gets disabled if either MC is
+	 * disabled, or the mrouter does not exist.
+	 */
+	WARN_ON(prestera_mdb_enable_set(br_mdb, br_dev->multicast_enabled &&
+					br_dev->mrouter_exist));
+
+	err = prestera_br_mdb_port_add(br_mdb, br_port);
+	if (err) {
+		prestera_br_mdb_entry_put(br_mdb);
+		return err;
+	}
 
-	swdev->swdev_nb_blk.notifier_call = prestera_switchdev_blk_event;
-	err = register_switchdev_blocking_notifier(&swdev->swdev_nb_blk);
+	err = prestera_br_mdb_sync(br_dev);
 	if (err)
-		goto err_register_blk_swdev_notifier;
+		return err;
 
 	return 0;
-
-err_register_blk_swdev_notifier:
-	unregister_switchdev_notifier(&swdev->swdev_nb);
-err_register_swdev_notifier:
-	destroy_workqueue(swdev_wq);
-	return err;
 }
 
-static void prestera_switchdev_handler_fini(struct prestera_switchdev *swdev)
+static int
+prestera_mdb_port_addr_obj_del(struct prestera_port *port,
+			       const struct switchdev_obj_port_mdb *mdb)
 {
-	unregister_switchdev_blocking_notifier(&swdev->swdev_nb_blk);
-	unregister_switchdev_notifier(&swdev->swdev_nb);
+	struct prestera_br_mdb_entry *br_mdb;
+	struct prestera_bridge_port *br_port;
+	struct prestera_bridge *br_dev;
+	int err;
+
+	/* Bridge port no longer exists - and so does this MDB entry */
+	br_port = prestera_bridge_port_find(port->sw, mdb->obj.orig_dev);
+	if (!br_port)
+		return 0;
+
+	/* Removing MDB with non-existing VLAN - not supported; */
+	if (mdb->vid && !prestera_port_vlan_find_by_vid(port, mdb->vid))
+		return 0;
+
+	br_dev = br_port->bridge;
+
+	if (br_port->bridge->vlan_enabled)
+		br_mdb = prestera_br_mdb_entry_find(br_dev, &mdb->addr[0],
+						    mdb->vid);
+	else
+		br_mdb = prestera_br_mdb_entry_find(br_dev, &mdb->addr[0],
+						    br_port->bridge->bridge_id);
+
+	if (!br_mdb)
+		return 0;
+
+	/*
+	 * Since there might be a situation that this port was the last in the
+	 * MDB group, we have to both remove this port from software and HW MDB,
+	 * and then sync MDB table, and destroy software MDB (if needed).
+	 */
+	prestera_br_mdb_port_del(br_mdb, br_port);
+
+	prestera_br_mdb_entry_put(br_mdb);
+
+	err = prestera_br_mdb_sync(br_dev);
+	if (err)
+		return err;
+
+	return 0;
 }
 
 int prestera_switchdev_init(struct prestera_switch *sw)
 {
 	struct prestera_switchdev *swdev;
-	int err;
+	int err = 0;
+
+	if (sw->swdev)
+		return -EPERM;
 
-	swdev = kzalloc(sizeof(*swdev), GFP_KERNEL);
+	swdev = kzalloc(sizeof(*sw->swdev), GFP_KERNEL);
 	if (!swdev)
 		return -ENOMEM;
 
 	sw->swdev = swdev;
-	swdev->sw = sw;
 
-	INIT_LIST_HEAD(&swdev->bridge_list);
+	INIT_LIST_HEAD(&sw->swdev->bridge_list);
 
-	swdev_wq = alloc_ordered_workqueue("%s_ordered", 0, "prestera_br");
-	if (!swdev_wq) {
+	swdev_owq = alloc_ordered_workqueue("%s_ordered", 0, "prestera_sw");
+	if (!swdev_owq) {
 		err = -ENOMEM;
-		goto err_alloc_wq;
+		goto err_alloc_workqueue;
 	}
 
-	err = prestera_switchdev_handler_init(swdev);
+	swdev->swdev_n.notifier_call = prestera_switchdev_event;
+	err = register_switchdev_notifier(&swdev->swdev_n);
 	if (err)
-		goto err_swdev_init;
+		goto err_register_switchdev_notifier;
 
-	err = prestera_fdb_init(sw);
+	swdev->swdev_blocking_n.notifier_call =
+			prestera_switchdev_blocking_event;
+	err = register_switchdev_blocking_notifier(&swdev->swdev_blocking_n);
 	if (err)
-		goto err_fdb_init;
+		goto err_register_block_switchdev_notifier;
+
+	prestera_fdb_init(sw);
 
 	return 0;
 
-err_fdb_init:
-err_swdev_init:
-	destroy_workqueue(swdev_wq);
-err_alloc_wq:
+err_register_block_switchdev_notifier:
+	unregister_switchdev_notifier(&swdev->swdev_n);
+err_register_switchdev_notifier:
+	destroy_workqueue(swdev_owq);
+err_alloc_workqueue:
 	kfree(swdev);
-
 	return err;
 }
 
 void prestera_switchdev_fini(struct prestera_switch *sw)
 {
-	struct prestera_switchdev *swdev = sw->swdev;
+	if (!sw->swdev)
+		return;
 
-	prestera_fdb_fini(sw);
-	prestera_switchdev_handler_fini(swdev);
-	destroy_workqueue(swdev_wq);
-	kfree(swdev);
+	unregister_switchdev_notifier(&sw->swdev->swdev_n);
+	unregister_switchdev_blocking_notifier
+	    (&sw->swdev->swdev_blocking_n);
+	flush_workqueue(swdev_owq);
+	destroy_workqueue(swdev_owq);
+	kfree(sw->swdev);
+	sw->swdev = NULL;
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_switchdev.h b/drivers/net/ethernet/marvell/prestera/prestera_switchdev.h
index 0e93fda3d9a5..0963c63cd390 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_switchdev.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_switchdev.h
@@ -7,11 +7,18 @@
 int prestera_switchdev_init(struct prestera_switch *sw);
 void prestera_switchdev_fini(struct prestera_switch *sw);
 
-int prestera_bridge_port_join(struct net_device *br_dev,
-			      struct prestera_port *port,
+int prestera_port_bridge_join(struct prestera_port *port,
+			      struct net_device *brport_dev,
+			      struct net_device *br_dev,
 			      struct netlink_ext_ack *extack);
 
-void prestera_bridge_port_leave(struct net_device *br_dev,
-				struct prestera_port *port);
+void prestera_port_bridge_leave(struct prestera_port *port,
+				struct net_device *brport_dev,
+				struct net_device *br_dev);
+
+bool prestera_bridge_is_offloaded(const struct prestera_switch *sw,
+				  const struct net_device *br_dev);
+
+int prestera_bridge_port_down(struct prestera_port *port);
 
 #endif /* _PRESTERA_SWITCHDEV_H_ */
-- 
2.17.1

